{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from sklearn import preprocessing \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from __future__ import division\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_table(\"data_content\", header=None, skip_blank_lines=False)\n",
    "label = pd.read_table(\"label\", header=None, dtype='category', skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns = ['question']\n",
    "label.columns = ['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67213, 1)\n",
      "(67213, 1)\n"
     ]
    }
   ],
   "source": [
    "print train.shape\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = 0.2\n",
    "# Separate each muscle group data\n",
    "chest = train[label['group']=='Chest']\n",
    "chest_label = label[label['group']=='Chest']\n",
    "chest_len = int(chest.shape[0]*ratio)\n",
    "\n",
    "shoulder = train[label['group']=='Shoulders']\n",
    "shoulder_len = int(shoulder.shape[0]*ratio)\n",
    "shoulder_label = label[label['group']=='Shoulders']\n",
    "\n",
    "back = train[label['group']=='Back']\n",
    "back_label = label[label['group']=='Back']\n",
    "back_len = int(back.shape[0]*ratio)\n",
    "\n",
    "leg = train[label['group']=='Leg']\n",
    "leg_label = label[label['group']=='Leg']\n",
    "leg_len = int(leg.shape[0]*ratio)\n",
    "\n",
    "tricep = train[label['group']=='Triceps']\n",
    "tricep_label = label[label['group']=='Triceps']\n",
    "tricep_len = int(tricep.shape[0]*ratio)\n",
    "\n",
    "bicep = train[label['group']=='Biceps']\n",
    "bicep_label = label[label['group']=='Biceps']\n",
    "bicep_len = int(bicep.shape[0]*ratio)\n",
    "\n",
    "ab = train[label['group']=='Abs']\n",
    "ab_label = label[label['group']=='Abs']\n",
    "ab_len = int(ab.shape[0]*ratio)\n",
    "\n",
    "glute = train[label['group']=='Glutes']\n",
    "glute_label = label[label['group']=='Glutes']\n",
    "glute_len = int(glute.shape[0]*ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13440, 1)\n",
      "(13440, 1)\n"
     ]
    }
   ],
   "source": [
    "# Take only the top ratio% of each group of data\n",
    "train_data = pd.concat([chest[0:chest_len], shoulder[0:shoulder_len], back[0:back_len], \n",
    "                        leg[0:leg_len], tricep[0:tricep_len], bicep[0:bicep_len], ab[0:ab_len], glute[0: glute_len]])\n",
    "print train_data.shape\n",
    "train_label = pd.concat([chest_label[0:chest_len], shoulder_label[0:shoulder_len], back_label[0:back_len], \n",
    "                   leg_label[0:leg_len], tricep_label[0:tricep_len], bicep_label[0:bicep_len], ab_label[0:ab_len],\n",
    "                         glute_label[0: glute_len]])\n",
    "print train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_label = pd.Series(train_label['group'],dtype='category')\n",
    "y_label.cat.categories \n",
    "y_label.cat.categories = [0,1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#label binizer\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([0,1,2,3,4,5,6,7])\n",
    "label = lb.transform(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize TFIDF vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),stop_words=\"english\")\n",
    "data = vectorizer.fit_transform(train_data['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reduce features using SVD\n",
    "SVD = TruncatedSVD(n_components=500, n_iter=5, random_state=0)\n",
    "train = SVD.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10752, 500)\n",
      "(10752, 8)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "train_data, testX, train_label, testY = train_test_split(train, label, test_size=0.2, random_state=0)\n",
    "print train_data.shape\n",
    "print train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tensorflow setup\n",
    "numFeatures = train_data.shape[1]\n",
    "numLabels = 8\n",
    "numEpochs = 1000\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.08,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=train_data.shape[0],\n",
    "                                          decay_rate= 0.9,\n",
    "                                          staircase=True)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures])\n",
    "Y = tf.placeholder(tf.float32, [None, numLabels])\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=(np.sqrt(6/numFeatures+\n",
    "                                                         numLabels+1)),\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=(np.sqrt(6/numFeatures+numLabels+1)),\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tensorflow operation\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")\n",
    "\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-Y, name=\"squared_error_cost\")\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.102865\n",
      "step 0, cost 5374.77\n",
      "step 0, change in cost 5374.77\n",
      "step 10, training accuracy 0.102028\n",
      "step 10, cost 5373.05\n",
      "step 10, change in cost 1.71973\n",
      "step 20, training accuracy 0.102493\n",
      "step 20, cost 5369.15\n",
      "step 20, change in cost 3.89795\n",
      "step 30, training accuracy 0.102307\n",
      "step 30, cost 5367.72\n",
      "step 30, change in cost 1.43115\n",
      "step 40, training accuracy 0.102307\n",
      "step 40, cost 5366.38\n",
      "step 40, change in cost 1.34619\n",
      "step 50, training accuracy 0.102307\n",
      "step 50, cost 5365.07\n",
      "step 50, change in cost 1.30225\n",
      "step 60, training accuracy 0.102307\n",
      "step 60, cost 5363.81\n",
      "step 60, change in cost 1.26758\n",
      "step 70, training accuracy 0.1024\n",
      "step 70, cost 5362.56\n",
      "step 70, change in cost 1.24414\n",
      "step 80, training accuracy 0.1024\n",
      "step 80, cost 5361.32\n",
      "step 80, change in cost 1.24658\n",
      "step 90, training accuracy 0.1024\n",
      "step 90, cost 5360.03\n",
      "step 90, change in cost 1.28809\n",
      "step 100, training accuracy 0.1024\n",
      "step 100, cost 5358.6\n",
      "step 100, change in cost 1.42627\n",
      "step 110, training accuracy 0.102493\n",
      "step 110, cost 5356.76\n",
      "step 110, change in cost 1.83936\n",
      "step 120, training accuracy 0.102679\n",
      "step 120, cost 5353.39\n",
      "step 120, change in cost 3.36719\n",
      "step 130, training accuracy 0.115699\n",
      "step 130, cost 5345.62\n",
      "step 130, change in cost 7.77539\n",
      "step 140, training accuracy 0.120722\n",
      "step 140, cost 5341.26\n",
      "step 140, change in cost 4.35693\n",
      "step 150, training accuracy 0.12314\n",
      "step 150, cost 5336.87\n",
      "step 150, change in cost 4.39209\n",
      "step 160, training accuracy 0.124814\n",
      "step 160, cost 5332.46\n",
      "step 160, change in cost 4.41016\n",
      "step 170, training accuracy 0.125837\n",
      "step 170, cost 5328.09\n",
      "step 170, change in cost 4.37305\n",
      "step 180, training accuracy 0.12686\n",
      "step 180, cost 5323.8\n",
      "step 180, change in cost 4.28369\n",
      "step 190, training accuracy 0.126116\n",
      "step 190, cost 5320.21\n",
      "step 190, change in cost 3.59619\n",
      "step 200, training accuracy 0.126302\n",
      "step 200, cost 5317.73\n",
      "step 200, change in cost 2.48145\n",
      "step 210, training accuracy 0.130952\n",
      "step 210, cost 5319.79\n",
      "step 210, change in cost 2.0625\n",
      "step 220, training accuracy 0.13151\n",
      "step 220, cost 5320.62\n",
      "step 220, change in cost 0.828613\n",
      "step 230, training accuracy 0.103144\n",
      "step 230, cost 5342.01\n",
      "step 230, change in cost 21.3887\n",
      "step 240, training accuracy 0.105748\n",
      "step 240, cost 5333.99\n",
      "step 240, change in cost 8.01172\n",
      "step 250, training accuracy 0.105841\n",
      "step 250, cost 5338.7\n",
      "step 250, change in cost 4.70215\n",
      "step 260, training accuracy 0.12407\n",
      "step 260, cost 5305.56\n",
      "step 260, change in cost 33.1318\n",
      "step 270, training accuracy 0.1024\n",
      "step 270, cost 5343.02\n",
      "step 270, change in cost 37.4561\n",
      "step 280, training accuracy 0.115885\n",
      "step 280, cost 5311\n",
      "step 280, change in cost 32.02\n",
      "step 290, training accuracy 0.104446\n",
      "step 290, cost 5365.78\n",
      "step 290, change in cost 54.7822\n",
      "step 300, training accuracy 0.105841\n",
      "step 300, cost 5329.58\n",
      "step 300, change in cost 36.1973\n",
      "step 310, training accuracy 0.10426\n",
      "step 310, cost 5335.57\n",
      "step 310, change in cost 5.98438\n",
      "step 320, training accuracy 0.101842\n",
      "step 320, cost 5351.15\n",
      "step 320, change in cost 15.585\n",
      "step 330, training accuracy 0.101842\n",
      "step 330, cost 5345.28\n",
      "step 330, change in cost 5.87109\n",
      "step 340, training accuracy 0.101935\n",
      "step 340, cost 5343.65\n",
      "step 340, change in cost 1.62891\n",
      "step 350, training accuracy 0.101842\n",
      "step 350, cost 5352.51\n",
      "step 350, change in cost 8.854\n",
      "step 360, training accuracy 0.102493\n",
      "step 360, cost 5372.52\n",
      "step 360, change in cost 20.0103\n",
      "step 370, training accuracy 0.102214\n",
      "step 370, cost 5366.38\n",
      "step 370, change in cost 6.14111\n",
      "step 380, training accuracy 0.102214\n",
      "step 380, cost 5368.95\n",
      "step 380, change in cost 2.57227\n",
      "step 390, training accuracy 0.102586\n",
      "step 390, cost 5371.02\n",
      "step 390, change in cost 2.07471\n",
      "step 400, training accuracy 0.102028\n",
      "step 400, cost 5354.67\n",
      "step 400, change in cost 16.3501\n",
      "step 410, training accuracy 0.101935\n",
      "step 410, cost 5338.3\n",
      "step 410, change in cost 16.3784\n",
      "step 420, training accuracy 0.102307\n",
      "step 420, cost 5372.98\n",
      "step 420, change in cost 34.6841\n",
      "step 430, training accuracy 0.10426\n",
      "step 430, cost 5374.83\n",
      "step 430, change in cost 1.85059\n",
      "step 440, training accuracy 0.102214\n",
      "step 440, cost 5371.63\n",
      "step 440, change in cost 3.20264\n",
      "step 450, training accuracy 0.103702\n",
      "step 450, cost 5373.9\n",
      "step 450, change in cost 2.27637\n",
      "step 460, training accuracy 0.104167\n",
      "step 460, cost 5374.19\n",
      "step 460, change in cost 0.28418\n",
      "step 470, training accuracy 0.102028\n",
      "step 470, cost 5337.34\n",
      "step 470, change in cost 36.8486\n",
      "step 480, training accuracy 0.106678\n",
      "step 480, cost 5374.2\n",
      "step 480, change in cost 36.8579\n",
      "step 490, training accuracy 0.102121\n",
      "step 490, cost 5347.23\n",
      "step 490, change in cost 26.9653\n",
      "step 500, training accuracy 0.109375\n",
      "step 500, cost 5373.13\n",
      "step 500, change in cost 25.8945\n",
      "step 510, training accuracy 0.103795\n",
      "step 510, cost 5360.03\n",
      "step 510, change in cost 13.0938\n",
      "step 520, training accuracy 0.132719\n",
      "step 520, cost 5306.19\n",
      "step 520, change in cost 53.8398\n",
      "step 530, training accuracy 0.102028\n",
      "step 530, cost 5335.3\n",
      "step 530, change in cost 29.1113\n",
      "step 540, training accuracy 0.107887\n",
      "step 540, cost 5372.95\n",
      "step 540, change in cost 37.6499\n",
      "step 550, training accuracy 0.102214\n",
      "step 550, cost 5352.1\n",
      "step 550, change in cost 20.8496\n",
      "step 560, training accuracy 0.132719\n",
      "step 560, cost 5359.22\n",
      "step 560, change in cost 7.11182\n",
      "step 570, training accuracy 0.101842\n",
      "step 570, cost 5353.89\n",
      "step 570, change in cost 5.32227\n",
      "step 580, training accuracy 0.102214\n",
      "step 580, cost 5373.33\n",
      "step 580, change in cost 19.4331\n",
      "step 590, training accuracy 0.102586\n",
      "step 590, cost 5375.64\n",
      "step 590, change in cost 2.31006\n",
      "step 600, training accuracy 0.1024\n",
      "step 600, cost 5375.5\n",
      "step 600, change in cost 0.133789\n",
      "step 610, training accuracy 0.102493\n",
      "step 610, cost 5375.21\n",
      "step 610, change in cost 0.296875\n",
      "step 620, training accuracy 0.102214\n",
      "step 620, cost 5374.06\n",
      "step 620, change in cost 1.14844\n",
      "step 630, training accuracy 0.102958\n",
      "step 630, cost 5375.73\n",
      "step 630, change in cost 1.67285\n",
      "step 640, training accuracy 0.102586\n",
      "step 640, cost 5375.67\n",
      "step 640, change in cost 0.0654297\n",
      "step 650, training accuracy 0.102493\n",
      "step 650, cost 5375.56\n",
      "step 650, change in cost 0.108398\n",
      "step 660, training accuracy 0.102493\n",
      "step 660, cost 5375.34\n",
      "step 660, change in cost 0.219727\n",
      "step 670, training accuracy 0.102214\n",
      "step 670, cost 5374.69\n",
      "step 670, change in cost 0.652344\n",
      "step 680, training accuracy 0.101935\n",
      "step 680, cost 5363.34\n",
      "step 680, change in cost 11.3428\n",
      "step 690, training accuracy 0.101935\n",
      "step 690, cost 5362.44\n",
      "step 690, change in cost 0.899414\n",
      "step 700, training accuracy 0.101842\n",
      "step 700, cost 5363.06\n",
      "step 700, change in cost 0.614746\n",
      "step 710, training accuracy 0.103702\n",
      "step 710, cost 5375.77\n",
      "step 710, change in cost 12.707\n",
      "step 720, training accuracy 0.102865\n",
      "step 720, cost 5375.72\n",
      "step 720, change in cost 0.0463867\n",
      "step 730, training accuracy 0.102307\n",
      "step 730, cost 5375.65\n",
      "step 730, change in cost 0.0717773\n",
      "step 740, training accuracy 0.102586\n",
      "step 740, cost 5375.52\n",
      "step 740, change in cost 0.122559\n",
      "step 750, training accuracy 0.102493\n",
      "step 750, cost 5375.26\n",
      "step 750, change in cost 0.259766\n",
      "step 760, training accuracy 0.102214\n",
      "step 760, cost 5374.38\n",
      "step 760, change in cost 0.884766\n",
      "step 770, training accuracy 0.101842\n",
      "step 770, cost 5335.87\n",
      "step 770, change in cost 38.5098\n",
      "step 780, training accuracy 0.103981\n",
      "step 780, cost 5375.75\n",
      "step 780, change in cost 39.8838\n",
      "step 790, training accuracy 0.103237\n",
      "step 790, cost 5375.7\n",
      "step 790, change in cost 0.0507812\n",
      "step 800, training accuracy 0.102586\n",
      "step 800, cost 5375.62\n",
      "step 800, change in cost 0.0791016\n",
      "step 810, training accuracy 0.102586\n",
      "step 810, cost 5375.48\n",
      "step 810, change in cost 0.140137\n",
      "step 820, training accuracy 0.102586\n",
      "step 820, cost 5375.17\n",
      "step 820, change in cost 0.317871\n",
      "step 830, training accuracy 0.102307\n",
      "step 830, cost 5373.85\n",
      "step 830, change in cost 1.31592\n",
      "step 840, training accuracy 0.101935\n",
      "step 840, cost 5356.51\n",
      "step 840, change in cost 17.3354\n",
      "step 850, training accuracy 0.102028\n",
      "step 850, cost 5369.65\n",
      "step 850, change in cost 13.1392\n",
      "step 860, training accuracy 0.102493\n",
      "step 860, cost 5375.47\n",
      "step 860, change in cost 5.81348\n",
      "step 870, training accuracy 0.102307\n",
      "step 870, cost 5375.13\n",
      "step 870, change in cost 0.340332\n",
      "step 880, training accuracy 0.102307\n",
      "step 880, cost 5373.6\n",
      "step 880, change in cost 1.52686\n",
      "step 890, training accuracy 0.101935\n",
      "step 890, cost 5353.43\n",
      "step 890, change in cost 20.1665\n",
      "step 900, training accuracy 0.102028\n",
      "step 900, cost 5368.32\n",
      "step 900, change in cost 14.8853\n",
      "step 910, training accuracy 0.101842\n",
      "step 910, cost 5367.65\n",
      "step 910, change in cost 0.664062\n",
      "step 920, training accuracy 0.112723\n",
      "step 920, cost 5375.9\n",
      "step 920, change in cost 8.24268\n",
      "step 930, training accuracy 0.11263\n",
      "step 930, cost 5375.89\n",
      "step 930, change in cost 0.00488281\n",
      "step 940, training accuracy 0.112258\n",
      "step 940, cost 5375.89\n",
      "step 940, change in cost 0.00683594\n",
      "step 950, training accuracy 0.112165\n",
      "step 950, cost 5375.88\n",
      "step 950, change in cost 0.00683594\n",
      "step 960, training accuracy 0.111514\n",
      "step 960, cost 5375.87\n",
      "step 960, change in cost 0.0078125\n",
      "step 970, training accuracy 0.11077\n",
      "step 970, cost 5375.86\n",
      "step 970, change in cost 0.00976562\n",
      "step 980, training accuracy 0.110398\n",
      "step 980, cost 5375.85\n",
      "step 980, change in cost 0.0107422\n",
      "step 990, training accuracy 0.109654\n",
      "step 990, cost 5375.84\n",
      "step 990, change in cost 0.0126953\n",
      "final accuracy on test set: 0.104167\n"
     ]
    }
   ],
   "source": [
    "# tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(Y,1))\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "\n",
    "\n",
    "cost = 0\n",
    "diff = 1\n",
    "epoch_values=[]\n",
    "accuracy_values=[]\n",
    "cost_values=[]\n",
    "\n",
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "        break\n",
    "    else:\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={X: train_data, Y: train_label})\n",
    "        # Report occasional stats\n",
    "        if i % 10 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            train_accuracy, newCost = sess.run(\n",
    "                [accuracy_OP, cost_OP], \n",
    "                feed_dict={X: train_data, Y: train_label}\n",
    "            )\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            \n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            print(\"step %d, cost %g\"%(i, newCost))\n",
    "            print(\"step %d, change in cost %g\"%(i, diff))\n",
    "\n",
    "            \n",
    "\n",
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={X: testX, \n",
    "                                                                Y: testY})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
