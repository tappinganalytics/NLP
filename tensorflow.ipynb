{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from sklearn import preprocessing \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from __future__ import division\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('fit_modified.json', orient = 'records', dtype={\"A\":str, \"B\":list})\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "data = df[['exercisename','synergists','target','execution']]\n",
    "group = df['functional_muscle_group'].apply(pd.Series)\n",
    "label = group.rename(columns = lambda x : 'label' + str(x))\n",
    "label.columns = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercisename</th>\n",
       "      <th>synergists</th>\n",
       "      <th>target</th>\n",
       "      <th>execution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Lever Lying Hip Abduction</td>\n",
       "      <td>[Tensor FasciaeLatae, Gluteus Medius, Gluteus ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Move legs away from one another by abduction h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Lying Straight Leg Raise</td>\n",
       "      <td>[Incline Straight Leg Raise, InclineLeg-Hip Ra...</td>\n",
       "      <td>[Lying Leg Raise]</td>\n",
       "      <td>Keeping knees straight, raise legs by flexing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Cable Seated Pullover</td>\n",
       "      <td>[PectoralisMajor, Sternal, Triceps, LongHead, ...</td>\n",
       "      <td>[Latissimus Dorsi]</td>\n",
       "      <td>With elbows fixed with slight bend, pull cable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Barbell Straight Leg Deadlift</td>\n",
       "      <td>[Hamstrings, Gluteus Maximus, Adductor Magnus]</td>\n",
       "      <td>[Erector Spinae]</td>\n",
       "      <td>With knees straight, lower bar toward top of f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Weighted Side Bend (on stability ball)</td>\n",
       "      <td>[Quadratuslumborum, Psoas major, Iliocastalis ...</td>\n",
       "      <td>[Obliques]</td>\n",
       "      <td>Raise side of torso up by laterally flexing wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               exercisename  \\\n",
       "90                Lever Lying Hip Abduction   \n",
       "32                 Lying Straight Leg Raise   \n",
       "156                   Cable Seated Pullover   \n",
       "147           Barbell Straight Leg Deadlift   \n",
       "254  Weighted Side Bend (on stability ball)   \n",
       "\n",
       "                                            synergists              target  \\\n",
       "90   [Tensor FasciaeLatae, Gluteus Medius, Gluteus ...                  []   \n",
       "32   [Incline Straight Leg Raise, InclineLeg-Hip Ra...   [Lying Leg Raise]   \n",
       "156  [PectoralisMajor, Sternal, Triceps, LongHead, ...  [Latissimus Dorsi]   \n",
       "147     [Hamstrings, Gluteus Maximus, Adductor Magnus]    [Erector Spinae]   \n",
       "254  [Quadratuslumborum, Psoas major, Iliocastalis ...          [Obliques]   \n",
       "\n",
       "                                             execution  \n",
       "90   Move legs away from one another by abduction h...  \n",
       "32   Keeping knees straight, raise legs by flexing ...  \n",
       "156  With elbows fixed with slight bend, pull cable...  \n",
       "147  With knees straight, lower bar toward top of f...  \n",
       "254  Raise side of torso up by laterally flexing wa...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#unlist synergists and target columns\n",
    "data['synergists'] = data['synergists'].fillna(\"\").apply(lambda x: \" \".join(x))\n",
    "data['target'] = data['target'].fillna(\"\").apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     Dumbbell Kickback  Triceps Brachii Extend arm ...\n",
       "47     Lever Shoulder External Rotation (plate loaded...\n",
       "127    Cable Stiff Leg Deadlift Gluteus Maximus Adduc...\n",
       "40     Weighted Hanging Straight Leg Raise Tensor Fas...\n",
       "13     Sled Hack Calf Press Soleus Gastrocnemius Push...\n",
       "dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.apply(lambda x: ' '.join(x.values.tolist()), axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize TFIDF vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),stop_words=\"english\")\n",
    "train_tfidf = vectorizer.fit_transform(train)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils import shuffle\n",
    "# reduce features using SVD\n",
    "SVD = TruncatedSVD(n_components=100, n_iter=10, random_state=0)\n",
    "train = SVD.fit_transform(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = pd.Series(label['label'],dtype='category')\n",
    "label.cat.categories = [0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#label binizer\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([0,1,2,3,4,5,6])\n",
    "label = lb.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 100)\n",
      "(62, 100)\n"
     ]
    }
   ],
   "source": [
    "# separate data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2, random_state=0)\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tensorflow setup\n",
    "numFeatures = X_train.shape[1]\n",
    "numLabels = 7\n",
    "numEpochs = 100000\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.01,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=X_train.shape[0],\n",
    "                                          decay_rate= 0.9,\n",
    "                                          staircase=True)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures])\n",
    "Y = tf.placeholder(tf.float32, [None, numLabels])\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=(np.sqrt(6/numFeatures+\n",
    "                                                         numLabels+1)),\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=(np.sqrt(6/numFeatures+numLabels+1)),\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tensorflow operation\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")\n",
    "\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-Y, name=\"squared_error_cost\")\n",
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.138211\n",
      "step 0, cost 357.849\n",
      "step 0, change in cost 357.849\n",
      "step 10, training accuracy 0.121951\n",
      "step 10, cost 304.876\n",
      "step 10, change in cost 52.9733\n",
      "step 20, training accuracy 0.113821\n",
      "step 20, cost 270.312\n",
      "step 20, change in cost 34.5636\n",
      "step 30, training accuracy 0.117886\n",
      "step 30, cost 244.357\n",
      "step 30, change in cost 25.9547\n",
      "step 40, training accuracy 0.121951\n",
      "step 40, cost 217.976\n",
      "step 40, change in cost 26.3816\n",
      "step 50, training accuracy 0.150407\n",
      "step 50, cost 191.479\n",
      "step 50, change in cost 26.4967\n",
      "step 60, training accuracy 0.170732\n",
      "step 60, cost 169.897\n",
      "step 60, change in cost 21.5822\n",
      "step 70, training accuracy 0.195122\n",
      "step 70, cost 152.858\n",
      "step 70, change in cost 17.0392\n",
      "step 80, training accuracy 0.191057\n",
      "step 80, cost 140.18\n",
      "step 80, change in cost 12.6777\n",
      "step 90, training accuracy 0.207317\n",
      "step 90, cost 131.485\n",
      "step 90, change in cost 8.69479\n",
      "step 100, training accuracy 0.207317\n",
      "step 100, cost 125.576\n",
      "step 100, change in cost 5.90929\n",
      "step 110, training accuracy 0.219512\n",
      "step 110, cost 121.556\n",
      "step 110, change in cost 4.01969\n",
      "step 120, training accuracy 0.227642\n",
      "step 120, cost 118.748\n",
      "step 120, change in cost 2.80788\n",
      "step 130, training accuracy 0.247967\n",
      "step 130, cost 116.652\n",
      "step 130, change in cost 2.09642\n",
      "step 140, training accuracy 0.268293\n",
      "step 140, cost 114.972\n",
      "step 140, change in cost 1.68015\n",
      "step 150, training accuracy 0.280488\n",
      "step 150, cost 113.55\n",
      "step 150, change in cost 1.42136\n",
      "step 160, training accuracy 0.292683\n",
      "step 160, cost 112.302\n",
      "step 160, change in cost 1.24827\n",
      "step 170, training accuracy 0.288618\n",
      "step 170, cost 111.178\n",
      "step 170, change in cost 1.12437\n",
      "step 180, training accuracy 0.296748\n",
      "step 180, cost 110.147\n",
      "step 180, change in cost 1.03101\n",
      "step 190, training accuracy 0.296748\n",
      "step 190, cost 109.189\n",
      "step 190, change in cost 0.957527\n",
      "step 200, training accuracy 0.296748\n",
      "step 200, cost 108.292\n",
      "step 200, change in cost 0.897499\n",
      "step 210, training accuracy 0.296748\n",
      "step 210, cost 107.445\n",
      "step 210, change in cost 0.846756\n",
      "step 220, training accuracy 0.300813\n",
      "step 220, cost 106.642\n",
      "step 220, change in cost 0.80265\n",
      "step 230, training accuracy 0.304878\n",
      "step 230, cost 105.879\n",
      "step 230, change in cost 0.763153\n",
      "step 240, training accuracy 0.304878\n",
      "step 240, cost 105.152\n",
      "step 240, change in cost 0.72702\n",
      "step 250, training accuracy 0.304878\n",
      "step 250, cost 104.459\n",
      "step 250, change in cost 0.693466\n",
      "step 260, training accuracy 0.304878\n",
      "step 260, cost 103.797\n",
      "step 260, change in cost 0.661987\n",
      "step 270, training accuracy 0.317073\n",
      "step 270, cost 103.164\n",
      "step 270, change in cost 0.632256\n",
      "step 280, training accuracy 0.321138\n",
      "step 280, cost 102.56\n",
      "step 280, change in cost 0.604248\n",
      "step 290, training accuracy 0.325203\n",
      "step 290, cost 101.982\n",
      "step 290, change in cost 0.577881\n",
      "step 300, training accuracy 0.325203\n",
      "step 300, cost 101.429\n",
      "step 300, change in cost 0.553192\n",
      "step 310, training accuracy 0.329268\n",
      "step 310, cost 100.899\n",
      "step 310, change in cost 0.530243\n",
      "step 320, training accuracy 0.329268\n",
      "step 320, cost 100.39\n",
      "step 320, change in cost 0.508995\n",
      "step 330, training accuracy 0.329268\n",
      "step 330, cost 99.9\n",
      "step 330, change in cost 0.489754\n",
      "step 340, training accuracy 0.337398\n",
      "step 340, cost 99.4277\n",
      "step 340, change in cost 0.47229\n",
      "step 350, training accuracy 0.341463\n",
      "step 350, cost 98.9709\n",
      "step 350, change in cost 0.456772\n",
      "step 360, training accuracy 0.341463\n",
      "step 360, cost 98.5278\n",
      "step 360, change in cost 0.443115\n",
      "step 370, training accuracy 0.349593\n",
      "step 370, cost 98.0964\n",
      "step 370, change in cost 0.431404\n",
      "step 380, training accuracy 0.349593\n",
      "step 380, cost 97.6749\n",
      "step 380, change in cost 0.421532\n",
      "step 390, training accuracy 0.357724\n",
      "step 390, cost 97.2614\n",
      "step 390, change in cost 0.413452\n",
      "step 400, training accuracy 0.353659\n",
      "step 400, cost 96.8543\n",
      "step 400, change in cost 0.407104\n",
      "step 410, training accuracy 0.353659\n",
      "step 410, cost 96.452\n",
      "step 410, change in cost 0.402351\n",
      "step 420, training accuracy 0.357724\n",
      "step 420, cost 96.0528\n",
      "step 420, change in cost 0.399117\n",
      "step 430, training accuracy 0.361789\n",
      "step 430, cost 95.6557\n",
      "step 430, change in cost 0.397095\n",
      "step 440, training accuracy 0.365854\n",
      "step 440, cost 95.2596\n",
      "step 440, change in cost 0.396133\n",
      "step 450, training accuracy 0.373984\n",
      "step 450, cost 94.8637\n",
      "step 450, change in cost 0.395874\n",
      "step 460, training accuracy 0.382114\n",
      "step 460, cost 94.4678\n",
      "step 460, change in cost 0.39595\n",
      "step 470, training accuracy 0.390244\n",
      "step 470, cost 94.0718\n",
      "step 470, change in cost 0.396027\n",
      "step 480, training accuracy 0.390244\n",
      "step 480, cost 93.6759\n",
      "step 480, change in cost 0.395851\n",
      "step 490, training accuracy 0.398374\n",
      "step 490, cost 93.281\n",
      "step 490, change in cost 0.394951\n",
      "step 500, training accuracy 0.406504\n",
      "step 500, cost 92.8877\n",
      "step 500, change in cost 0.393265\n",
      "step 510, training accuracy 0.406504\n",
      "step 510, cost 92.497\n",
      "step 510, change in cost 0.390717\n",
      "step 520, training accuracy 0.406504\n",
      "step 520, cost 92.1097\n",
      "step 520, change in cost 0.387253\n",
      "step 530, training accuracy 0.414634\n",
      "step 530, cost 91.7266\n",
      "step 530, change in cost 0.383087\n",
      "step 540, training accuracy 0.418699\n",
      "step 540, cost 91.3483\n",
      "step 540, change in cost 0.378349\n",
      "step 550, training accuracy 0.418699\n",
      "step 550, cost 90.9752\n",
      "step 550, change in cost 0.3731\n",
      "step 560, training accuracy 0.418699\n",
      "step 560, cost 90.6076\n",
      "step 560, change in cost 0.367592\n",
      "step 570, training accuracy 0.418699\n",
      "step 570, cost 90.2458\n",
      "step 570, change in cost 0.361824\n",
      "step 580, training accuracy 0.422764\n",
      "step 580, cost 89.8898\n",
      "step 580, change in cost 0.356018\n",
      "step 590, training accuracy 0.422764\n",
      "step 590, cost 89.5396\n",
      "step 590, change in cost 0.350128\n",
      "step 600, training accuracy 0.430894\n",
      "step 600, cost 89.1953\n",
      "step 600, change in cost 0.344315\n",
      "step 610, training accuracy 0.430894\n",
      "step 610, cost 88.8569\n",
      "step 610, change in cost 0.338455\n",
      "step 620, training accuracy 0.434959\n",
      "step 620, cost 88.5241\n",
      "step 620, change in cost 0.332748\n",
      "step 630, training accuracy 0.434959\n",
      "step 630, cost 88.197\n",
      "step 630, change in cost 0.327103\n",
      "step 640, training accuracy 0.439024\n",
      "step 640, cost 87.8754\n",
      "step 640, change in cost 0.321564\n",
      "step 650, training accuracy 0.439024\n",
      "step 650, cost 87.5593\n",
      "step 650, change in cost 0.316116\n",
      "step 660, training accuracy 0.439024\n",
      "step 660, cost 87.2485\n",
      "step 660, change in cost 0.310829\n",
      "step 670, training accuracy 0.439024\n",
      "step 670, cost 86.9429\n",
      "step 670, change in cost 0.305611\n",
      "step 680, training accuracy 0.443089\n",
      "step 680, cost 86.6424\n",
      "step 680, change in cost 0.300476\n",
      "step 690, training accuracy 0.443089\n",
      "step 690, cost 86.3469\n",
      "step 690, change in cost 0.295486\n",
      "step 700, training accuracy 0.443089\n",
      "step 700, cost 86.0564\n",
      "step 700, change in cost 0.29052\n",
      "step 710, training accuracy 0.443089\n",
      "step 710, cost 85.7708\n",
      "step 710, change in cost 0.285629\n",
      "step 720, training accuracy 0.439024\n",
      "step 720, cost 85.49\n",
      "step 720, change in cost 0.2808\n",
      "step 730, training accuracy 0.439024\n",
      "step 730, cost 85.214\n",
      "step 730, change in cost 0.276001\n",
      "step 740, training accuracy 0.443089\n",
      "step 740, cost 84.9428\n",
      "step 740, change in cost 0.27121\n",
      "step 750, training accuracy 0.443089\n",
      "step 750, cost 84.6763\n",
      "step 750, change in cost 0.266479\n",
      "step 760, training accuracy 0.443089\n",
      "step 760, cost 84.4146\n",
      "step 760, change in cost 0.261734\n",
      "step 770, training accuracy 0.443089\n",
      "step 770, cost 84.1575\n",
      "step 770, change in cost 0.257027\n",
      "step 780, training accuracy 0.443089\n",
      "step 780, cost 83.9052\n",
      "step 780, change in cost 0.252327\n",
      "step 790, training accuracy 0.443089\n",
      "step 790, cost 83.6575\n",
      "step 790, change in cost 0.247665\n",
      "step 800, training accuracy 0.443089\n",
      "step 800, cost 83.4145\n",
      "step 800, change in cost 0.242996\n",
      "step 810, training accuracy 0.447154\n",
      "step 810, cost 83.1762\n",
      "step 810, change in cost 0.238358\n",
      "step 820, training accuracy 0.447154\n",
      "step 820, cost 82.9424\n",
      "step 820, change in cost 0.23378\n",
      "step 830, training accuracy 0.447154\n",
      "step 830, cost 82.7132\n",
      "step 830, change in cost 0.229218\n",
      "step 840, training accuracy 0.447154\n",
      "step 840, cost 82.4884\n",
      "step 840, change in cost 0.224762\n",
      "step 850, training accuracy 0.447154\n",
      "step 850, cost 82.2681\n",
      "step 850, change in cost 0.220291\n",
      "step 860, training accuracy 0.451219\n",
      "step 860, cost 82.0522\n",
      "step 860, change in cost 0.21595\n",
      "step 870, training accuracy 0.451219\n",
      "step 870, cost 81.8405\n",
      "step 870, change in cost 0.211647\n",
      "step 880, training accuracy 0.455285\n",
      "step 880, cost 81.6331\n",
      "step 880, change in cost 0.207443\n",
      "step 890, training accuracy 0.455285\n",
      "step 890, cost 81.4298\n",
      "step 890, change in cost 0.203308\n",
      "step 900, training accuracy 0.455285\n",
      "step 900, cost 81.2305\n",
      "step 900, change in cost 0.199326\n",
      "step 910, training accuracy 0.455285\n",
      "step 910, cost 81.0351\n",
      "step 910, change in cost 0.195351\n",
      "step 920, training accuracy 0.455285\n",
      "step 920, cost 80.8436\n",
      "step 920, change in cost 0.191551\n",
      "step 930, training accuracy 0.455285\n",
      "step 930, cost 80.6557\n",
      "step 930, change in cost 0.187805\n",
      "step 940, training accuracy 0.455285\n",
      "step 940, cost 80.4716\n",
      "step 940, change in cost 0.184181\n",
      "step 950, training accuracy 0.455285\n",
      "step 950, cost 80.2909\n",
      "step 950, change in cost 0.180634\n",
      "step 960, training accuracy 0.455285\n",
      "step 960, cost 80.1137\n",
      "step 960, change in cost 0.177254\n",
      "step 970, training accuracy 0.455285\n",
      "step 970, cost 79.9397\n",
      "step 970, change in cost 0.173935\n",
      "step 980, training accuracy 0.45935\n",
      "step 980, cost 79.769\n",
      "step 980, change in cost 0.1707\n",
      "step 990, training accuracy 0.45935\n",
      "step 990, cost 79.6015\n",
      "step 990, change in cost 0.167587\n",
      "step 1000, training accuracy 0.45935\n",
      "step 1000, cost 79.4369\n",
      "step 1000, change in cost 0.164589\n",
      "step 1010, training accuracy 0.45935\n",
      "step 1010, cost 79.2752\n",
      "step 1010, change in cost 0.161667\n",
      "step 1020, training accuracy 0.45935\n",
      "step 1020, cost 79.1163\n",
      "step 1020, change in cost 0.158852\n",
      "step 1030, training accuracy 0.45935\n",
      "step 1030, cost 78.9602\n",
      "step 1030, change in cost 0.156136\n",
      "step 1040, training accuracy 0.45935\n",
      "step 1040, cost 78.8068\n",
      "step 1040, change in cost 0.153435\n",
      "step 1050, training accuracy 0.45935\n",
      "step 1050, cost 78.6559\n",
      "step 1050, change in cost 0.150925\n",
      "step 1060, training accuracy 0.45935\n",
      "step 1060, cost 78.5074\n",
      "step 1060, change in cost 0.148422\n",
      "step 1070, training accuracy 0.45935\n",
      "step 1070, cost 78.3614\n",
      "step 1070, change in cost 0.146027\n",
      "step 1080, training accuracy 0.45935\n",
      "step 1080, cost 78.2177\n",
      "step 1080, change in cost 0.14373\n",
      "step 1090, training accuracy 0.45935\n",
      "step 1090, cost 78.0762\n",
      "step 1090, change in cost 0.141449\n",
      "step 1100, training accuracy 0.45935\n",
      "step 1100, cost 77.937\n",
      "step 1100, change in cost 0.139259\n",
      "step 1110, training accuracy 0.45935\n",
      "step 1110, cost 77.7998\n",
      "step 1110, change in cost 0.137146\n",
      "step 1120, training accuracy 0.45935\n",
      "step 1120, cost 77.6647\n",
      "step 1120, change in cost 0.135101\n",
      "step 1130, training accuracy 0.45935\n",
      "step 1130, cost 77.5316\n",
      "step 1130, change in cost 0.13311\n",
      "step 1140, training accuracy 0.45935\n",
      "step 1140, cost 77.4004\n",
      "step 1140, change in cost 0.131165\n",
      "step 1150, training accuracy 0.463415\n",
      "step 1150, cost 77.2712\n",
      "step 1150, change in cost 0.12928\n",
      "step 1160, training accuracy 0.463415\n",
      "step 1160, cost 77.1437\n",
      "step 1160, change in cost 0.127472\n",
      "step 1170, training accuracy 0.463415\n",
      "step 1170, cost 77.018\n",
      "step 1170, change in cost 0.125687\n",
      "step 1180, training accuracy 0.463415\n",
      "step 1180, cost 76.894\n",
      "step 1180, change in cost 0.12397\n",
      "step 1190, training accuracy 0.471545\n",
      "step 1190, cost 76.7718\n",
      "step 1190, change in cost 0.122269\n",
      "step 1200, training accuracy 0.471545\n",
      "step 1200, cost 76.6511\n",
      "step 1200, change in cost 0.120628\n",
      "step 1210, training accuracy 0.471545\n",
      "step 1210, cost 76.5321\n",
      "step 1210, change in cost 0.119034\n",
      "step 1220, training accuracy 0.471545\n",
      "step 1220, cost 76.4146\n",
      "step 1220, change in cost 0.117493\n",
      "step 1230, training accuracy 0.471545\n",
      "step 1230, cost 76.2986\n",
      "step 1230, change in cost 0.115982\n",
      "step 1240, training accuracy 0.471545\n",
      "step 1240, cost 76.1841\n",
      "step 1240, change in cost 0.114517\n",
      "step 1250, training accuracy 0.471545\n",
      "step 1250, cost 76.0711\n",
      "step 1250, change in cost 0.113037\n",
      "step 1260, training accuracy 0.471545\n",
      "step 1260, cost 75.9594\n",
      "step 1260, change in cost 0.111687\n",
      "step 1270, training accuracy 0.471545\n",
      "step 1270, cost 75.8491\n",
      "step 1270, change in cost 0.110306\n",
      "step 1280, training accuracy 0.47561\n",
      "step 1280, cost 75.7401\n",
      "step 1280, change in cost 0.108971\n",
      "step 1290, training accuracy 0.47561\n",
      "step 1290, cost 75.6324\n",
      "step 1290, change in cost 0.107674\n",
      "step 1300, training accuracy 0.47561\n",
      "step 1300, cost 75.526\n",
      "step 1300, change in cost 0.106407\n",
      "step 1310, training accuracy 0.47561\n",
      "step 1310, cost 75.4208\n",
      "step 1310, change in cost 0.105209\n",
      "step 1320, training accuracy 0.47561\n",
      "step 1320, cost 75.3168\n",
      "step 1320, change in cost 0.103973\n",
      "step 1330, training accuracy 0.47561\n",
      "step 1330, cost 75.214\n",
      "step 1330, change in cost 0.102837\n",
      "step 1340, training accuracy 0.47561\n",
      "step 1340, cost 75.1123\n",
      "step 1340, change in cost 0.101692\n",
      "step 1350, training accuracy 0.479675\n",
      "step 1350, cost 75.0117\n",
      "step 1350, change in cost 0.100586\n",
      "step 1360, training accuracy 0.479675\n",
      "step 1360, cost 74.9122\n",
      "step 1360, change in cost 0.0995483\n",
      "step 1370, training accuracy 0.479675\n",
      "step 1370, cost 74.8137\n",
      "step 1370, change in cost 0.0984802\n",
      "step 1380, training accuracy 0.479675\n",
      "step 1380, cost 74.7162\n",
      "step 1380, change in cost 0.097496\n",
      "step 1390, training accuracy 0.479675\n",
      "step 1390, cost 74.6197\n",
      "step 1390, change in cost 0.0965347\n",
      "step 1400, training accuracy 0.479675\n",
      "step 1400, cost 74.5241\n",
      "step 1400, change in cost 0.0955658\n",
      "step 1410, training accuracy 0.479675\n",
      "step 1410, cost 74.4294\n",
      "step 1410, change in cost 0.0946655\n",
      "step 1420, training accuracy 0.479675\n",
      "step 1420, cost 74.3356\n",
      "step 1420, change in cost 0.093811\n",
      "step 1430, training accuracy 0.479675\n",
      "step 1430, cost 74.2427\n",
      "step 1430, change in cost 0.0929565\n",
      "step 1440, training accuracy 0.479675\n",
      "step 1440, cost 74.1505\n",
      "step 1440, change in cost 0.0921707\n",
      "step 1450, training accuracy 0.479675\n",
      "step 1450, cost 74.0591\n",
      "step 1450, change in cost 0.0913925\n",
      "step 1460, training accuracy 0.479675\n",
      "step 1460, cost 73.9684\n",
      "step 1460, change in cost 0.0906677\n",
      "step 1470, training accuracy 0.479675\n",
      "step 1470, cost 73.8785\n",
      "step 1470, change in cost 0.0899506\n",
      "step 1480, training accuracy 0.479675\n",
      "step 1480, cost 73.7892\n",
      "step 1480, change in cost 0.0893097\n",
      "step 1490, training accuracy 0.479675\n",
      "step 1490, cost 73.7005\n",
      "step 1490, change in cost 0.0886917\n",
      "step 1500, training accuracy 0.479675\n",
      "step 1500, cost 73.6124\n",
      "step 1500, change in cost 0.0881042\n",
      "step 1510, training accuracy 0.479675\n",
      "step 1510, cost 73.5248\n",
      "step 1510, change in cost 0.0875473\n",
      "step 1520, training accuracy 0.479675\n",
      "step 1520, cost 73.4378\n",
      "step 1520, change in cost 0.087059\n",
      "step 1530, training accuracy 0.479675\n",
      "step 1530, cost 73.3512\n",
      "step 1530, change in cost 0.0866013\n",
      "step 1540, training accuracy 0.479675\n",
      "step 1540, cost 73.265\n",
      "step 1540, change in cost 0.086174\n",
      "step 1550, training accuracy 0.479675\n",
      "step 1550, cost 73.1792\n",
      "step 1550, change in cost 0.0857849\n",
      "step 1560, training accuracy 0.48374\n",
      "step 1560, cost 73.0938\n",
      "step 1560, change in cost 0.0854721\n",
      "step 1570, training accuracy 0.48374\n",
      "step 1570, cost 73.0086\n",
      "step 1570, change in cost 0.085144\n",
      "step 1580, training accuracy 0.48374\n",
      "step 1580, cost 72.9237\n",
      "step 1580, change in cost 0.0849457\n",
      "step 1590, training accuracy 0.48374\n",
      "step 1590, cost 72.8389\n",
      "step 1590, change in cost 0.0847321\n",
      "step 1600, training accuracy 0.48374\n",
      "step 1600, cost 72.7543\n",
      "step 1600, change in cost 0.0845871\n",
      "step 1610, training accuracy 0.487805\n",
      "step 1610, cost 72.6699\n",
      "step 1610, change in cost 0.0844803\n",
      "step 1620, training accuracy 0.495935\n",
      "step 1620, cost 72.5854\n",
      "step 1620, change in cost 0.0844421\n",
      "step 1630, training accuracy 0.495935\n",
      "step 1630, cost 72.501\n",
      "step 1630, change in cost 0.0844269\n",
      "step 1640, training accuracy 0.495935\n",
      "step 1640, cost 72.4165\n",
      "step 1640, change in cost 0.0844803\n",
      "step 1650, training accuracy 0.495935\n",
      "step 1650, cost 72.3319\n",
      "step 1650, change in cost 0.0846176\n",
      "step 1660, training accuracy 0.495935\n",
      "step 1660, cost 72.2471\n",
      "step 1660, change in cost 0.0847702\n",
      "step 1670, training accuracy 0.495935\n",
      "step 1670, cost 72.1621\n",
      "step 1670, change in cost 0.0849838\n",
      "step 1680, training accuracy 0.495935\n",
      "step 1680, cost 72.0769\n",
      "step 1680, change in cost 0.0852661\n",
      "step 1690, training accuracy 0.495935\n",
      "step 1690, cost 71.9913\n",
      "step 1690, change in cost 0.0856018\n",
      "step 1700, training accuracy 0.5\n",
      "step 1700, cost 71.9053\n",
      "step 1700, change in cost 0.0860214\n",
      "step 1710, training accuracy 0.504065\n",
      "step 1710, cost 71.8188\n",
      "step 1710, change in cost 0.0864639\n",
      "step 1720, training accuracy 0.50813\n",
      "step 1720, cost 71.7318\n",
      "step 1720, change in cost 0.0869904\n",
      "step 1730, training accuracy 0.50813\n",
      "step 1730, cost 71.6442\n",
      "step 1730, change in cost 0.0875854\n",
      "step 1740, training accuracy 0.512195\n",
      "step 1740, cost 71.556\n",
      "step 1740, change in cost 0.0882263\n",
      "step 1750, training accuracy 0.512195\n",
      "step 1750, cost 71.467\n",
      "step 1750, change in cost 0.0889435\n",
      "step 1760, training accuracy 0.51626\n",
      "step 1760, cost 71.3773\n",
      "step 1760, change in cost 0.0897522\n",
      "step 1770, training accuracy 0.520325\n",
      "step 1770, cost 71.2867\n",
      "step 1770, change in cost 0.0905762\n",
      "step 1780, training accuracy 0.52439\n",
      "step 1780, cost 71.1952\n",
      "step 1780, change in cost 0.0914993\n",
      "step 1790, training accuracy 0.528455\n",
      "step 1790, cost 71.1027\n",
      "step 1790, change in cost 0.0924911\n",
      "step 1800, training accuracy 0.528455\n",
      "step 1800, cost 71.0091\n",
      "step 1800, change in cost 0.0935822\n",
      "step 1810, training accuracy 0.528455\n",
      "step 1810, cost 70.9145\n",
      "step 1810, change in cost 0.0946808\n",
      "step 1820, training accuracy 0.53252\n",
      "step 1820, cost 70.8186\n",
      "step 1820, change in cost 0.0958557\n",
      "step 1830, training accuracy 0.53252\n",
      "step 1830, cost 70.7215\n",
      "step 1830, change in cost 0.0971527\n",
      "step 1840, training accuracy 0.536585\n",
      "step 1840, cost 70.623\n",
      "step 1840, change in cost 0.0984573\n",
      "step 1850, training accuracy 0.536585\n",
      "step 1850, cost 70.5231\n",
      "step 1850, change in cost 0.0998459\n",
      "step 1860, training accuracy 0.536585\n",
      "step 1860, cost 70.4219\n",
      "step 1860, change in cost 0.10128\n",
      "step 1870, training accuracy 0.54065\n",
      "step 1870, cost 70.3191\n",
      "step 1870, change in cost 0.102814\n",
      "step 1880, training accuracy 0.54065\n",
      "step 1880, cost 70.2147\n",
      "step 1880, change in cost 0.104362\n",
      "step 1890, training accuracy 0.54065\n",
      "step 1890, cost 70.1087\n",
      "step 1890, change in cost 0.105995\n",
      "step 1900, training accuracy 0.54065\n",
      "step 1900, cost 70.001\n",
      "step 1900, change in cost 0.107674\n",
      "step 1910, training accuracy 0.544715\n",
      "step 1910, cost 69.8917\n",
      "step 1910, change in cost 0.109344\n",
      "step 1920, training accuracy 0.544715\n",
      "step 1920, cost 69.7805\n",
      "step 1920, change in cost 0.111137\n",
      "step 1930, training accuracy 0.544715\n",
      "step 1930, cost 69.6676\n",
      "step 1930, change in cost 0.112923\n",
      "step 1940, training accuracy 0.544715\n",
      "step 1940, cost 69.5529\n",
      "step 1940, change in cost 0.114746\n",
      "step 1950, training accuracy 0.544715\n",
      "step 1950, cost 69.4363\n",
      "step 1950, change in cost 0.116562\n",
      "step 1960, training accuracy 0.548781\n",
      "step 1960, cost 69.3179\n",
      "step 1960, change in cost 0.118439\n",
      "step 1970, training accuracy 0.548781\n",
      "step 1970, cost 69.1976\n",
      "step 1970, change in cost 0.1203\n",
      "step 1980, training accuracy 0.548781\n",
      "step 1980, cost 69.0754\n",
      "step 1980, change in cost 0.122147\n",
      "step 1990, training accuracy 0.552846\n",
      "step 1990, cost 68.9514\n",
      "step 1990, change in cost 0.124008\n",
      "step 2000, training accuracy 0.552846\n",
      "step 2000, cost 68.8256\n",
      "step 2000, change in cost 0.125793\n",
      "step 2010, training accuracy 0.556911\n",
      "step 2010, cost 68.698\n",
      "step 2010, change in cost 0.127579\n",
      "step 2020, training accuracy 0.556911\n",
      "step 2020, cost 68.5687\n",
      "step 2020, change in cost 0.129295\n",
      "step 2030, training accuracy 0.560976\n",
      "step 2030, cost 68.4378\n",
      "step 2030, change in cost 0.130928\n",
      "step 2040, training accuracy 0.560976\n",
      "step 2040, cost 68.3053\n",
      "step 2040, change in cost 0.132477\n",
      "step 2050, training accuracy 0.565041\n",
      "step 2050, cost 68.1715\n",
      "step 2050, change in cost 0.133865\n",
      "step 2060, training accuracy 0.565041\n",
      "step 2060, cost 68.0363\n",
      "step 2060, change in cost 0.135208\n",
      "step 2070, training accuracy 0.565041\n",
      "step 2070, cost 67.8999\n",
      "step 2070, change in cost 0.136391\n",
      "step 2080, training accuracy 0.569106\n",
      "step 2080, cost 67.7625\n",
      "step 2080, change in cost 0.137367\n",
      "step 2090, training accuracy 0.569106\n",
      "step 2090, cost 67.6243\n",
      "step 2090, change in cost 0.138222\n",
      "step 2100, training accuracy 0.569106\n",
      "step 2100, cost 67.4854\n",
      "step 2100, change in cost 0.138916\n",
      "step 2110, training accuracy 0.569106\n",
      "step 2110, cost 67.346\n",
      "step 2110, change in cost 0.13942\n",
      "step 2120, training accuracy 0.569106\n",
      "step 2120, cost 67.2062\n",
      "step 2120, change in cost 0.139748\n",
      "step 2130, training accuracy 0.573171\n",
      "step 2130, cost 67.0662\n",
      "step 2130, change in cost 0.139992\n",
      "step 2140, training accuracy 0.573171\n",
      "step 2140, cost 66.9262\n",
      "step 2140, change in cost 0.14003\n",
      "step 2150, training accuracy 0.573171\n",
      "step 2150, cost 66.7862\n",
      "step 2150, change in cost 0.139961\n",
      "step 2160, training accuracy 0.577236\n",
      "step 2160, cost 66.6464\n",
      "step 2160, change in cost 0.139786\n",
      "step 2170, training accuracy 0.577236\n",
      "step 2170, cost 66.5069\n",
      "step 2170, change in cost 0.139526\n",
      "step 2180, training accuracy 0.581301\n",
      "step 2180, cost 66.3677\n",
      "step 2180, change in cost 0.139206\n",
      "step 2190, training accuracy 0.581301\n",
      "step 2190, cost 66.2289\n",
      "step 2190, change in cost 0.138809\n",
      "step 2200, training accuracy 0.581301\n",
      "step 2200, cost 66.0905\n",
      "step 2200, change in cost 0.138397\n",
      "step 2210, training accuracy 0.581301\n",
      "step 2210, cost 65.9525\n",
      "step 2210, change in cost 0.13797\n",
      "step 2220, training accuracy 0.581301\n",
      "step 2220, cost 65.815\n",
      "step 2220, change in cost 0.137527\n",
      "step 2230, training accuracy 0.581301\n",
      "step 2230, cost 65.6779\n",
      "step 2230, change in cost 0.137085\n",
      "step 2240, training accuracy 0.585366\n",
      "step 2240, cost 65.5412\n",
      "step 2240, change in cost 0.136703\n",
      "step 2250, training accuracy 0.585366\n",
      "step 2250, cost 65.4049\n",
      "step 2250, change in cost 0.136314\n",
      "step 2260, training accuracy 0.589431\n",
      "step 2260, cost 65.2689\n",
      "step 2260, change in cost 0.135963\n",
      "step 2270, training accuracy 0.589431\n",
      "step 2270, cost 65.1333\n",
      "step 2270, change in cost 0.135658\n",
      "step 2280, training accuracy 0.589431\n",
      "step 2280, cost 64.9979\n",
      "step 2280, change in cost 0.135406\n",
      "step 2290, training accuracy 0.589431\n",
      "step 2290, cost 64.8627\n",
      "step 2290, change in cost 0.135193\n",
      "step 2300, training accuracy 0.589431\n",
      "step 2300, cost 64.7276\n",
      "step 2300, change in cost 0.13504\n",
      "step 2310, training accuracy 0.589431\n",
      "step 2310, cost 64.5927\n",
      "step 2310, change in cost 0.134964\n",
      "step 2320, training accuracy 0.593496\n",
      "step 2320, cost 64.4577\n",
      "step 2320, change in cost 0.134926\n",
      "step 2330, training accuracy 0.593496\n",
      "step 2330, cost 64.3228\n",
      "step 2330, change in cost 0.134972\n",
      "step 2340, training accuracy 0.597561\n",
      "step 2340, cost 64.1877\n",
      "step 2340, change in cost 0.135101\n",
      "step 2350, training accuracy 0.601626\n",
      "step 2350, cost 64.0524\n",
      "step 2350, change in cost 0.135269\n",
      "step 2360, training accuracy 0.601626\n",
      "step 2360, cost 63.9169\n",
      "step 2360, change in cost 0.13554\n",
      "step 2370, training accuracy 0.605691\n",
      "step 2370, cost 63.781\n",
      "step 2370, change in cost 0.135914\n",
      "step 2380, training accuracy 0.605691\n",
      "step 2380, cost 63.6446\n",
      "step 2380, change in cost 0.136333\n",
      "step 2390, training accuracy 0.609756\n",
      "step 2390, cost 63.5077\n",
      "step 2390, change in cost 0.136871\n",
      "step 2400, training accuracy 0.609756\n",
      "step 2400, cost 63.3702\n",
      "step 2400, change in cost 0.137508\n",
      "step 2410, training accuracy 0.609756\n",
      "step 2410, cost 63.232\n",
      "step 2410, change in cost 0.13826\n",
      "step 2420, training accuracy 0.609756\n",
      "step 2420, cost 63.0929\n",
      "step 2420, change in cost 0.139114\n",
      "step 2430, training accuracy 0.609756\n",
      "step 2430, cost 62.9528\n",
      "step 2430, change in cost 0.140072\n",
      "step 2440, training accuracy 0.609756\n",
      "step 2440, cost 62.8116\n",
      "step 2440, change in cost 0.141232\n",
      "step 2450, training accuracy 0.609756\n",
      "step 2450, cost 62.6691\n",
      "step 2450, change in cost 0.142467\n",
      "step 2460, training accuracy 0.609756\n",
      "step 2460, cost 62.5252\n",
      "step 2460, change in cost 0.143867\n",
      "step 2470, training accuracy 0.609756\n",
      "step 2470, cost 62.3798\n",
      "step 2470, change in cost 0.145454\n",
      "step 2480, training accuracy 0.609756\n",
      "step 2480, cost 62.2325\n",
      "step 2480, change in cost 0.147224\n",
      "step 2490, training accuracy 0.613821\n",
      "step 2490, cost 62.0834\n",
      "step 2490, change in cost 0.14917\n",
      "step 2500, training accuracy 0.613821\n",
      "step 2500, cost 61.932\n",
      "step 2500, change in cost 0.151348\n",
      "step 2510, training accuracy 0.613821\n",
      "step 2510, cost 61.7783\n",
      "step 2510, change in cost 0.153767\n",
      "step 2520, training accuracy 0.617886\n",
      "step 2520, cost 61.6218\n",
      "step 2520, change in cost 0.156445\n",
      "step 2530, training accuracy 0.617886\n",
      "step 2530, cost 61.4624\n",
      "step 2530, change in cost 0.159431\n",
      "step 2540, training accuracy 0.617886\n",
      "step 2540, cost 61.2996\n",
      "step 2540, change in cost 0.162746\n",
      "step 2550, training accuracy 0.617886\n",
      "step 2550, cost 61.1332\n",
      "step 2550, change in cost 0.166431\n",
      "step 2560, training accuracy 0.621951\n",
      "step 2560, cost 60.9627\n",
      "step 2560, change in cost 0.170517\n",
      "step 2570, training accuracy 0.626016\n",
      "step 2570, cost 60.7876\n",
      "step 2570, change in cost 0.175079\n",
      "step 2580, training accuracy 0.634146\n",
      "step 2580, cost 60.6075\n",
      "step 2580, change in cost 0.18013\n",
      "step 2590, training accuracy 0.642276\n",
      "step 2590, cost 60.4217\n",
      "step 2590, change in cost 0.185818\n",
      "step 2600, training accuracy 0.646341\n",
      "step 2600, cost 60.2295\n",
      "step 2600, change in cost 0.192123\n",
      "step 2610, training accuracy 0.654472\n",
      "step 2610, cost 60.0304\n",
      "step 2610, change in cost 0.199188\n",
      "step 2620, training accuracy 0.658537\n",
      "step 2620, cost 59.8233\n",
      "step 2620, change in cost 0.207085\n",
      "step 2630, training accuracy 0.662602\n",
      "step 2630, cost 59.6074\n",
      "step 2630, change in cost 0.215889\n",
      "step 2640, training accuracy 0.662602\n",
      "step 2640, cost 59.3816\n",
      "step 2640, change in cost 0.225784\n",
      "step 2650, training accuracy 0.666667\n",
      "step 2650, cost 59.1448\n",
      "step 2650, change in cost 0.236797\n",
      "step 2660, training accuracy 0.666667\n",
      "step 2660, cost 58.8958\n",
      "step 2660, change in cost 0.249012\n",
      "step 2670, training accuracy 0.666667\n",
      "step 2670, cost 58.6332\n",
      "step 2670, change in cost 0.262589\n",
      "step 2680, training accuracy 0.666667\n",
      "step 2680, cost 58.3558\n",
      "step 2680, change in cost 0.277439\n",
      "step 2690, training accuracy 0.666667\n",
      "step 2690, cost 58.0622\n",
      "step 2690, change in cost 0.293598\n",
      "step 2700, training accuracy 0.666667\n",
      "step 2700, cost 57.7514\n",
      "step 2700, change in cost 0.310787\n",
      "step 2710, training accuracy 0.674797\n",
      "step 2710, cost 57.4227\n",
      "step 2710, change in cost 0.328663\n",
      "step 2720, training accuracy 0.678862\n",
      "step 2720, cost 57.0761\n",
      "step 2720, change in cost 0.34663\n",
      "step 2730, training accuracy 0.678862\n",
      "step 2730, cost 56.7122\n",
      "step 2730, change in cost 0.363857\n",
      "step 2740, training accuracy 0.686992\n",
      "step 2740, cost 56.333\n",
      "step 2740, change in cost 0.379238\n",
      "step 2750, training accuracy 0.686992\n",
      "step 2750, cost 55.9412\n",
      "step 2750, change in cost 0.391823\n",
      "step 2760, training accuracy 0.699187\n",
      "step 2760, cost 55.5405\n",
      "step 2760, change in cost 0.40065\n",
      "step 2770, training accuracy 0.699187\n",
      "step 2770, cost 55.1352\n",
      "step 2770, change in cost 0.405289\n",
      "step 2780, training accuracy 0.703252\n",
      "step 2780, cost 54.7295\n",
      "step 2780, change in cost 0.405758\n",
      "step 2790, training accuracy 0.703252\n",
      "step 2790, cost 54.3268\n",
      "step 2790, change in cost 0.402683\n",
      "step 2800, training accuracy 0.703252\n",
      "step 2800, cost 53.9299\n",
      "step 2800, change in cost 0.39687\n",
      "step 2810, training accuracy 0.707317\n",
      "step 2810, cost 53.5407\n",
      "step 2810, change in cost 0.389187\n",
      "step 2820, training accuracy 0.707317\n",
      "step 2820, cost 53.1603\n",
      "step 2820, change in cost 0.380413\n",
      "step 2830, training accuracy 0.707317\n",
      "step 2830, cost 52.7892\n",
      "step 2830, change in cost 0.371086\n",
      "step 2840, training accuracy 0.707317\n",
      "step 2840, cost 52.4277\n",
      "step 2840, change in cost 0.361534\n",
      "step 2850, training accuracy 0.707317\n",
      "step 2850, cost 52.0757\n",
      "step 2850, change in cost 0.351971\n",
      "step 2860, training accuracy 0.711382\n",
      "step 2860, cost 51.7332\n",
      "step 2860, change in cost 0.34256\n",
      "step 2870, training accuracy 0.711382\n",
      "step 2870, cost 51.3998\n",
      "step 2870, change in cost 0.33337\n",
      "step 2880, training accuracy 0.711382\n",
      "step 2880, cost 51.0753\n",
      "step 2880, change in cost 0.324459\n",
      "step 2890, training accuracy 0.711382\n",
      "step 2890, cost 50.7594\n",
      "step 2890, change in cost 0.315907\n",
      "step 2900, training accuracy 0.711382\n",
      "step 2900, cost 50.4517\n",
      "step 2900, change in cost 0.307747\n",
      "step 2910, training accuracy 0.711382\n",
      "step 2910, cost 50.1517\n",
      "step 2910, change in cost 0.299995\n",
      "step 2920, training accuracy 0.711382\n",
      "step 2920, cost 49.859\n",
      "step 2920, change in cost 0.292667\n",
      "step 2930, training accuracy 0.719512\n",
      "step 2930, cost 49.5732\n",
      "step 2930, change in cost 0.285809\n",
      "step 2940, training accuracy 0.719512\n",
      "step 2940, cost 49.2938\n",
      "step 2940, change in cost 0.2794\n",
      "step 2950, training accuracy 0.723577\n",
      "step 2950, cost 49.0203\n",
      "step 2950, change in cost 0.273464\n",
      "step 2960, training accuracy 0.723577\n",
      "step 2960, cost 48.7524\n",
      "step 2960, change in cost 0.267967\n",
      "step 2970, training accuracy 0.727642\n",
      "step 2970, cost 48.4895\n",
      "step 2970, change in cost 0.262901\n",
      "step 2980, training accuracy 0.731707\n",
      "step 2980, cost 48.2312\n",
      "step 2980, change in cost 0.258293\n",
      "step 2990, training accuracy 0.731707\n",
      "step 2990, cost 47.9771\n",
      "step 2990, change in cost 0.25407\n",
      "step 3000, training accuracy 0.731707\n",
      "step 3000, cost 47.7269\n",
      "step 3000, change in cost 0.250237\n",
      "step 3010, training accuracy 0.731707\n",
      "step 3010, cost 47.4801\n",
      "step 3010, change in cost 0.24678\n",
      "step 3020, training accuracy 0.731707\n",
      "step 3020, cost 47.2364\n",
      "step 3020, change in cost 0.243652\n",
      "step 3030, training accuracy 0.731707\n",
      "step 3030, cost 46.9956\n",
      "step 3030, change in cost 0.240871\n",
      "step 3040, training accuracy 0.731707\n",
      "step 3040, cost 46.7572\n",
      "step 3040, change in cost 0.238335\n",
      "step 3050, training accuracy 0.731707\n",
      "step 3050, cost 46.5212\n",
      "step 3050, change in cost 0.236084\n",
      "step 3060, training accuracy 0.731707\n",
      "step 3060, cost 46.2871\n",
      "step 3060, change in cost 0.234074\n",
      "step 3070, training accuracy 0.731707\n",
      "step 3070, cost 46.0548\n",
      "step 3070, change in cost 0.232262\n",
      "step 3080, training accuracy 0.735772\n",
      "step 3080, cost 45.8242\n",
      "step 3080, change in cost 0.230637\n",
      "step 3090, training accuracy 0.735772\n",
      "step 3090, cost 45.595\n",
      "step 3090, change in cost 0.229179\n",
      "step 3100, training accuracy 0.743902\n",
      "step 3100, cost 45.3672\n",
      "step 3100, change in cost 0.227844\n",
      "step 3110, training accuracy 0.743902\n",
      "step 3110, cost 45.1405\n",
      "step 3110, change in cost 0.226624\n",
      "step 3120, training accuracy 0.743902\n",
      "step 3120, cost 44.915\n",
      "step 3120, change in cost 0.225513\n",
      "step 3130, training accuracy 0.743902\n",
      "step 3130, cost 44.6906\n",
      "step 3130, change in cost 0.224457\n",
      "step 3140, training accuracy 0.743902\n",
      "step 3140, cost 44.4671\n",
      "step 3140, change in cost 0.223469\n",
      "step 3150, training accuracy 0.747967\n",
      "step 3150, cost 44.2445\n",
      "step 3150, change in cost 0.222561\n",
      "step 3160, training accuracy 0.747967\n",
      "step 3160, cost 44.0229\n",
      "step 3160, change in cost 0.22168\n",
      "step 3170, training accuracy 0.752033\n",
      "step 3170, cost 43.802\n",
      "step 3170, change in cost 0.220818\n",
      "step 3180, training accuracy 0.756098\n",
      "step 3180, cost 43.5821\n",
      "step 3180, change in cost 0.219986\n",
      "step 3190, training accuracy 0.756098\n",
      "step 3190, cost 43.3629\n",
      "step 3190, change in cost 0.219185\n",
      "step 3200, training accuracy 0.756098\n",
      "step 3200, cost 43.1445\n",
      "step 3200, change in cost 0.218388\n",
      "step 3210, training accuracy 0.756098\n",
      "step 3210, cost 42.9269\n",
      "step 3210, change in cost 0.217602\n",
      "step 3220, training accuracy 0.760163\n",
      "step 3220, cost 42.7101\n",
      "step 3220, change in cost 0.216812\n",
      "step 3230, training accuracy 0.760163\n",
      "step 3230, cost 42.494\n",
      "step 3230, change in cost 0.216026\n",
      "step 3240, training accuracy 0.760163\n",
      "step 3240, cost 42.2788\n",
      "step 3240, change in cost 0.21524\n",
      "step 3250, training accuracy 0.760163\n",
      "step 3250, cost 42.0644\n",
      "step 3250, change in cost 0.214386\n",
      "step 3260, training accuracy 0.760163\n",
      "step 3260, cost 41.8509\n",
      "step 3260, change in cost 0.213539\n",
      "step 3270, training accuracy 0.760163\n",
      "step 3270, cost 41.6383\n",
      "step 3270, change in cost 0.212616\n",
      "step 3280, training accuracy 0.768293\n",
      "step 3280, cost 41.4266\n",
      "step 3280, change in cost 0.211617\n",
      "step 3290, training accuracy 0.768293\n",
      "step 3290, cost 41.2161\n",
      "step 3290, change in cost 0.210537\n",
      "step 3300, training accuracy 0.768293\n",
      "step 3300, cost 41.0067\n",
      "step 3300, change in cost 0.209358\n",
      "step 3310, training accuracy 0.768293\n",
      "step 3310, cost 40.7987\n",
      "step 3310, change in cost 0.208038\n",
      "step 3320, training accuracy 0.772358\n",
      "step 3320, cost 40.5921\n",
      "step 3320, change in cost 0.206593\n",
      "step 3330, training accuracy 0.772358\n",
      "step 3330, cost 40.3872\n",
      "step 3330, change in cost 0.204952\n",
      "step 3340, training accuracy 0.780488\n",
      "step 3340, cost 40.184\n",
      "step 3340, change in cost 0.203167\n",
      "step 3350, training accuracy 0.780488\n",
      "step 3350, cost 39.9828\n",
      "step 3350, change in cost 0.201172\n",
      "step 3360, training accuracy 0.780488\n",
      "step 3360, cost 39.7838\n",
      "step 3360, change in cost 0.199005\n",
      "step 3370, training accuracy 0.780488\n",
      "step 3370, cost 39.5872\n",
      "step 3370, change in cost 0.196659\n",
      "step 3380, training accuracy 0.780488\n",
      "step 3380, cost 39.393\n",
      "step 3380, change in cost 0.194141\n",
      "step 3390, training accuracy 0.784553\n",
      "step 3390, cost 39.2016\n",
      "step 3390, change in cost 0.191441\n",
      "step 3400, training accuracy 0.784553\n",
      "step 3400, cost 39.013\n",
      "step 3400, change in cost 0.188606\n",
      "step 3410, training accuracy 0.784553\n",
      "step 3410, cost 38.8273\n",
      "step 3410, change in cost 0.18565\n",
      "step 3420, training accuracy 0.784553\n",
      "step 3420, cost 38.6447\n",
      "step 3420, change in cost 0.182571\n",
      "step 3430, training accuracy 0.784553\n",
      "step 3430, cost 38.4653\n",
      "step 3430, change in cost 0.179436\n",
      "step 3440, training accuracy 0.784553\n",
      "step 3440, cost 38.2891\n",
      "step 3440, change in cost 0.176228\n",
      "step 3450, training accuracy 0.784553\n",
      "step 3450, cost 38.1161\n",
      "step 3450, change in cost 0.173016\n",
      "step 3460, training accuracy 0.784553\n",
      "step 3460, cost 37.9463\n",
      "step 3460, change in cost 0.169758\n",
      "step 3470, training accuracy 0.784553\n",
      "step 3470, cost 37.7798\n",
      "step 3470, change in cost 0.166542\n",
      "step 3480, training accuracy 0.784553\n",
      "step 3480, cost 37.6164\n",
      "step 3480, change in cost 0.163345\n",
      "step 3490, training accuracy 0.784553\n",
      "step 3490, cost 37.4562\n",
      "step 3490, change in cost 0.160183\n",
      "step 3500, training accuracy 0.784553\n",
      "step 3500, cost 37.2991\n",
      "step 3500, change in cost 0.157097\n",
      "step 3510, training accuracy 0.784553\n",
      "step 3510, cost 37.1451\n",
      "step 3510, change in cost 0.154072\n",
      "step 3520, training accuracy 0.784553\n",
      "step 3520, cost 36.994\n",
      "step 3520, change in cost 0.151115\n",
      "step 3530, training accuracy 0.788618\n",
      "step 3530, cost 36.8457\n",
      "step 3530, change in cost 0.148247\n",
      "step 3540, training accuracy 0.788618\n",
      "step 3540, cost 36.7002\n",
      "step 3540, change in cost 0.145462\n",
      "step 3550, training accuracy 0.788618\n",
      "step 3550, cost 36.5575\n",
      "step 3550, change in cost 0.142754\n",
      "step 3560, training accuracy 0.788618\n",
      "step 3560, cost 36.4173\n",
      "step 3560, change in cost 0.140148\n",
      "step 3570, training accuracy 0.792683\n",
      "step 3570, cost 36.2797\n",
      "step 3570, change in cost 0.137627\n",
      "step 3580, training accuracy 0.792683\n",
      "step 3580, cost 36.1445\n",
      "step 3580, change in cost 0.135193\n",
      "step 3590, training accuracy 0.792683\n",
      "step 3590, cost 36.0117\n",
      "step 3590, change in cost 0.132843\n",
      "step 3600, training accuracy 0.792683\n",
      "step 3600, cost 35.8811\n",
      "step 3600, change in cost 0.130562\n",
      "step 3610, training accuracy 0.792683\n",
      "step 3610, cost 35.7527\n",
      "step 3610, change in cost 0.128395\n",
      "step 3620, training accuracy 0.792683\n",
      "step 3620, cost 35.6265\n",
      "step 3620, change in cost 0.126263\n",
      "step 3630, training accuracy 0.792683\n",
      "step 3630, cost 35.5022\n",
      "step 3630, change in cost 0.124218\n",
      "step 3640, training accuracy 0.792683\n",
      "step 3640, cost 35.38\n",
      "step 3640, change in cost 0.122261\n",
      "step 3650, training accuracy 0.800813\n",
      "step 3650, cost 35.2596\n",
      "step 3650, change in cost 0.120358\n",
      "step 3660, training accuracy 0.800813\n",
      "step 3660, cost 35.1411\n",
      "step 3660, change in cost 0.118523\n",
      "step 3670, training accuracy 0.800813\n",
      "step 3670, cost 35.0244\n",
      "step 3670, change in cost 0.116734\n",
      "step 3680, training accuracy 0.800813\n",
      "step 3680, cost 34.9094\n",
      "step 3680, change in cost 0.115005\n",
      "step 3690, training accuracy 0.800813\n",
      "step 3690, cost 34.796\n",
      "step 3690, change in cost 0.113354\n",
      "step 3700, training accuracy 0.804878\n",
      "step 3700, cost 34.6843\n",
      "step 3700, change in cost 0.111736\n",
      "step 3710, training accuracy 0.804878\n",
      "step 3710, cost 34.5741\n",
      "step 3710, change in cost 0.110176\n",
      "step 3720, training accuracy 0.804878\n",
      "step 3720, cost 34.4655\n",
      "step 3720, change in cost 0.108635\n",
      "step 3730, training accuracy 0.804878\n",
      "step 3730, cost 34.3583\n",
      "step 3730, change in cost 0.107185\n",
      "step 3740, training accuracy 0.804878\n",
      "step 3740, cost 34.2525\n",
      "step 3740, change in cost 0.105759\n",
      "step 3750, training accuracy 0.804878\n",
      "step 3750, cost 34.1482\n",
      "step 3750, change in cost 0.104366\n",
      "step 3760, training accuracy 0.804878\n",
      "step 3760, cost 34.0451\n",
      "step 3760, change in cost 0.103031\n",
      "step 3770, training accuracy 0.804878\n",
      "step 3770, cost 33.9434\n",
      "step 3770, change in cost 0.101723\n",
      "step 3780, training accuracy 0.804878\n",
      "step 3780, cost 33.8429\n",
      "step 3780, change in cost 0.100468\n",
      "step 3790, training accuracy 0.804878\n",
      "step 3790, cost 33.7437\n",
      "step 3790, change in cost 0.099247\n",
      "step 3800, training accuracy 0.804878\n",
      "step 3800, cost 33.6456\n",
      "step 3800, change in cost 0.0980453\n",
      "step 3810, training accuracy 0.808943\n",
      "step 3810, cost 33.5487\n",
      "step 3810, change in cost 0.0968933\n",
      "step 3820, training accuracy 0.808943\n",
      "step 3820, cost 33.453\n",
      "step 3820, change in cost 0.0957756\n",
      "step 3830, training accuracy 0.817073\n",
      "step 3830, cost 33.3583\n",
      "step 3830, change in cost 0.0946884\n",
      "step 3840, training accuracy 0.817073\n",
      "step 3840, cost 33.2647\n",
      "step 3840, change in cost 0.0936279\n",
      "step 3850, training accuracy 0.817073\n",
      "step 3850, cost 33.1721\n",
      "step 3850, change in cost 0.092598\n",
      "step 3860, training accuracy 0.817073\n",
      "step 3860, cost 33.0805\n",
      "step 3860, change in cost 0.0915871\n",
      "step 3870, training accuracy 0.817073\n",
      "step 3870, cost 32.9899\n",
      "step 3870, change in cost 0.0906029\n",
      "step 3880, training accuracy 0.817073\n",
      "step 3880, cost 32.9002\n",
      "step 3880, change in cost 0.0896606\n",
      "step 3890, training accuracy 0.817073\n",
      "step 3890, cost 32.8115\n",
      "step 3890, change in cost 0.0887108\n",
      "step 3900, training accuracy 0.817073\n",
      "step 3900, cost 32.7237\n",
      "step 3900, change in cost 0.0878067\n",
      "step 3910, training accuracy 0.817073\n",
      "step 3910, cost 32.6368\n",
      "step 3910, change in cost 0.086895\n",
      "step 3920, training accuracy 0.817073\n",
      "step 3920, cost 32.5508\n",
      "step 3920, change in cost 0.0860176\n",
      "step 3930, training accuracy 0.817073\n",
      "step 3930, cost 32.4656\n",
      "step 3930, change in cost 0.0851479\n",
      "step 3940, training accuracy 0.817073\n",
      "step 3940, cost 32.3814\n",
      "step 3940, change in cost 0.0842781\n",
      "step 3950, training accuracy 0.817073\n",
      "step 3950, cost 32.2979\n",
      "step 3950, change in cost 0.0834389\n",
      "step 3960, training accuracy 0.817073\n",
      "step 3960, cost 32.2153\n",
      "step 3960, change in cost 0.0826035\n",
      "step 3970, training accuracy 0.817073\n",
      "step 3970, cost 32.1335\n",
      "step 3970, change in cost 0.0817642\n",
      "step 3980, training accuracy 0.817073\n",
      "step 3980, cost 32.0526\n",
      "step 3980, change in cost 0.0809364\n",
      "step 3990, training accuracy 0.817073\n",
      "step 3990, cost 31.9725\n",
      "step 3990, change in cost 0.080122\n",
      "step 4000, training accuracy 0.817073\n",
      "step 4000, cost 31.8932\n",
      "step 4000, change in cost 0.0793018\n",
      "step 4010, training accuracy 0.817073\n",
      "step 4010, cost 31.8147\n",
      "step 4010, change in cost 0.0784855\n",
      "step 4020, training accuracy 0.817073\n",
      "step 4020, cost 31.737\n",
      "step 4020, change in cost 0.0776787\n",
      "step 4030, training accuracy 0.817073\n",
      "step 4030, cost 31.6602\n",
      "step 4030, change in cost 0.0768642\n",
      "step 4040, training accuracy 0.817073\n",
      "step 4040, cost 31.5841\n",
      "step 4040, change in cost 0.0760574\n",
      "step 4050, training accuracy 0.817073\n",
      "step 4050, cost 31.5089\n",
      "step 4050, change in cost 0.0752487\n",
      "step 4060, training accuracy 0.817073\n",
      "step 4060, cost 31.4344\n",
      "step 4060, change in cost 0.0744419\n",
      "step 4070, training accuracy 0.817073\n",
      "step 4070, cost 31.3608\n",
      "step 4070, change in cost 0.0736523\n",
      "step 4080, training accuracy 0.821138\n",
      "step 4080, cost 31.2879\n",
      "step 4080, change in cost 0.0728416\n",
      "step 4090, training accuracy 0.821138\n",
      "step 4090, cost 31.2159\n",
      "step 4090, change in cost 0.0720444\n",
      "step 4100, training accuracy 0.821138\n",
      "step 4100, cost 31.1446\n",
      "step 4100, change in cost 0.0712433\n",
      "step 4110, training accuracy 0.821138\n",
      "step 4110, cost 31.0742\n",
      "step 4110, change in cost 0.0704498\n",
      "step 4120, training accuracy 0.821138\n",
      "step 4120, cost 31.0045\n",
      "step 4120, change in cost 0.0696583\n",
      "step 4130, training accuracy 0.821138\n",
      "step 4130, cost 30.9356\n",
      "step 4130, change in cost 0.0688801\n",
      "step 4140, training accuracy 0.821138\n",
      "step 4140, cost 30.8675\n",
      "step 4140, change in cost 0.0680923\n",
      "step 4150, training accuracy 0.821138\n",
      "step 4150, cost 30.8002\n",
      "step 4150, change in cost 0.0673256\n",
      "step 4160, training accuracy 0.821138\n",
      "step 4160, cost 30.7337\n",
      "step 4160, change in cost 0.0665474\n",
      "step 4170, training accuracy 0.821138\n",
      "step 4170, cost 30.6679\n",
      "step 4170, change in cost 0.0657959\n",
      "step 4180, training accuracy 0.821138\n",
      "step 4180, cost 30.6028\n",
      "step 4180, change in cost 0.065033\n",
      "step 4190, training accuracy 0.821138\n",
      "step 4190, cost 30.5386\n",
      "step 4190, change in cost 0.0642872\n",
      "step 4200, training accuracy 0.821138\n",
      "step 4200, cost 30.475\n",
      "step 4200, change in cost 0.0635414\n",
      "step 4210, training accuracy 0.821138\n",
      "step 4210, cost 30.4122\n",
      "step 4210, change in cost 0.0628071\n",
      "step 4220, training accuracy 0.825203\n",
      "step 4220, cost 30.3501\n",
      "step 4220, change in cost 0.0620937\n",
      "step 4230, training accuracy 0.825203\n",
      "step 4230, cost 30.2887\n",
      "step 4230, change in cost 0.0613728\n",
      "step 4240, training accuracy 0.825203\n",
      "step 4240, cost 30.2281\n",
      "step 4240, change in cost 0.060667\n",
      "step 4250, training accuracy 0.825203\n",
      "step 4250, cost 30.1681\n",
      "step 4250, change in cost 0.059967\n",
      "step 4260, training accuracy 0.825203\n",
      "step 4260, cost 30.1088\n",
      "step 4260, change in cost 0.0592918\n",
      "step 4270, training accuracy 0.825203\n",
      "step 4270, cost 30.0502\n",
      "step 4270, change in cost 0.0586166\n",
      "step 4280, training accuracy 0.825203\n",
      "step 4280, cost 29.9922\n",
      "step 4280, change in cost 0.0579548\n",
      "step 4290, training accuracy 0.825203\n",
      "step 4290, cost 29.935\n",
      "step 4290, change in cost 0.057291\n",
      "step 4300, training accuracy 0.825203\n",
      "step 4300, cost 29.8783\n",
      "step 4300, change in cost 0.0566597\n",
      "step 4310, training accuracy 0.825203\n",
      "step 4310, cost 29.8223\n",
      "step 4310, change in cost 0.056015\n",
      "step 4320, training accuracy 0.825203\n",
      "step 4320, cost 29.7669\n",
      "step 4320, change in cost 0.0553932\n",
      "step 4330, training accuracy 0.825203\n",
      "step 4330, cost 29.7121\n",
      "step 4330, change in cost 0.0547829\n",
      "step 4340, training accuracy 0.825203\n",
      "step 4340, cost 29.6579\n",
      "step 4340, change in cost 0.0541878\n",
      "step 4350, training accuracy 0.829268\n",
      "step 4350, cost 29.6043\n",
      "step 4350, change in cost 0.0535965\n",
      "step 4360, training accuracy 0.829268\n",
      "step 4360, cost 29.5513\n",
      "step 4360, change in cost 0.0530128\n",
      "step 4370, training accuracy 0.829268\n",
      "step 4370, cost 29.4989\n",
      "step 4370, change in cost 0.0524368\n",
      "step 4380, training accuracy 0.829268\n",
      "step 4380, cost 29.447\n",
      "step 4380, change in cost 0.0518742\n",
      "step 4390, training accuracy 0.829268\n",
      "step 4390, cost 29.3957\n",
      "step 4390, change in cost 0.0513287\n",
      "step 4400, training accuracy 0.829268\n",
      "step 4400, cost 29.3449\n",
      "step 4400, change in cost 0.0507755\n",
      "step 4410, training accuracy 0.829268\n",
      "step 4410, cost 29.2946\n",
      "step 4410, change in cost 0.0502548\n",
      "step 4420, training accuracy 0.829268\n",
      "step 4420, cost 29.2449\n",
      "step 4420, change in cost 0.0497246\n",
      "step 4430, training accuracy 0.829268\n",
      "step 4430, cost 29.1957\n",
      "step 4430, change in cost 0.0492058\n",
      "step 4440, training accuracy 0.829268\n",
      "step 4440, cost 29.147\n",
      "step 4440, change in cost 0.0487022\n",
      "step 4450, training accuracy 0.829268\n",
      "step 4450, cost 29.0988\n",
      "step 4450, change in cost 0.0482006\n",
      "step 4460, training accuracy 0.829268\n",
      "step 4460, cost 29.0511\n",
      "step 4460, change in cost 0.0477219\n",
      "step 4470, training accuracy 0.829268\n",
      "step 4470, cost 29.0039\n",
      "step 4470, change in cost 0.0472221\n",
      "step 4480, training accuracy 0.829268\n",
      "step 4480, cost 28.9571\n",
      "step 4480, change in cost 0.0467644\n",
      "step 4490, training accuracy 0.829268\n",
      "step 4490, cost 28.9108\n",
      "step 4490, change in cost 0.0462933\n",
      "step 4500, training accuracy 0.829268\n",
      "step 4500, cost 28.865\n",
      "step 4500, change in cost 0.045826\n",
      "step 4510, training accuracy 0.829268\n",
      "step 4510, cost 28.8196\n",
      "step 4510, change in cost 0.0453873\n",
      "step 4520, training accuracy 0.829268\n",
      "step 4520, cost 28.7746\n",
      "step 4520, change in cost 0.0449429\n",
      "step 4530, training accuracy 0.829268\n",
      "step 4530, cost 28.7302\n",
      "step 4530, change in cost 0.0444927\n",
      "step 4540, training accuracy 0.829268\n",
      "step 4540, cost 28.6861\n",
      "step 4540, change in cost 0.0440674\n",
      "step 4550, training accuracy 0.833333\n",
      "step 4550, cost 28.6424\n",
      "step 4550, change in cost 0.0436516\n",
      "step 4560, training accuracy 0.833333\n",
      "step 4560, cost 28.5992\n",
      "step 4560, change in cost 0.0432243\n",
      "step 4570, training accuracy 0.833333\n",
      "step 4570, cost 28.5564\n",
      "step 4570, change in cost 0.04282\n",
      "step 4580, training accuracy 0.833333\n",
      "step 4580, cost 28.514\n",
      "step 4580, change in cost 0.0424118\n",
      "step 4590, training accuracy 0.833333\n",
      "step 4590, cost 28.472\n",
      "step 4590, change in cost 0.0420189\n",
      "step 4600, training accuracy 0.833333\n",
      "step 4600, cost 28.4303\n",
      "step 4600, change in cost 0.0416183\n",
      "step 4610, training accuracy 0.833333\n",
      "step 4610, cost 28.3891\n",
      "step 4610, change in cost 0.0412483\n",
      "step 4620, training accuracy 0.833333\n",
      "step 4620, cost 28.3482\n",
      "step 4620, change in cost 0.0408573\n",
      "step 4630, training accuracy 0.833333\n",
      "step 4630, cost 28.3078\n",
      "step 4630, change in cost 0.0404778\n",
      "step 4640, training accuracy 0.833333\n",
      "step 4640, cost 28.2676\n",
      "step 4640, change in cost 0.0401268\n",
      "step 4650, training accuracy 0.833333\n",
      "step 4650, cost 28.2279\n",
      "step 4650, change in cost 0.0397491\n",
      "step 4660, training accuracy 0.833333\n",
      "step 4660, cost 28.1885\n",
      "step 4660, change in cost 0.0393906\n",
      "step 4670, training accuracy 0.833333\n",
      "step 4670, cost 28.1494\n",
      "step 4670, change in cost 0.0390511\n",
      "step 4680, training accuracy 0.833333\n",
      "step 4680, cost 28.1107\n",
      "step 4680, change in cost 0.0386925\n",
      "step 4690, training accuracy 0.833333\n",
      "step 4690, cost 28.0724\n",
      "step 4690, change in cost 0.0383644\n",
      "step 4700, training accuracy 0.833333\n",
      "step 4700, cost 28.0344\n",
      "step 4700, change in cost 0.0380268\n",
      "step 4710, training accuracy 0.833333\n",
      "step 4710, cost 27.9967\n",
      "step 4710, change in cost 0.0376854\n",
      "step 4720, training accuracy 0.833333\n",
      "step 4720, cost 27.9593\n",
      "step 4720, change in cost 0.0373688\n",
      "step 4730, training accuracy 0.833333\n",
      "step 4730, cost 27.9223\n",
      "step 4730, change in cost 0.0370445\n",
      "step 4740, training accuracy 0.833333\n",
      "step 4740, cost 27.8855\n",
      "step 4740, change in cost 0.0367374\n",
      "step 4750, training accuracy 0.833333\n",
      "step 4750, cost 27.8491\n",
      "step 4750, change in cost 0.0364323\n",
      "step 4760, training accuracy 0.833333\n",
      "step 4760, cost 27.813\n",
      "step 4760, change in cost 0.0361176\n",
      "step 4770, training accuracy 0.833333\n",
      "step 4770, cost 27.7771\n",
      "step 4770, change in cost 0.03582\n",
      "step 4780, training accuracy 0.833333\n",
      "step 4780, cost 27.7416\n",
      "step 4780, change in cost 0.0355263\n",
      "step 4790, training accuracy 0.833333\n",
      "step 4790, cost 27.7064\n",
      "step 4790, change in cost 0.0352402\n",
      "step 4800, training accuracy 0.833333\n",
      "step 4800, cost 27.6714\n",
      "step 4800, change in cost 0.034956\n",
      "step 4810, training accuracy 0.833333\n",
      "step 4810, cost 27.6368\n",
      "step 4810, change in cost 0.0346661\n",
      "step 4820, training accuracy 0.833333\n",
      "step 4820, cost 27.6024\n",
      "step 4820, change in cost 0.0343933\n",
      "step 4830, training accuracy 0.833333\n",
      "step 4830, cost 27.5682\n",
      "step 4830, change in cost 0.0341301\n",
      "step 4840, training accuracy 0.833333\n",
      "step 4840, cost 27.5344\n",
      "step 4840, change in cost 0.0338593\n",
      "step 4850, training accuracy 0.833333\n",
      "step 4850, cost 27.5008\n",
      "step 4850, change in cost 0.0336094\n",
      "step 4860, training accuracy 0.833333\n",
      "step 4860, cost 27.4674\n",
      "step 4860, change in cost 0.0333443\n",
      "step 4870, training accuracy 0.833333\n",
      "step 4870, cost 27.4343\n",
      "step 4870, change in cost 0.033102\n",
      "step 4880, training accuracy 0.833333\n",
      "step 4880, cost 27.4015\n",
      "step 4880, change in cost 0.0328522\n",
      "step 4890, training accuracy 0.833333\n",
      "step 4890, cost 27.3689\n",
      "step 4890, change in cost 0.0326042\n",
      "step 4900, training accuracy 0.833333\n",
      "step 4900, cost 27.3365\n",
      "step 4900, change in cost 0.0323753\n",
      "step 4910, training accuracy 0.833333\n",
      "step 4910, cost 27.3043\n",
      "step 4910, change in cost 0.0321407\n",
      "step 4920, training accuracy 0.833333\n",
      "step 4920, cost 27.2724\n",
      "step 4920, change in cost 0.0319118\n",
      "step 4930, training accuracy 0.837398\n",
      "step 4930, cost 27.2407\n",
      "step 4930, change in cost 0.0316887\n",
      "step 4940, training accuracy 0.837398\n",
      "step 4940, cost 27.2093\n",
      "step 4940, change in cost 0.0314789\n",
      "step 4950, training accuracy 0.837398\n",
      "step 4950, cost 27.178\n",
      "step 4950, change in cost 0.0312614\n",
      "step 4960, training accuracy 0.837398\n",
      "step 4960, cost 27.147\n",
      "step 4960, change in cost 0.0310478\n",
      "step 4970, training accuracy 0.837398\n",
      "step 4970, cost 27.1161\n",
      "step 4970, change in cost 0.0308533\n",
      "step 4980, training accuracy 0.837398\n",
      "step 4980, cost 27.0855\n",
      "step 4980, change in cost 0.0306473\n",
      "step 4990, training accuracy 0.837398\n",
      "step 4990, cost 27.055\n",
      "step 4990, change in cost 0.0304699\n",
      "step 5000, training accuracy 0.837398\n",
      "step 5000, cost 27.0247\n",
      "step 5000, change in cost 0.0302658\n",
      "step 5010, training accuracy 0.837398\n",
      "step 5010, cost 26.9946\n",
      "step 5010, change in cost 0.0300865\n",
      "step 5020, training accuracy 0.837398\n",
      "step 5020, cost 26.9647\n",
      "step 5020, change in cost 0.0299129\n",
      "step 5030, training accuracy 0.837398\n",
      "step 5030, cost 26.935\n",
      "step 5030, change in cost 0.0297394\n",
      "step 5040, training accuracy 0.837398\n",
      "step 5040, cost 26.9054\n",
      "step 5040, change in cost 0.0295677\n",
      "step 5050, training accuracy 0.837398\n",
      "step 5050, cost 26.876\n",
      "step 5050, change in cost 0.0294094\n",
      "step 5060, training accuracy 0.837398\n",
      "step 5060, cost 26.8468\n",
      "step 5060, change in cost 0.0292492\n",
      "step 5070, training accuracy 0.837398\n",
      "step 5070, cost 26.8177\n",
      "step 5070, change in cost 0.0290966\n",
      "step 5080, training accuracy 0.841463\n",
      "step 5080, cost 26.7887\n",
      "step 5080, change in cost 0.0289536\n",
      "step 5090, training accuracy 0.841463\n",
      "step 5090, cost 26.7599\n",
      "step 5090, change in cost 0.0288162\n",
      "step 5100, training accuracy 0.841463\n",
      "step 5100, cost 26.7312\n",
      "step 5100, change in cost 0.0286732\n",
      "step 5110, training accuracy 0.841463\n",
      "step 5110, cost 26.7027\n",
      "step 5110, change in cost 0.0285492\n",
      "step 5120, training accuracy 0.841463\n",
      "step 5120, cost 26.6742\n",
      "step 5120, change in cost 0.028429\n",
      "step 5130, training accuracy 0.841463\n",
      "step 5130, cost 26.6459\n",
      "step 5130, change in cost 0.028307\n",
      "step 5140, training accuracy 0.841463\n",
      "step 5140, cost 26.6177\n",
      "step 5140, change in cost 0.0281944\n",
      "step 5150, training accuracy 0.841463\n",
      "step 5150, cost 26.5897\n",
      "step 5150, change in cost 0.0280895\n",
      "step 5160, training accuracy 0.841463\n",
      "step 5160, cost 26.5617\n",
      "step 5160, change in cost 0.0279961\n",
      "step 5170, training accuracy 0.841463\n",
      "step 5170, cost 26.5338\n",
      "step 5170, change in cost 0.0279045\n",
      "step 5180, training accuracy 0.841463\n",
      "step 5180, cost 26.5059\n",
      "step 5180, change in cost 0.0278187\n",
      "step 5190, training accuracy 0.841463\n",
      "step 5190, cost 26.4782\n",
      "step 5190, change in cost 0.0277405\n",
      "step 5200, training accuracy 0.841463\n",
      "step 5200, cost 26.4505\n",
      "step 5200, change in cost 0.0276585\n",
      "step 5210, training accuracy 0.841463\n",
      "step 5210, cost 26.4229\n",
      "step 5210, change in cost 0.027607\n",
      "step 5220, training accuracy 0.841463\n",
      "step 5220, cost 26.3954\n",
      "step 5220, change in cost 0.027544\n",
      "step 5230, training accuracy 0.841463\n",
      "step 5230, cost 26.3679\n",
      "step 5230, change in cost 0.0274868\n",
      "step 5240, training accuracy 0.841463\n",
      "step 5240, cost 26.3404\n",
      "step 5240, change in cost 0.0274525\n",
      "step 5250, training accuracy 0.841463\n",
      "step 5250, cost 26.313\n",
      "step 5250, change in cost 0.0274067\n",
      "step 5260, training accuracy 0.841463\n",
      "step 5260, cost 26.2857\n",
      "step 5260, change in cost 0.0273857\n",
      "step 5270, training accuracy 0.841463\n",
      "step 5270, cost 26.2583\n",
      "step 5270, change in cost 0.0273685\n",
      "step 5280, training accuracy 0.841463\n",
      "step 5280, cost 26.2309\n",
      "step 5280, change in cost 0.0273399\n",
      "step 5290, training accuracy 0.841463\n",
      "step 5290, cost 26.2036\n",
      "step 5290, change in cost 0.0273418\n",
      "step 5300, training accuracy 0.841463\n",
      "step 5300, cost 26.1763\n",
      "step 5300, change in cost 0.0273495\n",
      "step 5310, training accuracy 0.841463\n",
      "step 5310, cost 26.1489\n",
      "step 5310, change in cost 0.0273495\n",
      "step 5320, training accuracy 0.841463\n",
      "step 5320, cost 26.1215\n",
      "step 5320, change in cost 0.0273666\n",
      "step 5330, training accuracy 0.841463\n",
      "step 5330, cost 26.0941\n",
      "step 5330, change in cost 0.0274029\n",
      "step 5340, training accuracy 0.841463\n",
      "step 5340, cost 26.0667\n",
      "step 5340, change in cost 0.0274258\n",
      "step 5350, training accuracy 0.841463\n",
      "step 5350, cost 26.0392\n",
      "step 5350, change in cost 0.0274658\n",
      "step 5360, training accuracy 0.841463\n",
      "step 5360, cost 26.0117\n",
      "step 5360, change in cost 0.0275192\n",
      "step 5370, training accuracy 0.841463\n",
      "step 5370, cost 25.9841\n",
      "step 5370, change in cost 0.0275764\n",
      "step 5380, training accuracy 0.841463\n",
      "step 5380, cost 25.9565\n",
      "step 5380, change in cost 0.0276451\n",
      "step 5390, training accuracy 0.841463\n",
      "step 5390, cost 25.9288\n",
      "step 5390, change in cost 0.02771\n",
      "step 5400, training accuracy 0.841463\n",
      "step 5400, cost 25.901\n",
      "step 5400, change in cost 0.0277958\n",
      "step 5410, training accuracy 0.841463\n",
      "step 5410, cost 25.8731\n",
      "step 5410, change in cost 0.0278778\n",
      "step 5420, training accuracy 0.841463\n",
      "step 5420, cost 25.8451\n",
      "step 5420, change in cost 0.0279789\n",
      "step 5430, training accuracy 0.841463\n",
      "step 5430, cost 25.8171\n",
      "step 5430, change in cost 0.0280685\n",
      "step 5440, training accuracy 0.841463\n",
      "step 5440, cost 25.7889\n",
      "step 5440, change in cost 0.0282021\n",
      "step 5450, training accuracy 0.841463\n",
      "step 5450, cost 25.7606\n",
      "step 5450, change in cost 0.0283031\n",
      "step 5460, training accuracy 0.841463\n",
      "step 5460, cost 25.7321\n",
      "step 5460, change in cost 0.0284348\n",
      "step 5470, training accuracy 0.841463\n",
      "step 5470, cost 25.7036\n",
      "step 5470, change in cost 0.0285625\n",
      "step 5480, training accuracy 0.841463\n",
      "step 5480, cost 25.6749\n",
      "step 5480, change in cost 0.0287018\n",
      "step 5490, training accuracy 0.841463\n",
      "step 5490, cost 25.646\n",
      "step 5490, change in cost 0.028862\n",
      "step 5500, training accuracy 0.841463\n",
      "step 5500, cost 25.617\n",
      "step 5500, change in cost 0.0289955\n",
      "step 5510, training accuracy 0.841463\n",
      "step 5510, cost 25.5878\n",
      "step 5510, change in cost 0.0291634\n",
      "step 5520, training accuracy 0.841463\n",
      "step 5520, cost 25.5585\n",
      "step 5520, change in cost 0.0293312\n",
      "step 5530, training accuracy 0.841463\n",
      "step 5530, cost 25.529\n",
      "step 5530, change in cost 0.0295105\n",
      "step 5540, training accuracy 0.845528\n",
      "step 5540, cost 25.4993\n",
      "step 5540, change in cost 0.0296879\n",
      "step 5550, training accuracy 0.845528\n",
      "step 5550, cost 25.4694\n",
      "step 5550, change in cost 0.0298786\n",
      "step 5560, training accuracy 0.845528\n",
      "step 5560, cost 25.4394\n",
      "step 5560, change in cost 0.0300789\n",
      "step 5570, training accuracy 0.845528\n",
      "step 5570, cost 25.4091\n",
      "step 5570, change in cost 0.0302811\n",
      "step 5580, training accuracy 0.845528\n",
      "step 5580, cost 25.3786\n",
      "step 5580, change in cost 0.0305023\n",
      "step 5590, training accuracy 0.845528\n",
      "step 5590, cost 25.3478\n",
      "step 5590, change in cost 0.0307312\n",
      "step 5600, training accuracy 0.849594\n",
      "step 5600, cost 25.3169\n",
      "step 5600, change in cost 0.0309563\n",
      "step 5610, training accuracy 0.849594\n",
      "step 5610, cost 25.2857\n",
      "step 5610, change in cost 0.0312042\n",
      "step 5620, training accuracy 0.849594\n",
      "step 5620, cost 25.2542\n",
      "step 5620, change in cost 0.0314674\n",
      "step 5630, training accuracy 0.853659\n",
      "step 5630, cost 25.2225\n",
      "step 5630, change in cost 0.0317192\n",
      "step 5640, training accuracy 0.853659\n",
      "step 5640, cost 25.1905\n",
      "step 5640, change in cost 0.032011\n",
      "step 5650, training accuracy 0.853659\n",
      "step 5650, cost 25.1582\n",
      "step 5650, change in cost 0.0323086\n",
      "step 5660, training accuracy 0.853659\n",
      "step 5660, cost 25.1256\n",
      "step 5660, change in cost 0.0326214\n",
      "step 5670, training accuracy 0.853659\n",
      "step 5670, cost 25.0926\n",
      "step 5670, change in cost 0.032938\n",
      "step 5680, training accuracy 0.853659\n",
      "step 5680, cost 25.0593\n",
      "step 5680, change in cost 0.0332832\n",
      "step 5690, training accuracy 0.853659\n",
      "step 5690, cost 25.0257\n",
      "step 5690, change in cost 0.0336494\n",
      "step 5700, training accuracy 0.853659\n",
      "step 5700, cost 24.9917\n",
      "step 5700, change in cost 0.0340157\n",
      "step 5710, training accuracy 0.853659\n",
      "step 5710, cost 24.9572\n",
      "step 5710, change in cost 0.03442\n",
      "step 5720, training accuracy 0.853659\n",
      "step 5720, cost 24.9224\n",
      "step 5720, change in cost 0.0348377\n",
      "step 5730, training accuracy 0.853659\n",
      "step 5730, cost 24.8871\n",
      "step 5730, change in cost 0.035284\n",
      "step 5740, training accuracy 0.857724\n",
      "step 5740, cost 24.8514\n",
      "step 5740, change in cost 0.0357437\n",
      "step 5750, training accuracy 0.861789\n",
      "step 5750, cost 24.8152\n",
      "step 5750, change in cost 0.0362244\n",
      "step 5760, training accuracy 0.861789\n",
      "step 5760, cost 24.7784\n",
      "step 5760, change in cost 0.0367336\n",
      "step 5770, training accuracy 0.861789\n",
      "step 5770, cost 24.7412\n",
      "step 5770, change in cost 0.0372715\n",
      "step 5780, training accuracy 0.861789\n",
      "step 5780, cost 24.7033\n",
      "step 5780, change in cost 0.0378265\n",
      "step 5790, training accuracy 0.861789\n",
      "step 5790, cost 24.6649\n",
      "step 5790, change in cost 0.038393\n",
      "step 5800, training accuracy 0.861789\n",
      "step 5800, cost 24.6259\n",
      "step 5800, change in cost 0.0390034\n",
      "step 5810, training accuracy 0.861789\n",
      "step 5810, cost 24.5863\n",
      "step 5810, change in cost 0.0396252\n",
      "step 5820, training accuracy 0.861789\n",
      "step 5820, cost 24.546\n",
      "step 5820, change in cost 0.0402622\n",
      "step 5830, training accuracy 0.861789\n",
      "step 5830, cost 24.5051\n",
      "step 5830, change in cost 0.0409203\n",
      "step 5840, training accuracy 0.861789\n",
      "step 5840, cost 24.4635\n",
      "step 5840, change in cost 0.0415974\n",
      "step 5850, training accuracy 0.861789\n",
      "step 5850, cost 24.4212\n",
      "step 5850, change in cost 0.0422878\n",
      "step 5860, training accuracy 0.861789\n",
      "step 5860, cost 24.3783\n",
      "step 5860, change in cost 0.0429802\n",
      "step 5870, training accuracy 0.865854\n",
      "step 5870, cost 24.3346\n",
      "step 5870, change in cost 0.0436916\n",
      "step 5880, training accuracy 0.865854\n",
      "step 5880, cost 24.2902\n",
      "step 5880, change in cost 0.0443707\n",
      "step 5890, training accuracy 0.865854\n",
      "step 5890, cost 24.2451\n",
      "step 5890, change in cost 0.0450802\n",
      "step 5900, training accuracy 0.865854\n",
      "step 5900, cost 24.1993\n",
      "step 5900, change in cost 0.0457668\n",
      "step 5910, training accuracy 0.869919\n",
      "step 5910, cost 24.1529\n",
      "step 5910, change in cost 0.0464439\n",
      "step 5920, training accuracy 0.869919\n",
      "step 5920, cost 24.1058\n",
      "step 5920, change in cost 0.0470924\n",
      "step 5930, training accuracy 0.869919\n",
      "step 5930, cost 24.0581\n",
      "step 5930, change in cost 0.0477161\n",
      "step 5940, training accuracy 0.869919\n",
      "step 5940, cost 24.0098\n",
      "step 5940, change in cost 0.0483131\n",
      "step 5950, training accuracy 0.869919\n",
      "step 5950, cost 23.9609\n",
      "step 5950, change in cost 0.0488644\n",
      "step 5960, training accuracy 0.869919\n",
      "step 5960, cost 23.9115\n",
      "step 5960, change in cost 0.0493774\n",
      "step 5970, training accuracy 0.869919\n",
      "step 5970, cost 23.8617\n",
      "step 5970, change in cost 0.0498447\n",
      "step 5980, training accuracy 0.869919\n",
      "step 5980, cost 23.8114\n",
      "step 5980, change in cost 0.0502777\n",
      "step 5990, training accuracy 0.869919\n",
      "step 5990, cost 23.7608\n",
      "step 5990, change in cost 0.0506382\n",
      "step 6000, training accuracy 0.869919\n",
      "step 6000, cost 23.7098\n",
      "step 6000, change in cost 0.0509453\n",
      "step 6010, training accuracy 0.869919\n",
      "step 6010, cost 23.6586\n",
      "step 6010, change in cost 0.0512142\n",
      "step 6020, training accuracy 0.869919\n",
      "step 6020, cost 23.6072\n",
      "step 6020, change in cost 0.0514183\n",
      "step 6030, training accuracy 0.869919\n",
      "step 6030, cost 23.5556\n",
      "step 6030, change in cost 0.0515804\n",
      "step 6040, training accuracy 0.873984\n",
      "step 6040, cost 23.5039\n",
      "step 6040, change in cost 0.0516777\n",
      "step 6050, training accuracy 0.873984\n",
      "step 6050, cost 23.4522\n",
      "step 6050, change in cost 0.0517464\n",
      "step 6060, training accuracy 0.873984\n",
      "step 6060, cost 23.4004\n",
      "step 6060, change in cost 0.0517521\n",
      "step 6070, training accuracy 0.873984\n",
      "step 6070, cost 23.3487\n",
      "step 6070, change in cost 0.0517216\n",
      "step 6080, training accuracy 0.873984\n",
      "step 6080, cost 23.2971\n",
      "step 6080, change in cost 0.0516701\n",
      "step 6090, training accuracy 0.873984\n",
      "step 6090, cost 23.2455\n",
      "step 6090, change in cost 0.0515709\n",
      "step 6100, training accuracy 0.878049\n",
      "step 6100, cost 23.194\n",
      "step 6100, change in cost 0.0514469\n",
      "step 6110, training accuracy 0.878049\n",
      "step 6110, cost 23.1427\n",
      "step 6110, change in cost 0.0512905\n",
      "step 6120, training accuracy 0.878049\n",
      "step 6120, cost 23.0916\n",
      "step 6120, change in cost 0.0511284\n",
      "step 6130, training accuracy 0.878049\n",
      "step 6130, cost 23.0407\n",
      "step 6130, change in cost 0.0509491\n",
      "step 6140, training accuracy 0.878049\n",
      "step 6140, cost 22.9899\n",
      "step 6140, change in cost 0.0507488\n",
      "step 6150, training accuracy 0.878049\n",
      "step 6150, cost 22.9394\n",
      "step 6150, change in cost 0.0505447\n",
      "step 6160, training accuracy 0.878049\n",
      "step 6160, cost 22.889\n",
      "step 6160, change in cost 0.0503292\n",
      "step 6170, training accuracy 0.878049\n",
      "step 6170, cost 22.8389\n",
      "step 6170, change in cost 0.0501194\n",
      "step 6180, training accuracy 0.882114\n",
      "step 6180, cost 22.789\n",
      "step 6180, change in cost 0.0498867\n",
      "step 6190, training accuracy 0.882114\n",
      "step 6190, cost 22.7394\n",
      "step 6190, change in cost 0.0496845\n",
      "step 6200, training accuracy 0.882114\n",
      "step 6200, cost 22.6899\n",
      "step 6200, change in cost 0.049469\n",
      "step 6210, training accuracy 0.882114\n",
      "step 6210, cost 22.6406\n",
      "step 6210, change in cost 0.0492611\n",
      "step 6220, training accuracy 0.882114\n",
      "step 6220, cost 22.5916\n",
      "step 6220, change in cost 0.0490608\n",
      "step 6230, training accuracy 0.882114\n",
      "step 6230, cost 22.5427\n",
      "step 6230, change in cost 0.0488663\n",
      "step 6240, training accuracy 0.882114\n",
      "step 6240, cost 22.494\n",
      "step 6240, change in cost 0.0486679\n",
      "step 6250, training accuracy 0.882114\n",
      "step 6250, cost 22.4455\n",
      "step 6250, change in cost 0.0485001\n",
      "step 6260, training accuracy 0.882114\n",
      "step 6260, cost 22.3972\n",
      "step 6260, change in cost 0.0483265\n",
      "step 6270, training accuracy 0.882114\n",
      "step 6270, cost 22.349\n",
      "step 6270, change in cost 0.0481739\n",
      "step 6280, training accuracy 0.882114\n",
      "step 6280, cost 22.301\n",
      "step 6280, change in cost 0.0480118\n",
      "step 6290, training accuracy 0.882114\n",
      "step 6290, cost 22.2531\n",
      "step 6290, change in cost 0.0478859\n",
      "step 6300, training accuracy 0.882114\n",
      "step 6300, cost 22.2054\n",
      "step 6300, change in cost 0.0477486\n",
      "step 6310, training accuracy 0.886179\n",
      "step 6310, cost 22.1577\n",
      "step 6310, change in cost 0.0476341\n",
      "step 6320, training accuracy 0.886179\n",
      "step 6320, cost 22.1102\n",
      "step 6320, change in cost 0.0475235\n",
      "step 6330, training accuracy 0.886179\n",
      "step 6330, cost 22.0628\n",
      "step 6330, change in cost 0.0474186\n",
      "step 6340, training accuracy 0.886179\n",
      "step 6340, cost 22.0155\n",
      "step 6340, change in cost 0.0473347\n",
      "step 6350, training accuracy 0.886179\n",
      "step 6350, cost 21.9682\n",
      "step 6350, change in cost 0.0472507\n",
      "step 6360, training accuracy 0.886179\n",
      "step 6360, cost 21.921\n",
      "step 6360, change in cost 0.047184\n",
      "step 6370, training accuracy 0.886179\n",
      "step 6370, cost 21.8739\n",
      "step 6370, change in cost 0.0471058\n",
      "step 6380, training accuracy 0.886179\n",
      "step 6380, cost 21.8269\n",
      "step 6380, change in cost 0.0470562\n",
      "step 6390, training accuracy 0.890244\n",
      "step 6390, cost 21.7799\n",
      "step 6390, change in cost 0.0470104\n",
      "step 6400, training accuracy 0.890244\n",
      "step 6400, cost 21.7329\n",
      "step 6400, change in cost 0.0469627\n",
      "step 6410, training accuracy 0.890244\n",
      "step 6410, cost 21.686\n",
      "step 6410, change in cost 0.0469227\n",
      "step 6420, training accuracy 0.890244\n",
      "step 6420, cost 21.6391\n",
      "step 6420, change in cost 0.0468884\n",
      "step 6430, training accuracy 0.890244\n",
      "step 6430, cost 21.5922\n",
      "step 6430, change in cost 0.0468674\n",
      "step 6440, training accuracy 0.890244\n",
      "step 6440, cost 21.5454\n",
      "step 6440, change in cost 0.0468483\n",
      "step 6450, training accuracy 0.890244\n",
      "step 6450, cost 21.4985\n",
      "step 6450, change in cost 0.0468349\n",
      "step 6460, training accuracy 0.890244\n",
      "step 6460, cost 21.4517\n",
      "step 6460, change in cost 0.0468082\n",
      "step 6470, training accuracy 0.890244\n",
      "step 6470, cost 21.4049\n",
      "step 6470, change in cost 0.0468063\n",
      "step 6480, training accuracy 0.890244\n",
      "step 6480, cost 21.3581\n",
      "step 6480, change in cost 0.0468025\n",
      "step 6490, training accuracy 0.890244\n",
      "step 6490, cost 21.3113\n",
      "step 6490, change in cost 0.0467987\n",
      "step 6500, training accuracy 0.890244\n",
      "step 6500, cost 21.2645\n",
      "step 6500, change in cost 0.0467987\n",
      "step 6510, training accuracy 0.890244\n",
      "step 6510, cost 21.2177\n",
      "step 6510, change in cost 0.0467987\n",
      "step 6520, training accuracy 0.894309\n",
      "step 6520, cost 21.1709\n",
      "step 6520, change in cost 0.0468102\n",
      "step 6530, training accuracy 0.894309\n",
      "step 6530, cost 21.1241\n",
      "step 6530, change in cost 0.0468082\n",
      "step 6540, training accuracy 0.894309\n",
      "step 6540, cost 21.0773\n",
      "step 6540, change in cost 0.0468273\n",
      "step 6550, training accuracy 0.894309\n",
      "step 6550, cost 21.0305\n",
      "step 6550, change in cost 0.0468292\n",
      "step 6560, training accuracy 0.894309\n",
      "step 6560, cost 20.9836\n",
      "step 6560, change in cost 0.0468407\n",
      "step 6570, training accuracy 0.894309\n",
      "step 6570, cost 20.9368\n",
      "step 6570, change in cost 0.0468521\n",
      "step 6580, training accuracy 0.894309\n",
      "step 6580, cost 20.8899\n",
      "step 6580, change in cost 0.0468674\n",
      "step 6590, training accuracy 0.894309\n",
      "step 6590, cost 20.843\n",
      "step 6590, change in cost 0.0468788\n",
      "step 6600, training accuracy 0.894309\n",
      "step 6600, cost 20.7961\n",
      "step 6600, change in cost 0.0468979\n",
      "step 6610, training accuracy 0.894309\n",
      "step 6610, cost 20.7492\n",
      "step 6610, change in cost 0.0469055\n",
      "step 6620, training accuracy 0.894309\n",
      "step 6620, cost 20.7023\n",
      "step 6620, change in cost 0.0469093\n",
      "step 6630, training accuracy 0.894309\n",
      "step 6630, cost 20.6554\n",
      "step 6630, change in cost 0.0469284\n",
      "step 6640, training accuracy 0.894309\n",
      "step 6640, cost 20.6084\n",
      "step 6640, change in cost 0.046936\n",
      "step 6650, training accuracy 0.894309\n",
      "step 6650, cost 20.5615\n",
      "step 6650, change in cost 0.046936\n",
      "step 6660, training accuracy 0.894309\n",
      "step 6660, cost 20.5146\n",
      "step 6660, change in cost 0.0469379\n",
      "step 6670, training accuracy 0.894309\n",
      "step 6670, cost 20.4676\n",
      "step 6670, change in cost 0.0469494\n",
      "step 6680, training accuracy 0.894309\n",
      "step 6680, cost 20.4207\n",
      "step 6680, change in cost 0.0469322\n",
      "step 6690, training accuracy 0.894309\n",
      "step 6690, cost 20.3737\n",
      "step 6690, change in cost 0.0469322\n",
      "step 6700, training accuracy 0.898374\n",
      "step 6700, cost 20.3268\n",
      "step 6700, change in cost 0.0469055\n",
      "step 6710, training accuracy 0.898374\n",
      "step 6710, cost 20.2799\n",
      "step 6710, change in cost 0.0468941\n",
      "step 6720, training accuracy 0.898374\n",
      "step 6720, cost 20.2331\n",
      "step 6720, change in cost 0.0468502\n",
      "step 6730, training accuracy 0.898374\n",
      "step 6730, cost 20.1863\n",
      "step 6730, change in cost 0.0468273\n",
      "step 6740, training accuracy 0.902439\n",
      "step 6740, cost 20.1395\n",
      "step 6740, change in cost 0.0467758\n",
      "step 6750, training accuracy 0.902439\n",
      "step 6750, cost 20.0928\n",
      "step 6750, change in cost 0.0467224\n",
      "step 6760, training accuracy 0.902439\n",
      "step 6760, cost 20.0461\n",
      "step 6760, change in cost 0.0466537\n",
      "step 6770, training accuracy 0.902439\n",
      "step 6770, cost 19.9995\n",
      "step 6770, change in cost 0.0465775\n",
      "step 6780, training accuracy 0.906504\n",
      "step 6780, cost 19.953\n",
      "step 6780, change in cost 0.0464935\n",
      "step 6790, training accuracy 0.906504\n",
      "step 6790, cost 19.9067\n",
      "step 6790, change in cost 0.0463924\n",
      "step 6800, training accuracy 0.906504\n",
      "step 6800, cost 19.8604\n",
      "step 6800, change in cost 0.046278\n",
      "step 6810, training accuracy 0.910569\n",
      "step 6810, cost 19.8142\n",
      "step 6810, change in cost 0.0461559\n",
      "step 6820, training accuracy 0.910569\n",
      "step 6820, cost 19.7682\n",
      "step 6820, change in cost 0.0460186\n",
      "step 6830, training accuracy 0.910569\n",
      "step 6830, cost 19.7223\n",
      "step 6830, change in cost 0.0458603\n",
      "step 6840, training accuracy 0.910569\n",
      "step 6840, cost 19.6766\n",
      "step 6840, change in cost 0.0456944\n",
      "step 6850, training accuracy 0.910569\n",
      "step 6850, cost 19.6311\n",
      "step 6850, change in cost 0.0455151\n",
      "step 6860, training accuracy 0.910569\n",
      "step 6860, cost 19.5858\n",
      "step 6860, change in cost 0.0453224\n",
      "step 6870, training accuracy 0.910569\n",
      "step 6870, cost 19.5407\n",
      "step 6870, change in cost 0.0451164\n",
      "step 6880, training accuracy 0.910569\n",
      "step 6880, cost 19.4958\n",
      "step 6880, change in cost 0.0448952\n",
      "step 6890, training accuracy 0.910569\n",
      "step 6890, cost 19.4511\n",
      "step 6890, change in cost 0.0446529\n",
      "step 6900, training accuracy 0.910569\n",
      "step 6900, cost 19.4067\n",
      "step 6900, change in cost 0.0444164\n",
      "step 6910, training accuracy 0.910569\n",
      "step 6910, cost 19.3626\n",
      "step 6910, change in cost 0.0441589\n",
      "step 6920, training accuracy 0.910569\n",
      "step 6920, cost 19.3187\n",
      "step 6920, change in cost 0.0438843\n",
      "step 6930, training accuracy 0.910569\n",
      "step 6930, cost 19.2751\n",
      "step 6930, change in cost 0.043602\n",
      "step 6940, training accuracy 0.910569\n",
      "step 6940, cost 19.2318\n",
      "step 6940, change in cost 0.0433083\n",
      "step 6950, training accuracy 0.910569\n",
      "step 6950, cost 19.1888\n",
      "step 6950, change in cost 0.0430183\n",
      "step 6960, training accuracy 0.910569\n",
      "step 6960, cost 19.146\n",
      "step 6960, change in cost 0.0427113\n",
      "step 6970, training accuracy 0.910569\n",
      "step 6970, cost 19.1037\n",
      "step 6970, change in cost 0.0423927\n",
      "step 6980, training accuracy 0.910569\n",
      "step 6980, cost 19.0616\n",
      "step 6980, change in cost 0.0420666\n",
      "step 6990, training accuracy 0.910569\n",
      "step 6990, cost 19.0198\n",
      "step 6990, change in cost 0.04175\n",
      "step 7000, training accuracy 0.910569\n",
      "step 7000, cost 18.9784\n",
      "step 7000, change in cost 0.0414066\n",
      "step 7010, training accuracy 0.910569\n",
      "step 7010, cost 18.9373\n",
      "step 7010, change in cost 0.0410805\n",
      "step 7020, training accuracy 0.910569\n",
      "step 7020, cost 18.8966\n",
      "step 7020, change in cost 0.040741\n",
      "step 7030, training accuracy 0.910569\n",
      "step 7030, cost 18.8562\n",
      "step 7030, change in cost 0.0403976\n",
      "step 7040, training accuracy 0.910569\n",
      "step 7040, cost 18.8161\n",
      "step 7040, change in cost 0.040062\n",
      "step 7050, training accuracy 0.910569\n",
      "step 7050, cost 18.7764\n",
      "step 7050, change in cost 0.0397148\n",
      "step 7060, training accuracy 0.910569\n",
      "step 7060, cost 18.7371\n",
      "step 7060, change in cost 0.0393829\n",
      "step 7070, training accuracy 0.910569\n",
      "step 7070, cost 18.698\n",
      "step 7070, change in cost 0.0390396\n",
      "step 7080, training accuracy 0.910569\n",
      "step 7080, cost 18.6593\n",
      "step 7080, change in cost 0.0387039\n",
      "step 7090, training accuracy 0.910569\n",
      "step 7090, cost 18.6209\n",
      "step 7090, change in cost 0.0383644\n",
      "step 7100, training accuracy 0.910569\n",
      "step 7100, cost 18.5829\n",
      "step 7100, change in cost 0.0380363\n",
      "step 7110, training accuracy 0.910569\n",
      "step 7110, cost 18.5452\n",
      "step 7110, change in cost 0.0377121\n",
      "step 7120, training accuracy 0.914634\n",
      "step 7120, cost 18.5078\n",
      "step 7120, change in cost 0.0373878\n",
      "step 7130, training accuracy 0.914634\n",
      "step 7130, cost 18.4707\n",
      "step 7130, change in cost 0.037075\n",
      "step 7140, training accuracy 0.914634\n",
      "step 7140, cost 18.434\n",
      "step 7140, change in cost 0.0367527\n",
      "step 7150, training accuracy 0.914634\n",
      "step 7150, cost 18.3975\n",
      "step 7150, change in cost 0.0364513\n",
      "step 7160, training accuracy 0.914634\n",
      "step 7160, cost 18.3614\n",
      "step 7160, change in cost 0.03615\n",
      "step 7170, training accuracy 0.914634\n",
      "step 7170, cost 18.3255\n",
      "step 7170, change in cost 0.0358486\n",
      "step 7180, training accuracy 0.914634\n",
      "step 7180, cost 18.29\n",
      "step 7180, change in cost 0.0355644\n",
      "step 7190, training accuracy 0.914634\n",
      "step 7190, cost 18.2547\n",
      "step 7190, change in cost 0.0352821\n",
      "step 7200, training accuracy 0.914634\n",
      "step 7200, cost 18.2197\n",
      "step 7200, change in cost 0.0350018\n",
      "step 7210, training accuracy 0.914634\n",
      "step 7210, cost 18.1849\n",
      "step 7210, change in cost 0.0347347\n",
      "step 7220, training accuracy 0.914634\n",
      "step 7220, cost 18.1505\n",
      "step 7220, change in cost 0.0344772\n",
      "step 7230, training accuracy 0.914634\n",
      "step 7230, cost 18.1162\n",
      "step 7230, change in cost 0.0342216\n",
      "step 7240, training accuracy 0.914634\n",
      "step 7240, cost 18.0823\n",
      "step 7240, change in cost 0.0339699\n",
      "step 7250, training accuracy 0.914634\n",
      "step 7250, cost 18.0485\n",
      "step 7250, change in cost 0.0337315\n",
      "step 7260, training accuracy 0.914634\n",
      "step 7260, cost 18.015\n",
      "step 7260, change in cost 0.0334988\n",
      "step 7270, training accuracy 0.918699\n",
      "step 7270, cost 17.9818\n",
      "step 7270, change in cost 0.0332642\n",
      "step 7280, training accuracy 0.918699\n",
      "step 7280, cost 17.9487\n",
      "step 7280, change in cost 0.0330544\n",
      "step 7290, training accuracy 0.918699\n",
      "step 7290, cost 17.9159\n",
      "step 7290, change in cost 0.032835\n",
      "step 7300, training accuracy 0.918699\n",
      "step 7300, cost 17.8833\n",
      "step 7300, change in cost 0.0326214\n",
      "step 7310, training accuracy 0.918699\n",
      "step 7310, cost 17.8508\n",
      "step 7310, change in cost 0.0324306\n",
      "step 7320, training accuracy 0.918699\n",
      "step 7320, cost 17.8186\n",
      "step 7320, change in cost 0.0322361\n",
      "step 7330, training accuracy 0.918699\n",
      "step 7330, cost 17.7866\n",
      "step 7330, change in cost 0.0320377\n",
      "step 7340, training accuracy 0.918699\n",
      "step 7340, cost 17.7547\n",
      "step 7340, change in cost 0.0318661\n",
      "step 7350, training accuracy 0.918699\n",
      "step 7350, cost 17.723\n",
      "step 7350, change in cost 0.0316887\n",
      "step 7360, training accuracy 0.918699\n",
      "step 7360, cost 17.6915\n",
      "step 7360, change in cost 0.031517\n",
      "step 7370, training accuracy 0.918699\n",
      "step 7370, cost 17.6601\n",
      "step 7370, change in cost 0.0313492\n",
      "step 7380, training accuracy 0.918699\n",
      "step 7380, cost 17.629\n",
      "step 7380, change in cost 0.031189\n",
      "step 7390, training accuracy 0.918699\n",
      "step 7390, cost 17.5979\n",
      "step 7390, change in cost 0.0310402\n",
      "step 7400, training accuracy 0.918699\n",
      "step 7400, cost 17.567\n",
      "step 7400, change in cost 0.0308838\n",
      "step 7410, training accuracy 0.918699\n",
      "step 7410, cost 17.5363\n",
      "step 7410, change in cost 0.030735\n",
      "step 7420, training accuracy 0.918699\n",
      "step 7420, cost 17.5057\n",
      "step 7420, change in cost 0.0305977\n",
      "step 7430, training accuracy 0.918699\n",
      "step 7430, cost 17.4752\n",
      "step 7430, change in cost 0.0304565\n",
      "step 7440, training accuracy 0.918699\n",
      "step 7440, cost 17.4449\n",
      "step 7440, change in cost 0.0303307\n",
      "step 7450, training accuracy 0.918699\n",
      "step 7450, cost 17.4147\n",
      "step 7450, change in cost 0.0301933\n",
      "step 7460, training accuracy 0.918699\n",
      "step 7460, cost 17.3847\n",
      "step 7460, change in cost 0.0300655\n",
      "step 7470, training accuracy 0.918699\n",
      "step 7470, cost 17.3547\n",
      "step 7470, change in cost 0.0299435\n",
      "step 7480, training accuracy 0.918699\n",
      "step 7480, cost 17.3249\n",
      "step 7480, change in cost 0.0298233\n",
      "step 7490, training accuracy 0.918699\n",
      "step 7490, cost 17.2952\n",
      "step 7490, change in cost 0.0296974\n",
      "step 7500, training accuracy 0.918699\n",
      "step 7500, cost 17.2656\n",
      "step 7500, change in cost 0.029583\n",
      "step 7510, training accuracy 0.918699\n",
      "step 7510, cost 17.2361\n",
      "step 7510, change in cost 0.0294647\n",
      "step 7520, training accuracy 0.918699\n",
      "step 7520, cost 17.2068\n",
      "step 7520, change in cost 0.0293636\n",
      "step 7530, training accuracy 0.918699\n",
      "step 7530, cost 17.1775\n",
      "step 7530, change in cost 0.0292435\n",
      "step 7540, training accuracy 0.918699\n",
      "step 7540, cost 17.1484\n",
      "step 7540, change in cost 0.0291348\n",
      "step 7550, training accuracy 0.918699\n",
      "step 7550, cost 17.1194\n",
      "step 7550, change in cost 0.0290184\n",
      "step 7560, training accuracy 0.918699\n",
      "step 7560, cost 17.0905\n",
      "step 7560, change in cost 0.0289135\n",
      "step 7570, training accuracy 0.918699\n",
      "step 7570, cost 17.0617\n",
      "step 7570, change in cost 0.0288029\n",
      "step 7580, training accuracy 0.918699\n",
      "step 7580, cost 17.033\n",
      "step 7580, change in cost 0.0286922\n",
      "step 7590, training accuracy 0.918699\n",
      "step 7590, cost 17.0044\n",
      "step 7590, change in cost 0.0285854\n",
      "step 7600, training accuracy 0.918699\n",
      "step 7600, cost 16.9759\n",
      "step 7600, change in cost 0.0284729\n",
      "step 7610, training accuracy 0.918699\n",
      "step 7610, cost 16.9476\n",
      "step 7610, change in cost 0.0283604\n",
      "step 7620, training accuracy 0.918699\n",
      "step 7620, cost 16.9193\n",
      "step 7620, change in cost 0.0282516\n",
      "step 7630, training accuracy 0.918699\n",
      "step 7630, cost 16.8912\n",
      "step 7630, change in cost 0.0281429\n",
      "step 7640, training accuracy 0.918699\n",
      "step 7640, cost 16.8631\n",
      "step 7640, change in cost 0.0280285\n",
      "step 7650, training accuracy 0.918699\n",
      "step 7650, cost 16.8352\n",
      "step 7650, change in cost 0.0279064\n",
      "step 7660, training accuracy 0.918699\n",
      "step 7660, cost 16.8074\n",
      "step 7660, change in cost 0.0277901\n",
      "step 7670, training accuracy 0.918699\n",
      "step 7670, cost 16.7798\n",
      "step 7670, change in cost 0.0276756\n",
      "step 7680, training accuracy 0.918699\n",
      "step 7680, cost 16.7522\n",
      "step 7680, change in cost 0.0275536\n",
      "step 7690, training accuracy 0.918699\n",
      "step 7690, cost 16.7248\n",
      "step 7690, change in cost 0.0274258\n",
      "step 7700, training accuracy 0.918699\n",
      "step 7700, cost 16.6975\n",
      "step 7700, change in cost 0.0273037\n",
      "step 7710, training accuracy 0.918699\n",
      "step 7710, cost 16.6703\n",
      "step 7710, change in cost 0.0271759\n",
      "step 7720, training accuracy 0.918699\n",
      "step 7720, cost 16.6433\n",
      "step 7720, change in cost 0.0270462\n",
      "step 7730, training accuracy 0.918699\n",
      "step 7730, cost 16.6164\n",
      "step 7730, change in cost 0.0269051\n",
      "step 7740, training accuracy 0.918699\n",
      "step 7740, cost 16.5896\n",
      "step 7740, change in cost 0.0267735\n",
      "step 7750, training accuracy 0.918699\n",
      "step 7750, cost 16.5629\n",
      "step 7750, change in cost 0.0266342\n",
      "step 7760, training accuracy 0.918699\n",
      "step 7760, cost 16.5364\n",
      "step 7760, change in cost 0.0264969\n",
      "step 7770, training accuracy 0.918699\n",
      "step 7770, cost 16.5101\n",
      "step 7770, change in cost 0.0263443\n",
      "step 7780, training accuracy 0.922764\n",
      "step 7780, cost 16.4839\n",
      "step 7780, change in cost 0.0261974\n",
      "step 7790, training accuracy 0.922764\n",
      "step 7790, cost 16.4579\n",
      "step 7790, change in cost 0.0260487\n",
      "step 7800, training accuracy 0.922764\n",
      "step 7800, cost 16.432\n",
      "step 7800, change in cost 0.0258942\n",
      "step 7810, training accuracy 0.922764\n",
      "step 7810, cost 16.4062\n",
      "step 7810, change in cost 0.0257397\n",
      "step 7820, training accuracy 0.922764\n",
      "step 7820, cost 16.3806\n",
      "step 7820, change in cost 0.0255756\n",
      "step 7830, training accuracy 0.922764\n",
      "step 7830, cost 16.3552\n",
      "step 7830, change in cost 0.0254173\n",
      "step 7840, training accuracy 0.922764\n",
      "step 7840, cost 16.33\n",
      "step 7840, change in cost 0.0252571\n",
      "step 7850, training accuracy 0.922764\n",
      "step 7850, cost 16.3049\n",
      "step 7850, change in cost 0.0250854\n",
      "step 7860, training accuracy 0.922764\n",
      "step 7860, cost 16.28\n",
      "step 7860, change in cost 0.0249176\n",
      "step 7870, training accuracy 0.922764\n",
      "step 7870, cost 16.2552\n",
      "step 7870, change in cost 0.024744\n",
      "step 7880, training accuracy 0.922764\n",
      "step 7880, cost 16.2307\n",
      "step 7880, change in cost 0.0245686\n",
      "step 7890, training accuracy 0.922764\n",
      "step 7890, cost 16.2063\n",
      "step 7890, change in cost 0.0243988\n",
      "step 7900, training accuracy 0.922764\n",
      "step 7900, cost 16.182\n",
      "step 7900, change in cost 0.0242119\n",
      "step 7910, training accuracy 0.922764\n",
      "step 7910, cost 16.158\n",
      "step 7910, change in cost 0.0240402\n",
      "step 7920, training accuracy 0.922764\n",
      "step 7920, cost 16.1341\n",
      "step 7920, change in cost 0.023859\n",
      "step 7930, training accuracy 0.922764\n",
      "step 7930, cost 16.1105\n",
      "step 7930, change in cost 0.0236664\n",
      "step 7940, training accuracy 0.922764\n",
      "step 7940, cost 16.087\n",
      "step 7940, change in cost 0.0234947\n",
      "step 7950, training accuracy 0.922764\n",
      "step 7950, cost 16.0637\n",
      "step 7950, change in cost 0.0233021\n",
      "step 7960, training accuracy 0.922764\n",
      "step 7960, cost 16.0406\n",
      "step 7960, change in cost 0.0231247\n",
      "step 7970, training accuracy 0.922764\n",
      "step 7970, cost 16.0176\n",
      "step 7970, change in cost 0.0229321\n",
      "step 7980, training accuracy 0.922764\n",
      "step 7980, cost 15.9949\n",
      "step 7980, change in cost 0.0227461\n",
      "step 7990, training accuracy 0.922764\n",
      "step 7990, cost 15.9723\n",
      "step 7990, change in cost 0.0225582\n",
      "step 8000, training accuracy 0.922764\n",
      "step 8000, cost 15.9499\n",
      "step 8000, change in cost 0.0223751\n",
      "step 8010, training accuracy 0.922764\n",
      "step 8010, cost 15.9278\n",
      "step 8010, change in cost 0.0221834\n",
      "step 8020, training accuracy 0.922764\n",
      "step 8020, cost 15.9058\n",
      "step 8020, change in cost 0.0219965\n",
      "step 8030, training accuracy 0.922764\n",
      "step 8030, cost 15.884\n",
      "step 8030, change in cost 0.0218096\n",
      "step 8040, training accuracy 0.922764\n",
      "step 8040, cost 15.8623\n",
      "step 8040, change in cost 0.0216217\n",
      "step 8050, training accuracy 0.922764\n",
      "step 8050, cost 15.8409\n",
      "step 8050, change in cost 0.0214396\n",
      "step 8060, training accuracy 0.922764\n",
      "step 8060, cost 15.8196\n",
      "step 8060, change in cost 0.0212555\n",
      "step 8070, training accuracy 0.922764\n",
      "step 8070, cost 15.7986\n",
      "step 8070, change in cost 0.0210686\n",
      "step 8080, training accuracy 0.922764\n",
      "step 8080, cost 15.7777\n",
      "step 8080, change in cost 0.0208864\n",
      "step 8090, training accuracy 0.922764\n",
      "step 8090, cost 15.757\n",
      "step 8090, change in cost 0.020709\n",
      "step 8100, training accuracy 0.922764\n",
      "step 8100, cost 15.7364\n",
      "step 8100, change in cost 0.0205269\n",
      "step 8110, training accuracy 0.922764\n",
      "step 8110, cost 15.7161\n",
      "step 8110, change in cost 0.0203495\n",
      "step 8120, training accuracy 0.922764\n",
      "step 8120, cost 15.6959\n",
      "step 8120, change in cost 0.0201693\n",
      "step 8130, training accuracy 0.922764\n",
      "step 8130, cost 15.6759\n",
      "step 8130, change in cost 0.0199947\n",
      "step 8140, training accuracy 0.922764\n",
      "step 8140, cost 15.6561\n",
      "step 8140, change in cost 0.0198278\n",
      "step 8150, training accuracy 0.922764\n",
      "step 8150, cost 15.6365\n",
      "step 8150, change in cost 0.0196524\n",
      "step 8160, training accuracy 0.922764\n",
      "step 8160, cost 15.617\n",
      "step 8160, change in cost 0.0194836\n",
      "step 8170, training accuracy 0.922764\n",
      "step 8170, cost 15.5977\n",
      "step 8170, change in cost 0.019311\n",
      "step 8180, training accuracy 0.922764\n",
      "step 8180, cost 15.5785\n",
      "step 8180, change in cost 0.0191593\n",
      "step 8190, training accuracy 0.922764\n",
      "step 8190, cost 15.5595\n",
      "step 8190, change in cost 0.0189886\n",
      "step 8200, training accuracy 0.922764\n",
      "step 8200, cost 15.5407\n",
      "step 8200, change in cost 0.0188322\n",
      "step 8210, training accuracy 0.922764\n",
      "step 8210, cost 15.522\n",
      "step 8210, change in cost 0.0186729\n",
      "step 8220, training accuracy 0.922764\n",
      "step 8220, cost 15.5035\n",
      "step 8220, change in cost 0.0185223\n",
      "step 8230, training accuracy 0.922764\n",
      "step 8230, cost 15.4851\n",
      "step 8230, change in cost 0.0183649\n",
      "step 8240, training accuracy 0.922764\n",
      "step 8240, cost 15.4669\n",
      "step 8240, change in cost 0.0182219\n",
      "step 8250, training accuracy 0.922764\n",
      "step 8250, cost 15.4488\n",
      "step 8250, change in cost 0.0180683\n",
      "step 8260, training accuracy 0.922764\n",
      "step 8260, cost 15.4309\n",
      "step 8260, change in cost 0.017931\n",
      "step 8270, training accuracy 0.922764\n",
      "step 8270, cost 15.4131\n",
      "step 8270, change in cost 0.0177832\n",
      "step 8280, training accuracy 0.926829\n",
      "step 8280, cost 15.3955\n",
      "step 8280, change in cost 0.0176535\n",
      "step 8290, training accuracy 0.926829\n",
      "step 8290, cost 15.3779\n",
      "step 8290, change in cost 0.0175152\n",
      "step 8300, training accuracy 0.926829\n",
      "step 8300, cost 15.3606\n",
      "step 8300, change in cost 0.0173855\n",
      "step 8310, training accuracy 0.926829\n",
      "step 8310, cost 15.3433\n",
      "step 8310, change in cost 0.0172491\n",
      "step 8320, training accuracy 0.926829\n",
      "step 8320, cost 15.3262\n",
      "step 8320, change in cost 0.0171232\n",
      "step 8330, training accuracy 0.926829\n",
      "step 8330, cost 15.3092\n",
      "step 8330, change in cost 0.0170059\n",
      "step 8340, training accuracy 0.926829\n",
      "step 8340, cost 15.2923\n",
      "step 8340, change in cost 0.0168781\n",
      "step 8350, training accuracy 0.926829\n",
      "step 8350, cost 15.2755\n",
      "step 8350, change in cost 0.0167589\n",
      "step 8360, training accuracy 0.926829\n",
      "step 8360, cost 15.2589\n",
      "step 8360, change in cost 0.0166521\n",
      "step 8370, training accuracy 0.926829\n",
      "step 8370, cost 15.2424\n",
      "step 8370, change in cost 0.0165348\n",
      "step 8380, training accuracy 0.926829\n",
      "step 8380, cost 15.2259\n",
      "step 8380, change in cost 0.016428\n",
      "step 8390, training accuracy 0.926829\n",
      "step 8390, cost 15.2096\n",
      "step 8390, change in cost 0.0163193\n",
      "step 8400, training accuracy 0.926829\n",
      "step 8400, cost 15.1934\n",
      "step 8400, change in cost 0.0162096\n",
      "step 8410, training accuracy 0.926829\n",
      "step 8410, cost 15.1773\n",
      "step 8410, change in cost 0.0161219\n",
      "step 8420, training accuracy 0.926829\n",
      "step 8420, cost 15.1613\n",
      "step 8420, change in cost 0.0160179\n",
      "step 8430, training accuracy 0.926829\n",
      "step 8430, cost 15.1453\n",
      "step 8430, change in cost 0.0159216\n",
      "step 8440, training accuracy 0.926829\n",
      "step 8440, cost 15.1295\n",
      "step 8440, change in cost 0.0158339\n",
      "step 8450, training accuracy 0.926829\n",
      "step 8450, cost 15.1138\n",
      "step 8450, change in cost 0.0157404\n",
      "step 8460, training accuracy 0.926829\n",
      "step 8460, cost 15.0981\n",
      "step 8460, change in cost 0.0156546\n",
      "step 8470, training accuracy 0.926829\n",
      "step 8470, cost 15.0825\n",
      "step 8470, change in cost 0.0155716\n",
      "step 8480, training accuracy 0.926829\n",
      "step 8480, cost 15.067\n",
      "step 8480, change in cost 0.0154943\n",
      "step 8490, training accuracy 0.926829\n",
      "step 8490, cost 15.0516\n",
      "step 8490, change in cost 0.0154142\n",
      "step 8500, training accuracy 0.926829\n",
      "step 8500, cost 15.0363\n",
      "step 8500, change in cost 0.0153303\n",
      "step 8510, training accuracy 0.926829\n",
      "step 8510, cost 15.021\n",
      "step 8510, change in cost 0.0152578\n",
      "step 8520, training accuracy 0.926829\n",
      "step 8520, cost 15.0058\n",
      "step 8520, change in cost 0.0152016\n",
      "step 8530, training accuracy 0.926829\n",
      "step 8530, cost 14.9907\n",
      "step 8530, change in cost 0.0151262\n",
      "step 8540, training accuracy 0.926829\n",
      "step 8540, cost 14.9757\n",
      "step 8540, change in cost 0.0150604\n",
      "step 8550, training accuracy 0.926829\n",
      "step 8550, cost 14.9607\n",
      "step 8550, change in cost 0.0149965\n",
      "step 8560, training accuracy 0.926829\n",
      "step 8560, cost 14.9457\n",
      "step 8560, change in cost 0.0149403\n",
      "step 8570, training accuracy 0.926829\n",
      "step 8570, cost 14.9308\n",
      "step 8570, change in cost 0.014883\n",
      "step 8580, training accuracy 0.926829\n",
      "step 8580, cost 14.916\n",
      "step 8580, change in cost 0.014822\n",
      "step 8590, training accuracy 0.926829\n",
      "step 8590, cost 14.9012\n",
      "step 8590, change in cost 0.0147705\n",
      "step 8600, training accuracy 0.926829\n",
      "step 8600, cost 14.8865\n",
      "step 8600, change in cost 0.0147209\n",
      "step 8610, training accuracy 0.926829\n",
      "step 8610, cost 14.8718\n",
      "step 8610, change in cost 0.0146742\n",
      "step 8620, training accuracy 0.926829\n",
      "step 8620, cost 14.8572\n",
      "step 8620, change in cost 0.0146284\n",
      "step 8630, training accuracy 0.926829\n",
      "step 8630, cost 14.8426\n",
      "step 8630, change in cost 0.0145836\n",
      "step 8640, training accuracy 0.926829\n",
      "step 8640, cost 14.8281\n",
      "step 8640, change in cost 0.0145473\n",
      "step 8650, training accuracy 0.926829\n",
      "step 8650, cost 14.8136\n",
      "step 8650, change in cost 0.0145035\n",
      "step 8660, training accuracy 0.930894\n",
      "step 8660, cost 14.7991\n",
      "step 8660, change in cost 0.0144663\n",
      "step 8670, training accuracy 0.930894\n",
      "step 8670, cost 14.7847\n",
      "step 8670, change in cost 0.0144358\n",
      "step 8680, training accuracy 0.930894\n",
      "step 8680, cost 14.7703\n",
      "step 8680, change in cost 0.0143967\n",
      "step 8690, training accuracy 0.930894\n",
      "step 8690, cost 14.7559\n",
      "step 8690, change in cost 0.0143728\n",
      "step 8700, training accuracy 0.930894\n",
      "step 8700, cost 14.7416\n",
      "step 8700, change in cost 0.0143347\n",
      "step 8710, training accuracy 0.930894\n",
      "step 8710, cost 14.7273\n",
      "step 8710, change in cost 0.0143185\n",
      "step 8720, training accuracy 0.930894\n",
      "step 8720, cost 14.713\n",
      "step 8720, change in cost 0.0142908\n",
      "step 8730, training accuracy 0.930894\n",
      "step 8730, cost 14.6987\n",
      "step 8730, change in cost 0.014266\n",
      "step 8740, training accuracy 0.930894\n",
      "step 8740, cost 14.6845\n",
      "step 8740, change in cost 0.0142479\n",
      "step 8750, training accuracy 0.930894\n",
      "step 8750, cost 14.6702\n",
      "step 8750, change in cost 0.014225\n",
      "step 8760, training accuracy 0.930894\n",
      "step 8760, cost 14.656\n",
      "step 8760, change in cost 0.0142136\n",
      "step 8770, training accuracy 0.930894\n",
      "step 8770, cost 14.6418\n",
      "step 8770, change in cost 0.0141973\n",
      "step 8780, training accuracy 0.930894\n",
      "step 8780, cost 14.6276\n",
      "step 8780, change in cost 0.0141754\n",
      "step 8790, training accuracy 0.930894\n",
      "step 8790, cost 14.6135\n",
      "step 8790, change in cost 0.0141706\n",
      "step 8800, training accuracy 0.930894\n",
      "step 8800, cost 14.5993\n",
      "step 8800, change in cost 0.0141582\n",
      "step 8810, training accuracy 0.930894\n",
      "step 8810, cost 14.5852\n",
      "step 8810, change in cost 0.0141506\n",
      "step 8820, training accuracy 0.930894\n",
      "step 8820, cost 14.571\n",
      "step 8820, change in cost 0.0141449\n",
      "step 8830, training accuracy 0.930894\n",
      "step 8830, cost 14.5569\n",
      "step 8830, change in cost 0.0141392\n",
      "step 8840, training accuracy 0.930894\n",
      "step 8840, cost 14.5427\n",
      "step 8840, change in cost 0.0141344\n",
      "step 8850, training accuracy 0.930894\n",
      "step 8850, cost 14.5286\n",
      "step 8850, change in cost 0.0141306\n",
      "step 8860, training accuracy 0.930894\n",
      "step 8860, cost 14.5145\n",
      "step 8860, change in cost 0.0141325\n",
      "step 8870, training accuracy 0.930894\n",
      "step 8870, cost 14.5004\n",
      "step 8870, change in cost 0.0141268\n",
      "step 8880, training accuracy 0.930894\n",
      "step 8880, cost 14.4862\n",
      "step 8880, change in cost 0.0141315\n",
      "step 8890, training accuracy 0.930894\n",
      "step 8890, cost 14.4721\n",
      "step 8890, change in cost 0.0141325\n",
      "step 8900, training accuracy 0.930894\n",
      "step 8900, cost 14.458\n",
      "step 8900, change in cost 0.0141344\n",
      "step 8910, training accuracy 0.930894\n",
      "step 8910, cost 14.4438\n",
      "step 8910, change in cost 0.0141392\n",
      "step 8920, training accuracy 0.930894\n",
      "step 8920, cost 14.4297\n",
      "step 8920, change in cost 0.0141449\n",
      "step 8930, training accuracy 0.930894\n",
      "step 8930, cost 14.4155\n",
      "step 8930, change in cost 0.0141516\n",
      "step 8940, training accuracy 0.930894\n",
      "step 8940, cost 14.4014\n",
      "step 8940, change in cost 0.014163\n",
      "step 8950, training accuracy 0.930894\n",
      "step 8950, cost 14.3872\n",
      "step 8950, change in cost 0.0141687\n",
      "step 8960, training accuracy 0.930894\n",
      "step 8960, cost 14.373\n",
      "step 8960, change in cost 0.0141745\n",
      "step 8970, training accuracy 0.930894\n",
      "step 8970, cost 14.3588\n",
      "step 8970, change in cost 0.0141897\n",
      "step 8980, training accuracy 0.930894\n",
      "step 8980, cost 14.3446\n",
      "step 8980, change in cost 0.014205\n",
      "step 8990, training accuracy 0.930894\n",
      "step 8990, cost 14.3304\n",
      "step 8990, change in cost 0.0142069\n",
      "step 9000, training accuracy 0.930894\n",
      "step 9000, cost 14.3162\n",
      "step 9000, change in cost 0.0142202\n",
      "step 9010, training accuracy 0.930894\n",
      "step 9010, cost 14.302\n",
      "step 9010, change in cost 0.0142317\n",
      "step 9020, training accuracy 0.930894\n",
      "step 9020, cost 14.2877\n",
      "step 9020, change in cost 0.0142488\n",
      "step 9030, training accuracy 0.930894\n",
      "step 9030, cost 14.2735\n",
      "step 9030, change in cost 0.0142555\n",
      "step 9040, training accuracy 0.930894\n",
      "step 9040, cost 14.2592\n",
      "step 9040, change in cost 0.0142775\n",
      "step 9050, training accuracy 0.930894\n",
      "step 9050, cost 14.2449\n",
      "step 9050, change in cost 0.0142832\n",
      "step 9060, training accuracy 0.930894\n",
      "step 9060, cost 14.2306\n",
      "step 9060, change in cost 0.0143013\n",
      "step 9070, training accuracy 0.930894\n",
      "step 9070, cost 14.2163\n",
      "step 9070, change in cost 0.0143099\n",
      "step 9080, training accuracy 0.930894\n",
      "step 9080, cost 14.202\n",
      "step 9080, change in cost 0.0143337\n",
      "step 9090, training accuracy 0.930894\n",
      "step 9090, cost 14.1876\n",
      "step 9090, change in cost 0.0143414\n",
      "step 9100, training accuracy 0.930894\n",
      "step 9100, cost 14.1733\n",
      "step 9100, change in cost 0.0143557\n",
      "step 9110, training accuracy 0.930894\n",
      "step 9110, cost 14.1589\n",
      "step 9110, change in cost 0.0143719\n",
      "step 9120, training accuracy 0.930894\n",
      "step 9120, cost 14.1445\n",
      "step 9120, change in cost 0.0143805\n",
      "step 9130, training accuracy 0.930894\n",
      "step 9130, cost 14.1301\n",
      "step 9130, change in cost 0.0144014\n",
      "step 9140, training accuracy 0.930894\n",
      "step 9140, cost 14.1157\n",
      "step 9140, change in cost 0.0144157\n",
      "step 9150, training accuracy 0.930894\n",
      "step 9150, cost 14.1013\n",
      "step 9150, change in cost 0.0144196\n",
      "step 9160, training accuracy 0.930894\n",
      "step 9160, cost 14.0868\n",
      "step 9160, change in cost 0.0144358\n",
      "step 9170, training accuracy 0.930894\n",
      "step 9170, cost 14.0724\n",
      "step 9170, change in cost 0.0144539\n",
      "step 9180, training accuracy 0.930894\n",
      "step 9180, cost 14.0579\n",
      "step 9180, change in cost 0.0144606\n",
      "step 9190, training accuracy 0.930894\n",
      "step 9190, cost 14.0434\n",
      "step 9190, change in cost 0.0144739\n",
      "step 9200, training accuracy 0.930894\n",
      "step 9200, cost 14.029\n",
      "step 9200, change in cost 0.0144835\n",
      "step 9210, training accuracy 0.930894\n",
      "step 9210, cost 14.0145\n",
      "step 9210, change in cost 0.014492\n",
      "step 9220, training accuracy 0.930894\n",
      "step 9220, cost 14\n",
      "step 9220, change in cost 0.0145006\n",
      "step 9230, training accuracy 0.930894\n",
      "step 9230, cost 13.9855\n",
      "step 9230, change in cost 0.0145149\n",
      "step 9240, training accuracy 0.930894\n",
      "step 9240, cost 13.9709\n",
      "step 9240, change in cost 0.0145178\n",
      "step 9250, training accuracy 0.930894\n",
      "step 9250, cost 13.9564\n",
      "step 9250, change in cost 0.0145283\n",
      "step 9260, training accuracy 0.930894\n",
      "step 9260, cost 13.9419\n",
      "step 9260, change in cost 0.0145359\n",
      "step 9270, training accuracy 0.934959\n",
      "step 9270, cost 13.9273\n",
      "step 9270, change in cost 0.0145454\n",
      "step 9280, training accuracy 0.934959\n",
      "step 9280, cost 13.9128\n",
      "step 9280, change in cost 0.0145483\n",
      "step 9290, training accuracy 0.934959\n",
      "step 9290, cost 13.8982\n",
      "step 9290, change in cost 0.0145521\n",
      "step 9300, training accuracy 0.934959\n",
      "step 9300, cost 13.8837\n",
      "step 9300, change in cost 0.0145559\n",
      "step 9310, training accuracy 0.934959\n",
      "step 9310, cost 13.8691\n",
      "step 9310, change in cost 0.0145683\n",
      "step 9320, training accuracy 0.934959\n",
      "step 9320, cost 13.8545\n",
      "step 9320, change in cost 0.0145636\n",
      "step 9330, training accuracy 0.934959\n",
      "step 9330, cost 13.84\n",
      "step 9330, change in cost 0.0145683\n",
      "step 9340, training accuracy 0.934959\n",
      "step 9340, cost 13.8254\n",
      "step 9340, change in cost 0.0145741\n",
      "step 9350, training accuracy 0.934959\n",
      "step 9350, cost 13.8108\n",
      "step 9350, change in cost 0.0145712\n",
      "step 9360, training accuracy 0.934959\n",
      "step 9360, cost 13.7962\n",
      "step 9360, change in cost 0.0145779\n",
      "step 9370, training accuracy 0.934959\n",
      "step 9370, cost 13.7817\n",
      "step 9370, change in cost 0.0145769\n",
      "step 9380, training accuracy 0.934959\n",
      "step 9380, cost 13.7671\n",
      "step 9380, change in cost 0.0145817\n",
      "step 9390, training accuracy 0.934959\n",
      "step 9390, cost 13.7525\n",
      "step 9390, change in cost 0.0145769\n",
      "step 9400, training accuracy 0.934959\n",
      "step 9400, cost 13.7379\n",
      "step 9400, change in cost 0.0145817\n",
      "step 9410, training accuracy 0.934959\n",
      "step 9410, cost 13.7233\n",
      "step 9410, change in cost 0.0145836\n",
      "step 9420, training accuracy 0.934959\n",
      "step 9420, cost 13.7088\n",
      "step 9420, change in cost 0.0145836\n",
      "step 9430, training accuracy 0.934959\n",
      "step 9430, cost 13.6942\n",
      "step 9430, change in cost 0.0145836\n",
      "step 9440, training accuracy 0.934959\n",
      "step 9440, cost 13.6796\n",
      "step 9440, change in cost 0.0145864\n",
      "step 9450, training accuracy 0.934959\n",
      "step 9450, cost 13.665\n",
      "step 9450, change in cost 0.0145817\n",
      "step 9460, training accuracy 0.934959\n",
      "step 9460, cost 13.6504\n",
      "step 9460, change in cost 0.0145893\n",
      "step 9470, training accuracy 0.934959\n",
      "step 9470, cost 13.6358\n",
      "step 9470, change in cost 0.0145922\n",
      "step 9480, training accuracy 0.934959\n",
      "step 9480, cost 13.6212\n",
      "step 9480, change in cost 0.0145969\n",
      "step 9490, training accuracy 0.934959\n",
      "step 9490, cost 13.6066\n",
      "step 9490, change in cost 0.0145998\n",
      "step 9500, training accuracy 0.934959\n",
      "step 9500, cost 13.592\n",
      "step 9500, change in cost 0.0146027\n",
      "step 9510, training accuracy 0.934959\n",
      "step 9510, cost 13.5774\n",
      "step 9510, change in cost 0.0146112\n",
      "step 9520, training accuracy 0.934959\n",
      "step 9520, cost 13.5628\n",
      "step 9520, change in cost 0.014617\n",
      "step 9530, training accuracy 0.934959\n",
      "step 9530, cost 13.5482\n",
      "step 9530, change in cost 0.0146255\n",
      "step 9540, training accuracy 0.934959\n",
      "step 9540, cost 13.5335\n",
      "step 9540, change in cost 0.0146351\n",
      "step 9550, training accuracy 0.934959\n",
      "step 9550, cost 13.5189\n",
      "step 9550, change in cost 0.0146437\n",
      "step 9560, training accuracy 0.934959\n",
      "step 9560, cost 13.5042\n",
      "step 9560, change in cost 0.0146542\n",
      "step 9570, training accuracy 0.934959\n",
      "step 9570, cost 13.4896\n",
      "step 9570, change in cost 0.0146742\n",
      "step 9580, training accuracy 0.934959\n",
      "step 9580, cost 13.4749\n",
      "step 9580, change in cost 0.0146904\n",
      "step 9590, training accuracy 0.934959\n",
      "step 9590, cost 13.4602\n",
      "step 9590, change in cost 0.0147057\n",
      "step 9600, training accuracy 0.934959\n",
      "step 9600, cost 13.4454\n",
      "step 9600, change in cost 0.0147247\n",
      "step 9610, training accuracy 0.934959\n",
      "step 9610, cost 13.4307\n",
      "step 9610, change in cost 0.0147476\n",
      "step 9620, training accuracy 0.934959\n",
      "step 9620, cost 13.4159\n",
      "step 9620, change in cost 0.0147696\n",
      "step 9630, training accuracy 0.934959\n",
      "step 9630, cost 13.4011\n",
      "step 9630, change in cost 0.0147972\n",
      "step 9640, training accuracy 0.934959\n",
      "step 9640, cost 13.3863\n",
      "step 9640, change in cost 0.0148268\n",
      "step 9650, training accuracy 0.934959\n",
      "step 9650, cost 13.3714\n",
      "step 9650, change in cost 0.0148621\n",
      "step 9660, training accuracy 0.934959\n",
      "step 9660, cost 13.3566\n",
      "step 9660, change in cost 0.0148897\n",
      "step 9670, training accuracy 0.934959\n",
      "step 9670, cost 13.3416\n",
      "step 9670, change in cost 0.0149317\n",
      "step 9680, training accuracy 0.934959\n",
      "step 9680, cost 13.3267\n",
      "step 9680, change in cost 0.014966\n",
      "step 9690, training accuracy 0.934959\n",
      "step 9690, cost 13.3116\n",
      "step 9690, change in cost 0.0150099\n",
      "step 9700, training accuracy 0.934959\n",
      "step 9700, cost 13.2966\n",
      "step 9700, change in cost 0.0150547\n",
      "step 9710, training accuracy 0.934959\n",
      "step 9710, cost 13.2815\n",
      "step 9710, change in cost 0.0151024\n",
      "step 9720, training accuracy 0.934959\n",
      "step 9720, cost 13.2663\n",
      "step 9720, change in cost 0.0151567\n",
      "step 9730, training accuracy 0.934959\n",
      "step 9730, cost 13.2511\n",
      "step 9730, change in cost 0.0152092\n",
      "step 9740, training accuracy 0.934959\n",
      "step 9740, cost 13.2359\n",
      "step 9740, change in cost 0.0152655\n",
      "step 9750, training accuracy 0.934959\n",
      "step 9750, cost 13.2205\n",
      "step 9750, change in cost 0.0153275\n",
      "step 9760, training accuracy 0.934959\n",
      "step 9760, cost 13.2051\n",
      "step 9760, change in cost 0.0153828\n",
      "step 9770, training accuracy 0.934959\n",
      "step 9770, cost 13.1897\n",
      "step 9770, change in cost 0.0154581\n",
      "step 9780, training accuracy 0.934959\n",
      "step 9780, cost 13.1742\n",
      "step 9780, change in cost 0.0155191\n",
      "step 9790, training accuracy 0.934959\n",
      "step 9790, cost 13.1586\n",
      "step 9790, change in cost 0.0155926\n",
      "step 9800, training accuracy 0.934959\n",
      "step 9800, cost 13.1429\n",
      "step 9800, change in cost 0.0156651\n",
      "step 9810, training accuracy 0.934959\n",
      "step 9810, cost 13.1272\n",
      "step 9810, change in cost 0.0157423\n",
      "step 9820, training accuracy 0.934959\n",
      "step 9820, cost 13.1114\n",
      "step 9820, change in cost 0.0158205\n",
      "step 9830, training accuracy 0.934959\n",
      "step 9830, cost 13.0954\n",
      "step 9830, change in cost 0.0159016\n",
      "step 9840, training accuracy 0.934959\n",
      "step 9840, cost 13.0795\n",
      "step 9840, change in cost 0.0159845\n",
      "step 9850, training accuracy 0.934959\n",
      "step 9850, cost 13.0634\n",
      "step 9850, change in cost 0.0160666\n",
      "step 9860, training accuracy 0.934959\n",
      "step 9860, cost 13.0472\n",
      "step 9860, change in cost 0.0161572\n",
      "step 9870, training accuracy 0.934959\n",
      "step 9870, cost 13.031\n",
      "step 9870, change in cost 0.0162411\n",
      "step 9880, training accuracy 0.934959\n",
      "step 9880, cost 13.0147\n",
      "step 9880, change in cost 0.016324\n",
      "step 9890, training accuracy 0.934959\n",
      "step 9890, cost 12.9983\n",
      "step 9890, change in cost 0.0164127\n",
      "step 9900, training accuracy 0.934959\n",
      "step 9900, cost 12.9818\n",
      "step 9900, change in cost 0.0165081\n",
      "step 9910, training accuracy 0.934959\n",
      "step 9910, cost 12.9652\n",
      "step 9910, change in cost 0.0165911\n",
      "step 9920, training accuracy 0.934959\n",
      "step 9920, cost 12.9485\n",
      "step 9920, change in cost 0.0166731\n",
      "step 9930, training accuracy 0.934959\n",
      "step 9930, cost 12.9317\n",
      "step 9930, change in cost 0.0167627\n",
      "step 9940, training accuracy 0.934959\n",
      "step 9940, cost 12.9149\n",
      "step 9940, change in cost 0.0168495\n",
      "step 9950, training accuracy 0.934959\n",
      "step 9950, cost 12.898\n",
      "step 9950, change in cost 0.016923\n",
      "step 9960, training accuracy 0.934959\n",
      "step 9960, cost 12.8809\n",
      "step 9960, change in cost 0.0170116\n",
      "step 9970, training accuracy 0.934959\n",
      "step 9970, cost 12.8639\n",
      "step 9970, change in cost 0.0170813\n",
      "step 9980, training accuracy 0.934959\n",
      "step 9980, cost 12.8467\n",
      "step 9980, change in cost 0.0171537\n",
      "step 9990, training accuracy 0.934959\n",
      "step 9990, cost 12.8295\n",
      "step 9990, change in cost 0.0172195\n",
      "step 10000, training accuracy 0.934959\n",
      "step 10000, cost 12.8122\n",
      "step 10000, change in cost 0.0172863\n",
      "step 10010, training accuracy 0.934959\n",
      "step 10010, cost 12.7949\n",
      "step 10010, change in cost 0.0173416\n",
      "step 10020, training accuracy 0.934959\n",
      "step 10020, cost 12.7775\n",
      "step 10020, change in cost 0.0173874\n",
      "step 10030, training accuracy 0.934959\n",
      "step 10030, cost 12.76\n",
      "step 10030, change in cost 0.0174417\n",
      "step 10040, training accuracy 0.934959\n",
      "step 10040, cost 12.7426\n",
      "step 10040, change in cost 0.0174704\n",
      "step 10050, training accuracy 0.934959\n",
      "step 10050, cost 12.7251\n",
      "step 10050, change in cost 0.0174999\n",
      "step 10060, training accuracy 0.934959\n",
      "step 10060, cost 12.7075\n",
      "step 10060, change in cost 0.0175276\n",
      "step 10070, training accuracy 0.934959\n",
      "step 10070, cost 12.69\n",
      "step 10070, change in cost 0.0175409\n",
      "step 10080, training accuracy 0.934959\n",
      "step 10080, cost 12.6724\n",
      "step 10080, change in cost 0.0175438\n",
      "step 10090, training accuracy 0.934959\n",
      "step 10090, cost 12.6549\n",
      "step 10090, change in cost 0.0175419\n",
      "step 10100, training accuracy 0.934959\n",
      "step 10100, cost 12.6374\n",
      "step 10100, change in cost 0.0175285\n",
      "step 10110, training accuracy 0.934959\n",
      "step 10110, cost 12.6199\n",
      "step 10110, change in cost 0.0175056\n",
      "step 10120, training accuracy 0.934959\n",
      "step 10120, cost 12.6024\n",
      "step 10120, change in cost 0.0174751\n",
      "step 10130, training accuracy 0.934959\n",
      "step 10130, cost 12.585\n",
      "step 10130, change in cost 0.0174351\n",
      "step 10140, training accuracy 0.934959\n",
      "step 10140, cost 12.5676\n",
      "step 10140, change in cost 0.0173836\n",
      "step 10150, training accuracy 0.934959\n",
      "step 10150, cost 12.5503\n",
      "step 10150, change in cost 0.0173178\n",
      "step 10160, training accuracy 0.934959\n",
      "step 10160, cost 12.533\n",
      "step 10160, change in cost 0.0172567\n",
      "step 10170, training accuracy 0.934959\n",
      "step 10170, cost 12.5158\n",
      "step 10170, change in cost 0.0171738\n",
      "step 10180, training accuracy 0.934959\n",
      "step 10180, cost 12.4987\n",
      "step 10180, change in cost 0.017086\n",
      "step 10190, training accuracy 0.934959\n",
      "step 10190, cost 12.4818\n",
      "step 10190, change in cost 0.0169888\n",
      "step 10200, training accuracy 0.934959\n",
      "step 10200, cost 12.4649\n",
      "step 10200, change in cost 0.0168839\n",
      "step 10210, training accuracy 0.934959\n",
      "step 10210, cost 12.4481\n",
      "step 10210, change in cost 0.0167713\n",
      "step 10220, training accuracy 0.934959\n",
      "step 10220, cost 12.4314\n",
      "step 10220, change in cost 0.016655\n",
      "step 10230, training accuracy 0.934959\n",
      "step 10230, cost 12.4149\n",
      "step 10230, change in cost 0.0165195\n",
      "step 10240, training accuracy 0.934959\n",
      "step 10240, cost 12.3985\n",
      "step 10240, change in cost 0.0163898\n",
      "step 10250, training accuracy 0.934959\n",
      "step 10250, cost 12.3823\n",
      "step 10250, change in cost 0.0162439\n",
      "step 10260, training accuracy 0.934959\n",
      "step 10260, cost 12.3662\n",
      "step 10260, change in cost 0.0161028\n",
      "step 10270, training accuracy 0.934959\n",
      "step 10270, cost 12.3502\n",
      "step 10270, change in cost 0.0159473\n",
      "step 10280, training accuracy 0.934959\n",
      "step 10280, cost 12.3345\n",
      "step 10280, change in cost 0.015789\n",
      "step 10290, training accuracy 0.934959\n",
      "step 10290, cost 12.3188\n",
      "step 10290, change in cost 0.0156298\n",
      "step 10300, training accuracy 0.934959\n",
      "step 10300, cost 12.3034\n",
      "step 10300, change in cost 0.01546\n",
      "step 10310, training accuracy 0.934959\n",
      "step 10310, cost 12.2881\n",
      "step 10310, change in cost 0.0152988\n",
      "step 10320, training accuracy 0.934959\n",
      "step 10320, cost 12.2729\n",
      "step 10320, change in cost 0.0151234\n",
      "step 10330, training accuracy 0.934959\n",
      "step 10330, cost 12.258\n",
      "step 10330, change in cost 0.0149469\n",
      "step 10340, training accuracy 0.934959\n",
      "step 10340, cost 12.2432\n",
      "step 10340, change in cost 0.0147724\n",
      "step 10350, training accuracy 0.934959\n",
      "step 10350, cost 12.2286\n",
      "step 10350, change in cost 0.0145912\n",
      "step 10360, training accuracy 0.934959\n",
      "step 10360, cost 12.2142\n",
      "step 10360, change in cost 0.0144148\n",
      "step 10370, training accuracy 0.934959\n",
      "step 10370, cost 12.2\n",
      "step 10370, change in cost 0.0142345\n",
      "step 10380, training accuracy 0.934959\n",
      "step 10380, cost 12.1859\n",
      "step 10380, change in cost 0.0140505\n",
      "step 10390, training accuracy 0.934959\n",
      "step 10390, cost 12.1721\n",
      "step 10390, change in cost 0.0138731\n",
      "step 10400, training accuracy 0.934959\n",
      "step 10400, cost 12.1584\n",
      "step 10400, change in cost 0.0136909\n",
      "step 10410, training accuracy 0.934959\n",
      "step 10410, cost 12.1449\n",
      "step 10410, change in cost 0.0135117\n",
      "step 10420, training accuracy 0.934959\n",
      "step 10420, cost 12.1315\n",
      "step 10420, change in cost 0.0133343\n",
      "step 10430, training accuracy 0.934959\n",
      "step 10430, cost 12.1184\n",
      "step 10430, change in cost 0.0131531\n",
      "step 10440, training accuracy 0.934959\n",
      "step 10440, cost 12.1054\n",
      "step 10440, change in cost 0.0129747\n",
      "step 10450, training accuracy 0.934959\n",
      "step 10450, cost 12.0926\n",
      "step 10450, change in cost 0.012804\n",
      "step 10460, training accuracy 0.934959\n",
      "step 10460, cost 12.08\n",
      "step 10460, change in cost 0.0126257\n",
      "step 10470, training accuracy 0.934959\n",
      "step 10470, cost 12.0675\n",
      "step 10470, change in cost 0.0124531\n",
      "step 10480, training accuracy 0.934959\n",
      "step 10480, cost 12.0552\n",
      "step 10480, change in cost 0.0122814\n",
      "step 10490, training accuracy 0.934959\n",
      "step 10490, cost 12.0431\n",
      "step 10490, change in cost 0.0121174\n",
      "step 10500, training accuracy 0.934959\n",
      "step 10500, cost 12.0312\n",
      "step 10500, change in cost 0.0119438\n",
      "step 10510, training accuracy 0.934959\n",
      "step 10510, cost 12.0194\n",
      "step 10510, change in cost 0.0117893\n",
      "step 10520, training accuracy 0.934959\n",
      "step 10520, cost 12.0078\n",
      "step 10520, change in cost 0.0116243\n",
      "step 10530, training accuracy 0.934959\n",
      "step 10530, cost 11.9963\n",
      "step 10530, change in cost 0.0114651\n",
      "step 10540, training accuracy 0.934959\n",
      "step 10540, cost 11.985\n",
      "step 10540, change in cost 0.0113058\n",
      "step 10550, training accuracy 0.934959\n",
      "step 10550, cost 11.9738\n",
      "step 10550, change in cost 0.0111542\n",
      "step 10560, training accuracy 0.934959\n",
      "step 10560, cost 11.9628\n",
      "step 10560, change in cost 0.0109987\n",
      "step 10570, training accuracy 0.934959\n",
      "step 10570, cost 11.952\n",
      "step 10570, change in cost 0.0108566\n",
      "step 10580, training accuracy 0.934959\n",
      "step 10580, cost 11.9413\n",
      "step 10580, change in cost 0.0107031\n",
      "step 10590, training accuracy 0.934959\n",
      "step 10590, cost 11.9307\n",
      "step 10590, change in cost 0.0105648\n",
      "step 10600, training accuracy 0.934959\n",
      "step 10600, cost 11.9203\n",
      "step 10600, change in cost 0.0104189\n",
      "step 10610, training accuracy 0.934959\n",
      "step 10610, cost 11.91\n",
      "step 10610, change in cost 0.0102825\n",
      "step 10620, training accuracy 0.934959\n",
      "step 10620, cost 11.8999\n",
      "step 10620, change in cost 0.010148\n",
      "step 10630, training accuracy 0.934959\n",
      "step 10630, cost 11.8898\n",
      "step 10630, change in cost 0.0100136\n",
      "step 10640, training accuracy 0.934959\n",
      "step 10640, cost 11.88\n",
      "step 10640, change in cost 0.00988197\n",
      "step 10650, training accuracy 0.934959\n",
      "step 10650, cost 11.8702\n",
      "step 10650, change in cost 0.00975513\n",
      "step 10660, training accuracy 0.934959\n",
      "step 10660, cost 11.8606\n",
      "step 10660, change in cost 0.00962639\n",
      "step 10670, training accuracy 0.934959\n",
      "step 10670, cost 11.8511\n",
      "step 10670, change in cost 0.00950623\n",
      "step 10680, training accuracy 0.934959\n",
      "step 10680, cost 11.8417\n",
      "step 10680, change in cost 0.00938416\n",
      "step 10690, training accuracy 0.934959\n",
      "step 10690, cost 11.8324\n",
      "step 10690, change in cost 0.0092659\n",
      "step 10700, training accuracy 0.934959\n",
      "step 10700, cost 11.8233\n",
      "step 10700, change in cost 0.00914764\n",
      "step 10710, training accuracy 0.934959\n",
      "step 10710, cost 11.8142\n",
      "step 10710, change in cost 0.00903988\n",
      "step 10720, training accuracy 0.934959\n",
      "step 10720, cost 11.8053\n",
      "step 10720, change in cost 0.00892639\n",
      "step 10730, training accuracy 0.934959\n",
      "step 10730, cost 11.7965\n",
      "step 10730, change in cost 0.00881767\n",
      "step 10740, training accuracy 0.934959\n",
      "step 10740, cost 11.7878\n",
      "step 10740, change in cost 0.00871277\n",
      "step 10750, training accuracy 0.934959\n",
      "step 10750, cost 11.7792\n",
      "step 10750, change in cost 0.00860214\n",
      "step 10760, training accuracy 0.934959\n",
      "step 10760, cost 11.7707\n",
      "step 10760, change in cost 0.00850487\n",
      "step 10770, training accuracy 0.934959\n",
      "step 10770, cost 11.7623\n",
      "step 10770, change in cost 0.00840569\n",
      "step 10780, training accuracy 0.934959\n",
      "step 10780, cost 11.754\n",
      "step 10780, change in cost 0.0083046\n",
      "step 10790, training accuracy 0.934959\n",
      "step 10790, cost 11.7458\n",
      "step 10790, change in cost 0.00821018\n",
      "step 10800, training accuracy 0.934959\n",
      "step 10800, cost 11.7376\n",
      "step 10800, change in cost 0.00811577\n",
      "step 10810, training accuracy 0.934959\n",
      "step 10810, cost 11.7296\n",
      "step 10810, change in cost 0.00802326\n",
      "step 10820, training accuracy 0.934959\n",
      "step 10820, cost 11.7217\n",
      "step 10820, change in cost 0.00793552\n",
      "step 10830, training accuracy 0.934959\n",
      "step 10830, cost 11.7138\n",
      "step 10830, change in cost 0.00784779\n",
      "step 10840, training accuracy 0.934959\n",
      "step 10840, cost 11.7061\n",
      "step 10840, change in cost 0.00775909\n",
      "step 10850, training accuracy 0.934959\n",
      "step 10850, cost 11.6984\n",
      "step 10850, change in cost 0.00767517\n",
      "step 10860, training accuracy 0.934959\n",
      "step 10860, cost 11.6908\n",
      "step 10860, change in cost 0.00759125\n",
      "step 10870, training accuracy 0.934959\n",
      "step 10870, cost 11.6833\n",
      "step 10870, change in cost 0.007514\n",
      "step 10880, training accuracy 0.934959\n",
      "step 10880, cost 11.6759\n",
      "step 10880, change in cost 0.00743198\n",
      "step 10890, training accuracy 0.934959\n",
      "step 10890, cost 11.6685\n",
      "step 10890, change in cost 0.00735092\n",
      "step 10900, training accuracy 0.934959\n",
      "step 10900, cost 11.6612\n",
      "step 10900, change in cost 0.00727463\n",
      "step 10910, training accuracy 0.934959\n",
      "step 10910, cost 11.654\n",
      "step 10910, change in cost 0.00720406\n",
      "step 10920, training accuracy 0.934959\n",
      "step 10920, cost 11.6469\n",
      "step 10920, change in cost 0.00712776\n",
      "step 10930, training accuracy 0.934959\n",
      "step 10930, cost 11.6398\n",
      "step 10930, change in cost 0.00706005\n",
      "step 10940, training accuracy 0.934959\n",
      "step 10940, cost 11.6329\n",
      "step 10940, change in cost 0.00698757\n",
      "step 10950, training accuracy 0.934959\n",
      "step 10950, cost 11.6259\n",
      "step 10950, change in cost 0.00691795\n",
      "step 10960, training accuracy 0.934959\n",
      "step 10960, cost 11.6191\n",
      "step 10960, change in cost 0.0068512\n",
      "step 10970, training accuracy 0.934959\n",
      "step 10970, cost 11.6123\n",
      "step 10970, change in cost 0.00678539\n",
      "step 10980, training accuracy 0.934959\n",
      "step 10980, cost 11.6056\n",
      "step 10980, change in cost 0.00671673\n",
      "step 10990, training accuracy 0.934959\n",
      "step 10990, cost 11.5989\n",
      "step 10990, change in cost 0.00665855\n",
      "step 11000, training accuracy 0.934959\n",
      "step 11000, cost 11.5923\n",
      "step 11000, change in cost 0.0065937\n",
      "step 11010, training accuracy 0.934959\n",
      "step 11010, cost 11.5858\n",
      "step 11010, change in cost 0.00653648\n",
      "step 11020, training accuracy 0.934959\n",
      "step 11020, cost 11.5793\n",
      "step 11020, change in cost 0.00647354\n",
      "step 11030, training accuracy 0.934959\n",
      "step 11030, cost 11.5729\n",
      "step 11030, change in cost 0.00641632\n",
      "step 11040, training accuracy 0.934959\n",
      "step 11040, cost 11.5665\n",
      "step 11040, change in cost 0.00635719\n",
      "step 11050, training accuracy 0.934959\n",
      "step 11050, cost 11.5602\n",
      "step 11050, change in cost 0.00630188\n",
      "step 11060, training accuracy 0.934959\n",
      "step 11060, cost 11.554\n",
      "step 11060, change in cost 0.00624466\n",
      "step 11070, training accuracy 0.934959\n",
      "step 11070, cost 11.5478\n",
      "step 11070, change in cost 0.00619507\n",
      "step 11080, training accuracy 0.934959\n",
      "step 11080, cost 11.5417\n",
      "step 11080, change in cost 0.00614071\n",
      "step 11090, training accuracy 0.934959\n",
      "step 11090, cost 11.5356\n",
      "step 11090, change in cost 0.00608444\n",
      "step 11100, training accuracy 0.934959\n",
      "step 11100, cost 11.5295\n",
      "step 11100, change in cost 0.00603771\n",
      "step 11110, training accuracy 0.934959\n",
      "step 11110, cost 11.5236\n",
      "step 11110, change in cost 0.00598526\n",
      "step 11120, training accuracy 0.934959\n",
      "step 11120, cost 11.5176\n",
      "step 11120, change in cost 0.00593567\n",
      "step 11130, training accuracy 0.934959\n",
      "step 11130, cost 11.5117\n",
      "step 11130, change in cost 0.0058918\n",
      "step 11140, training accuracy 0.934959\n",
      "step 11140, cost 11.5059\n",
      "step 11140, change in cost 0.00584221\n",
      "step 11150, training accuracy 0.934959\n",
      "step 11150, cost 11.5001\n",
      "step 11150, change in cost 0.00579357\n",
      "step 11160, training accuracy 0.934959\n",
      "step 11160, cost 11.4943\n",
      "step 11160, change in cost 0.00575161\n",
      "step 11170, training accuracy 0.934959\n",
      "step 11170, cost 11.4886\n",
      "step 11170, change in cost 0.00570679\n",
      "step 11180, training accuracy 0.934959\n",
      "step 11180, cost 11.483\n",
      "step 11180, change in cost 0.00566006\n",
      "step 11190, training accuracy 0.934959\n",
      "step 11190, cost 11.4774\n",
      "step 11190, change in cost 0.0056181\n",
      "step 11200, training accuracy 0.934959\n",
      "step 11200, cost 11.4718\n",
      "step 11200, change in cost 0.00557899\n",
      "step 11210, training accuracy 0.934959\n",
      "step 11210, cost 11.4662\n",
      "step 11210, change in cost 0.00553608\n",
      "step 11220, training accuracy 0.934959\n",
      "step 11220, cost 11.4607\n",
      "step 11220, change in cost 0.00549603\n",
      "step 11230, training accuracy 0.934959\n",
      "step 11230, cost 11.4553\n",
      "step 11230, change in cost 0.00545597\n",
      "step 11240, training accuracy 0.934959\n",
      "step 11240, cost 11.4499\n",
      "step 11240, change in cost 0.00541782\n",
      "step 11250, training accuracy 0.934959\n",
      "step 11250, cost 11.4445\n",
      "step 11250, change in cost 0.00537777\n",
      "step 11260, training accuracy 0.939024\n",
      "step 11260, cost 11.4391\n",
      "step 11260, change in cost 0.00534534\n",
      "step 11270, training accuracy 0.939024\n",
      "step 11270, cost 11.4338\n",
      "step 11270, change in cost 0.00530338\n",
      "step 11280, training accuracy 0.939024\n",
      "step 11280, cost 11.4286\n",
      "step 11280, change in cost 0.00527\n",
      "step 11290, training accuracy 0.939024\n",
      "step 11290, cost 11.4233\n",
      "step 11290, change in cost 0.00523663\n",
      "step 11300, training accuracy 0.939024\n",
      "step 11300, cost 11.4181\n",
      "step 11300, change in cost 0.00519848\n",
      "step 11310, training accuracy 0.939024\n",
      "step 11310, cost 11.413\n",
      "step 11310, change in cost 0.00516224\n",
      "step 11320, training accuracy 0.939024\n",
      "step 11320, cost 11.4078\n",
      "step 11320, change in cost 0.00513458\n",
      "step 11330, training accuracy 0.939024\n",
      "step 11330, cost 11.4027\n",
      "step 11330, change in cost 0.00510025\n",
      "step 11340, training accuracy 0.939024\n",
      "step 11340, cost 11.3977\n",
      "step 11340, change in cost 0.00507069\n",
      "step 11350, training accuracy 0.939024\n",
      "step 11350, cost 11.3926\n",
      "step 11350, change in cost 0.00503349\n",
      "step 11360, training accuracy 0.939024\n",
      "step 11360, cost 11.3876\n",
      "step 11360, change in cost 0.00500774\n",
      "step 11370, training accuracy 0.939024\n",
      "step 11370, cost 11.3827\n",
      "step 11370, change in cost 0.00497627\n",
      "step 11380, training accuracy 0.939024\n",
      "step 11380, cost 11.3777\n",
      "step 11380, change in cost 0.0049448\n",
      "step 11390, training accuracy 0.939024\n",
      "step 11390, cost 11.3728\n",
      "step 11390, change in cost 0.00492096\n",
      "step 11400, training accuracy 0.939024\n",
      "step 11400, cost 11.3679\n",
      "step 11400, change in cost 0.00488949\n",
      "step 11410, training accuracy 0.939024\n",
      "step 11410, cost 11.363\n",
      "step 11410, change in cost 0.00486183\n",
      "step 11420, training accuracy 0.939024\n",
      "step 11420, cost 11.3582\n",
      "step 11420, change in cost 0.00483608\n",
      "step 11430, training accuracy 0.939024\n",
      "step 11430, cost 11.3534\n",
      "step 11430, change in cost 0.00480747\n",
      "step 11440, training accuracy 0.939024\n",
      "step 11440, cost 11.3486\n",
      "step 11440, change in cost 0.00478268\n",
      "step 11450, training accuracy 0.939024\n",
      "step 11450, cost 11.3439\n",
      "step 11450, change in cost 0.00475693\n",
      "step 11460, training accuracy 0.939024\n",
      "step 11460, cost 11.3391\n",
      "step 11460, change in cost 0.00473309\n",
      "step 11470, training accuracy 0.939024\n",
      "step 11470, cost 11.3344\n",
      "step 11470, change in cost 0.00470924\n",
      "step 11480, training accuracy 0.939024\n",
      "step 11480, cost 11.3297\n",
      "step 11480, change in cost 0.00468063\n",
      "step 11490, training accuracy 0.939024\n",
      "step 11490, cost 11.3251\n",
      "step 11490, change in cost 0.00466251\n",
      "step 11500, training accuracy 0.939024\n",
      "step 11500, cost 11.3204\n",
      "step 11500, change in cost 0.00463772\n",
      "step 11510, training accuracy 0.939024\n",
      "step 11510, cost 11.3158\n",
      "step 11510, change in cost 0.00461197\n",
      "step 11520, training accuracy 0.939024\n",
      "step 11520, cost 11.3112\n",
      "step 11520, change in cost 0.0045948\n",
      "step 11530, training accuracy 0.939024\n",
      "step 11530, cost 11.3067\n",
      "step 11530, change in cost 0.00457287\n",
      "step 11540, training accuracy 0.939024\n",
      "step 11540, cost 11.3021\n",
      "step 11540, change in cost 0.00454903\n",
      "step 11550, training accuracy 0.939024\n",
      "step 11550, cost 11.2976\n",
      "step 11550, change in cost 0.00453568\n",
      "step 11560, training accuracy 0.939024\n",
      "step 11560, cost 11.2931\n",
      "step 11560, change in cost 0.00450993\n",
      "step 11570, training accuracy 0.939024\n",
      "step 11570, cost 11.2886\n",
      "step 11570, change in cost 0.00449085\n",
      "step 11580, training accuracy 0.939024\n",
      "step 11580, cost 11.2841\n",
      "step 11580, change in cost 0.00447178\n",
      "step 11590, training accuracy 0.939024\n",
      "step 11590, cost 11.2796\n",
      "step 11590, change in cost 0.00445747\n",
      "step 11600, training accuracy 0.939024\n",
      "step 11600, cost 11.2752\n",
      "step 11600, change in cost 0.00443459\n",
      "step 11610, training accuracy 0.939024\n",
      "step 11610, cost 11.2708\n",
      "step 11610, change in cost 0.00442314\n",
      "step 11620, training accuracy 0.939024\n",
      "step 11620, cost 11.2664\n",
      "step 11620, change in cost 0.00439835\n",
      "step 11630, training accuracy 0.939024\n",
      "step 11630, cost 11.262\n",
      "step 11630, change in cost 0.00438404\n",
      "step 11640, training accuracy 0.939024\n",
      "step 11640, cost 11.2576\n",
      "step 11640, change in cost 0.00436974\n",
      "step 11650, training accuracy 0.939024\n",
      "step 11650, cost 11.2533\n",
      "step 11650, change in cost 0.00435162\n",
      "step 11660, training accuracy 0.939024\n",
      "step 11660, cost 11.2489\n",
      "step 11660, change in cost 0.00434113\n",
      "step 11670, training accuracy 0.939024\n",
      "step 11670, cost 11.2446\n",
      "step 11670, change in cost 0.00432205\n",
      "step 11680, training accuracy 0.939024\n",
      "step 11680, cost 11.2403\n",
      "step 11680, change in cost 0.00430965\n",
      "step 11690, training accuracy 0.939024\n",
      "step 11690, cost 11.236\n",
      "step 11690, change in cost 0.00429249\n",
      "step 11700, training accuracy 0.943089\n",
      "step 11700, cost 11.2317\n",
      "step 11700, change in cost 0.004282\n",
      "step 11710, training accuracy 0.943089\n",
      "step 11710, cost 11.2275\n",
      "step 11710, change in cost 0.0042696\n",
      "step 11720, training accuracy 0.943089\n",
      "step 11720, cost 11.2232\n",
      "step 11720, change in cost 0.00425625\n",
      "step 11730, training accuracy 0.943089\n",
      "step 11730, cost 11.219\n",
      "step 11730, change in cost 0.0042429\n",
      "step 11740, training accuracy 0.943089\n",
      "step 11740, cost 11.2147\n",
      "step 11740, change in cost 0.00423431\n",
      "step 11750, training accuracy 0.943089\n",
      "step 11750, cost 11.2105\n",
      "step 11750, change in cost 0.00421906\n",
      "step 11760, training accuracy 0.943089\n",
      "step 11760, cost 11.2063\n",
      "step 11760, change in cost 0.00421238\n",
      "step 11770, training accuracy 0.943089\n",
      "step 11770, cost 11.2021\n",
      "step 11770, change in cost 0.00419617\n",
      "step 11780, training accuracy 0.943089\n",
      "step 11780, cost 11.1979\n",
      "step 11780, change in cost 0.0041914\n",
      "step 11790, training accuracy 0.943089\n",
      "step 11790, cost 11.1937\n",
      "step 11790, change in cost 0.00417995\n",
      "step 11800, training accuracy 0.943089\n",
      "step 11800, cost 11.1896\n",
      "step 11800, change in cost 0.00417233\n",
      "step 11810, training accuracy 0.943089\n",
      "step 11810, cost 11.1854\n",
      "step 11810, change in cost 0.00415897\n",
      "step 11820, training accuracy 0.943089\n",
      "step 11820, cost 11.1812\n",
      "step 11820, change in cost 0.00415611\n",
      "step 11830, training accuracy 0.943089\n",
      "step 11830, cost 11.1771\n",
      "step 11830, change in cost 0.00414467\n",
      "step 11840, training accuracy 0.943089\n",
      "step 11840, cost 11.173\n",
      "step 11840, change in cost 0.0041399\n",
      "step 11850, training accuracy 0.943089\n",
      "step 11850, cost 11.1688\n",
      "step 11850, change in cost 0.00413322\n",
      "step 11860, training accuracy 0.943089\n",
      "step 11860, cost 11.1647\n",
      "step 11860, change in cost 0.00412464\n",
      "step 11870, training accuracy 0.943089\n",
      "step 11870, cost 11.1606\n",
      "step 11870, change in cost 0.00411987\n",
      "step 11880, training accuracy 0.943089\n",
      "step 11880, cost 11.1565\n",
      "step 11880, change in cost 0.00411415\n",
      "step 11890, training accuracy 0.943089\n",
      "step 11890, cost 11.1523\n",
      "step 11890, change in cost 0.00411224\n",
      "step 11900, training accuracy 0.943089\n",
      "step 11900, cost 11.1482\n",
      "step 11900, change in cost 0.00410175\n",
      "step 11910, training accuracy 0.943089\n",
      "step 11910, cost 11.1441\n",
      "step 11910, change in cost 0.00410175\n",
      "step 11920, training accuracy 0.943089\n",
      "step 11920, cost 11.14\n",
      "step 11920, change in cost 0.00409698\n",
      "step 11930, training accuracy 0.943089\n",
      "step 11930, cost 11.136\n",
      "step 11930, change in cost 0.00409317\n",
      "step 11940, training accuracy 0.943089\n",
      "step 11940, cost 11.1319\n",
      "step 11940, change in cost 0.00409126\n",
      "step 11950, training accuracy 0.943089\n",
      "step 11950, cost 11.1278\n",
      "step 11950, change in cost 0.0040884\n",
      "step 11960, training accuracy 0.943089\n",
      "step 11960, cost 11.1237\n",
      "step 11960, change in cost 0.00408649\n",
      "step 11970, training accuracy 0.943089\n",
      "step 11970, cost 11.1196\n",
      "step 11970, change in cost 0.00408745\n",
      "step 11980, training accuracy 0.943089\n",
      "step 11980, cost 11.1155\n",
      "step 11980, change in cost 0.00408554\n",
      "step 11990, training accuracy 0.943089\n",
      "step 11990, cost 11.1114\n",
      "step 11990, change in cost 0.00408554\n",
      "step 12000, training accuracy 0.943089\n",
      "step 12000, cost 11.1073\n",
      "step 12000, change in cost 0.00408363\n",
      "step 12010, training accuracy 0.943089\n",
      "step 12010, cost 11.1033\n",
      "step 12010, change in cost 0.00408554\n",
      "step 12020, training accuracy 0.943089\n",
      "step 12020, cost 11.0992\n",
      "step 12020, change in cost 0.00409031\n",
      "step 12030, training accuracy 0.943089\n",
      "step 12030, cost 11.0951\n",
      "step 12030, change in cost 0.00408649\n",
      "step 12040, training accuracy 0.943089\n",
      "step 12040, cost 11.091\n",
      "step 12040, change in cost 0.00409317\n",
      "step 12050, training accuracy 0.943089\n",
      "step 12050, cost 11.0869\n",
      "step 12050, change in cost 0.00409126\n",
      "step 12060, training accuracy 0.943089\n",
      "step 12060, cost 11.0828\n",
      "step 12060, change in cost 0.0041008\n",
      "step 12070, training accuracy 0.943089\n",
      "step 12070, cost 11.0787\n",
      "step 12070, change in cost 0.00410271\n",
      "step 12080, training accuracy 0.943089\n",
      "step 12080, cost 11.0746\n",
      "step 12080, change in cost 0.00410652\n",
      "step 12090, training accuracy 0.943089\n",
      "step 12090, cost 11.0705\n",
      "step 12090, change in cost 0.00411129\n",
      "step 12100, training accuracy 0.943089\n",
      "step 12100, cost 11.0664\n",
      "step 12100, change in cost 0.00411797\n",
      "step 12110, training accuracy 0.943089\n",
      "step 12110, cost 11.0622\n",
      "step 12110, change in cost 0.0041256\n",
      "step 12120, training accuracy 0.943089\n",
      "step 12120, cost 11.0581\n",
      "step 12120, change in cost 0.00413227\n",
      "step 12130, training accuracy 0.943089\n",
      "step 12130, cost 11.054\n",
      "step 12130, change in cost 0.00414085\n",
      "step 12140, training accuracy 0.943089\n",
      "step 12140, cost 11.0498\n",
      "step 12140, change in cost 0.00414658\n",
      "step 12150, training accuracy 0.943089\n",
      "step 12150, cost 11.0457\n",
      "step 12150, change in cost 0.00416088\n",
      "step 12160, training accuracy 0.943089\n",
      "step 12160, cost 11.0415\n",
      "step 12160, change in cost 0.0041647\n",
      "step 12170, training accuracy 0.943089\n",
      "step 12170, cost 11.0373\n",
      "step 12170, change in cost 0.00417709\n",
      "step 12180, training accuracy 0.943089\n",
      "step 12180, cost 11.0331\n",
      "step 12180, change in cost 0.00418949\n",
      "step 12190, training accuracy 0.943089\n",
      "step 12190, cost 11.0289\n",
      "step 12190, change in cost 0.00420475\n",
      "step 12200, training accuracy 0.943089\n",
      "step 12200, cost 11.0247\n",
      "step 12200, change in cost 0.00421429\n",
      "step 12210, training accuracy 0.943089\n",
      "step 12210, cost 11.0205\n",
      "step 12210, change in cost 0.00422764\n",
      "step 12220, training accuracy 0.943089\n",
      "step 12220, cost 11.0162\n",
      "step 12220, change in cost 0.00424099\n",
      "step 12230, training accuracy 0.943089\n",
      "step 12230, cost 11.012\n",
      "step 12230, change in cost 0.00425911\n",
      "step 12240, training accuracy 0.943089\n",
      "step 12240, cost 11.0077\n",
      "step 12240, change in cost 0.00427151\n",
      "step 12250, training accuracy 0.943089\n",
      "step 12250, cost 11.0034\n",
      "step 12250, change in cost 0.00429535\n",
      "step 12260, training accuracy 0.943089\n",
      "step 12260, cost 10.9991\n",
      "step 12260, change in cost 0.0043087\n",
      "step 12270, training accuracy 0.943089\n",
      "step 12270, cost 10.9948\n",
      "step 12270, change in cost 0.00432873\n",
      "step 12280, training accuracy 0.943089\n",
      "step 12280, cost 10.9904\n",
      "step 12280, change in cost 0.00434303\n",
      "step 12290, training accuracy 0.943089\n",
      "step 12290, cost 10.9861\n",
      "step 12290, change in cost 0.00436878\n",
      "step 12300, training accuracy 0.943089\n",
      "step 12300, cost 10.9817\n",
      "step 12300, change in cost 0.00439262\n",
      "step 12310, training accuracy 0.943089\n",
      "step 12310, cost 10.9773\n",
      "step 12310, change in cost 0.0044117\n",
      "step 12320, training accuracy 0.943089\n",
      "step 12320, cost 10.9728\n",
      "step 12320, change in cost 0.00444221\n",
      "step 12330, training accuracy 0.943089\n",
      "step 12330, cost 10.9684\n",
      "step 12330, change in cost 0.00446033\n",
      "step 12340, training accuracy 0.943089\n",
      "step 12340, cost 10.9639\n",
      "step 12340, change in cost 0.00448608\n",
      "step 12350, training accuracy 0.943089\n",
      "step 12350, cost 10.9594\n",
      "step 12350, change in cost 0.00451756\n",
      "step 12360, training accuracy 0.943089\n",
      "step 12360, cost 10.9548\n",
      "step 12360, change in cost 0.00454521\n",
      "step 12370, training accuracy 0.943089\n",
      "step 12370, cost 10.9502\n",
      "step 12370, change in cost 0.00457287\n",
      "step 12380, training accuracy 0.943089\n",
      "step 12380, cost 10.9456\n",
      "step 12380, change in cost 0.00460529\n",
      "step 12390, training accuracy 0.943089\n",
      "step 12390, cost 10.941\n",
      "step 12390, change in cost 0.00463867\n",
      "step 12400, training accuracy 0.943089\n",
      "step 12400, cost 10.9363\n",
      "step 12400, change in cost 0.00466919\n",
      "step 12410, training accuracy 0.943089\n",
      "step 12410, cost 10.9316\n",
      "step 12410, change in cost 0.00470924\n",
      "step 12420, training accuracy 0.943089\n",
      "step 12420, cost 10.9269\n",
      "step 12420, change in cost 0.00474644\n",
      "step 12430, training accuracy 0.943089\n",
      "step 12430, cost 10.9221\n",
      "step 12430, change in cost 0.00478268\n",
      "step 12440, training accuracy 0.943089\n",
      "step 12440, cost 10.9173\n",
      "step 12440, change in cost 0.00482368\n",
      "step 12450, training accuracy 0.943089\n",
      "step 12450, cost 10.9124\n",
      "step 12450, change in cost 0.00486565\n",
      "step 12460, training accuracy 0.943089\n",
      "step 12460, cost 10.9075\n",
      "step 12460, change in cost 0.00490761\n",
      "step 12470, training accuracy 0.943089\n",
      "step 12470, cost 10.9025\n",
      "step 12470, change in cost 0.00495148\n",
      "step 12480, training accuracy 0.943089\n",
      "step 12480, cost 10.8975\n",
      "step 12480, change in cost 0.00500679\n",
      "step 12490, training accuracy 0.943089\n",
      "step 12490, cost 10.8925\n",
      "step 12490, change in cost 0.00504971\n",
      "step 12500, training accuracy 0.943089\n",
      "step 12500, cost 10.8874\n",
      "step 12500, change in cost 0.00510311\n",
      "step 12510, training accuracy 0.943089\n",
      "step 12510, cost 10.8822\n",
      "step 12510, change in cost 0.00515556\n",
      "step 12520, training accuracy 0.943089\n",
      "step 12520, cost 10.877\n",
      "step 12520, change in cost 0.00521183\n",
      "step 12530, training accuracy 0.943089\n",
      "step 12530, cost 10.8717\n",
      "step 12530, change in cost 0.00527096\n",
      "step 12540, training accuracy 0.947154\n",
      "step 12540, cost 10.8664\n",
      "step 12540, change in cost 0.00532913\n",
      "step 12550, training accuracy 0.947154\n",
      "step 12550, cost 10.861\n",
      "step 12550, change in cost 0.00539398\n",
      "step 12560, training accuracy 0.947154\n",
      "step 12560, cost 10.8556\n",
      "step 12560, change in cost 0.00545979\n",
      "step 12570, training accuracy 0.947154\n",
      "step 12570, cost 10.85\n",
      "step 12570, change in cost 0.0055275\n",
      "step 12580, training accuracy 0.947154\n",
      "step 12580, cost 10.8444\n",
      "step 12580, change in cost 0.00559902\n",
      "step 12590, training accuracy 0.947154\n",
      "step 12590, cost 10.8388\n",
      "step 12590, change in cost 0.00567245\n",
      "step 12600, training accuracy 0.947154\n",
      "step 12600, cost 10.833\n",
      "step 12600, change in cost 0.00574684\n",
      "step 12610, training accuracy 0.947154\n",
      "step 12610, cost 10.8272\n",
      "step 12610, change in cost 0.00583172\n",
      "step 12620, training accuracy 0.947154\n",
      "step 12620, cost 10.8213\n",
      "step 12620, change in cost 0.00591183\n",
      "step 12630, training accuracy 0.947154\n",
      "step 12630, cost 10.8153\n",
      "step 12630, change in cost 0.00600052\n",
      "step 12640, training accuracy 0.947154\n",
      "step 12640, cost 10.8092\n",
      "step 12640, change in cost 0.00609207\n",
      "step 12650, training accuracy 0.947154\n",
      "step 12650, cost 10.803\n",
      "step 12650, change in cost 0.00618553\n",
      "step 12660, training accuracy 0.947154\n",
      "step 12660, cost 10.7967\n",
      "step 12660, change in cost 0.00628376\n",
      "step 12670, training accuracy 0.947154\n",
      "step 12670, cost 10.7903\n",
      "step 12670, change in cost 0.00638676\n",
      "step 12680, training accuracy 0.947154\n",
      "step 12680, cost 10.7838\n",
      "step 12680, change in cost 0.00649452\n",
      "step 12690, training accuracy 0.947154\n",
      "step 12690, cost 10.7772\n",
      "step 12690, change in cost 0.00660515\n",
      "step 12700, training accuracy 0.947154\n",
      "step 12700, cost 10.7705\n",
      "step 12700, change in cost 0.00671959\n",
      "step 12710, training accuracy 0.947154\n",
      "step 12710, cost 10.7637\n",
      "step 12710, change in cost 0.00683975\n",
      "step 12720, training accuracy 0.947154\n",
      "step 12720, cost 10.7567\n",
      "step 12720, change in cost 0.00696945\n",
      "step 12730, training accuracy 0.947154\n",
      "step 12730, cost 10.7496\n",
      "step 12730, change in cost 0.00709438\n",
      "step 12740, training accuracy 0.947154\n",
      "step 12740, cost 10.7424\n",
      "step 12740, change in cost 0.00723457\n",
      "step 12750, training accuracy 0.947154\n",
      "step 12750, cost 10.735\n",
      "step 12750, change in cost 0.00737572\n",
      "step 12760, training accuracy 0.947154\n",
      "step 12760, cost 10.7275\n",
      "step 12760, change in cost 0.00752544\n",
      "step 12770, training accuracy 0.947154\n",
      "step 12770, cost 10.7198\n",
      "step 12770, change in cost 0.00767899\n",
      "step 12780, training accuracy 0.947154\n",
      "step 12780, cost 10.7119\n",
      "step 12780, change in cost 0.0078392\n",
      "step 12790, training accuracy 0.947154\n",
      "step 12790, cost 10.7039\n",
      "step 12790, change in cost 0.008008\n",
      "step 12800, training accuracy 0.947154\n",
      "step 12800, cost 10.6957\n",
      "step 12800, change in cost 0.00817966\n",
      "step 12810, training accuracy 0.947154\n",
      "step 12810, cost 10.6874\n",
      "step 12810, change in cost 0.00836182\n",
      "step 12820, training accuracy 0.947154\n",
      "step 12820, cost 10.6788\n",
      "step 12820, change in cost 0.00855064\n",
      "step 12830, training accuracy 0.951219\n",
      "step 12830, cost 10.6701\n",
      "step 12830, change in cost 0.00875092\n",
      "step 12840, training accuracy 0.951219\n",
      "step 12840, cost 10.6611\n",
      "step 12840, change in cost 0.00894928\n",
      "step 12850, training accuracy 0.951219\n",
      "step 12850, cost 10.652\n",
      "step 12850, change in cost 0.00916386\n",
      "step 12860, training accuracy 0.951219\n",
      "step 12860, cost 10.6426\n",
      "step 12860, change in cost 0.00938511\n",
      "step 12870, training accuracy 0.951219\n",
      "step 12870, cost 10.633\n",
      "step 12870, change in cost 0.0096159\n",
      "step 12880, training accuracy 0.951219\n",
      "step 12880, cost 10.6231\n",
      "step 12880, change in cost 0.00985146\n",
      "step 12890, training accuracy 0.951219\n",
      "step 12890, cost 10.613\n",
      "step 12890, change in cost 0.0100965\n",
      "step 12900, training accuracy 0.951219\n",
      "step 12900, cost 10.6027\n",
      "step 12900, change in cost 0.010354\n",
      "step 12910, training accuracy 0.951219\n",
      "step 12910, cost 10.5921\n",
      "step 12910, change in cost 0.0106182\n",
      "step 12920, training accuracy 0.951219\n",
      "step 12920, cost 10.5812\n",
      "step 12920, change in cost 0.0108938\n",
      "step 12930, training accuracy 0.951219\n",
      "step 12930, cost 10.57\n",
      "step 12930, change in cost 0.0111771\n",
      "step 12940, training accuracy 0.951219\n",
      "step 12940, cost 10.5585\n",
      "step 12940, change in cost 0.0114708\n",
      "step 12950, training accuracy 0.951219\n",
      "step 12950, cost 10.5467\n",
      "step 12950, change in cost 0.0117702\n",
      "step 12960, training accuracy 0.951219\n",
      "step 12960, cost 10.5347\n",
      "step 12960, change in cost 0.0120802\n",
      "step 12970, training accuracy 0.951219\n",
      "step 12970, cost 10.5223\n",
      "step 12970, change in cost 0.0124035\n",
      "step 12980, training accuracy 0.951219\n",
      "step 12980, cost 10.5095\n",
      "step 12980, change in cost 0.0127296\n",
      "step 12990, training accuracy 0.951219\n",
      "step 12990, cost 10.4965\n",
      "step 12990, change in cost 0.0130625\n",
      "step 13000, training accuracy 0.951219\n",
      "step 13000, cost 10.4831\n",
      "step 13000, change in cost 0.0134087\n",
      "step 13010, training accuracy 0.951219\n",
      "step 13010, cost 10.4693\n",
      "step 13010, change in cost 0.0137606\n",
      "step 13020, training accuracy 0.951219\n",
      "step 13020, cost 10.4552\n",
      "step 13020, change in cost 0.0141134\n",
      "step 13030, training accuracy 0.951219\n",
      "step 13030, cost 10.4407\n",
      "step 13030, change in cost 0.0144787\n",
      "step 13040, training accuracy 0.951219\n",
      "step 13040, cost 10.4259\n",
      "step 13040, change in cost 0.0148411\n",
      "step 13050, training accuracy 0.951219\n",
      "step 13050, cost 10.4106\n",
      "step 13050, change in cost 0.015214\n",
      "step 13060, training accuracy 0.951219\n",
      "step 13060, cost 10.3951\n",
      "step 13060, change in cost 0.0155859\n",
      "step 13070, training accuracy 0.951219\n",
      "step 13070, cost 10.3791\n",
      "step 13070, change in cost 0.0159521\n",
      "step 13080, training accuracy 0.951219\n",
      "step 13080, cost 10.3628\n",
      "step 13080, change in cost 0.016326\n",
      "step 13090, training accuracy 0.951219\n",
      "step 13090, cost 10.3461\n",
      "step 13090, change in cost 0.0166912\n",
      "step 13100, training accuracy 0.951219\n",
      "step 13100, cost 10.329\n",
      "step 13100, change in cost 0.0170546\n",
      "step 13110, training accuracy 0.951219\n",
      "step 13110, cost 10.3116\n",
      "step 13110, change in cost 0.0174112\n",
      "step 13120, training accuracy 0.951219\n",
      "step 13120, cost 10.2939\n",
      "step 13120, change in cost 0.0177555\n",
      "step 13130, training accuracy 0.951219\n",
      "step 13130, cost 10.2758\n",
      "step 13130, change in cost 0.018095\n",
      "step 13140, training accuracy 0.951219\n",
      "step 13140, cost 10.2574\n",
      "step 13140, change in cost 0.0184221\n",
      "step 13150, training accuracy 0.951219\n",
      "step 13150, cost 10.2386\n",
      "step 13150, change in cost 0.0187292\n",
      "step 13160, training accuracy 0.951219\n",
      "step 13160, cost 10.2196\n",
      "step 13160, change in cost 0.0190239\n",
      "step 13170, training accuracy 0.951219\n",
      "step 13170, cost 10.2003\n",
      "step 13170, change in cost 0.0192966\n",
      "step 13180, training accuracy 0.951219\n",
      "step 13180, cost 10.1808\n",
      "step 13180, change in cost 0.0195522\n",
      "step 13190, training accuracy 0.951219\n",
      "step 13190, cost 10.161\n",
      "step 13190, change in cost 0.0197849\n",
      "step 13200, training accuracy 0.951219\n",
      "step 13200, cost 10.141\n",
      "step 13200, change in cost 0.0199966\n",
      "step 13210, training accuracy 0.951219\n",
      "step 13210, cost 10.1208\n",
      "step 13210, change in cost 0.0201797\n",
      "step 13220, training accuracy 0.951219\n",
      "step 13220, cost 10.1005\n",
      "step 13220, change in cost 0.0203371\n",
      "step 13230, training accuracy 0.951219\n",
      "step 13230, cost 10.08\n",
      "step 13230, change in cost 0.0204697\n",
      "step 13240, training accuracy 0.951219\n",
      "step 13240, cost 10.0594\n",
      "step 13240, change in cost 0.0205736\n",
      "step 13250, training accuracy 0.951219\n",
      "step 13250, cost 10.0388\n",
      "step 13250, change in cost 0.0206547\n",
      "step 13260, training accuracy 0.951219\n",
      "step 13260, cost 10.0181\n",
      "step 13260, change in cost 0.0206976\n",
      "step 13270, training accuracy 0.951219\n",
      "step 13270, cost 9.99733\n",
      "step 13270, change in cost 0.0207253\n",
      "step 13280, training accuracy 0.951219\n",
      "step 13280, cost 9.97662\n",
      "step 13280, change in cost 0.0207167\n",
      "step 13290, training accuracy 0.951219\n",
      "step 13290, cost 9.95593\n",
      "step 13290, change in cost 0.0206861\n",
      "step 13300, training accuracy 0.951219\n",
      "step 13300, cost 9.9353\n",
      "step 13300, change in cost 0.020627\n",
      "step 13310, training accuracy 0.951219\n",
      "step 13310, cost 9.91476\n",
      "step 13310, change in cost 0.0205469\n",
      "step 13320, training accuracy 0.951219\n",
      "step 13320, cost 9.89432\n",
      "step 13320, change in cost 0.0204391\n",
      "step 13330, training accuracy 0.951219\n",
      "step 13330, cost 9.874\n",
      "step 13330, change in cost 0.0203142\n",
      "step 13340, training accuracy 0.951219\n",
      "step 13340, cost 9.85384\n",
      "step 13340, change in cost 0.0201645\n",
      "step 13350, training accuracy 0.951219\n",
      "step 13350, cost 9.83384\n",
      "step 13350, change in cost 0.0199986\n",
      "step 13360, training accuracy 0.951219\n",
      "step 13360, cost 9.81403\n",
      "step 13360, change in cost 0.0198078\n",
      "step 13370, training accuracy 0.951219\n",
      "step 13370, cost 9.79442\n",
      "step 13370, change in cost 0.0196095\n",
      "step 13380, training accuracy 0.951219\n",
      "step 13380, cost 9.77503\n",
      "step 13380, change in cost 0.0193882\n",
      "step 13390, training accuracy 0.951219\n",
      "step 13390, cost 9.75588\n",
      "step 13390, change in cost 0.0191584\n",
      "step 13400, training accuracy 0.951219\n",
      "step 13400, cost 9.73696\n",
      "step 13400, change in cost 0.018918\n",
      "step 13410, training accuracy 0.951219\n",
      "step 13410, cost 9.7183\n",
      "step 13410, change in cost 0.0186615\n",
      "step 13420, training accuracy 0.951219\n",
      "step 13420, cost 9.6999\n",
      "step 13420, change in cost 0.0183973\n",
      "step 13430, training accuracy 0.951219\n",
      "step 13430, cost 9.68177\n",
      "step 13430, change in cost 0.0181274\n",
      "step 13440, training accuracy 0.951219\n",
      "step 13440, cost 9.66392\n",
      "step 13440, change in cost 0.0178537\n",
      "step 13450, training accuracy 0.951219\n",
      "step 13450, cost 9.64635\n",
      "step 13450, change in cost 0.0175667\n",
      "step 13460, training accuracy 0.951219\n",
      "step 13460, cost 9.62907\n",
      "step 13460, change in cost 0.0172815\n",
      "step 13470, training accuracy 0.951219\n",
      "step 13470, cost 9.61208\n",
      "step 13470, change in cost 0.0169897\n",
      "step 13480, training accuracy 0.951219\n",
      "step 13480, cost 9.59539\n",
      "step 13480, change in cost 0.0166931\n",
      "step 13490, training accuracy 0.951219\n",
      "step 13490, cost 9.57899\n",
      "step 13490, change in cost 0.0164013\n",
      "step 13500, training accuracy 0.951219\n",
      "step 13500, cost 9.56288\n",
      "step 13500, change in cost 0.0161057\n",
      "step 13510, training accuracy 0.951219\n",
      "step 13510, cost 9.54707\n",
      "step 13510, change in cost 0.0158081\n",
      "step 13520, training accuracy 0.951219\n",
      "step 13520, cost 9.53156\n",
      "step 13520, change in cost 0.0155144\n",
      "step 13530, training accuracy 0.951219\n",
      "step 13530, cost 9.51634\n",
      "step 13530, change in cost 0.0152206\n",
      "step 13540, training accuracy 0.951219\n",
      "step 13540, cost 9.50141\n",
      "step 13540, change in cost 0.0149298\n",
      "step 13550, training accuracy 0.951219\n",
      "step 13550, cost 9.48677\n",
      "step 13550, change in cost 0.0146379\n",
      "step 13560, training accuracy 0.951219\n",
      "step 13560, cost 9.47242\n",
      "step 13560, change in cost 0.0143509\n",
      "step 13570, training accuracy 0.951219\n",
      "step 13570, cost 9.45835\n",
      "step 13570, change in cost 0.0140705\n",
      "step 13580, training accuracy 0.951219\n",
      "step 13580, cost 9.44456\n",
      "step 13580, change in cost 0.0137825\n",
      "step 13590, training accuracy 0.951219\n",
      "step 13590, cost 9.43106\n",
      "step 13590, change in cost 0.0135098\n",
      "step 13600, training accuracy 0.951219\n",
      "step 13600, cost 9.41782\n",
      "step 13600, change in cost 0.0132389\n",
      "step 13610, training accuracy 0.951219\n",
      "step 13610, cost 9.40485\n",
      "step 13610, change in cost 0.012969\n",
      "step 13620, training accuracy 0.951219\n",
      "step 13620, cost 9.39214\n",
      "step 13620, change in cost 0.0127096\n",
      "step 13630, training accuracy 0.951219\n",
      "step 13630, cost 9.37969\n",
      "step 13630, change in cost 0.0124445\n",
      "step 13640, training accuracy 0.951219\n",
      "step 13640, cost 9.3675\n",
      "step 13640, change in cost 0.0121908\n",
      "step 13650, training accuracy 0.951219\n",
      "step 13650, cost 9.35556\n",
      "step 13650, change in cost 0.0119419\n",
      "step 13660, training accuracy 0.951219\n",
      "step 13660, cost 9.34386\n",
      "step 13660, change in cost 0.0116997\n",
      "step 13670, training accuracy 0.951219\n",
      "step 13670, cost 9.3324\n",
      "step 13670, change in cost 0.0114574\n",
      "step 13680, training accuracy 0.951219\n",
      "step 13680, cost 9.32118\n",
      "step 13680, change in cost 0.0112219\n",
      "step 13690, training accuracy 0.951219\n",
      "step 13690, cost 9.31019\n",
      "step 13690, change in cost 0.0109949\n",
      "step 13700, training accuracy 0.951219\n",
      "step 13700, cost 9.29942\n",
      "step 13700, change in cost 0.0107679\n",
      "step 13710, training accuracy 0.951219\n",
      "step 13710, cost 9.28887\n",
      "step 13710, change in cost 0.0105505\n",
      "step 13720, training accuracy 0.951219\n",
      "step 13720, cost 9.27853\n",
      "step 13720, change in cost 0.0103331\n",
      "step 13730, training accuracy 0.951219\n",
      "step 13730, cost 9.26841\n",
      "step 13730, change in cost 0.0101271\n",
      "step 13740, training accuracy 0.951219\n",
      "step 13740, cost 9.25849\n",
      "step 13740, change in cost 0.00992203\n",
      "step 13750, training accuracy 0.951219\n",
      "step 13750, cost 9.24876\n",
      "step 13750, change in cost 0.00972271\n",
      "step 13760, training accuracy 0.951219\n",
      "step 13760, cost 9.23924\n",
      "step 13760, change in cost 0.00952721\n",
      "step 13770, training accuracy 0.951219\n",
      "step 13770, cost 9.2299\n",
      "step 13770, change in cost 0.00933552\n",
      "step 13780, training accuracy 0.951219\n",
      "step 13780, cost 9.22075\n",
      "step 13780, change in cost 0.00915146\n",
      "step 13790, training accuracy 0.951219\n",
      "step 13790, cost 9.21178\n",
      "step 13790, change in cost 0.00896835\n",
      "step 13800, training accuracy 0.951219\n",
      "step 13800, cost 9.20298\n",
      "step 13800, change in cost 0.00879574\n",
      "step 13810, training accuracy 0.951219\n",
      "step 13810, cost 9.19436\n",
      "step 13810, change in cost 0.00862217\n",
      "step 13820, training accuracy 0.951219\n",
      "step 13820, cost 9.18591\n",
      "step 13820, change in cost 0.00845718\n",
      "step 13830, training accuracy 0.951219\n",
      "step 13830, cost 9.17762\n",
      "step 13830, change in cost 0.00829029\n",
      "step 13840, training accuracy 0.951219\n",
      "step 13840, cost 9.16948\n",
      "step 13840, change in cost 0.0081358\n",
      "step 13850, training accuracy 0.951219\n",
      "step 13850, cost 9.1615\n",
      "step 13850, change in cost 0.00797653\n",
      "step 13860, training accuracy 0.951219\n",
      "step 13860, cost 9.15367\n",
      "step 13860, change in cost 0.00783062\n",
      "step 13870, training accuracy 0.951219\n",
      "step 13870, cost 9.14599\n",
      "step 13870, change in cost 0.00767899\n",
      "step 13880, training accuracy 0.951219\n",
      "step 13880, cost 9.13845\n",
      "step 13880, change in cost 0.00753975\n",
      "step 13890, training accuracy 0.951219\n",
      "step 13890, cost 9.13105\n",
      "step 13890, change in cost 0.00739956\n",
      "step 13900, training accuracy 0.951219\n",
      "step 13900, cost 9.12379\n",
      "step 13900, change in cost 0.00726318\n",
      "step 13910, training accuracy 0.951219\n",
      "step 13910, cost 9.11666\n",
      "step 13910, change in cost 0.00713158\n",
      "step 13920, training accuracy 0.951219\n",
      "step 13920, cost 9.10966\n",
      "step 13920, change in cost 0.00699997\n",
      "step 13930, training accuracy 0.951219\n",
      "step 13930, cost 9.10278\n",
      "step 13930, change in cost 0.00687599\n",
      "step 13940, training accuracy 0.951219\n",
      "step 13940, cost 9.09603\n",
      "step 13940, change in cost 0.00675583\n",
      "step 13950, training accuracy 0.951219\n",
      "step 13950, cost 9.08939\n",
      "step 13950, change in cost 0.00663662\n",
      "step 13960, training accuracy 0.951219\n",
      "step 13960, cost 9.08287\n",
      "step 13960, change in cost 0.00652027\n",
      "step 13970, training accuracy 0.951219\n",
      "step 13970, cost 9.07646\n",
      "step 13970, change in cost 0.00640774\n",
      "step 13980, training accuracy 0.951219\n",
      "step 13980, cost 9.07016\n",
      "step 13980, change in cost 0.00629902\n",
      "step 13990, training accuracy 0.951219\n",
      "step 13990, cost 9.06397\n",
      "step 13990, change in cost 0.00619316\n",
      "step 14000, training accuracy 0.951219\n",
      "step 14000, cost 9.05789\n",
      "step 14000, change in cost 0.00608253\n",
      "step 14010, training accuracy 0.951219\n",
      "step 14010, cost 9.0519\n",
      "step 14010, change in cost 0.00598812\n",
      "step 14020, training accuracy 0.951219\n",
      "step 14020, cost 9.04601\n",
      "step 14020, change in cost 0.00588512\n",
      "step 14030, training accuracy 0.951219\n",
      "step 14030, cost 9.04023\n",
      "step 14030, change in cost 0.00578976\n",
      "step 14040, training accuracy 0.951219\n",
      "step 14040, cost 9.03453\n",
      "step 14040, change in cost 0.00569439\n",
      "step 14050, training accuracy 0.951219\n",
      "step 14050, cost 9.02892\n",
      "step 14050, change in cost 0.0056057\n",
      "step 14060, training accuracy 0.951219\n",
      "step 14060, cost 9.02341\n",
      "step 14060, change in cost 0.00551701\n",
      "step 14070, training accuracy 0.951219\n",
      "step 14070, cost 9.01798\n",
      "step 14070, change in cost 0.00542927\n",
      "step 14080, training accuracy 0.951219\n",
      "step 14080, cost 9.01263\n",
      "step 14080, change in cost 0.00534439\n",
      "step 14090, training accuracy 0.951219\n",
      "step 14090, cost 9.00737\n",
      "step 14090, change in cost 0.00526333\n",
      "step 14100, training accuracy 0.951219\n",
      "step 14100, cost 9.00219\n",
      "step 14100, change in cost 0.00518131\n",
      "step 14110, training accuracy 0.951219\n",
      "step 14110, cost 8.99709\n",
      "step 14110, change in cost 0.00510406\n",
      "step 14120, training accuracy 0.951219\n",
      "step 14120, cost 8.99206\n",
      "step 14120, change in cost 0.00502777\n",
      "step 14130, training accuracy 0.951219\n",
      "step 14130, cost 8.9871\n",
      "step 14130, change in cost 0.00495529\n",
      "step 14140, training accuracy 0.951219\n",
      "step 14140, cost 8.98222\n",
      "step 14140, change in cost 0.004879\n",
      "step 14150, training accuracy 0.951219\n",
      "step 14150, cost 8.97741\n",
      "step 14150, change in cost 0.00481224\n",
      "step 14160, training accuracy 0.951219\n",
      "step 14160, cost 8.97267\n",
      "step 14160, change in cost 0.00474072\n",
      "step 14170, training accuracy 0.951219\n",
      "step 14170, cost 8.968\n",
      "step 14170, change in cost 0.00467396\n",
      "step 14180, training accuracy 0.951219\n",
      "step 14180, cost 8.96339\n",
      "step 14180, change in cost 0.00461006\n",
      "step 14190, training accuracy 0.951219\n",
      "step 14190, cost 8.95885\n",
      "step 14190, change in cost 0.0045414\n",
      "step 14200, training accuracy 0.951219\n",
      "step 14200, cost 8.95436\n",
      "step 14200, change in cost 0.00448608\n",
      "step 14210, training accuracy 0.951219\n",
      "step 14210, cost 8.94994\n",
      "step 14210, change in cost 0.00442123\n",
      "step 14220, training accuracy 0.951219\n",
      "step 14220, cost 8.94558\n",
      "step 14220, change in cost 0.00436211\n",
      "step 14230, training accuracy 0.951219\n",
      "step 14230, cost 8.94127\n",
      "step 14230, change in cost 0.00430393\n",
      "step 14240, training accuracy 0.951219\n",
      "step 14240, cost 8.93703\n",
      "step 14240, change in cost 0.00424671\n",
      "step 14250, training accuracy 0.951219\n",
      "step 14250, cost 8.93283\n",
      "step 14250, change in cost 0.00419426\n",
      "step 14260, training accuracy 0.951219\n",
      "step 14260, cost 8.92869\n",
      "step 14260, change in cost 0.00413799\n",
      "step 14270, training accuracy 0.951219\n",
      "step 14270, cost 8.92461\n",
      "step 14270, change in cost 0.00408554\n",
      "step 14280, training accuracy 0.951219\n",
      "step 14280, cost 8.92057\n",
      "step 14280, change in cost 0.00403595\n",
      "step 14290, training accuracy 0.951219\n",
      "step 14290, cost 8.91659\n",
      "step 14290, change in cost 0.0039854\n",
      "step 14300, training accuracy 0.951219\n",
      "step 14300, cost 8.91265\n",
      "step 14300, change in cost 0.00393486\n",
      "step 14310, training accuracy 0.951219\n",
      "step 14310, cost 8.90876\n",
      "step 14310, change in cost 0.00388718\n",
      "step 14320, training accuracy 0.951219\n",
      "step 14320, cost 8.90492\n",
      "step 14320, change in cost 0.0038414\n",
      "step 14330, training accuracy 0.951219\n",
      "step 14330, cost 8.90113\n",
      "step 14330, change in cost 0.00379562\n",
      "step 14340, training accuracy 0.951219\n",
      "step 14340, cost 8.89738\n",
      "step 14340, change in cost 0.00375175\n",
      "step 14350, training accuracy 0.951219\n",
      "step 14350, cost 8.89367\n",
      "step 14350, change in cost 0.00370979\n",
      "step 14360, training accuracy 0.951219\n",
      "step 14360, cost 8.89\n",
      "step 14360, change in cost 0.00366306\n",
      "step 14370, training accuracy 0.951219\n",
      "step 14370, cost 8.88638\n",
      "step 14370, change in cost 0.00362492\n",
      "step 14380, training accuracy 0.951219\n",
      "step 14380, cost 8.88279\n",
      "step 14380, change in cost 0.00358391\n",
      "step 14390, training accuracy 0.951219\n",
      "step 14390, cost 8.87925\n",
      "step 14390, change in cost 0.00354195\n",
      "step 14400, training accuracy 0.951219\n",
      "step 14400, cost 8.87575\n",
      "step 14400, change in cost 0.0035038\n",
      "step 14410, training accuracy 0.951219\n",
      "step 14410, cost 8.87228\n",
      "step 14410, change in cost 0.00346661\n",
      "step 14420, training accuracy 0.951219\n",
      "step 14420, cost 8.86885\n",
      "step 14420, change in cost 0.00343323\n",
      "step 14430, training accuracy 0.951219\n",
      "step 14430, cost 8.86546\n",
      "step 14430, change in cost 0.00339031\n",
      "step 14440, training accuracy 0.951219\n",
      "step 14440, cost 8.8621\n",
      "step 14440, change in cost 0.00335979\n",
      "step 14450, training accuracy 0.951219\n",
      "step 14450, cost 8.85878\n",
      "step 14450, change in cost 0.00332069\n",
      "step 14460, training accuracy 0.951219\n",
      "step 14460, cost 8.85549\n",
      "step 14460, change in cost 0.00329113\n",
      "step 14470, training accuracy 0.951219\n",
      "step 14470, cost 8.85223\n",
      "step 14470, change in cost 0.0032568\n",
      "step 14480, training accuracy 0.951219\n",
      "step 14480, cost 8.849\n",
      "step 14480, change in cost 0.00322533\n",
      "step 14490, training accuracy 0.951219\n",
      "step 14490, cost 8.84581\n",
      "step 14490, change in cost 0.00319004\n",
      "step 14500, training accuracy 0.951219\n",
      "step 14500, cost 8.84265\n",
      "step 14500, change in cost 0.00316238\n",
      "step 14510, training accuracy 0.951219\n",
      "step 14510, cost 8.83952\n",
      "step 14510, change in cost 0.00312805\n",
      "step 14520, training accuracy 0.951219\n",
      "step 14520, cost 8.83642\n",
      "step 14520, change in cost 0.00310135\n",
      "step 14530, training accuracy 0.951219\n",
      "step 14530, cost 8.83335\n",
      "step 14530, change in cost 0.00307274\n",
      "step 14540, training accuracy 0.951219\n",
      "step 14540, cost 8.83031\n",
      "step 14540, change in cost 0.00304413\n",
      "step 14550, training accuracy 0.951219\n",
      "step 14550, cost 8.82729\n",
      "step 14550, change in cost 0.00301552\n",
      "step 14560, training accuracy 0.951219\n",
      "step 14560, cost 8.8243\n",
      "step 14560, change in cost 0.00298977\n",
      "step 14570, training accuracy 0.951219\n",
      "step 14570, cost 8.82134\n",
      "step 14570, change in cost 0.00296307\n",
      "step 14580, training accuracy 0.951219\n",
      "step 14580, cost 8.8184\n",
      "step 14580, change in cost 0.00293446\n",
      "step 14590, training accuracy 0.951219\n",
      "step 14590, cost 8.81549\n",
      "step 14590, change in cost 0.00291157\n",
      "step 14600, training accuracy 0.951219\n",
      "step 14600, cost 8.8126\n",
      "step 14600, change in cost 0.00288677\n",
      "step 14610, training accuracy 0.951219\n",
      "step 14610, cost 8.80975\n",
      "step 14610, change in cost 0.00285816\n",
      "step 14620, training accuracy 0.951219\n",
      "step 14620, cost 8.80691\n",
      "step 14620, change in cost 0.00283718\n",
      "step 14630, training accuracy 0.951219\n",
      "step 14630, cost 8.8041\n",
      "step 14630, change in cost 0.00281334\n",
      "step 14640, training accuracy 0.951219\n",
      "step 14640, cost 8.80131\n",
      "step 14640, change in cost 0.00278854\n",
      "step 14650, training accuracy 0.951219\n",
      "step 14650, cost 8.79854\n",
      "step 14650, change in cost 0.00276852\n",
      "step 14660, training accuracy 0.951219\n",
      "step 14660, cost 8.7958\n",
      "step 14660, change in cost 0.00274277\n",
      "step 14670, training accuracy 0.951219\n",
      "step 14670, cost 8.79307\n",
      "step 14670, change in cost 0.00272274\n",
      "step 14680, training accuracy 0.951219\n",
      "step 14680, cost 8.79037\n",
      "step 14680, change in cost 0.00270557\n",
      "step 14690, training accuracy 0.951219\n",
      "step 14690, cost 8.78769\n",
      "step 14690, change in cost 0.00267982\n",
      "step 14700, training accuracy 0.951219\n",
      "step 14700, cost 8.78503\n",
      "step 14700, change in cost 0.00266075\n",
      "step 14710, training accuracy 0.951219\n",
      "step 14710, cost 8.78239\n",
      "step 14710, change in cost 0.00263786\n",
      "step 14720, training accuracy 0.951219\n",
      "step 14720, cost 8.77977\n",
      "step 14720, change in cost 0.0026207\n",
      "step 14730, training accuracy 0.951219\n",
      "step 14730, cost 8.77716\n",
      "step 14730, change in cost 0.00260544\n",
      "step 14740, training accuracy 0.951219\n",
      "step 14740, cost 8.77458\n",
      "step 14740, change in cost 0.00258541\n",
      "step 14750, training accuracy 0.951219\n",
      "step 14750, cost 8.77201\n",
      "step 14750, change in cost 0.00256348\n",
      "step 14760, training accuracy 0.951219\n",
      "step 14760, cost 8.76947\n",
      "step 14760, change in cost 0.00254726\n",
      "step 14770, training accuracy 0.951219\n",
      "step 14770, cost 8.76694\n",
      "step 14770, change in cost 0.00252724\n",
      "step 14780, training accuracy 0.951219\n",
      "step 14780, cost 8.76443\n",
      "step 14780, change in cost 0.00251007\n",
      "step 14790, training accuracy 0.951219\n",
      "step 14790, cost 8.76194\n",
      "step 14790, change in cost 0.0024929\n",
      "step 14800, training accuracy 0.951219\n",
      "step 14800, cost 8.75946\n",
      "step 14800, change in cost 0.0024786\n",
      "step 14810, training accuracy 0.951219\n",
      "step 14810, cost 8.757\n",
      "step 14810, change in cost 0.00246048\n",
      "step 14820, training accuracy 0.951219\n",
      "step 14820, cost 8.75455\n",
      "step 14820, change in cost 0.00244522\n",
      "step 14830, training accuracy 0.951219\n",
      "step 14830, cost 8.75212\n",
      "step 14830, change in cost 0.00242805\n",
      "step 14840, training accuracy 0.951219\n",
      "step 14840, cost 8.74971\n",
      "step 14840, change in cost 0.00241375\n",
      "step 14850, training accuracy 0.951219\n",
      "step 14850, cost 8.74731\n",
      "step 14850, change in cost 0.00239658\n",
      "step 14860, training accuracy 0.951219\n",
      "step 14860, cost 8.74493\n",
      "step 14860, change in cost 0.00238323\n",
      "step 14870, training accuracy 0.951219\n",
      "step 14870, cost 8.74256\n",
      "step 14870, change in cost 0.00236893\n",
      "step 14880, training accuracy 0.951219\n",
      "step 14880, cost 8.74021\n",
      "step 14880, change in cost 0.00235367\n",
      "step 14890, training accuracy 0.951219\n",
      "step 14890, cost 8.73787\n",
      "step 14890, change in cost 0.00234032\n",
      "step 14900, training accuracy 0.951219\n",
      "step 14900, cost 8.73554\n",
      "step 14900, change in cost 0.00232506\n",
      "step 14910, training accuracy 0.951219\n",
      "step 14910, cost 8.73323\n",
      "step 14910, change in cost 0.00231171\n",
      "step 14920, training accuracy 0.951219\n",
      "step 14920, cost 8.73093\n",
      "step 14920, change in cost 0.00230026\n",
      "step 14930, training accuracy 0.951219\n",
      "step 14930, cost 8.72865\n",
      "step 14930, change in cost 0.002285\n",
      "step 14940, training accuracy 0.951219\n",
      "step 14940, cost 8.72637\n",
      "step 14940, change in cost 0.00227451\n",
      "step 14950, training accuracy 0.951219\n",
      "step 14950, cost 8.72411\n",
      "step 14950, change in cost 0.00225925\n",
      "step 14960, training accuracy 0.951219\n",
      "step 14960, cost 8.72186\n",
      "step 14960, change in cost 0.00224876\n",
      "step 14970, training accuracy 0.951219\n",
      "step 14970, cost 8.71963\n",
      "step 14970, change in cost 0.00223637\n",
      "step 14980, training accuracy 0.951219\n",
      "step 14980, cost 8.7174\n",
      "step 14980, change in cost 0.00222492\n",
      "step 14990, training accuracy 0.951219\n",
      "step 14990, cost 8.71519\n",
      "step 14990, change in cost 0.00221252\n",
      "step 15000, training accuracy 0.951219\n",
      "step 15000, cost 8.71299\n",
      "step 15000, change in cost 0.00220108\n",
      "step 15010, training accuracy 0.951219\n",
      "step 15010, cost 8.7108\n",
      "step 15010, change in cost 0.00218678\n",
      "step 15020, training accuracy 0.951219\n",
      "step 15020, cost 8.70862\n",
      "step 15020, change in cost 0.0021801\n",
      "step 15030, training accuracy 0.951219\n",
      "step 15030, cost 8.70645\n",
      "step 15030, change in cost 0.0021677\n",
      "step 15040, training accuracy 0.951219\n",
      "step 15040, cost 8.7043\n",
      "step 15040, change in cost 0.00215626\n",
      "step 15050, training accuracy 0.951219\n",
      "step 15050, cost 8.70215\n",
      "step 15050, change in cost 0.00214767\n",
      "step 15060, training accuracy 0.951219\n",
      "step 15060, cost 8.70001\n",
      "step 15060, change in cost 0.00213528\n",
      "step 15070, training accuracy 0.951219\n",
      "step 15070, cost 8.69789\n",
      "step 15070, change in cost 0.00212669\n",
      "step 15080, training accuracy 0.951219\n",
      "step 15080, cost 8.69577\n",
      "step 15080, change in cost 0.0021162\n",
      "step 15090, training accuracy 0.951219\n",
      "step 15090, cost 8.69367\n",
      "step 15090, change in cost 0.00210571\n",
      "step 15100, training accuracy 0.951219\n",
      "step 15100, cost 8.69157\n",
      "step 15100, change in cost 0.00209522\n",
      "step 15110, training accuracy 0.951219\n",
      "step 15110, cost 8.68948\n",
      "step 15110, change in cost 0.00209045\n",
      "step 15120, training accuracy 0.951219\n",
      "step 15120, cost 8.6874\n",
      "step 15120, change in cost 0.0020771\n",
      "step 15130, training accuracy 0.951219\n",
      "step 15130, cost 8.68533\n",
      "step 15130, change in cost 0.00206947\n",
      "step 15140, training accuracy 0.951219\n",
      "step 15140, cost 8.68328\n",
      "step 15140, change in cost 0.00205803\n",
      "step 15150, training accuracy 0.951219\n",
      "step 15150, cost 8.68122\n",
      "step 15150, change in cost 0.00205135\n",
      "step 15160, training accuracy 0.951219\n",
      "step 15160, cost 8.67918\n",
      "step 15160, change in cost 0.00204182\n",
      "step 15170, training accuracy 0.951219\n",
      "step 15170, cost 8.67715\n",
      "step 15170, change in cost 0.00203609\n",
      "step 15180, training accuracy 0.951219\n",
      "step 15180, cost 8.67512\n",
      "step 15180, change in cost 0.0020237\n",
      "step 15190, training accuracy 0.951219\n",
      "step 15190, cost 8.67311\n",
      "step 15190, change in cost 0.00201702\n",
      "step 15200, training accuracy 0.951219\n",
      "step 15200, cost 8.6711\n",
      "step 15200, change in cost 0.00200939\n",
      "step 15210, training accuracy 0.951219\n",
      "step 15210, cost 8.66909\n",
      "step 15210, change in cost 0.00200367\n",
      "step 15220, training accuracy 0.951219\n",
      "step 15220, cost 8.6671\n",
      "step 15220, change in cost 0.00199127\n",
      "step 15230, training accuracy 0.951219\n",
      "step 15230, cost 8.66511\n",
      "step 15230, change in cost 0.00198841\n",
      "step 15240, training accuracy 0.951219\n",
      "step 15240, cost 8.66313\n",
      "step 15240, change in cost 0.00197887\n",
      "step 15250, training accuracy 0.951219\n",
      "step 15250, cost 8.66116\n",
      "step 15250, change in cost 0.00197029\n",
      "step 15260, training accuracy 0.951219\n",
      "step 15260, cost 8.6592\n",
      "step 15260, change in cost 0.00196552\n",
      "step 15270, training accuracy 0.951219\n",
      "step 15270, cost 8.65724\n",
      "step 15270, change in cost 0.00195694\n",
      "step 15280, training accuracy 0.951219\n",
      "step 15280, cost 8.65529\n",
      "step 15280, change in cost 0.00195026\n",
      "step 15290, training accuracy 0.951219\n",
      "step 15290, cost 8.65335\n",
      "step 15290, change in cost 0.0019455\n",
      "step 15300, training accuracy 0.951219\n",
      "step 15300, cost 8.65141\n",
      "step 15300, change in cost 0.00193691\n",
      "step 15310, training accuracy 0.951219\n",
      "step 15310, cost 8.64948\n",
      "step 15310, change in cost 0.00192928\n",
      "step 15320, training accuracy 0.951219\n",
      "step 15320, cost 8.64755\n",
      "step 15320, change in cost 0.00192547\n",
      "step 15330, training accuracy 0.951219\n",
      "step 15330, cost 8.64564\n",
      "step 15330, change in cost 0.00191498\n",
      "step 15340, training accuracy 0.951219\n",
      "step 15340, cost 8.64372\n",
      "step 15340, change in cost 0.00191689\n",
      "step 15350, training accuracy 0.951219\n",
      "step 15350, cost 8.64182\n",
      "step 15350, change in cost 0.00190353\n",
      "step 15360, training accuracy 0.951219\n",
      "step 15360, cost 8.63992\n",
      "step 15360, change in cost 0.00189781\n",
      "step 15370, training accuracy 0.951219\n",
      "step 15370, cost 8.63803\n",
      "step 15370, change in cost 0.00189495\n",
      "step 15380, training accuracy 0.951219\n",
      "step 15380, cost 8.63614\n",
      "step 15380, change in cost 0.00188637\n",
      "step 15390, training accuracy 0.951219\n",
      "step 15390, cost 8.63426\n",
      "step 15390, change in cost 0.00188255\n",
      "step 15400, training accuracy 0.951219\n",
      "step 15400, cost 8.63238\n",
      "step 15400, change in cost 0.00187874\n",
      "step 15410, training accuracy 0.951219\n",
      "step 15410, cost 8.63051\n",
      "step 15410, change in cost 0.00187111\n",
      "step 15420, training accuracy 0.951219\n",
      "step 15420, cost 8.62864\n",
      "step 15420, change in cost 0.00186634\n",
      "step 15430, training accuracy 0.951219\n",
      "step 15430, cost 8.62678\n",
      "step 15430, change in cost 0.00185871\n",
      "step 15440, training accuracy 0.951219\n",
      "step 15440, cost 8.62492\n",
      "step 15440, change in cost 0.0018568\n",
      "step 15450, training accuracy 0.951219\n",
      "step 15450, cost 8.62307\n",
      "step 15450, change in cost 0.00185108\n",
      "step 15460, training accuracy 0.951219\n",
      "step 15460, cost 8.62123\n",
      "step 15460, change in cost 0.00184631\n",
      "step 15470, training accuracy 0.951219\n",
      "step 15470, cost 8.61939\n",
      "step 15470, change in cost 0.00184059\n",
      "step 15480, training accuracy 0.951219\n",
      "step 15480, cost 8.61755\n",
      "step 15480, change in cost 0.00183296\n",
      "step 15490, training accuracy 0.951219\n",
      "step 15490, cost 8.61572\n",
      "step 15490, change in cost 0.00183487\n",
      "step 15500, training accuracy 0.951219\n",
      "step 15500, cost 8.6139\n",
      "step 15500, change in cost 0.00182343\n",
      "step 15510, training accuracy 0.951219\n",
      "step 15510, cost 8.61207\n",
      "step 15510, change in cost 0.00182152\n",
      "step 15520, training accuracy 0.951219\n",
      "step 15520, cost 8.61025\n",
      "step 15520, change in cost 0.00181961\n",
      "step 15530, training accuracy 0.951219\n",
      "step 15530, cost 8.60844\n",
      "step 15530, change in cost 0.00181198\n",
      "step 15540, training accuracy 0.951219\n",
      "step 15540, cost 8.60663\n",
      "step 15540, change in cost 0.00181007\n",
      "step 15550, training accuracy 0.951219\n",
      "step 15550, cost 8.60483\n",
      "step 15550, change in cost 0.00180435\n",
      "step 15560, training accuracy 0.951219\n",
      "step 15560, cost 8.60303\n",
      "step 15560, change in cost 0.00180054\n",
      "step 15570, training accuracy 0.951219\n",
      "step 15570, cost 8.60123\n",
      "step 15570, change in cost 0.00179672\n",
      "step 15580, training accuracy 0.951219\n",
      "step 15580, cost 8.59943\n",
      "step 15580, change in cost 0.00179577\n",
      "step 15590, training accuracy 0.951219\n",
      "step 15590, cost 8.59765\n",
      "step 15590, change in cost 0.00178814\n",
      "step 15600, training accuracy 0.951219\n",
      "step 15600, cost 8.59586\n",
      "step 15600, change in cost 0.00178528\n",
      "step 15610, training accuracy 0.951219\n",
      "step 15610, cost 8.59408\n",
      "step 15610, change in cost 0.00178337\n",
      "step 15620, training accuracy 0.951219\n",
      "step 15620, cost 8.5923\n",
      "step 15620, change in cost 0.00177765\n",
      "step 15630, training accuracy 0.951219\n",
      "step 15630, cost 8.59052\n",
      "step 15630, change in cost 0.00177765\n",
      "step 15640, training accuracy 0.951219\n",
      "step 15640, cost 8.58875\n",
      "step 15640, change in cost 0.00177193\n",
      "step 15650, training accuracy 0.951219\n",
      "step 15650, cost 8.58698\n",
      "step 15650, change in cost 0.00176811\n",
      "step 15660, training accuracy 0.951219\n",
      "step 15660, cost 8.58522\n",
      "step 15660, change in cost 0.00176525\n",
      "step 15670, training accuracy 0.951219\n",
      "step 15670, cost 8.58346\n",
      "step 15670, change in cost 0.00176239\n",
      "step 15680, training accuracy 0.951219\n",
      "step 15680, cost 8.5817\n",
      "step 15680, change in cost 0.00175667\n",
      "step 15690, training accuracy 0.951219\n",
      "step 15690, cost 8.57994\n",
      "step 15690, change in cost 0.00175571\n",
      "step 15700, training accuracy 0.951219\n",
      "step 15700, cost 8.57819\n",
      "step 15700, change in cost 0.00175476\n",
      "step 15710, training accuracy 0.951219\n",
      "step 15710, cost 8.57644\n",
      "step 15710, change in cost 0.00174904\n",
      "step 15720, training accuracy 0.951219\n",
      "step 15720, cost 8.57469\n",
      "step 15720, change in cost 0.00174713\n",
      "step 15730, training accuracy 0.951219\n",
      "step 15730, cost 8.57295\n",
      "step 15730, change in cost 0.00174427\n",
      "step 15740, training accuracy 0.951219\n",
      "step 15740, cost 8.57121\n",
      "step 15740, change in cost 0.00174046\n",
      "step 15750, training accuracy 0.951219\n",
      "step 15750, cost 8.56947\n",
      "step 15750, change in cost 0.00174046\n",
      "step 15760, training accuracy 0.951219\n",
      "step 15760, cost 8.56773\n",
      "step 15760, change in cost 0.00173759\n",
      "step 15770, training accuracy 0.951219\n",
      "step 15770, cost 8.56599\n",
      "step 15770, change in cost 0.00173569\n",
      "step 15780, training accuracy 0.951219\n",
      "step 15780, cost 8.56426\n",
      "step 15780, change in cost 0.00172901\n",
      "step 15790, training accuracy 0.951219\n",
      "step 15790, cost 8.56253\n",
      "step 15790, change in cost 0.00173187\n",
      "step 15800, training accuracy 0.951219\n",
      "step 15800, cost 8.56081\n",
      "step 15800, change in cost 0.00172424\n",
      "step 15810, training accuracy 0.951219\n",
      "step 15810, cost 8.55908\n",
      "step 15810, change in cost 0.00172615\n",
      "step 15820, training accuracy 0.951219\n",
      "step 15820, cost 8.55736\n",
      "step 15820, change in cost 0.00172329\n",
      "step 15830, training accuracy 0.951219\n",
      "step 15830, cost 8.55564\n",
      "step 15830, change in cost 0.00172043\n",
      "step 15840, training accuracy 0.951219\n",
      "step 15840, cost 8.55392\n",
      "step 15840, change in cost 0.00171757\n",
      "step 15850, training accuracy 0.951219\n",
      "step 15850, cost 8.5522\n",
      "step 15850, change in cost 0.00171757\n",
      "step 15860, training accuracy 0.951219\n",
      "step 15860, cost 8.55049\n",
      "step 15860, change in cost 0.00171566\n",
      "step 15870, training accuracy 0.951219\n",
      "step 15870, cost 8.54877\n",
      "step 15870, change in cost 0.0017128\n",
      "step 15880, training accuracy 0.951219\n",
      "step 15880, cost 8.54707\n",
      "step 15880, change in cost 0.00170898\n",
      "step 15890, training accuracy 0.951219\n",
      "step 15890, cost 8.54536\n",
      "step 15890, change in cost 0.00170994\n",
      "step 15900, training accuracy 0.951219\n",
      "step 15900, cost 8.54365\n",
      "step 15900, change in cost 0.00170994\n",
      "step 15910, training accuracy 0.951219\n",
      "step 15910, cost 8.54194\n",
      "step 15910, change in cost 0.00170708\n",
      "step 15920, training accuracy 0.951219\n",
      "step 15920, cost 8.54023\n",
      "step 15920, change in cost 0.00170422\n",
      "step 15930, training accuracy 0.951219\n",
      "step 15930, cost 8.53853\n",
      "step 15930, change in cost 0.00170517\n",
      "step 15940, training accuracy 0.951219\n",
      "step 15940, cost 8.53683\n",
      "step 15940, change in cost 0.00169849\n",
      "step 15950, training accuracy 0.951219\n",
      "step 15950, cost 8.53513\n",
      "step 15950, change in cost 0.00170135\n",
      "step 15960, training accuracy 0.951219\n",
      "step 15960, cost 8.53343\n",
      "step 15960, change in cost 0.00170135\n",
      "step 15970, training accuracy 0.951219\n",
      "step 15970, cost 8.53173\n",
      "step 15970, change in cost 0.00169849\n",
      "step 15980, training accuracy 0.951219\n",
      "step 15980, cost 8.53003\n",
      "step 15980, change in cost 0.00169754\n",
      "step 15990, training accuracy 0.951219\n",
      "step 15990, cost 8.52834\n",
      "step 15990, change in cost 0.00169468\n",
      "step 16000, training accuracy 0.951219\n",
      "step 16000, cost 8.52664\n",
      "step 16000, change in cost 0.00169468\n",
      "step 16010, training accuracy 0.951219\n",
      "step 16010, cost 8.52495\n",
      "step 16010, change in cost 0.00169277\n",
      "step 16020, training accuracy 0.951219\n",
      "step 16020, cost 8.52326\n",
      "step 16020, change in cost 0.00169373\n",
      "step 16030, training accuracy 0.951219\n",
      "step 16030, cost 8.52156\n",
      "step 16030, change in cost 0.00169373\n",
      "step 16040, training accuracy 0.951219\n",
      "step 16040, cost 8.51987\n",
      "step 16040, change in cost 0.00169182\n",
      "step 16050, training accuracy 0.951219\n",
      "step 16050, cost 8.51818\n",
      "step 16050, change in cost 0.00168991\n",
      "step 16060, training accuracy 0.951219\n",
      "step 16060, cost 8.51649\n",
      "step 16060, change in cost 0.001688\n",
      "step 16070, training accuracy 0.951219\n",
      "step 16070, cost 8.5148\n",
      "step 16070, change in cost 0.00169086\n",
      "step 16080, training accuracy 0.951219\n",
      "step 16080, cost 8.51311\n",
      "step 16080, change in cost 0.00168896\n",
      "step 16090, training accuracy 0.951219\n",
      "step 16090, cost 8.51142\n",
      "step 16090, change in cost 0.00168991\n",
      "step 16100, training accuracy 0.951219\n",
      "step 16100, cost 8.50974\n",
      "step 16100, change in cost 0.00168705\n",
      "step 16110, training accuracy 0.951219\n",
      "step 16110, cost 8.50805\n",
      "step 16110, change in cost 0.00168705\n",
      "step 16120, training accuracy 0.951219\n",
      "step 16120, cost 8.50636\n",
      "step 16120, change in cost 0.00168896\n",
      "step 16130, training accuracy 0.951219\n",
      "step 16130, cost 8.50467\n",
      "step 16130, change in cost 0.00168514\n",
      "step 16140, training accuracy 0.951219\n",
      "step 16140, cost 8.50299\n",
      "step 16140, change in cost 0.0016861\n",
      "step 16150, training accuracy 0.951219\n",
      "step 16150, cost 8.5013\n",
      "step 16150, change in cost 0.0016861\n",
      "step 16160, training accuracy 0.951219\n",
      "step 16160, cost 8.49961\n",
      "step 16160, change in cost 0.001688\n",
      "step 16170, training accuracy 0.951219\n",
      "step 16170, cost 8.49793\n",
      "step 16170, change in cost 0.00168419\n",
      "step 16180, training accuracy 0.951219\n",
      "step 16180, cost 8.49624\n",
      "step 16180, change in cost 0.001688\n",
      "step 16190, training accuracy 0.951219\n",
      "step 16190, cost 8.49455\n",
      "step 16190, change in cost 0.001688\n",
      "step 16200, training accuracy 0.951219\n",
      "step 16200, cost 8.49287\n",
      "step 16200, change in cost 0.0016861\n",
      "step 16210, training accuracy 0.951219\n",
      "step 16210, cost 8.49118\n",
      "step 16210, change in cost 0.00168419\n",
      "step 16220, training accuracy 0.951219\n",
      "step 16220, cost 8.48949\n",
      "step 16220, change in cost 0.00169086\n",
      "step 16230, training accuracy 0.951219\n",
      "step 16230, cost 8.48781\n",
      "step 16230, change in cost 0.00168514\n",
      "step 16240, training accuracy 0.951219\n",
      "step 16240, cost 8.48612\n",
      "step 16240, change in cost 0.001688\n",
      "step 16250, training accuracy 0.951219\n",
      "step 16250, cost 8.48443\n",
      "step 16250, change in cost 0.001688\n",
      "step 16260, training accuracy 0.951219\n",
      "step 16260, cost 8.48275\n",
      "step 16260, change in cost 0.0016861\n",
      "step 16270, training accuracy 0.951219\n",
      "step 16270, cost 8.48106\n",
      "step 16270, change in cost 0.00168991\n",
      "step 16280, training accuracy 0.951219\n",
      "step 16280, cost 8.47937\n",
      "step 16280, change in cost 0.00168991\n",
      "step 16290, training accuracy 0.951219\n",
      "step 16290, cost 8.47767\n",
      "step 16290, change in cost 0.00169182\n",
      "step 16300, training accuracy 0.951219\n",
      "step 16300, cost 8.47598\n",
      "step 16300, change in cost 0.00169182\n",
      "step 16310, training accuracy 0.951219\n",
      "step 16310, cost 8.47429\n",
      "step 16310, change in cost 0.00169182\n",
      "step 16320, training accuracy 0.951219\n",
      "step 16320, cost 8.4726\n",
      "step 16320, change in cost 0.00169277\n",
      "step 16330, training accuracy 0.951219\n",
      "step 16330, cost 8.4709\n",
      "step 16330, change in cost 0.00169468\n",
      "step 16340, training accuracy 0.951219\n",
      "step 16340, cost 8.46921\n",
      "step 16340, change in cost 0.00169373\n",
      "step 16350, training accuracy 0.951219\n",
      "step 16350, cost 8.46751\n",
      "step 16350, change in cost 0.00169468\n",
      "step 16360, training accuracy 0.951219\n",
      "step 16360, cost 8.46582\n",
      "step 16360, change in cost 0.00169563\n",
      "step 16370, training accuracy 0.951219\n",
      "step 16370, cost 8.46412\n",
      "step 16370, change in cost 0.00169659\n",
      "step 16380, training accuracy 0.951219\n",
      "step 16380, cost 8.46242\n",
      "step 16380, change in cost 0.00169945\n",
      "step 16390, training accuracy 0.951219\n",
      "step 16390, cost 8.46072\n",
      "step 16390, change in cost 0.00169945\n",
      "step 16400, training accuracy 0.951219\n",
      "step 16400, cost 8.45902\n",
      "step 16400, change in cost 0.00169945\n",
      "step 16410, training accuracy 0.951219\n",
      "step 16410, cost 8.45732\n",
      "step 16410, change in cost 0.00170326\n",
      "step 16420, training accuracy 0.951219\n",
      "step 16420, cost 8.45562\n",
      "step 16420, change in cost 0.00170517\n",
      "step 16430, training accuracy 0.951219\n",
      "step 16430, cost 8.45391\n",
      "step 16430, change in cost 0.00170326\n",
      "step 16440, training accuracy 0.951219\n",
      "step 16440, cost 8.45221\n",
      "step 16440, change in cost 0.00170708\n",
      "step 16450, training accuracy 0.951219\n",
      "step 16450, cost 8.4505\n",
      "step 16450, change in cost 0.00170708\n",
      "step 16460, training accuracy 0.951219\n",
      "step 16460, cost 8.44879\n",
      "step 16460, change in cost 0.00171089\n",
      "step 16470, training accuracy 0.951219\n",
      "step 16470, cost 8.44708\n",
      "step 16470, change in cost 0.00171089\n",
      "step 16480, training accuracy 0.951219\n",
      "step 16480, cost 8.44536\n",
      "step 16480, change in cost 0.00171185\n",
      "step 16490, training accuracy 0.951219\n",
      "step 16490, cost 8.44365\n",
      "step 16490, change in cost 0.00171566\n",
      "step 16500, training accuracy 0.951219\n",
      "step 16500, cost 8.44193\n",
      "step 16500, change in cost 0.00171852\n",
      "step 16510, training accuracy 0.951219\n",
      "step 16510, cost 8.44021\n",
      "step 16510, change in cost 0.00171661\n",
      "step 16520, training accuracy 0.951219\n",
      "step 16520, cost 8.4385\n",
      "step 16520, change in cost 0.00171852\n",
      "step 16530, training accuracy 0.951219\n",
      "step 16530, cost 8.43677\n",
      "step 16530, change in cost 0.00172615\n",
      "step 16540, training accuracy 0.951219\n",
      "step 16540, cost 8.43505\n",
      "step 16540, change in cost 0.00172424\n",
      "step 16550, training accuracy 0.951219\n",
      "step 16550, cost 8.43332\n",
      "step 16550, change in cost 0.0017252\n",
      "step 16560, training accuracy 0.951219\n",
      "step 16560, cost 8.43159\n",
      "step 16560, change in cost 0.00172997\n",
      "step 16570, training accuracy 0.951219\n",
      "step 16570, cost 8.42986\n",
      "step 16570, change in cost 0.00173283\n",
      "step 16580, training accuracy 0.951219\n",
      "step 16580, cost 8.42813\n",
      "step 16580, change in cost 0.00173187\n",
      "step 16590, training accuracy 0.951219\n",
      "step 16590, cost 8.42639\n",
      "step 16590, change in cost 0.00173664\n",
      "step 16600, training accuracy 0.951219\n",
      "step 16600, cost 8.42465\n",
      "step 16600, change in cost 0.00173855\n",
      "step 16610, training accuracy 0.951219\n",
      "step 16610, cost 8.42291\n",
      "step 16610, change in cost 0.00174141\n",
      "step 16620, training accuracy 0.951219\n",
      "step 16620, cost 8.42117\n",
      "step 16620, change in cost 0.00174236\n",
      "step 16630, training accuracy 0.951219\n",
      "step 16630, cost 8.41942\n",
      "step 16630, change in cost 0.00174522\n",
      "step 16640, training accuracy 0.951219\n",
      "step 16640, cost 8.41767\n",
      "step 16640, change in cost 0.00174999\n",
      "step 16650, training accuracy 0.951219\n",
      "step 16650, cost 8.41592\n",
      "step 16650, change in cost 0.00175095\n",
      "step 16660, training accuracy 0.951219\n",
      "step 16660, cost 8.41417\n",
      "step 16660, change in cost 0.00175476\n",
      "step 16670, training accuracy 0.951219\n",
      "step 16670, cost 8.41241\n",
      "step 16670, change in cost 0.00175762\n",
      "step 16680, training accuracy 0.951219\n",
      "step 16680, cost 8.41065\n",
      "step 16680, change in cost 0.00175858\n",
      "step 16690, training accuracy 0.951219\n",
      "step 16690, cost 8.40888\n",
      "step 16690, change in cost 0.00176525\n",
      "step 16700, training accuracy 0.951219\n",
      "step 16700, cost 8.40712\n",
      "step 16700, change in cost 0.0017662\n",
      "step 16710, training accuracy 0.951219\n",
      "step 16710, cost 8.40535\n",
      "step 16710, change in cost 0.00176811\n",
      "step 16720, training accuracy 0.951219\n",
      "step 16720, cost 8.40358\n",
      "step 16720, change in cost 0.00177193\n",
      "step 16730, training accuracy 0.951219\n",
      "step 16730, cost 8.4018\n",
      "step 16730, change in cost 0.00177574\n",
      "step 16740, training accuracy 0.951219\n",
      "step 16740, cost 8.40002\n",
      "step 16740, change in cost 0.00177956\n",
      "step 16750, training accuracy 0.951219\n",
      "step 16750, cost 8.39824\n",
      "step 16750, change in cost 0.00178337\n",
      "step 16760, training accuracy 0.951219\n",
      "step 16760, cost 8.39645\n",
      "step 16760, change in cost 0.00178623\n",
      "step 16770, training accuracy 0.951219\n",
      "step 16770, cost 8.39466\n",
      "step 16770, change in cost 0.00179195\n",
      "step 16780, training accuracy 0.951219\n",
      "step 16780, cost 8.39287\n",
      "step 16780, change in cost 0.001791\n",
      "step 16790, training accuracy 0.951219\n",
      "step 16790, cost 8.39107\n",
      "step 16790, change in cost 0.00179672\n",
      "step 16800, training accuracy 0.951219\n",
      "step 16800, cost 8.38927\n",
      "step 16800, change in cost 0.00179863\n",
      "step 16810, training accuracy 0.951219\n",
      "step 16810, cost 8.38747\n",
      "step 16810, change in cost 0.00180244\n",
      "step 16820, training accuracy 0.951219\n",
      "step 16820, cost 8.38566\n",
      "step 16820, change in cost 0.00180721\n",
      "step 16830, training accuracy 0.951219\n",
      "step 16830, cost 8.38385\n",
      "step 16830, change in cost 0.00181103\n",
      "step 16840, training accuracy 0.951219\n",
      "step 16840, cost 8.38204\n",
      "step 16840, change in cost 0.0018158\n",
      "step 16850, training accuracy 0.951219\n",
      "step 16850, cost 8.38021\n",
      "step 16850, change in cost 0.00182343\n",
      "step 16860, training accuracy 0.951219\n",
      "step 16860, cost 8.37839\n",
      "step 16860, change in cost 0.00182343\n",
      "step 16870, training accuracy 0.951219\n",
      "step 16870, cost 8.37657\n",
      "step 16870, change in cost 0.00182533\n",
      "step 16880, training accuracy 0.951219\n",
      "step 16880, cost 8.37473\n",
      "step 16880, change in cost 0.00183296\n",
      "step 16890, training accuracy 0.951219\n",
      "step 16890, cost 8.3729\n",
      "step 16890, change in cost 0.00183487\n",
      "step 16900, training accuracy 0.951219\n",
      "step 16900, cost 8.37106\n",
      "step 16900, change in cost 0.0018425\n",
      "step 16910, training accuracy 0.951219\n",
      "step 16910, cost 8.36921\n",
      "step 16910, change in cost 0.00184441\n",
      "step 16920, training accuracy 0.951219\n",
      "step 16920, cost 8.36736\n",
      "step 16920, change in cost 0.00185013\n",
      "step 16930, training accuracy 0.951219\n",
      "step 16930, cost 8.36551\n",
      "step 16930, change in cost 0.00185394\n",
      "step 16940, training accuracy 0.951219\n",
      "step 16940, cost 8.36365\n",
      "step 16940, change in cost 0.00185871\n",
      "step 16950, training accuracy 0.951219\n",
      "step 16950, cost 8.36179\n",
      "step 16950, change in cost 0.00186157\n",
      "step 16960, training accuracy 0.951219\n",
      "step 16960, cost 8.35992\n",
      "step 16960, change in cost 0.0018692\n",
      "step 16970, training accuracy 0.951219\n",
      "step 16970, cost 8.35805\n",
      "step 16970, change in cost 0.00187016\n",
      "step 16980, training accuracy 0.951219\n",
      "step 16980, cost 8.35617\n",
      "step 16980, change in cost 0.00187874\n",
      "step 16990, training accuracy 0.951219\n",
      "step 16990, cost 8.35429\n",
      "step 16990, change in cost 0.0018816\n",
      "step 17000, training accuracy 0.951219\n",
      "step 17000, cost 8.3524\n",
      "step 17000, change in cost 0.00188732\n",
      "step 17010, training accuracy 0.951219\n",
      "step 17010, cost 8.35051\n",
      "step 17010, change in cost 0.00189209\n",
      "step 17020, training accuracy 0.951219\n",
      "step 17020, cost 8.34861\n",
      "step 17020, change in cost 0.0018959\n",
      "step 17030, training accuracy 0.951219\n",
      "step 17030, cost 8.34671\n",
      "step 17030, change in cost 0.00190163\n",
      "step 17040, training accuracy 0.951219\n",
      "step 17040, cost 8.3448\n",
      "step 17040, change in cost 0.00190735\n",
      "step 17050, training accuracy 0.951219\n",
      "step 17050, cost 8.34289\n",
      "step 17050, change in cost 0.00191307\n",
      "step 17060, training accuracy 0.951219\n",
      "step 17060, cost 8.34097\n",
      "step 17060, change in cost 0.00191975\n",
      "step 17070, training accuracy 0.951219\n",
      "step 17070, cost 8.33905\n",
      "step 17070, change in cost 0.00192356\n",
      "step 17080, training accuracy 0.951219\n",
      "step 17080, cost 8.33712\n",
      "step 17080, change in cost 0.00192833\n",
      "step 17090, training accuracy 0.951219\n",
      "step 17090, cost 8.33519\n",
      "step 17090, change in cost 0.0019331\n",
      "step 17100, training accuracy 0.951219\n",
      "step 17100, cost 8.33324\n",
      "step 17100, change in cost 0.00194073\n",
      "step 17110, training accuracy 0.951219\n",
      "step 17110, cost 8.3313\n",
      "step 17110, change in cost 0.0019455\n",
      "step 17120, training accuracy 0.951219\n",
      "step 17120, cost 8.32935\n",
      "step 17120, change in cost 0.00195217\n",
      "step 17130, training accuracy 0.951219\n",
      "step 17130, cost 8.32739\n",
      "step 17130, change in cost 0.00195408\n",
      "step 17140, training accuracy 0.951219\n",
      "step 17140, cost 8.32543\n",
      "step 17140, change in cost 0.00196457\n",
      "step 17150, training accuracy 0.951219\n",
      "step 17150, cost 8.32346\n",
      "step 17150, change in cost 0.00197029\n",
      "step 17160, training accuracy 0.951219\n",
      "step 17160, cost 8.32149\n",
      "step 17160, change in cost 0.00197029\n",
      "step 17170, training accuracy 0.951219\n",
      "step 17170, cost 8.31951\n",
      "step 17170, change in cost 0.00198078\n",
      "step 17180, training accuracy 0.951219\n",
      "step 17180, cost 8.31752\n",
      "step 17180, change in cost 0.00198841\n",
      "step 17190, training accuracy 0.951219\n",
      "step 17190, cost 8.31553\n",
      "step 17190, change in cost 0.00199127\n",
      "step 17200, training accuracy 0.951219\n",
      "step 17200, cost 8.31353\n",
      "step 17200, change in cost 0.00199795\n",
      "step 17210, training accuracy 0.951219\n",
      "step 17210, cost 8.31153\n",
      "step 17210, change in cost 0.00200367\n",
      "step 17220, training accuracy 0.951219\n",
      "step 17220, cost 8.30951\n",
      "step 17220, change in cost 0.00201035\n",
      "step 17230, training accuracy 0.951219\n",
      "step 17230, cost 8.3075\n",
      "step 17230, change in cost 0.00201797\n",
      "step 17240, training accuracy 0.951219\n",
      "step 17240, cost 8.30547\n",
      "step 17240, change in cost 0.00202274\n",
      "step 17250, training accuracy 0.951219\n",
      "step 17250, cost 8.30345\n",
      "step 17250, change in cost 0.00202847\n",
      "step 17260, training accuracy 0.951219\n",
      "step 17260, cost 8.30141\n",
      "step 17260, change in cost 0.00203323\n",
      "step 17270, training accuracy 0.951219\n",
      "step 17270, cost 8.29937\n",
      "step 17270, change in cost 0.00204182\n",
      "step 17280, training accuracy 0.951219\n",
      "step 17280, cost 8.29732\n",
      "step 17280, change in cost 0.00204849\n",
      "step 17290, training accuracy 0.951219\n",
      "step 17290, cost 8.29527\n",
      "step 17290, change in cost 0.00205421\n",
      "step 17300, training accuracy 0.951219\n",
      "step 17300, cost 8.2932\n",
      "step 17300, change in cost 0.00206375\n",
      "step 17310, training accuracy 0.951219\n",
      "step 17310, cost 8.29114\n",
      "step 17310, change in cost 0.00206757\n",
      "step 17320, training accuracy 0.951219\n",
      "step 17320, cost 8.28906\n",
      "step 17320, change in cost 0.00207233\n",
      "step 17330, training accuracy 0.951219\n",
      "step 17330, cost 8.28698\n",
      "step 17330, change in cost 0.00208187\n",
      "step 17340, training accuracy 0.951219\n",
      "step 17340, cost 8.2849\n",
      "step 17340, change in cost 0.00208569\n",
      "step 17350, training accuracy 0.951219\n",
      "step 17350, cost 8.2828\n",
      "step 17350, change in cost 0.00209332\n",
      "step 17360, training accuracy 0.951219\n",
      "step 17360, cost 8.28071\n",
      "step 17360, change in cost 0.00209713\n",
      "step 17370, training accuracy 0.951219\n",
      "step 17370, cost 8.2786\n",
      "step 17370, change in cost 0.00210857\n",
      "step 17380, training accuracy 0.951219\n",
      "step 17380, cost 8.27648\n",
      "step 17380, change in cost 0.0021162\n",
      "step 17390, training accuracy 0.951219\n",
      "step 17390, cost 8.27436\n",
      "step 17390, change in cost 0.00212097\n",
      "step 17400, training accuracy 0.951219\n",
      "step 17400, cost 8.27223\n",
      "step 17400, change in cost 0.00212574\n",
      "step 17410, training accuracy 0.951219\n",
      "step 17410, cost 8.2701\n",
      "step 17410, change in cost 0.00213337\n",
      "step 17420, training accuracy 0.951219\n",
      "step 17420, cost 8.26796\n",
      "step 17420, change in cost 0.002141\n",
      "step 17430, training accuracy 0.951219\n",
      "step 17430, cost 8.26581\n",
      "step 17430, change in cost 0.00214672\n",
      "step 17440, training accuracy 0.951219\n",
      "step 17440, cost 8.26366\n",
      "step 17440, change in cost 0.0021534\n",
      "step 17450, training accuracy 0.951219\n",
      "step 17450, cost 8.2615\n",
      "step 17450, change in cost 0.00216007\n",
      "step 17460, training accuracy 0.951219\n",
      "step 17460, cost 8.25933\n",
      "step 17460, change in cost 0.0021677\n",
      "step 17470, training accuracy 0.951219\n",
      "step 17470, cost 8.25716\n",
      "step 17470, change in cost 0.00217342\n",
      "step 17480, training accuracy 0.951219\n",
      "step 17480, cost 8.25498\n",
      "step 17480, change in cost 0.00217915\n",
      "step 17490, training accuracy 0.951219\n",
      "step 17490, cost 8.25279\n",
      "step 17490, change in cost 0.00218773\n",
      "step 17500, training accuracy 0.951219\n",
      "step 17500, cost 8.2506\n",
      "step 17500, change in cost 0.00219536\n",
      "step 17510, training accuracy 0.951219\n",
      "step 17510, cost 8.2484\n",
      "step 17510, change in cost 0.00220013\n",
      "step 17520, training accuracy 0.951219\n",
      "step 17520, cost 8.24619\n",
      "step 17520, change in cost 0.00220585\n",
      "step 17530, training accuracy 0.951219\n",
      "step 17530, cost 8.24398\n",
      "step 17530, change in cost 0.00221443\n",
      "step 17540, training accuracy 0.951219\n",
      "step 17540, cost 8.24176\n",
      "step 17540, change in cost 0.00222015\n",
      "step 17550, training accuracy 0.951219\n",
      "step 17550, cost 8.23953\n",
      "step 17550, change in cost 0.00222778\n",
      "step 17560, training accuracy 0.951219\n",
      "step 17560, cost 8.2373\n",
      "step 17560, change in cost 0.00223255\n",
      "step 17570, training accuracy 0.951219\n",
      "step 17570, cost 8.23506\n",
      "step 17570, change in cost 0.00223923\n",
      "step 17580, training accuracy 0.951219\n",
      "step 17580, cost 8.23281\n",
      "step 17580, change in cost 0.00224686\n",
      "step 17590, training accuracy 0.951219\n",
      "step 17590, cost 8.23056\n",
      "step 17590, change in cost 0.00225353\n",
      "step 17600, training accuracy 0.951219\n",
      "step 17600, cost 8.2283\n",
      "step 17600, change in cost 0.00225735\n",
      "step 17610, training accuracy 0.951219\n",
      "step 17610, cost 8.22603\n",
      "step 17610, change in cost 0.00226498\n",
      "step 17620, training accuracy 0.951219\n",
      "step 17620, cost 8.22376\n",
      "step 17620, change in cost 0.00227356\n",
      "step 17630, training accuracy 0.951219\n",
      "step 17630, cost 8.22148\n",
      "step 17630, change in cost 0.00227642\n",
      "step 17640, training accuracy 0.951219\n",
      "step 17640, cost 8.2192\n",
      "step 17640, change in cost 0.0022831\n",
      "step 17650, training accuracy 0.951219\n",
      "step 17650, cost 8.21691\n",
      "step 17650, change in cost 0.00229073\n",
      "step 17660, training accuracy 0.951219\n",
      "step 17660, cost 8.21461\n",
      "step 17660, change in cost 0.0022974\n",
      "step 17670, training accuracy 0.951219\n",
      "step 17670, cost 8.21231\n",
      "step 17670, change in cost 0.00230026\n",
      "step 17680, training accuracy 0.951219\n",
      "step 17680, cost 8.21001\n",
      "step 17680, change in cost 0.00230598\n",
      "step 17690, training accuracy 0.951219\n",
      "step 17690, cost 8.20769\n",
      "step 17690, change in cost 0.00231552\n",
      "step 17700, training accuracy 0.951219\n",
      "step 17700, cost 8.20537\n",
      "step 17700, change in cost 0.00231934\n",
      "step 17710, training accuracy 0.951219\n",
      "step 17710, cost 8.20305\n",
      "step 17710, change in cost 0.00232506\n",
      "step 17720, training accuracy 0.951219\n",
      "step 17720, cost 8.20072\n",
      "step 17720, change in cost 0.00232983\n",
      "step 17730, training accuracy 0.951219\n",
      "step 17730, cost 8.19838\n",
      "step 17730, change in cost 0.00233841\n",
      "step 17740, training accuracy 0.951219\n",
      "step 17740, cost 8.19604\n",
      "step 17740, change in cost 0.00233936\n",
      "step 17750, training accuracy 0.951219\n",
      "step 17750, cost 8.19369\n",
      "step 17750, change in cost 0.00234604\n",
      "step 17760, training accuracy 0.955285\n",
      "step 17760, cost 8.19134\n",
      "step 17760, change in cost 0.00235081\n",
      "step 17770, training accuracy 0.955285\n",
      "step 17770, cost 8.18899\n",
      "step 17770, change in cost 0.00235653\n",
      "step 17780, training accuracy 0.955285\n",
      "step 17780, cost 8.18662\n",
      "step 17780, change in cost 0.0023613\n",
      "step 17790, training accuracy 0.955285\n",
      "step 17790, cost 8.18426\n",
      "step 17790, change in cost 0.00236702\n",
      "step 17800, training accuracy 0.955285\n",
      "step 17800, cost 8.18189\n",
      "step 17800, change in cost 0.00236988\n",
      "step 17810, training accuracy 0.955285\n",
      "step 17810, cost 8.17951\n",
      "step 17810, change in cost 0.00237751\n",
      "step 17820, training accuracy 0.955285\n",
      "step 17820, cost 8.17713\n",
      "step 17820, change in cost 0.00237751\n",
      "step 17830, training accuracy 0.955285\n",
      "step 17830, cost 8.17475\n",
      "step 17830, change in cost 0.00238419\n",
      "step 17840, training accuracy 0.955285\n",
      "step 17840, cost 8.17236\n",
      "step 17840, change in cost 0.00238991\n",
      "step 17850, training accuracy 0.955285\n",
      "step 17850, cost 8.16997\n",
      "step 17850, change in cost 0.00239086\n",
      "step 17860, training accuracy 0.955285\n",
      "step 17860, cost 8.16757\n",
      "step 17860, change in cost 0.00239944\n",
      "step 17870, training accuracy 0.955285\n",
      "step 17870, cost 8.16517\n",
      "step 17870, change in cost 0.00239754\n",
      "step 17880, training accuracy 0.955285\n",
      "step 17880, cost 8.16277\n",
      "step 17880, change in cost 0.00240231\n",
      "step 17890, training accuracy 0.955285\n",
      "step 17890, cost 8.16036\n",
      "step 17890, change in cost 0.00240803\n",
      "step 17900, training accuracy 0.955285\n",
      "step 17900, cost 8.15795\n",
      "step 17900, change in cost 0.00241089\n",
      "step 17910, training accuracy 0.955285\n",
      "step 17910, cost 8.15553\n",
      "step 17910, change in cost 0.0024147\n",
      "step 17920, training accuracy 0.955285\n",
      "step 17920, cost 8.15312\n",
      "step 17920, change in cost 0.0024147\n",
      "step 17930, training accuracy 0.955285\n",
      "step 17930, cost 8.1507\n",
      "step 17930, change in cost 0.00241947\n",
      "step 17940, training accuracy 0.955285\n",
      "step 17940, cost 8.14828\n",
      "step 17940, change in cost 0.00242424\n",
      "step 17950, training accuracy 0.955285\n",
      "step 17950, cost 8.14585\n",
      "step 17950, change in cost 0.0024271\n",
      "step 17960, training accuracy 0.955285\n",
      "step 17960, cost 8.14342\n",
      "step 17960, change in cost 0.0024271\n",
      "step 17970, training accuracy 0.955285\n",
      "step 17970, cost 8.14099\n",
      "step 17970, change in cost 0.00242901\n",
      "step 17980, training accuracy 0.955285\n",
      "step 17980, cost 8.13856\n",
      "step 17980, change in cost 0.00243473\n",
      "step 17990, training accuracy 0.955285\n",
      "step 17990, cost 8.13613\n",
      "step 17990, change in cost 0.00243282\n",
      "step 18000, training accuracy 0.955285\n",
      "step 18000, cost 8.13369\n",
      "step 18000, change in cost 0.00243855\n",
      "step 18010, training accuracy 0.955285\n",
      "step 18010, cost 8.13125\n",
      "step 18010, change in cost 0.00243664\n",
      "step 18020, training accuracy 0.955285\n",
      "step 18020, cost 8.12881\n",
      "step 18020, change in cost 0.0024395\n",
      "step 18030, training accuracy 0.955285\n",
      "step 18030, cost 8.12637\n",
      "step 18030, change in cost 0.0024395\n",
      "step 18040, training accuracy 0.955285\n",
      "step 18040, cost 8.12393\n",
      "step 18040, change in cost 0.00244427\n",
      "step 18050, training accuracy 0.955285\n",
      "step 18050, cost 8.12148\n",
      "step 18050, change in cost 0.00244331\n",
      "step 18060, training accuracy 0.955285\n",
      "step 18060, cost 8.11904\n",
      "step 18060, change in cost 0.00244427\n",
      "step 18070, training accuracy 0.955285\n",
      "step 18070, cost 8.1166\n",
      "step 18070, change in cost 0.00244331\n",
      "step 18080, training accuracy 0.955285\n",
      "step 18080, cost 8.11415\n",
      "step 18080, change in cost 0.00244617\n",
      "step 18090, training accuracy 0.955285\n",
      "step 18090, cost 8.1117\n",
      "step 18090, change in cost 0.00244808\n",
      "step 18100, training accuracy 0.955285\n",
      "step 18100, cost 8.10926\n",
      "step 18100, change in cost 0.00244522\n",
      "step 18110, training accuracy 0.955285\n",
      "step 18110, cost 8.10681\n",
      "step 18110, change in cost 0.00244713\n",
      "step 18120, training accuracy 0.955285\n",
      "step 18120, cost 8.10436\n",
      "step 18120, change in cost 0.00244713\n",
      "step 18130, training accuracy 0.955285\n",
      "step 18130, cost 8.10192\n",
      "step 18130, change in cost 0.00244522\n",
      "step 18140, training accuracy 0.955285\n",
      "step 18140, cost 8.09947\n",
      "step 18140, change in cost 0.00244808\n",
      "step 18150, training accuracy 0.955285\n",
      "step 18150, cost 8.09703\n",
      "step 18150, change in cost 0.00244236\n",
      "step 18160, training accuracy 0.955285\n",
      "step 18160, cost 8.09458\n",
      "step 18160, change in cost 0.00244617\n",
      "step 18170, training accuracy 0.955285\n",
      "step 18170, cost 8.09213\n",
      "step 18170, change in cost 0.00244713\n",
      "step 18180, training accuracy 0.955285\n",
      "step 18180, cost 8.08969\n",
      "step 18180, change in cost 0.00244331\n",
      "step 18190, training accuracy 0.955285\n",
      "step 18190, cost 8.08725\n",
      "step 18190, change in cost 0.00244236\n",
      "step 18200, training accuracy 0.955285\n",
      "step 18200, cost 8.08481\n",
      "step 18200, change in cost 0.00244141\n",
      "step 18210, training accuracy 0.955285\n",
      "step 18210, cost 8.08237\n",
      "step 18210, change in cost 0.00243855\n",
      "step 18220, training accuracy 0.955285\n",
      "step 18220, cost 8.07993\n",
      "step 18220, change in cost 0.00244045\n",
      "step 18230, training accuracy 0.955285\n",
      "step 18230, cost 8.07749\n",
      "step 18230, change in cost 0.00243759\n",
      "step 18240, training accuracy 0.955285\n",
      "step 18240, cost 8.07505\n",
      "step 18240, change in cost 0.00243568\n",
      "step 18250, training accuracy 0.955285\n",
      "step 18250, cost 8.07262\n",
      "step 18250, change in cost 0.00243664\n",
      "step 18260, training accuracy 0.955285\n",
      "step 18260, cost 8.07019\n",
      "step 18260, change in cost 0.0024271\n",
      "step 18270, training accuracy 0.955285\n",
      "step 18270, cost 8.06776\n",
      "step 18270, change in cost 0.00243473\n",
      "step 18280, training accuracy 0.955285\n",
      "step 18280, cost 8.06533\n",
      "step 18280, change in cost 0.00242901\n",
      "step 18290, training accuracy 0.955285\n",
      "step 18290, cost 8.0629\n",
      "step 18290, change in cost 0.00242519\n",
      "step 18300, training accuracy 0.955285\n",
      "step 18300, cost 8.06048\n",
      "step 18300, change in cost 0.00242329\n",
      "step 18310, training accuracy 0.955285\n",
      "step 18310, cost 8.05805\n",
      "step 18310, change in cost 0.00242424\n",
      "step 18320, training accuracy 0.955285\n",
      "step 18320, cost 8.05564\n",
      "step 18320, change in cost 0.00241756\n",
      "step 18330, training accuracy 0.955285\n",
      "step 18330, cost 8.05322\n",
      "step 18330, change in cost 0.00241661\n",
      "step 18340, training accuracy 0.955285\n",
      "step 18340, cost 8.0508\n",
      "step 18340, change in cost 0.00241566\n",
      "step 18350, training accuracy 0.955285\n",
      "step 18350, cost 8.0484\n",
      "step 18350, change in cost 0.00240898\n",
      "step 18360, training accuracy 0.955285\n",
      "step 18360, cost 8.04599\n",
      "step 18360, change in cost 0.00240993\n",
      "step 18370, training accuracy 0.955285\n",
      "step 18370, cost 8.04358\n",
      "step 18370, change in cost 0.00240612\n",
      "step 18380, training accuracy 0.955285\n",
      "step 18380, cost 8.04118\n",
      "step 18380, change in cost 0.00240231\n",
      "step 18390, training accuracy 0.955285\n",
      "step 18390, cost 8.03878\n",
      "step 18390, change in cost 0.00239754\n",
      "step 18400, training accuracy 0.955285\n",
      "step 18400, cost 8.03638\n",
      "step 18400, change in cost 0.00239754\n",
      "step 18410, training accuracy 0.955285\n",
      "step 18410, cost 8.03399\n",
      "step 18410, change in cost 0.00239277\n",
      "step 18420, training accuracy 0.955285\n",
      "step 18420, cost 8.0316\n",
      "step 18420, change in cost 0.00238991\n",
      "step 18430, training accuracy 0.955285\n",
      "step 18430, cost 8.02921\n",
      "step 18430, change in cost 0.00238705\n",
      "step 18440, training accuracy 0.955285\n",
      "step 18440, cost 8.02683\n",
      "step 18440, change in cost 0.00238228\n",
      "step 18450, training accuracy 0.955285\n",
      "step 18450, cost 8.02445\n",
      "step 18450, change in cost 0.00238037\n",
      "step 18460, training accuracy 0.955285\n",
      "step 18460, cost 8.02207\n",
      "step 18460, change in cost 0.00237751\n",
      "step 18470, training accuracy 0.955285\n",
      "step 18470, cost 8.0197\n",
      "step 18470, change in cost 0.00237465\n",
      "step 18480, training accuracy 0.955285\n",
      "step 18480, cost 8.01733\n",
      "step 18480, change in cost 0.00237083\n",
      "step 18490, training accuracy 0.955285\n",
      "step 18490, cost 8.01496\n",
      "step 18490, change in cost 0.00236797\n",
      "step 18500, training accuracy 0.955285\n",
      "step 18500, cost 8.0126\n",
      "step 18500, change in cost 0.00235844\n",
      "step 18510, training accuracy 0.955285\n",
      "step 18510, cost 8.01024\n",
      "step 18510, change in cost 0.0023632\n",
      "step 18520, training accuracy 0.955285\n",
      "step 18520, cost 8.00788\n",
      "step 18520, change in cost 0.00235558\n",
      "step 18530, training accuracy 0.955285\n",
      "step 18530, cost 8.00553\n",
      "step 18530, change in cost 0.00234985\n",
      "step 18540, training accuracy 0.955285\n",
      "step 18540, cost 8.00318\n",
      "step 18540, change in cost 0.00234985\n",
      "step 18550, training accuracy 0.955285\n",
      "step 18550, cost 8.00083\n",
      "step 18550, change in cost 0.00234795\n",
      "step 18560, training accuracy 0.955285\n",
      "step 18560, cost 7.99849\n",
      "step 18560, change in cost 0.00234175\n",
      "step 18570, training accuracy 0.955285\n",
      "step 18570, cost 7.99615\n",
      "step 18570, change in cost 0.00233889\n",
      "step 18580, training accuracy 0.955285\n",
      "step 18580, cost 7.99382\n",
      "step 18580, change in cost 0.00233459\n",
      "step 18590, training accuracy 0.955285\n",
      "step 18590, cost 7.99149\n",
      "step 18590, change in cost 0.00233221\n",
      "step 18600, training accuracy 0.955285\n",
      "step 18600, cost 7.98916\n",
      "step 18600, change in cost 0.0023284\n",
      "step 18610, training accuracy 0.955285\n",
      "step 18610, cost 7.98683\n",
      "step 18610, change in cost 0.00232363\n",
      "step 18620, training accuracy 0.955285\n",
      "step 18620, cost 7.98451\n",
      "step 18620, change in cost 0.00232363\n",
      "step 18630, training accuracy 0.955285\n",
      "step 18630, cost 7.9822\n",
      "step 18630, change in cost 0.00231457\n",
      "step 18640, training accuracy 0.955285\n",
      "step 18640, cost 7.97988\n",
      "step 18640, change in cost 0.00231743\n",
      "step 18650, training accuracy 0.95935\n",
      "step 18650, cost 7.97757\n",
      "step 18650, change in cost 0.0023098\n",
      "step 18660, training accuracy 0.95935\n",
      "step 18660, cost 7.97526\n",
      "step 18660, change in cost 0.00230932\n",
      "step 18670, training accuracy 0.95935\n",
      "step 18670, cost 7.97295\n",
      "step 18670, change in cost 0.00230694\n",
      "step 18680, training accuracy 0.95935\n",
      "step 18680, cost 7.97065\n",
      "step 18680, change in cost 0.00229979\n",
      "step 18690, training accuracy 0.95935\n",
      "step 18690, cost 7.96835\n",
      "step 18690, change in cost 0.00229836\n",
      "step 18700, training accuracy 0.95935\n",
      "step 18700, cost 7.96606\n",
      "step 18700, change in cost 0.0022974\n",
      "step 18710, training accuracy 0.95935\n",
      "step 18710, cost 7.96377\n",
      "step 18710, change in cost 0.00229025\n",
      "step 18720, training accuracy 0.95935\n",
      "step 18720, cost 7.96147\n",
      "step 18720, change in cost 0.00229168\n",
      "step 18730, training accuracy 0.95935\n",
      "step 18730, cost 7.95919\n",
      "step 18730, change in cost 0.00228548\n",
      "step 18740, training accuracy 0.95935\n",
      "step 18740, cost 7.9569\n",
      "step 18740, change in cost 0.00228548\n",
      "step 18750, training accuracy 0.95935\n",
      "step 18750, cost 7.95462\n",
      "step 18750, change in cost 0.0022831\n",
      "step 18760, training accuracy 0.95935\n",
      "step 18760, cost 7.95234\n",
      "step 18760, change in cost 0.00227833\n",
      "step 18770, training accuracy 0.95935\n",
      "step 18770, cost 7.95007\n",
      "step 18770, change in cost 0.00227547\n",
      "step 18780, training accuracy 0.95935\n",
      "step 18780, cost 7.94779\n",
      "step 18780, change in cost 0.00227547\n",
      "step 18790, training accuracy 0.95935\n",
      "step 18790, cost 7.94552\n",
      "step 18790, change in cost 0.00226974\n",
      "step 18800, training accuracy 0.95935\n",
      "step 18800, cost 7.94325\n",
      "step 18800, change in cost 0.00226927\n",
      "step 18810, training accuracy 0.95935\n",
      "step 18810, cost 7.94099\n",
      "step 18810, change in cost 0.00226736\n",
      "step 18820, training accuracy 0.95935\n",
      "step 18820, cost 7.93872\n",
      "step 18820, change in cost 0.00226545\n",
      "step 18830, training accuracy 0.95935\n",
      "step 18830, cost 7.93646\n",
      "step 18830, change in cost 0.00226402\n",
      "step 18840, training accuracy 0.95935\n",
      "step 18840, cost 7.9342\n",
      "step 18840, change in cost 0.00225973\n",
      "step 18850, training accuracy 0.95935\n",
      "step 18850, cost 7.93194\n",
      "step 18850, change in cost 0.00225782\n",
      "step 18860, training accuracy 0.95935\n",
      "step 18860, cost 7.92968\n",
      "step 18860, change in cost 0.00225782\n",
      "step 18870, training accuracy 0.95935\n",
      "step 18870, cost 7.92742\n",
      "step 18870, change in cost 0.00225544\n",
      "step 18880, training accuracy 0.95935\n",
      "step 18880, cost 7.92517\n",
      "step 18880, change in cost 0.00225401\n",
      "step 18890, training accuracy 0.95935\n",
      "step 18890, cost 7.92292\n",
      "step 18890, change in cost 0.00225306\n",
      "step 18900, training accuracy 0.95935\n",
      "step 18900, cost 7.92067\n",
      "step 18900, change in cost 0.0022521\n",
      "step 18910, training accuracy 0.95935\n",
      "step 18910, cost 7.91842\n",
      "step 18910, change in cost 0.00224972\n",
      "step 18920, training accuracy 0.95935\n",
      "step 18920, cost 7.91617\n",
      "step 18920, change in cost 0.00224972\n",
      "step 18930, training accuracy 0.95935\n",
      "step 18930, cost 7.91392\n",
      "step 18930, change in cost 0.00224876\n",
      "step 18940, training accuracy 0.95935\n",
      "step 18940, cost 7.91167\n",
      "step 18940, change in cost 0.00224495\n",
      "step 18950, training accuracy 0.95935\n",
      "step 18950, cost 7.90943\n",
      "step 18950, change in cost 0.00224638\n",
      "step 18960, training accuracy 0.95935\n",
      "step 18960, cost 7.90718\n",
      "step 18960, change in cost 0.00224733\n",
      "step 18970, training accuracy 0.95935\n",
      "step 18970, cost 7.90493\n",
      "step 18970, change in cost 0.00224543\n",
      "step 18980, training accuracy 0.95935\n",
      "step 18980, cost 7.90269\n",
      "step 18980, change in cost 0.00224257\n",
      "step 18990, training accuracy 0.95935\n",
      "step 18990, cost 7.90045\n",
      "step 18990, change in cost 0.00224495\n",
      "step 19000, training accuracy 0.95935\n",
      "step 19000, cost 7.8982\n",
      "step 19000, change in cost 0.0022459\n",
      "step 19010, training accuracy 0.95935\n",
      "step 19010, cost 7.89596\n",
      "step 19010, change in cost 0.002244\n",
      "step 19020, training accuracy 0.95935\n",
      "step 19020, cost 7.89371\n",
      "step 19020, change in cost 0.002244\n",
      "step 19030, training accuracy 0.95935\n",
      "step 19030, cost 7.89147\n",
      "step 19030, change in cost 0.00224638\n",
      "step 19040, training accuracy 0.95935\n",
      "step 19040, cost 7.88922\n",
      "step 19040, change in cost 0.00224352\n",
      "step 19050, training accuracy 0.95935\n",
      "step 19050, cost 7.88698\n",
      "step 19050, change in cost 0.00224543\n",
      "step 19060, training accuracy 0.95935\n",
      "step 19060, cost 7.88473\n",
      "step 19060, change in cost 0.00225019\n",
      "step 19070, training accuracy 0.95935\n",
      "step 19070, cost 7.88248\n",
      "step 19070, change in cost 0.0022459\n",
      "step 19080, training accuracy 0.95935\n",
      "step 19080, cost 7.88023\n",
      "step 19080, change in cost 0.0022459\n",
      "step 19090, training accuracy 0.95935\n",
      "step 19090, cost 7.87799\n",
      "step 19090, change in cost 0.00224924\n",
      "step 19100, training accuracy 0.95935\n",
      "step 19100, cost 7.87574\n",
      "step 19100, change in cost 0.00224924\n",
      "step 19110, training accuracy 0.95935\n",
      "step 19110, cost 7.87348\n",
      "step 19110, change in cost 0.00225306\n",
      "step 19120, training accuracy 0.95935\n",
      "step 19120, cost 7.87123\n",
      "step 19120, change in cost 0.00225067\n",
      "step 19130, training accuracy 0.95935\n",
      "step 19130, cost 7.86897\n",
      "step 19130, change in cost 0.00225782\n",
      "step 19140, training accuracy 0.95935\n",
      "step 19140, cost 7.86672\n",
      "step 19140, change in cost 0.00225592\n",
      "step 19150, training accuracy 0.95935\n",
      "step 19150, cost 7.86446\n",
      "step 19150, change in cost 0.00225782\n",
      "step 19160, training accuracy 0.95935\n",
      "step 19160, cost 7.8622\n",
      "step 19160, change in cost 0.00225925\n",
      "step 19170, training accuracy 0.95935\n",
      "step 19170, cost 7.85994\n",
      "step 19170, change in cost 0.00226402\n",
      "step 19180, training accuracy 0.95935\n",
      "step 19180, cost 7.85767\n",
      "step 19180, change in cost 0.00226307\n",
      "step 19190, training accuracy 0.95935\n",
      "step 19190, cost 7.85541\n",
      "step 19190, change in cost 0.00226593\n",
      "step 19200, training accuracy 0.95935\n",
      "step 19200, cost 7.85313\n",
      "step 19200, change in cost 0.00227451\n",
      "step 19210, training accuracy 0.95935\n",
      "step 19210, cost 7.85086\n",
      "step 19210, change in cost 0.00227451\n",
      "step 19220, training accuracy 0.95935\n",
      "step 19220, cost 7.84858\n",
      "step 19220, change in cost 0.00227499\n",
      "step 19230, training accuracy 0.95935\n",
      "step 19230, cost 7.8463\n",
      "step 19230, change in cost 0.00228071\n",
      "step 19240, training accuracy 0.95935\n",
      "step 19240, cost 7.84402\n",
      "step 19240, change in cost 0.00228119\n",
      "step 19250, training accuracy 0.95935\n",
      "step 19250, cost 7.84174\n",
      "step 19250, change in cost 0.00228405\n",
      "step 19260, training accuracy 0.95935\n",
      "step 19260, cost 7.83945\n",
      "step 19260, change in cost 0.00229073\n",
      "step 19270, training accuracy 0.95935\n",
      "step 19270, cost 7.83716\n",
      "step 19270, change in cost 0.00229263\n",
      "step 19280, training accuracy 0.95935\n",
      "step 19280, cost 7.83486\n",
      "step 19280, change in cost 0.00229836\n",
      "step 19290, training accuracy 0.95935\n",
      "step 19290, cost 7.83256\n",
      "step 19290, change in cost 0.00230122\n",
      "step 19300, training accuracy 0.95935\n",
      "step 19300, cost 7.83025\n",
      "step 19300, change in cost 0.00230598\n",
      "step 19310, training accuracy 0.95935\n",
      "step 19310, cost 7.82794\n",
      "step 19310, change in cost 0.00230789\n",
      "step 19320, training accuracy 0.95935\n",
      "step 19320, cost 7.82563\n",
      "step 19320, change in cost 0.00231647\n",
      "step 19330, training accuracy 0.95935\n",
      "step 19330, cost 7.82331\n",
      "step 19330, change in cost 0.00231791\n",
      "step 19340, training accuracy 0.95935\n",
      "step 19340, cost 7.82098\n",
      "step 19340, change in cost 0.00232315\n",
      "step 19350, training accuracy 0.95935\n",
      "step 19350, cost 7.81865\n",
      "step 19350, change in cost 0.0023303\n",
      "step 19360, training accuracy 0.95935\n",
      "step 19360, cost 7.81632\n",
      "step 19360, change in cost 0.00233364\n",
      "step 19370, training accuracy 0.95935\n",
      "step 19370, cost 7.81398\n",
      "step 19370, change in cost 0.00234175\n",
      "step 19380, training accuracy 0.95935\n",
      "step 19380, cost 7.81163\n",
      "step 19380, change in cost 0.00234461\n",
      "step 19390, training accuracy 0.95935\n",
      "step 19390, cost 7.80928\n",
      "step 19390, change in cost 0.00234985\n",
      "step 19400, training accuracy 0.95935\n",
      "step 19400, cost 7.80692\n",
      "step 19400, change in cost 0.00235987\n",
      "step 19410, training accuracy 0.95935\n",
      "step 19410, cost 7.80456\n",
      "step 19410, change in cost 0.00236177\n",
      "step 19420, training accuracy 0.95935\n",
      "step 19420, cost 7.8022\n",
      "step 19420, change in cost 0.00236702\n",
      "step 19430, training accuracy 0.95935\n",
      "step 19430, cost 7.79982\n",
      "step 19430, change in cost 0.0023756\n",
      "step 19440, training accuracy 0.95935\n",
      "step 19440, cost 7.79744\n",
      "step 19440, change in cost 0.00238323\n",
      "step 19450, training accuracy 0.95935\n",
      "step 19450, cost 7.79505\n",
      "step 19450, change in cost 0.00238895\n",
      "step 19460, training accuracy 0.95935\n",
      "step 19460, cost 7.79265\n",
      "step 19460, change in cost 0.00239706\n",
      "step 19470, training accuracy 0.95935\n",
      "step 19470, cost 7.79025\n",
      "step 19470, change in cost 0.00239992\n",
      "step 19480, training accuracy 0.95935\n",
      "step 19480, cost 7.78784\n",
      "step 19480, change in cost 0.00241137\n",
      "step 19490, training accuracy 0.95935\n",
      "step 19490, cost 7.78542\n",
      "step 19490, change in cost 0.00241804\n",
      "step 19500, training accuracy 0.95935\n",
      "step 19500, cost 7.783\n",
      "step 19500, change in cost 0.00242281\n",
      "step 19510, training accuracy 0.95935\n",
      "step 19510, cost 7.78057\n",
      "step 19510, change in cost 0.00243235\n",
      "step 19520, training accuracy 0.95935\n",
      "step 19520, cost 7.77812\n",
      "step 19520, change in cost 0.00244236\n",
      "step 19530, training accuracy 0.95935\n",
      "step 19530, cost 7.77568\n",
      "step 19530, change in cost 0.00244713\n",
      "step 19540, training accuracy 0.95935\n",
      "step 19540, cost 7.77322\n",
      "step 19540, change in cost 0.0024581\n",
      "step 19550, training accuracy 0.963415\n",
      "step 19550, cost 7.77075\n",
      "step 19550, change in cost 0.00246382\n",
      "step 19560, training accuracy 0.963415\n",
      "step 19560, cost 7.76828\n",
      "step 19560, change in cost 0.00247383\n",
      "step 19570, training accuracy 0.963415\n",
      "step 19570, cost 7.7658\n",
      "step 19570, change in cost 0.00248528\n",
      "step 19580, training accuracy 0.963415\n",
      "step 19580, cost 7.76331\n",
      "step 19580, change in cost 0.00249004\n",
      "step 19590, training accuracy 0.963415\n",
      "step 19590, cost 7.7608\n",
      "step 19590, change in cost 0.00250149\n",
      "step 19600, training accuracy 0.963415\n",
      "step 19600, cost 7.75829\n",
      "step 19600, change in cost 0.00251102\n",
      "step 19610, training accuracy 0.963415\n",
      "step 19610, cost 7.75578\n",
      "step 19610, change in cost 0.00251675\n",
      "step 19620, training accuracy 0.963415\n",
      "step 19620, cost 7.75325\n",
      "step 19620, change in cost 0.00253105\n",
      "step 19630, training accuracy 0.963415\n",
      "step 19630, cost 7.75071\n",
      "step 19630, change in cost 0.0025382\n",
      "step 19640, training accuracy 0.963415\n",
      "step 19640, cost 7.74816\n",
      "step 19640, change in cost 0.00255156\n",
      "step 19650, training accuracy 0.963415\n",
      "step 19650, cost 7.7456\n",
      "step 19650, change in cost 0.00255632\n",
      "step 19660, training accuracy 0.963415\n",
      "step 19660, cost 7.74303\n",
      "step 19660, change in cost 0.00256968\n",
      "step 19670, training accuracy 0.963415\n",
      "step 19670, cost 7.74045\n",
      "step 19670, change in cost 0.00257778\n",
      "step 19680, training accuracy 0.963415\n",
      "step 19680, cost 7.73786\n",
      "step 19680, change in cost 0.00259113\n",
      "step 19690, training accuracy 0.963415\n",
      "step 19690, cost 7.73526\n",
      "step 19690, change in cost 0.00260067\n",
      "step 19700, training accuracy 0.963415\n",
      "step 19700, cost 7.73265\n",
      "step 19700, change in cost 0.00261116\n",
      "step 19710, training accuracy 0.963415\n",
      "step 19710, cost 7.73002\n",
      "step 19710, change in cost 0.00262403\n",
      "step 19720, training accuracy 0.963415\n",
      "step 19720, cost 7.72739\n",
      "step 19720, change in cost 0.00263214\n",
      "step 19730, training accuracy 0.963415\n",
      "step 19730, cost 7.72475\n",
      "step 19730, change in cost 0.00264502\n",
      "step 19740, training accuracy 0.963415\n",
      "step 19740, cost 7.72209\n",
      "step 19740, change in cost 0.00265694\n",
      "step 19750, training accuracy 0.963415\n",
      "step 19750, cost 7.71942\n",
      "step 19750, change in cost 0.00266838\n",
      "step 19760, training accuracy 0.963415\n",
      "step 19760, cost 7.71674\n",
      "step 19760, change in cost 0.00267887\n",
      "step 19770, training accuracy 0.963415\n",
      "step 19770, cost 7.71405\n",
      "step 19770, change in cost 0.00269365\n",
      "step 19780, training accuracy 0.963415\n",
      "step 19780, cost 7.71134\n",
      "step 19780, change in cost 0.00270557\n",
      "step 19790, training accuracy 0.963415\n",
      "step 19790, cost 7.70863\n",
      "step 19790, change in cost 0.00271702\n",
      "step 19800, training accuracy 0.963415\n",
      "step 19800, cost 7.7059\n",
      "step 19800, change in cost 0.00272989\n",
      "step 19810, training accuracy 0.963415\n",
      "step 19810, cost 7.70316\n",
      "step 19810, change in cost 0.00274086\n",
      "step 19820, training accuracy 0.963415\n",
      "step 19820, cost 7.7004\n",
      "step 19820, change in cost 0.0027585\n",
      "step 19830, training accuracy 0.963415\n",
      "step 19830, cost 7.69763\n",
      "step 19830, change in cost 0.00276661\n",
      "step 19840, training accuracy 0.963415\n",
      "step 19840, cost 7.69485\n",
      "step 19840, change in cost 0.00278044\n",
      "step 19850, training accuracy 0.963415\n",
      "step 19850, cost 7.69205\n",
      "step 19850, change in cost 0.00279617\n",
      "step 19860, training accuracy 0.963415\n",
      "step 19860, cost 7.68925\n",
      "step 19860, change in cost 0.00280428\n",
      "step 19870, training accuracy 0.963415\n",
      "step 19870, cost 7.68643\n",
      "step 19870, change in cost 0.0028224\n",
      "step 19880, training accuracy 0.963415\n",
      "step 19880, cost 7.68359\n",
      "step 19880, change in cost 0.00283337\n",
      "step 19890, training accuracy 0.963415\n",
      "step 19890, cost 7.68075\n",
      "step 19890, change in cost 0.00284624\n",
      "step 19900, training accuracy 0.963415\n",
      "step 19900, cost 7.67789\n",
      "step 19900, change in cost 0.00286198\n",
      "step 19910, training accuracy 0.963415\n",
      "step 19910, cost 7.67501\n",
      "step 19910, change in cost 0.0028758\n",
      "step 19920, training accuracy 0.963415\n",
      "step 19920, cost 7.67212\n",
      "step 19920, change in cost 0.00289154\n",
      "step 19930, training accuracy 0.963415\n",
      "step 19930, cost 7.66922\n",
      "step 19930, change in cost 0.00290251\n",
      "step 19940, training accuracy 0.963415\n",
      "step 19940, cost 7.6663\n",
      "step 19940, change in cost 0.00291967\n",
      "step 19950, training accuracy 0.963415\n",
      "step 19950, cost 7.66337\n",
      "step 19950, change in cost 0.00293064\n",
      "step 19960, training accuracy 0.963415\n",
      "step 19960, cost 7.66042\n",
      "step 19960, change in cost 0.00294876\n",
      "step 19970, training accuracy 0.963415\n",
      "step 19970, cost 7.65746\n",
      "step 19970, change in cost 0.00296021\n",
      "step 19980, training accuracy 0.963415\n",
      "step 19980, cost 7.65448\n",
      "step 19980, change in cost 0.00297546\n",
      "step 19990, training accuracy 0.963415\n",
      "step 19990, cost 7.65149\n",
      "step 19990, change in cost 0.00298786\n",
      "step 20000, training accuracy 0.963415\n",
      "step 20000, cost 7.64849\n",
      "step 20000, change in cost 0.00300789\n",
      "step 20010, training accuracy 0.963415\n",
      "step 20010, cost 7.64547\n",
      "step 20010, change in cost 0.00301886\n",
      "step 20020, training accuracy 0.963415\n",
      "step 20020, cost 7.64243\n",
      "step 20020, change in cost 0.00303411\n",
      "step 20030, training accuracy 0.963415\n",
      "step 20030, cost 7.63939\n",
      "step 20030, change in cost 0.00304747\n",
      "step 20040, training accuracy 0.963415\n",
      "step 20040, cost 7.63632\n",
      "step 20040, change in cost 0.00306606\n",
      "step 20050, training accuracy 0.963415\n",
      "step 20050, cost 7.63324\n",
      "step 20050, change in cost 0.00307894\n",
      "step 20060, training accuracy 0.963415\n",
      "step 20060, cost 7.63015\n",
      "step 20060, change in cost 0.00309372\n",
      "step 20070, training accuracy 0.963415\n",
      "step 20070, cost 7.62704\n",
      "step 20070, change in cost 0.00310898\n",
      "step 20080, training accuracy 0.963415\n",
      "step 20080, cost 7.62391\n",
      "step 20080, change in cost 0.00312471\n",
      "step 20090, training accuracy 0.963415\n",
      "step 20090, cost 7.62078\n",
      "step 20090, change in cost 0.00313807\n",
      "step 20100, training accuracy 0.963415\n",
      "step 20100, cost 7.61762\n",
      "step 20100, change in cost 0.00315619\n",
      "step 20110, training accuracy 0.963415\n",
      "step 20110, cost 7.61445\n",
      "step 20110, change in cost 0.00316906\n",
      "step 20120, training accuracy 0.963415\n",
      "step 20120, cost 7.61127\n",
      "step 20120, change in cost 0.0031848\n",
      "step 20130, training accuracy 0.963415\n",
      "step 20130, cost 7.60807\n",
      "step 20130, change in cost 0.00319719\n",
      "step 20140, training accuracy 0.963415\n",
      "step 20140, cost 7.60485\n",
      "step 20140, change in cost 0.00321531\n",
      "step 20150, training accuracy 0.963415\n",
      "step 20150, cost 7.60162\n",
      "step 20150, change in cost 0.00322962\n",
      "step 20160, training accuracy 0.963415\n",
      "step 20160, cost 7.59838\n",
      "step 20160, change in cost 0.00324297\n",
      "step 20170, training accuracy 0.963415\n",
      "step 20170, cost 7.59512\n",
      "step 20170, change in cost 0.00326061\n",
      "step 20180, training accuracy 0.963415\n",
      "step 20180, cost 7.59185\n",
      "step 20180, change in cost 0.00327301\n",
      "step 20190, training accuracy 0.963415\n",
      "step 20190, cost 7.58856\n",
      "step 20190, change in cost 0.0032897\n",
      "step 20200, training accuracy 0.963415\n",
      "step 20200, cost 7.58525\n",
      "step 20200, change in cost 0.00330305\n",
      "step 20210, training accuracy 0.963415\n",
      "step 20210, cost 7.58193\n",
      "step 20210, change in cost 0.00331974\n",
      "step 20220, training accuracy 0.963415\n",
      "step 20220, cost 7.5786\n",
      "step 20220, change in cost 0.00333166\n",
      "step 20230, training accuracy 0.963415\n",
      "step 20230, cost 7.57525\n",
      "step 20230, change in cost 0.00334787\n",
      "step 20240, training accuracy 0.963415\n",
      "step 20240, cost 7.57189\n",
      "step 20240, change in cost 0.00336027\n",
      "step 20250, training accuracy 0.963415\n",
      "step 20250, cost 7.56852\n",
      "step 20250, change in cost 0.00337505\n",
      "step 20260, training accuracy 0.963415\n",
      "step 20260, cost 7.56513\n",
      "step 20260, change in cost 0.00339031\n",
      "step 20270, training accuracy 0.963415\n",
      "step 20270, cost 7.56173\n",
      "step 20270, change in cost 0.00340319\n",
      "step 20280, training accuracy 0.963415\n",
      "step 20280, cost 7.55831\n",
      "step 20280, change in cost 0.00341702\n",
      "step 20290, training accuracy 0.963415\n",
      "step 20290, cost 7.55488\n",
      "step 20290, change in cost 0.0034318\n",
      "step 20300, training accuracy 0.963415\n",
      "step 20300, cost 7.55143\n",
      "step 20300, change in cost 0.00344419\n",
      "step 20310, training accuracy 0.963415\n",
      "step 20310, cost 7.54798\n",
      "step 20310, change in cost 0.00345755\n",
      "step 20320, training accuracy 0.963415\n",
      "step 20320, cost 7.54451\n",
      "step 20320, change in cost 0.00346994\n",
      "step 20330, training accuracy 0.963415\n",
      "step 20330, cost 7.54102\n",
      "step 20330, change in cost 0.00348473\n",
      "step 20340, training accuracy 0.963415\n",
      "step 20340, cost 7.53753\n",
      "step 20340, change in cost 0.00349426\n",
      "step 20350, training accuracy 0.963415\n",
      "step 20350, cost 7.53402\n",
      "step 20350, change in cost 0.00350857\n",
      "step 20360, training accuracy 0.963415\n",
      "step 20360, cost 7.5305\n",
      "step 20360, change in cost 0.0035181\n",
      "step 20370, training accuracy 0.963415\n",
      "step 20370, cost 7.52696\n",
      "step 20370, change in cost 0.00353479\n",
      "step 20380, training accuracy 0.963415\n",
      "step 20380, cost 7.52342\n",
      "step 20380, change in cost 0.00354338\n",
      "step 20390, training accuracy 0.963415\n",
      "step 20390, cost 7.51987\n",
      "step 20390, change in cost 0.00355625\n",
      "step 20400, training accuracy 0.963415\n",
      "step 20400, cost 7.5163\n",
      "step 20400, change in cost 0.00356579\n",
      "step 20410, training accuracy 0.963415\n",
      "step 20410, cost 7.51272\n",
      "step 20410, change in cost 0.00358009\n",
      "step 20420, training accuracy 0.963415\n",
      "step 20420, cost 7.50913\n",
      "step 20420, change in cost 0.00358677\n",
      "step 20430, training accuracy 0.963415\n",
      "step 20430, cost 7.50553\n",
      "step 20430, change in cost 0.00359821\n",
      "step 20440, training accuracy 0.963415\n",
      "step 20440, cost 7.50193\n",
      "step 20440, change in cost 0.0036087\n",
      "step 20450, training accuracy 0.963415\n",
      "step 20450, cost 7.49831\n",
      "step 20450, change in cost 0.00361681\n",
      "step 20460, training accuracy 0.963415\n",
      "step 20460, cost 7.49468\n",
      "step 20460, change in cost 0.00362635\n",
      "step 20470, training accuracy 0.963415\n",
      "step 20470, cost 7.49105\n",
      "step 20470, change in cost 0.00363684\n",
      "step 20480, training accuracy 0.963415\n",
      "step 20480, cost 7.4874\n",
      "step 20480, change in cost 0.00364542\n",
      "step 20490, training accuracy 0.963415\n",
      "step 20490, cost 7.48375\n",
      "step 20490, change in cost 0.00365114\n",
      "step 20500, training accuracy 0.963415\n",
      "step 20500, cost 7.48008\n",
      "step 20500, change in cost 0.00366402\n",
      "step 20510, training accuracy 0.963415\n",
      "step 20510, cost 7.47642\n",
      "step 20510, change in cost 0.00366831\n",
      "step 20520, training accuracy 0.963415\n",
      "step 20520, cost 7.47274\n",
      "step 20520, change in cost 0.00367737\n",
      "step 20530, training accuracy 0.963415\n",
      "step 20530, cost 7.46906\n",
      "step 20530, change in cost 0.00368404\n",
      "step 20540, training accuracy 0.963415\n",
      "step 20540, cost 7.46537\n",
      "step 20540, change in cost 0.00368929\n",
      "step 20550, training accuracy 0.963415\n",
      "step 20550, cost 7.46167\n",
      "step 20550, change in cost 0.00369644\n",
      "step 20560, training accuracy 0.963415\n",
      "step 20560, cost 7.45797\n",
      "step 20560, change in cost 0.0036993\n",
      "step 20570, training accuracy 0.963415\n",
      "step 20570, cost 7.45426\n",
      "step 20570, change in cost 0.00370741\n",
      "step 20580, training accuracy 0.963415\n",
      "step 20580, cost 7.45055\n",
      "step 20580, change in cost 0.00371265\n",
      "step 20590, training accuracy 0.963415\n",
      "step 20590, cost 7.44684\n",
      "step 20590, change in cost 0.00371456\n",
      "step 20600, training accuracy 0.963415\n",
      "step 20600, cost 7.44312\n",
      "step 20600, change in cost 0.00371933\n",
      "step 20610, training accuracy 0.963415\n",
      "step 20610, cost 7.43939\n",
      "step 20610, change in cost 0.00372314\n",
      "step 20620, training accuracy 0.963415\n",
      "step 20620, cost 7.43566\n",
      "step 20620, change in cost 0.00372982\n",
      "step 20630, training accuracy 0.963415\n",
      "step 20630, cost 7.43193\n",
      "step 20630, change in cost 0.00372887\n",
      "step 20640, training accuracy 0.963415\n",
      "step 20640, cost 7.4282\n",
      "step 20640, change in cost 0.00373363\n",
      "step 20650, training accuracy 0.963415\n",
      "step 20650, cost 7.42447\n",
      "step 20650, change in cost 0.00373411\n",
      "step 20660, training accuracy 0.963415\n",
      "step 20660, cost 7.42073\n",
      "step 20660, change in cost 0.00373697\n",
      "step 20670, training accuracy 0.963415\n",
      "step 20670, cost 7.41699\n",
      "step 20670, change in cost 0.00373745\n",
      "step 20680, training accuracy 0.963415\n",
      "step 20680, cost 7.41325\n",
      "step 20680, change in cost 0.00373793\n",
      "step 20690, training accuracy 0.963415\n",
      "step 20690, cost 7.40951\n",
      "step 20690, change in cost 0.00374174\n",
      "step 20700, training accuracy 0.963415\n",
      "step 20700, cost 7.40578\n",
      "step 20700, change in cost 0.0037365\n",
      "step 20710, training accuracy 0.963415\n",
      "step 20710, cost 7.40204\n",
      "step 20710, change in cost 0.0037384\n",
      "step 20720, training accuracy 0.963415\n",
      "step 20720, cost 7.3983\n",
      "step 20720, change in cost 0.00373554\n",
      "step 20730, training accuracy 0.963415\n",
      "step 20730, cost 7.39456\n",
      "step 20730, change in cost 0.0037384\n",
      "step 20740, training accuracy 0.963415\n",
      "step 20740, cost 7.39083\n",
      "step 20740, change in cost 0.00373173\n",
      "step 20750, training accuracy 0.963415\n",
      "step 20750, cost 7.3871\n",
      "step 20750, change in cost 0.00373077\n",
      "step 20760, training accuracy 0.963415\n",
      "step 20760, cost 7.38337\n",
      "step 20760, change in cost 0.0037303\n",
      "step 20770, training accuracy 0.963415\n",
      "step 20770, cost 7.37964\n",
      "step 20770, change in cost 0.00372601\n",
      "step 20780, training accuracy 0.963415\n",
      "step 20780, cost 7.37592\n",
      "step 20780, change in cost 0.00372362\n",
      "step 20790, training accuracy 0.963415\n",
      "step 20790, cost 7.3722\n",
      "step 20790, change in cost 0.00371647\n",
      "step 20800, training accuracy 0.963415\n",
      "step 20800, cost 7.36849\n",
      "step 20800, change in cost 0.00371838\n",
      "step 20810, training accuracy 0.963415\n",
      "step 20810, cost 7.36478\n",
      "step 20810, change in cost 0.00370693\n",
      "step 20820, training accuracy 0.963415\n",
      "step 20820, cost 7.36107\n",
      "step 20820, change in cost 0.00370598\n",
      "step 20830, training accuracy 0.963415\n",
      "step 20830, cost 7.35737\n",
      "step 20830, change in cost 0.00369883\n",
      "step 20840, training accuracy 0.963415\n",
      "step 20840, cost 7.35368\n",
      "step 20840, change in cost 0.0036931\n",
      "step 20850, training accuracy 0.963415\n",
      "step 20850, cost 7.34999\n",
      "step 20850, change in cost 0.00368786\n",
      "step 20860, training accuracy 0.963415\n",
      "step 20860, cost 7.34631\n",
      "step 20860, change in cost 0.00367928\n",
      "step 20870, training accuracy 0.963415\n",
      "step 20870, cost 7.34264\n",
      "step 20870, change in cost 0.00367355\n",
      "step 20880, training accuracy 0.963415\n",
      "step 20880, cost 7.33898\n",
      "step 20880, change in cost 0.00366497\n",
      "step 20890, training accuracy 0.963415\n",
      "step 20890, cost 7.33532\n",
      "step 20890, change in cost 0.00365829\n",
      "step 20900, training accuracy 0.963415\n",
      "step 20900, cost 7.33167\n",
      "step 20900, change in cost 0.00365114\n",
      "step 20910, training accuracy 0.963415\n",
      "step 20910, cost 7.32802\n",
      "step 20910, change in cost 0.00364256\n",
      "step 20920, training accuracy 0.963415\n",
      "step 20920, cost 7.32439\n",
      "step 20920, change in cost 0.00363207\n",
      "step 20930, training accuracy 0.963415\n",
      "step 20930, cost 7.32077\n",
      "step 20930, change in cost 0.00362539\n",
      "step 20940, training accuracy 0.963415\n",
      "step 20940, cost 7.31715\n",
      "step 20940, change in cost 0.00361347\n",
      "step 20950, training accuracy 0.963415\n",
      "step 20950, cost 7.31355\n",
      "step 20950, change in cost 0.00360298\n",
      "step 20960, training accuracy 0.963415\n",
      "step 20960, cost 7.30995\n",
      "step 20960, change in cost 0.00359678\n",
      "step 20970, training accuracy 0.963415\n",
      "step 20970, cost 7.30637\n",
      "step 20970, change in cost 0.00358343\n",
      "step 20980, training accuracy 0.963415\n",
      "step 20980, cost 7.3028\n",
      "step 20980, change in cost 0.00357294\n",
      "step 20990, training accuracy 0.963415\n",
      "step 20990, cost 7.29923\n",
      "step 20990, change in cost 0.00356245\n",
      "step 21000, training accuracy 0.963415\n",
      "step 21000, cost 7.29568\n",
      "step 21000, change in cost 0.00355196\n",
      "step 21010, training accuracy 0.963415\n",
      "step 21010, cost 7.29214\n",
      "step 21010, change in cost 0.00353956\n",
      "step 21020, training accuracy 0.963415\n",
      "step 21020, cost 7.28861\n",
      "step 21020, change in cost 0.00352812\n",
      "step 21030, training accuracy 0.963415\n",
      "step 21030, cost 7.2851\n",
      "step 21030, change in cost 0.00351381\n",
      "step 21040, training accuracy 0.963415\n",
      "step 21040, cost 7.2816\n",
      "step 21040, change in cost 0.00350332\n",
      "step 21050, training accuracy 0.963415\n",
      "step 21050, cost 7.27811\n",
      "step 21050, change in cost 0.0034914\n",
      "step 21060, training accuracy 0.963415\n",
      "step 21060, cost 7.27463\n",
      "step 21060, change in cost 0.00347757\n",
      "step 21070, training accuracy 0.963415\n",
      "step 21070, cost 7.27116\n",
      "step 21070, change in cost 0.00346661\n",
      "step 21080, training accuracy 0.963415\n",
      "step 21080, cost 7.26771\n",
      "step 21080, change in cost 0.00345135\n",
      "step 21090, training accuracy 0.963415\n",
      "step 21090, cost 7.26428\n",
      "step 21090, change in cost 0.00343466\n",
      "step 21100, training accuracy 0.963415\n",
      "step 21100, cost 7.26085\n",
      "step 21100, change in cost 0.0034256\n",
      "step 21110, training accuracy 0.963415\n",
      "step 21110, cost 7.25744\n",
      "step 21110, change in cost 0.00341129\n",
      "step 21120, training accuracy 0.963415\n",
      "step 21120, cost 7.25404\n",
      "step 21120, change in cost 0.0033946\n",
      "step 21130, training accuracy 0.963415\n",
      "step 21130, cost 7.25066\n",
      "step 21130, change in cost 0.0033803\n",
      "step 21140, training accuracy 0.963415\n",
      "step 21140, cost 7.2473\n",
      "step 21140, change in cost 0.00336885\n",
      "step 21150, training accuracy 0.963415\n",
      "step 21150, cost 7.24394\n",
      "step 21150, change in cost 0.00335217\n",
      "step 21160, training accuracy 0.963415\n",
      "step 21160, cost 7.24061\n",
      "step 21160, change in cost 0.00333691\n",
      "step 21170, training accuracy 0.963415\n",
      "step 21170, cost 7.23728\n",
      "step 21170, change in cost 0.0033226\n",
      "step 21180, training accuracy 0.963415\n",
      "step 21180, cost 7.23398\n",
      "step 21180, change in cost 0.00330734\n",
      "step 21190, training accuracy 0.963415\n",
      "step 21190, cost 7.23068\n",
      "step 21190, change in cost 0.00329256\n",
      "step 21200, training accuracy 0.963415\n",
      "step 21200, cost 7.22741\n",
      "step 21200, change in cost 0.00327492\n",
      "step 21210, training accuracy 0.963415\n",
      "step 21210, cost 7.22414\n",
      "step 21210, change in cost 0.00326395\n",
      "step 21220, training accuracy 0.963415\n",
      "step 21220, cost 7.2209\n",
      "step 21220, change in cost 0.0032444\n",
      "step 21230, training accuracy 0.963415\n",
      "step 21230, cost 7.21767\n",
      "step 21230, change in cost 0.00323105\n",
      "step 21240, training accuracy 0.963415\n",
      "step 21240, cost 7.21446\n",
      "step 21240, change in cost 0.00321293\n",
      "step 21250, training accuracy 0.963415\n",
      "step 21250, cost 7.21126\n",
      "step 21250, change in cost 0.00319719\n",
      "step 21260, training accuracy 0.963415\n",
      "step 21260, cost 7.20808\n",
      "step 21260, change in cost 0.00318003\n",
      "step 21270, training accuracy 0.963415\n",
      "step 21270, cost 7.20491\n",
      "step 21270, change in cost 0.00316906\n",
      "step 21280, training accuracy 0.963415\n",
      "step 21280, cost 7.20176\n",
      "step 21280, change in cost 0.00314808\n",
      "step 21290, training accuracy 0.963415\n",
      "step 21290, cost 7.19863\n",
      "step 21290, change in cost 0.00313234\n",
      "step 21300, training accuracy 0.963415\n",
      "step 21300, cost 7.19551\n",
      "step 21300, change in cost 0.00311661\n",
      "step 21310, training accuracy 0.963415\n",
      "step 21310, cost 7.19241\n",
      "step 21310, change in cost 0.00309992\n",
      "step 21320, training accuracy 0.963415\n",
      "step 21320, cost 7.18933\n",
      "step 21320, change in cost 0.00308609\n",
      "step 21330, training accuracy 0.963415\n",
      "step 21330, cost 7.18626\n",
      "step 21330, change in cost 0.00306892\n",
      "step 21340, training accuracy 0.963415\n",
      "step 21340, cost 7.18321\n",
      "step 21340, change in cost 0.00304794\n",
      "step 21350, training accuracy 0.963415\n",
      "step 21350, cost 7.18018\n",
      "step 21350, change in cost 0.00303268\n",
      "step 21360, training accuracy 0.963415\n",
      "step 21360, cost 7.17716\n",
      "step 21360, change in cost 0.00301933\n",
      "step 21370, training accuracy 0.963415\n",
      "step 21370, cost 7.17416\n",
      "step 21370, change in cost 0.00299788\n",
      "step 21380, training accuracy 0.963415\n",
      "step 21380, cost 7.17118\n",
      "step 21380, change in cost 0.00298262\n",
      "step 21390, training accuracy 0.963415\n",
      "step 21390, cost 7.16821\n",
      "step 21390, change in cost 0.00296783\n",
      "step 21400, training accuracy 0.963415\n",
      "step 21400, cost 7.16526\n",
      "step 21400, change in cost 0.00294971\n",
      "step 21410, training accuracy 0.963415\n",
      "step 21410, cost 7.16233\n",
      "step 21410, change in cost 0.00293255\n",
      "step 21420, training accuracy 0.963415\n",
      "step 21420, cost 7.15941\n",
      "step 21420, change in cost 0.00291634\n",
      "step 21430, training accuracy 0.963415\n",
      "step 21430, cost 7.15651\n",
      "step 21430, change in cost 0.00289917\n",
      "step 21440, training accuracy 0.963415\n",
      "step 21440, cost 7.15363\n",
      "step 21440, change in cost 0.00288296\n",
      "step 21450, training accuracy 0.963415\n",
      "step 21450, cost 7.15076\n",
      "step 21450, change in cost 0.00286627\n",
      "step 21460, training accuracy 0.963415\n",
      "step 21460, cost 7.14791\n",
      "step 21460, change in cost 0.0028491\n",
      "step 21470, training accuracy 0.963415\n",
      "step 21470, cost 7.14508\n",
      "step 21470, change in cost 0.00283241\n",
      "step 21480, training accuracy 0.963415\n",
      "step 21480, cost 7.14227\n",
      "step 21480, change in cost 0.00281525\n",
      "step 21490, training accuracy 0.963415\n",
      "step 21490, cost 7.13947\n",
      "step 21490, change in cost 0.00279999\n",
      "step 21500, training accuracy 0.963415\n",
      "step 21500, cost 7.13668\n",
      "step 21500, change in cost 0.00278282\n",
      "step 21510, training accuracy 0.963415\n",
      "step 21510, cost 7.13392\n",
      "step 21510, change in cost 0.00276375\n",
      "step 21520, training accuracy 0.963415\n",
      "step 21520, cost 7.13117\n",
      "step 21520, change in cost 0.00274992\n",
      "step 21530, training accuracy 0.963415\n",
      "step 21530, cost 7.12844\n",
      "step 21530, change in cost 0.00273085\n",
      "step 21540, training accuracy 0.963415\n",
      "step 21540, cost 7.12572\n",
      "step 21540, change in cost 0.00271463\n",
      "step 21550, training accuracy 0.963415\n",
      "step 21550, cost 7.12302\n",
      "step 21550, change in cost 0.00270128\n",
      "step 21560, training accuracy 0.963415\n",
      "step 21560, cost 7.12034\n",
      "step 21560, change in cost 0.00268269\n",
      "step 21570, training accuracy 0.963415\n",
      "step 21570, cost 7.11767\n",
      "step 21570, change in cost 0.00266695\n",
      "step 21580, training accuracy 0.963415\n",
      "step 21580, cost 7.11502\n",
      "step 21580, change in cost 0.00264883\n",
      "step 21590, training accuracy 0.963415\n",
      "step 21590, cost 7.11239\n",
      "step 21590, change in cost 0.002635\n",
      "step 21600, training accuracy 0.963415\n",
      "step 21600, cost 7.10977\n",
      "step 21600, change in cost 0.00261593\n",
      "step 21610, training accuracy 0.963415\n",
      "step 21610, cost 7.10717\n",
      "step 21610, change in cost 0.00260115\n",
      "step 21620, training accuracy 0.963415\n",
      "step 21620, cost 7.10459\n",
      "step 21620, change in cost 0.00258398\n",
      "step 21630, training accuracy 0.963415\n",
      "step 21630, cost 7.10202\n",
      "step 21630, change in cost 0.00257206\n",
      "step 21640, training accuracy 0.963415\n",
      "step 21640, cost 7.09946\n",
      "step 21640, change in cost 0.00255203\n",
      "step 21650, training accuracy 0.963415\n",
      "step 21650, cost 7.09693\n",
      "step 21650, change in cost 0.00253868\n",
      "step 21660, training accuracy 0.963415\n",
      "step 21660, cost 7.0944\n",
      "step 21660, change in cost 0.00252151\n",
      "step 21670, training accuracy 0.963415\n",
      "step 21670, cost 7.0919\n",
      "step 21670, change in cost 0.0025034\n",
      "step 21680, training accuracy 0.963415\n",
      "step 21680, cost 7.08941\n",
      "step 21680, change in cost 0.0024929\n",
      "step 21690, training accuracy 0.963415\n",
      "step 21690, cost 7.08693\n",
      "step 21690, change in cost 0.00247383\n",
      "step 21700, training accuracy 0.963415\n",
      "step 21700, cost 7.08447\n",
      "step 21700, change in cost 0.00245953\n",
      "step 21710, training accuracy 0.963415\n",
      "step 21710, cost 7.08203\n",
      "step 21710, change in cost 0.00244331\n",
      "step 21720, training accuracy 0.963415\n",
      "step 21720, cost 7.0796\n",
      "step 21720, change in cost 0.00242805\n",
      "step 21730, training accuracy 0.963415\n",
      "step 21730, cost 7.07719\n",
      "step 21730, change in cost 0.00241232\n",
      "step 21740, training accuracy 0.963415\n",
      "step 21740, cost 7.07479\n",
      "step 21740, change in cost 0.00239897\n",
      "step 21750, training accuracy 0.963415\n",
      "step 21750, cost 7.07241\n",
      "step 21750, change in cost 0.00237846\n",
      "step 21760, training accuracy 0.963415\n",
      "step 21760, cost 7.07004\n",
      "step 21760, change in cost 0.00236845\n",
      "step 21770, training accuracy 0.963415\n",
      "step 21770, cost 7.06769\n",
      "step 21770, change in cost 0.00235415\n",
      "step 21780, training accuracy 0.963415\n",
      "step 21780, cost 7.06535\n",
      "step 21780, change in cost 0.00233793\n",
      "step 21790, training accuracy 0.963415\n",
      "step 21790, cost 7.06303\n",
      "step 21790, change in cost 0.0023241\n",
      "step 21800, training accuracy 0.963415\n",
      "step 21800, cost 7.06072\n",
      "step 21800, change in cost 0.00230742\n",
      "step 21810, training accuracy 0.963415\n",
      "step 21810, cost 7.05843\n",
      "step 21810, change in cost 0.00229359\n",
      "step 21820, training accuracy 0.963415\n",
      "step 21820, cost 7.05615\n",
      "step 21820, change in cost 0.00228119\n",
      "step 21830, training accuracy 0.963415\n",
      "step 21830, cost 7.05388\n",
      "step 21830, change in cost 0.0022645\n",
      "step 21840, training accuracy 0.963415\n",
      "step 21840, cost 7.05163\n",
      "step 21840, change in cost 0.0022521\n",
      "step 21850, training accuracy 0.963415\n",
      "step 21850, cost 7.04939\n",
      "step 21850, change in cost 0.00223732\n",
      "step 21860, training accuracy 0.963415\n",
      "step 21860, cost 7.04717\n",
      "step 21860, change in cost 0.00222349\n",
      "step 21870, training accuracy 0.963415\n",
      "step 21870, cost 7.04496\n",
      "step 21870, change in cost 0.00220823\n",
      "step 21880, training accuracy 0.963415\n",
      "step 21880, cost 7.04277\n",
      "step 21880, change in cost 0.0021944\n",
      "step 21890, training accuracy 0.963415\n",
      "step 21890, cost 7.04059\n",
      "step 21890, change in cost 0.00218105\n",
      "step 21900, training accuracy 0.963415\n",
      "step 21900, cost 7.03842\n",
      "step 21900, change in cost 0.00216913\n",
      "step 21910, training accuracy 0.963415\n",
      "step 21910, cost 7.03626\n",
      "step 21910, change in cost 0.00215387\n",
      "step 21920, training accuracy 0.963415\n",
      "step 21920, cost 7.03412\n",
      "step 21920, change in cost 0.002141\n",
      "step 21930, training accuracy 0.963415\n",
      "step 21930, cost 7.03199\n",
      "step 21930, change in cost 0.00212669\n",
      "step 21940, training accuracy 0.963415\n",
      "step 21940, cost 7.02988\n",
      "step 21940, change in cost 0.00211287\n",
      "step 21950, training accuracy 0.963415\n",
      "step 21950, cost 7.02778\n",
      "step 21950, change in cost 0.00209999\n",
      "step 21960, training accuracy 0.963415\n",
      "step 21960, cost 7.02569\n",
      "step 21960, change in cost 0.00208902\n",
      "step 21970, training accuracy 0.963415\n",
      "step 21970, cost 7.02362\n",
      "step 21970, change in cost 0.0020752\n",
      "step 21980, training accuracy 0.963415\n",
      "step 21980, cost 7.02156\n",
      "step 21980, change in cost 0.00206089\n",
      "step 21990, training accuracy 0.963415\n",
      "step 21990, cost 7.01951\n",
      "step 21990, change in cost 0.00205135\n",
      "step 22000, training accuracy 0.963415\n",
      "step 22000, cost 7.01747\n",
      "step 22000, change in cost 0.00203753\n",
      "step 22010, training accuracy 0.963415\n",
      "step 22010, cost 7.01544\n",
      "step 22010, change in cost 0.0020237\n",
      "step 22020, training accuracy 0.963415\n",
      "step 22020, cost 7.01343\n",
      "step 22020, change in cost 0.00201035\n",
      "step 22030, training accuracy 0.963415\n",
      "step 22030, cost 7.01143\n",
      "step 22030, change in cost 0.00200033\n",
      "step 22040, training accuracy 0.963415\n",
      "step 22040, cost 7.00945\n",
      "step 22040, change in cost 0.0019865\n",
      "step 22050, training accuracy 0.963415\n",
      "step 22050, cost 7.00747\n",
      "step 22050, change in cost 0.00197411\n",
      "step 22060, training accuracy 0.963415\n",
      "step 22060, cost 7.00551\n",
      "step 22060, change in cost 0.00196457\n",
      "step 22070, training accuracy 0.963415\n",
      "step 22070, cost 7.00356\n",
      "step 22070, change in cost 0.00195312\n",
      "step 22080, training accuracy 0.963415\n",
      "step 22080, cost 7.00162\n",
      "step 22080, change in cost 0.00193691\n",
      "step 22090, training accuracy 0.963415\n",
      "step 22090, cost 6.99969\n",
      "step 22090, change in cost 0.00192881\n",
      "step 22100, training accuracy 0.963415\n",
      "step 22100, cost 6.99777\n",
      "step 22100, change in cost 0.00191545\n",
      "step 22110, training accuracy 0.963415\n",
      "step 22110, cost 6.99587\n",
      "step 22110, change in cost 0.00190496\n",
      "step 22120, training accuracy 0.963415\n",
      "step 22120, cost 6.99398\n",
      "step 22120, change in cost 0.00189352\n",
      "step 22130, training accuracy 0.963415\n",
      "step 22130, cost 6.99209\n",
      "step 22130, change in cost 0.00188112\n",
      "step 22140, training accuracy 0.963415\n",
      "step 22140, cost 6.99022\n",
      "step 22140, change in cost 0.00187063\n",
      "step 22150, training accuracy 0.963415\n",
      "step 22150, cost 6.98836\n",
      "step 22150, change in cost 0.00186062\n",
      "step 22160, training accuracy 0.963415\n",
      "step 22160, cost 6.98652\n",
      "step 22160, change in cost 0.00184727\n",
      "step 22170, training accuracy 0.963415\n",
      "step 22170, cost 6.98468\n",
      "step 22170, change in cost 0.00183725\n",
      "step 22180, training accuracy 0.963415\n",
      "step 22180, cost 6.98285\n",
      "step 22180, change in cost 0.00182629\n",
      "step 22190, training accuracy 0.963415\n",
      "step 22190, cost 6.98104\n",
      "step 22190, change in cost 0.00181532\n",
      "step 22200, training accuracy 0.963415\n",
      "step 22200, cost 6.97923\n",
      "step 22200, change in cost 0.00180483\n",
      "step 22210, training accuracy 0.963415\n",
      "step 22210, cost 6.97744\n",
      "step 22210, change in cost 0.0017972\n",
      "step 22220, training accuracy 0.963415\n",
      "step 22220, cost 6.97565\n",
      "step 22220, change in cost 0.00178385\n",
      "step 22230, training accuracy 0.963415\n",
      "step 22230, cost 6.97388\n",
      "step 22230, change in cost 0.00177288\n",
      "step 22240, training accuracy 0.963415\n",
      "step 22240, cost 6.97211\n",
      "step 22240, change in cost 0.00176477\n",
      "step 22250, training accuracy 0.963415\n",
      "step 22250, cost 6.97036\n",
      "step 22250, change in cost 0.00175381\n",
      "step 22260, training accuracy 0.963415\n",
      "step 22260, cost 6.96862\n",
      "step 22260, change in cost 0.00174332\n",
      "step 22270, training accuracy 0.963415\n",
      "step 22270, cost 6.96688\n",
      "step 22270, change in cost 0.00173378\n",
      "step 22280, training accuracy 0.963415\n",
      "step 22280, cost 6.96516\n",
      "step 22280, change in cost 0.00172234\n",
      "step 22290, training accuracy 0.963415\n",
      "step 22290, cost 6.96345\n",
      "step 22290, change in cost 0.00171518\n",
      "step 22300, training accuracy 0.963415\n",
      "step 22300, cost 6.96174\n",
      "step 22300, change in cost 0.00170469\n",
      "step 22310, training accuracy 0.963415\n",
      "step 22310, cost 6.96005\n",
      "step 22310, change in cost 0.00169182\n",
      "step 22320, training accuracy 0.963415\n",
      "step 22320, cost 6.95836\n",
      "step 22320, change in cost 0.00168514\n",
      "step 22330, training accuracy 0.963415\n",
      "step 22330, cost 6.95669\n",
      "step 22330, change in cost 0.00167561\n",
      "step 22340, training accuracy 0.963415\n",
      "step 22340, cost 6.95502\n",
      "step 22340, change in cost 0.00166655\n",
      "step 22350, training accuracy 0.963415\n",
      "step 22350, cost 6.95336\n",
      "step 22350, change in cost 0.00165701\n",
      "step 22360, training accuracy 0.963415\n",
      "step 22360, cost 6.95172\n",
      "step 22360, change in cost 0.00164652\n",
      "step 22370, training accuracy 0.963415\n",
      "step 22370, cost 6.95008\n",
      "step 22370, change in cost 0.00163984\n",
      "step 22380, training accuracy 0.963415\n",
      "step 22380, cost 6.94845\n",
      "step 22380, change in cost 0.00163174\n",
      "step 22390, training accuracy 0.963415\n",
      "step 22390, cost 6.94683\n",
      "step 22390, change in cost 0.00161934\n",
      "step 22400, training accuracy 0.963415\n",
      "step 22400, cost 6.94522\n",
      "step 22400, change in cost 0.00161076\n",
      "step 22410, training accuracy 0.963415\n",
      "step 22410, cost 6.94361\n",
      "step 22410, change in cost 0.00160217\n",
      "step 22420, training accuracy 0.963415\n",
      "step 22420, cost 6.94202\n",
      "step 22420, change in cost 0.00159502\n",
      "step 22430, training accuracy 0.963415\n",
      "step 22430, cost 6.94043\n",
      "step 22430, change in cost 0.00158548\n",
      "step 22440, training accuracy 0.963415\n",
      "step 22440, cost 6.93886\n",
      "step 22440, change in cost 0.00157833\n",
      "step 22450, training accuracy 0.963415\n",
      "step 22450, cost 6.93729\n",
      "step 22450, change in cost 0.00156689\n",
      "step 22460, training accuracy 0.963415\n",
      "step 22460, cost 6.93573\n",
      "step 22460, change in cost 0.00156116\n",
      "step 22470, training accuracy 0.963415\n",
      "step 22470, cost 6.93417\n",
      "step 22470, change in cost 0.00155258\n",
      "step 22480, training accuracy 0.963415\n",
      "step 22480, cost 6.93263\n",
      "step 22480, change in cost 0.00154305\n",
      "step 22490, training accuracy 0.963415\n",
      "step 22490, cost 6.9311\n",
      "step 22490, change in cost 0.00153589\n",
      "step 22500, training accuracy 0.963415\n",
      "step 22500, cost 6.92957\n",
      "step 22500, change in cost 0.00152922\n",
      "step 22510, training accuracy 0.963415\n",
      "step 22510, cost 6.92804\n",
      "step 22510, change in cost 0.00152159\n",
      "step 22520, training accuracy 0.963415\n",
      "step 22520, cost 6.92653\n",
      "step 22520, change in cost 0.0015111\n",
      "step 22530, training accuracy 0.963415\n",
      "step 22530, cost 6.92503\n",
      "step 22530, change in cost 0.0015049\n",
      "step 22540, training accuracy 0.963415\n",
      "step 22540, cost 6.92353\n",
      "step 22540, change in cost 0.00149584\n",
      "step 22550, training accuracy 0.963415\n",
      "step 22550, cost 6.92204\n",
      "step 22550, change in cost 0.00148916\n",
      "step 22560, training accuracy 0.963415\n",
      "step 22560, cost 6.92056\n",
      "step 22560, change in cost 0.0014801\n",
      "step 22570, training accuracy 0.963415\n",
      "step 22570, cost 6.91909\n",
      "step 22570, change in cost 0.00147438\n",
      "step 22580, training accuracy 0.963415\n",
      "step 22580, cost 6.91762\n",
      "step 22580, change in cost 0.00146723\n",
      "step 22590, training accuracy 0.963415\n",
      "step 22590, cost 6.91616\n",
      "step 22590, change in cost 0.00145912\n",
      "step 22600, training accuracy 0.963415\n",
      "step 22600, cost 6.91471\n",
      "step 22600, change in cost 0.00145197\n",
      "step 22610, training accuracy 0.963415\n",
      "step 22610, cost 6.91327\n",
      "step 22610, change in cost 0.00144291\n",
      "step 22620, training accuracy 0.963415\n",
      "step 22620, cost 6.91183\n",
      "step 22620, change in cost 0.00143862\n",
      "step 22630, training accuracy 0.963415\n",
      "step 22630, cost 6.9104\n",
      "step 22630, change in cost 0.00142813\n",
      "step 22640, training accuracy 0.963415\n",
      "step 22640, cost 6.90898\n",
      "step 22640, change in cost 0.00142479\n",
      "step 22650, training accuracy 0.963415\n",
      "step 22650, cost 6.90756\n",
      "step 22650, change in cost 0.0014143\n",
      "step 22660, training accuracy 0.963415\n",
      "step 22660, cost 6.90615\n",
      "step 22660, change in cost 0.00141001\n",
      "step 22670, training accuracy 0.963415\n",
      "step 22670, cost 6.90475\n",
      "step 22670, change in cost 0.00140285\n",
      "step 22680, training accuracy 0.963415\n",
      "step 22680, cost 6.90335\n",
      "step 22680, change in cost 0.00139618\n",
      "step 22690, training accuracy 0.963415\n",
      "step 22690, cost 6.90197\n",
      "step 22690, change in cost 0.00138807\n",
      "step 22700, training accuracy 0.963415\n",
      "step 22700, cost 6.90058\n",
      "step 22700, change in cost 0.0013814\n",
      "step 22710, training accuracy 0.963415\n",
      "step 22710, cost 6.89921\n",
      "step 22710, change in cost 0.00137568\n",
      "step 22720, training accuracy 0.963415\n",
      "step 22720, cost 6.89784\n",
      "step 22720, change in cost 0.00137043\n",
      "step 22730, training accuracy 0.963415\n",
      "step 22730, cost 6.89648\n",
      "step 22730, change in cost 0.00135994\n",
      "step 22740, training accuracy 0.963415\n",
      "step 22740, cost 6.89512\n",
      "step 22740, change in cost 0.00135899\n",
      "step 22750, training accuracy 0.963415\n",
      "step 22750, cost 6.89377\n",
      "step 22750, change in cost 0.00134993\n",
      "step 22760, training accuracy 0.963415\n",
      "step 22760, cost 6.89242\n",
      "step 22760, change in cost 0.0013442\n",
      "step 22770, training accuracy 0.963415\n",
      "step 22770, cost 6.89109\n",
      "step 22770, change in cost 0.00133514\n",
      "step 22780, training accuracy 0.963415\n",
      "step 22780, cost 6.88976\n",
      "step 22780, change in cost 0.00133228\n",
      "step 22790, training accuracy 0.963415\n",
      "step 22790, cost 6.88843\n",
      "step 22790, change in cost 0.00132418\n",
      "step 22800, training accuracy 0.963415\n",
      "step 22800, cost 6.88711\n",
      "step 22800, change in cost 0.00131941\n",
      "step 22810, training accuracy 0.963415\n",
      "step 22810, cost 6.8858\n",
      "step 22810, change in cost 0.00131226\n",
      "step 22820, training accuracy 0.963415\n",
      "step 22820, cost 6.88449\n",
      "step 22820, change in cost 0.00130844\n",
      "step 22830, training accuracy 0.963415\n",
      "step 22830, cost 6.88319\n",
      "step 22830, change in cost 0.00129986\n",
      "step 22840, training accuracy 0.963415\n",
      "step 22840, cost 6.8819\n",
      "step 22840, change in cost 0.00129366\n",
      "step 22850, training accuracy 0.963415\n",
      "step 22850, cost 6.88061\n",
      "step 22850, change in cost 0.00128984\n",
      "step 22860, training accuracy 0.963415\n",
      "step 22860, cost 6.87932\n",
      "step 22860, change in cost 0.0012846\n",
      "step 22870, training accuracy 0.963415\n",
      "step 22870, cost 6.87805\n",
      "step 22870, change in cost 0.00127697\n",
      "step 22880, training accuracy 0.963415\n",
      "step 22880, cost 6.87677\n",
      "step 22880, change in cost 0.00127316\n",
      "step 22890, training accuracy 0.963415\n",
      "step 22890, cost 6.87551\n",
      "step 22890, change in cost 0.00126457\n",
      "step 22900, training accuracy 0.963415\n",
      "step 22900, cost 6.87425\n",
      "step 22900, change in cost 0.00126076\n",
      "step 22910, training accuracy 0.963415\n",
      "step 22910, cost 6.87299\n",
      "step 22910, change in cost 0.0012598\n",
      "step 22920, training accuracy 0.963415\n",
      "step 22920, cost 6.87174\n",
      "step 22920, change in cost 0.00125027\n",
      "step 22930, training accuracy 0.963415\n",
      "step 22930, cost 6.87049\n",
      "step 22930, change in cost 0.00124502\n",
      "step 22940, training accuracy 0.963415\n",
      "step 22940, cost 6.86926\n",
      "step 22940, change in cost 0.0012393\n",
      "step 22950, training accuracy 0.963415\n",
      "step 22950, cost 6.86802\n",
      "step 22950, change in cost 0.0012331\n",
      "step 22960, training accuracy 0.963415\n",
      "step 22960, cost 6.86679\n",
      "step 22960, change in cost 0.00123024\n",
      "step 22970, training accuracy 0.963415\n",
      "step 22970, cost 6.86557\n",
      "step 22970, change in cost 0.00122499\n",
      "step 22980, training accuracy 0.963415\n",
      "step 22980, cost 6.86435\n",
      "step 22980, change in cost 0.00121975\n",
      "step 22990, training accuracy 0.963415\n",
      "step 22990, cost 6.86313\n",
      "step 22990, change in cost 0.0012145\n",
      "step 23000, training accuracy 0.963415\n",
      "step 23000, cost 6.86193\n",
      "step 23000, change in cost 0.00120735\n",
      "step 23010, training accuracy 0.963415\n",
      "step 23010, cost 6.86072\n",
      "step 23010, change in cost 0.00120354\n",
      "step 23020, training accuracy 0.963415\n",
      "step 23020, cost 6.85952\n",
      "step 23020, change in cost 0.00120068\n",
      "step 23030, training accuracy 0.963415\n",
      "step 23030, cost 6.85833\n",
      "step 23030, change in cost 0.00119305\n",
      "step 23040, training accuracy 0.963415\n",
      "step 23040, cost 6.85714\n",
      "step 23040, change in cost 0.00118923\n",
      "step 23050, training accuracy 0.963415\n",
      "step 23050, cost 6.85595\n",
      "step 23050, change in cost 0.00118637\n",
      "step 23060, training accuracy 0.963415\n",
      "step 23060, cost 6.85477\n",
      "step 23060, change in cost 0.00117779\n",
      "step 23070, training accuracy 0.963415\n",
      "step 23070, cost 6.8536\n",
      "step 23070, change in cost 0.00117588\n",
      "step 23080, training accuracy 0.963415\n",
      "step 23080, cost 6.85243\n",
      "step 23080, change in cost 0.00117207\n",
      "step 23090, training accuracy 0.963415\n",
      "step 23090, cost 6.85126\n",
      "step 23090, change in cost 0.00116539\n",
      "step 23100, training accuracy 0.963415\n",
      "step 23100, cost 6.8501\n",
      "step 23100, change in cost 0.00116253\n",
      "step 23110, training accuracy 0.963415\n",
      "step 23110, cost 6.84894\n",
      "step 23110, change in cost 0.00115681\n",
      "step 23120, training accuracy 0.963415\n",
      "step 23120, cost 6.84779\n",
      "step 23120, change in cost 0.00114918\n",
      "step 23130, training accuracy 0.963415\n",
      "step 23130, cost 6.84664\n",
      "step 23130, change in cost 0.00114918\n",
      "step 23140, training accuracy 0.963415\n",
      "step 23140, cost 6.8455\n",
      "step 23140, change in cost 0.00114536\n",
      "step 23150, training accuracy 0.963415\n",
      "step 23150, cost 6.84436\n",
      "step 23150, change in cost 0.00113773\n",
      "step 23160, training accuracy 0.963415\n",
      "step 23160, cost 6.84323\n",
      "step 23160, change in cost 0.00113344\n",
      "step 23170, training accuracy 0.963415\n",
      "step 23170, cost 6.8421\n",
      "step 23170, change in cost 0.00112963\n",
      "step 23180, training accuracy 0.963415\n",
      "step 23180, cost 6.84097\n",
      "step 23180, change in cost 0.00112629\n",
      "step 23190, training accuracy 0.963415\n",
      "step 23190, cost 6.83985\n",
      "step 23190, change in cost 0.00112247\n",
      "step 23200, training accuracy 0.963415\n",
      "step 23200, cost 6.83873\n",
      "step 23200, change in cost 0.00111771\n",
      "step 23210, training accuracy 0.963415\n",
      "step 23210, cost 6.83762\n",
      "step 23210, change in cost 0.00111008\n",
      "step 23220, training accuracy 0.963415\n",
      "step 23220, cost 6.83651\n",
      "step 23220, change in cost 0.00111294\n",
      "step 23230, training accuracy 0.963415\n",
      "step 23230, cost 6.83541\n",
      "step 23230, change in cost 0.00110054\n",
      "step 23240, training accuracy 0.963415\n",
      "step 23240, cost 6.83431\n",
      "step 23240, change in cost 0.00110197\n",
      "step 23250, training accuracy 0.963415\n",
      "step 23250, cost 6.8332\n",
      "step 23250, change in cost 0.00110054\n",
      "step 23260, training accuracy 0.963415\n",
      "step 23260, cost 6.83211\n",
      "step 23260, change in cost 0.00109243\n",
      "step 23270, training accuracy 0.963415\n",
      "step 23270, cost 6.83103\n",
      "step 23270, change in cost 0.00108671\n",
      "step 23280, training accuracy 0.963415\n",
      "step 23280, cost 6.82994\n",
      "step 23280, change in cost 0.00108671\n",
      "step 23290, training accuracy 0.963415\n",
      "step 23290, cost 6.82886\n",
      "step 23290, change in cost 0.00107956\n",
      "step 23300, training accuracy 0.963415\n",
      "step 23300, cost 6.82778\n",
      "step 23300, change in cost 0.00107813\n",
      "step 23310, training accuracy 0.963415\n",
      "step 23310, cost 6.82671\n",
      "step 23310, change in cost 0.00107384\n",
      "step 23320, training accuracy 0.963415\n",
      "step 23320, cost 6.82564\n",
      "step 23320, change in cost 0.00106812\n",
      "step 23330, training accuracy 0.963415\n",
      "step 23330, cost 6.82457\n",
      "step 23330, change in cost 0.00106764\n",
      "step 23340, training accuracy 0.963415\n",
      "step 23340, cost 6.82351\n",
      "step 23340, change in cost 0.00106144\n",
      "step 23350, training accuracy 0.963415\n",
      "step 23350, cost 6.82245\n",
      "step 23350, change in cost 0.00105906\n",
      "step 23360, training accuracy 0.963415\n",
      "step 23360, cost 6.8214\n",
      "step 23360, change in cost 0.00105572\n",
      "step 23370, training accuracy 0.963415\n",
      "step 23370, cost 6.82034\n",
      "step 23370, change in cost 0.00105238\n",
      "step 23380, training accuracy 0.963415\n",
      "step 23380, cost 6.8193\n",
      "step 23380, change in cost 0.00104475\n",
      "step 23390, training accuracy 0.963415\n",
      "step 23390, cost 6.81825\n",
      "step 23390, change in cost 0.00104618\n",
      "step 23400, training accuracy 0.963415\n",
      "step 23400, cost 6.81721\n",
      "step 23400, change in cost 0.00103855\n",
      "step 23410, training accuracy 0.963415\n",
      "step 23410, cost 6.81618\n",
      "step 23410, change in cost 0.00103712\n",
      "step 23420, training accuracy 0.963415\n",
      "step 23420, cost 6.81514\n",
      "step 23420, change in cost 0.00103474\n",
      "step 23430, training accuracy 0.963415\n",
      "step 23430, cost 6.81411\n",
      "step 23430, change in cost 0.00103045\n",
      "step 23440, training accuracy 0.963415\n",
      "step 23440, cost 6.81308\n",
      "step 23440, change in cost 0.00102663\n",
      "step 23450, training accuracy 0.963415\n",
      "step 23450, cost 6.81206\n",
      "step 23450, change in cost 0.00102329\n",
      "step 23460, training accuracy 0.963415\n",
      "step 23460, cost 6.81104\n",
      "step 23460, change in cost 0.00102043\n",
      "step 23470, training accuracy 0.963415\n",
      "step 23470, cost 6.81002\n",
      "step 23470, change in cost 0.00101662\n",
      "step 23480, training accuracy 0.963415\n",
      "step 23480, cost 6.80901\n",
      "step 23480, change in cost 0.0010128\n",
      "step 23490, training accuracy 0.963415\n",
      "step 23490, cost 6.808\n",
      "step 23490, change in cost 0.00101137\n",
      "step 23500, training accuracy 0.963415\n",
      "step 23500, cost 6.80699\n",
      "step 23500, change in cost 0.00100756\n",
      "step 23510, training accuracy 0.963415\n",
      "step 23510, cost 6.80599\n",
      "step 23510, change in cost 0.00100279\n",
      "step 23520, training accuracy 0.963415\n",
      "step 23520, cost 6.80499\n",
      "step 23520, change in cost 0.00100088\n",
      "step 23530, training accuracy 0.963415\n",
      "step 23530, cost 6.80399\n",
      "step 23530, change in cost 0.000994682\n",
      "step 23540, training accuracy 0.963415\n",
      "step 23540, cost 6.803\n",
      "step 23540, change in cost 0.000993729\n",
      "step 23550, training accuracy 0.963415\n",
      "step 23550, cost 6.80201\n",
      "step 23550, change in cost 0.000991821\n",
      "step 23560, training accuracy 0.963415\n",
      "step 23560, cost 6.80102\n",
      "step 23560, change in cost 0.000988007\n",
      "step 23570, training accuracy 0.963415\n",
      "step 23570, cost 6.80003\n",
      "step 23570, change in cost 0.000986099\n",
      "step 23580, training accuracy 0.963415\n",
      "step 23580, cost 6.79905\n",
      "step 23580, change in cost 0.0009799\n",
      "step 23590, training accuracy 0.963415\n",
      "step 23590, cost 6.79808\n",
      "step 23590, change in cost 0.000978947\n",
      "step 23600, training accuracy 0.963415\n",
      "step 23600, cost 6.7971\n",
      "step 23600, change in cost 0.000975132\n",
      "step 23610, training accuracy 0.963415\n",
      "step 23610, cost 6.79613\n",
      "step 23610, change in cost 0.000972748\n",
      "step 23620, training accuracy 0.963415\n",
      "step 23620, cost 6.79516\n",
      "step 23620, change in cost 0.00096941\n",
      "step 23630, training accuracy 0.963415\n",
      "step 23630, cost 6.79419\n",
      "step 23630, change in cost 0.000967026\n",
      "step 23640, training accuracy 0.963415\n",
      "step 23640, cost 6.79323\n",
      "step 23640, change in cost 0.000963211\n",
      "step 23650, training accuracy 0.963415\n",
      "step 23650, cost 6.79227\n",
      "step 23650, change in cost 0.000961304\n",
      "step 23660, training accuracy 0.963415\n",
      "step 23660, cost 6.79131\n",
      "step 23660, change in cost 0.00095892\n",
      "step 23670, training accuracy 0.963415\n",
      "step 23670, cost 6.79035\n",
      "step 23670, change in cost 0.000954628\n",
      "step 23680, training accuracy 0.963415\n",
      "step 23680, cost 6.7894\n",
      "step 23680, change in cost 0.000952244\n",
      "step 23690, training accuracy 0.963415\n",
      "step 23690, cost 6.78845\n",
      "step 23690, change in cost 0.000947952\n",
      "step 23700, training accuracy 0.963415\n",
      "step 23700, cost 6.78751\n",
      "step 23700, change in cost 0.000947952\n",
      "step 23710, training accuracy 0.963415\n",
      "step 23710, cost 6.78656\n",
      "step 23710, change in cost 0.000943661\n",
      "step 23720, training accuracy 0.963415\n",
      "step 23720, cost 6.78562\n",
      "step 23720, change in cost 0.000941753\n",
      "step 23730, training accuracy 0.963415\n",
      "step 23730, cost 6.78468\n",
      "step 23730, change in cost 0.000938416\n",
      "step 23740, training accuracy 0.963415\n",
      "step 23740, cost 6.78374\n",
      "step 23740, change in cost 0.000936508\n",
      "step 23750, training accuracy 0.963415\n",
      "step 23750, cost 6.78281\n",
      "step 23750, change in cost 0.00093174\n",
      "step 23760, training accuracy 0.963415\n",
      "step 23760, cost 6.78188\n",
      "step 23760, change in cost 0.000930309\n",
      "step 23770, training accuracy 0.963415\n",
      "step 23770, cost 6.78095\n",
      "step 23770, change in cost 0.000928402\n",
      "step 23780, training accuracy 0.963415\n",
      "step 23780, cost 6.78003\n",
      "step 23780, change in cost 0.000926495\n",
      "step 23790, training accuracy 0.963415\n",
      "step 23790, cost 6.77911\n",
      "step 23790, change in cost 0.000921249\n",
      "step 23800, training accuracy 0.963415\n",
      "step 23800, cost 6.77819\n",
      "step 23800, change in cost 0.000919819\n",
      "step 23810, training accuracy 0.963415\n",
      "step 23810, cost 6.77727\n",
      "step 23810, change in cost 0.000916481\n",
      "step 23820, training accuracy 0.963415\n",
      "step 23820, cost 6.77635\n",
      "step 23820, change in cost 0.000915527\n",
      "step 23830, training accuracy 0.963415\n",
      "step 23830, cost 6.77544\n",
      "step 23830, change in cost 0.000911713\n",
      "step 23840, training accuracy 0.963415\n",
      "step 23840, cost 6.77453\n",
      "step 23840, change in cost 0.000910282\n",
      "step 23850, training accuracy 0.963415\n",
      "step 23850, cost 6.77363\n",
      "step 23850, change in cost 0.000906944\n",
      "step 23860, training accuracy 0.963415\n",
      "step 23860, cost 6.77272\n",
      "step 23860, change in cost 0.000906467\n",
      "step 23870, training accuracy 0.963415\n",
      "step 23870, cost 6.77182\n",
      "step 23870, change in cost 0.000902176\n",
      "step 23880, training accuracy 0.963415\n",
      "step 23880, cost 6.77092\n",
      "step 23880, change in cost 0.000901222\n",
      "step 23890, training accuracy 0.963415\n",
      "step 23890, cost 6.77002\n",
      "step 23890, change in cost 0.000896454\n",
      "step 23900, training accuracy 0.963415\n",
      "step 23900, cost 6.76912\n",
      "step 23900, change in cost 0.000895977\n",
      "step 23910, training accuracy 0.963415\n",
      "step 23910, cost 6.76823\n",
      "step 23910, change in cost 0.000892639\n",
      "step 23920, training accuracy 0.963415\n",
      "step 23920, cost 6.76734\n",
      "step 23920, change in cost 0.000888348\n",
      "step 23930, training accuracy 0.963415\n",
      "step 23930, cost 6.76645\n",
      "step 23930, change in cost 0.000889301\n",
      "step 23940, training accuracy 0.963415\n",
      "step 23940, cost 6.76557\n",
      "step 23940, change in cost 0.000885487\n",
      "step 23950, training accuracy 0.963415\n",
      "step 23950, cost 6.76468\n",
      "step 23950, change in cost 0.000883102\n",
      "step 23960, training accuracy 0.963415\n",
      "step 23960, cost 6.7638\n",
      "step 23960, change in cost 0.000881195\n",
      "step 23970, training accuracy 0.963415\n",
      "step 23970, cost 6.76292\n",
      "step 23970, change in cost 0.000880241\n",
      "step 23980, training accuracy 0.963415\n",
      "step 23980, cost 6.76205\n",
      "step 23980, change in cost 0.000876904\n",
      "step 23990, training accuracy 0.963415\n",
      "step 23990, cost 6.76117\n",
      "step 23990, change in cost 0.000874043\n",
      "step 24000, training accuracy 0.963415\n",
      "step 24000, cost 6.7603\n",
      "step 24000, change in cost 0.000871658\n",
      "step 24010, training accuracy 0.963415\n",
      "step 24010, cost 6.75943\n",
      "step 24010, change in cost 0.000871658\n",
      "step 24020, training accuracy 0.963415\n",
      "step 24020, cost 6.75856\n",
      "step 24020, change in cost 0.000867844\n",
      "step 24030, training accuracy 0.963415\n",
      "step 24030, cost 6.7577\n",
      "step 24030, change in cost 0.000865936\n",
      "step 24040, training accuracy 0.963415\n",
      "step 24040, cost 6.75683\n",
      "step 24040, change in cost 0.000863552\n",
      "step 24050, training accuracy 0.963415\n",
      "step 24050, cost 6.75597\n",
      "step 24050, change in cost 0.000862122\n",
      "step 24060, training accuracy 0.963415\n",
      "step 24060, cost 6.75511\n",
      "step 24060, change in cost 0.000857353\n",
      "step 24070, training accuracy 0.963415\n",
      "step 24070, cost 6.75425\n",
      "step 24070, change in cost 0.000857353\n",
      "step 24080, training accuracy 0.963415\n",
      "step 24080, cost 6.7534\n",
      "step 24080, change in cost 0.000854015\n",
      "step 24090, training accuracy 0.963415\n",
      "step 24090, cost 6.75255\n",
      "step 24090, change in cost 0.000854492\n",
      "step 24100, training accuracy 0.963415\n",
      "step 24100, cost 6.7517\n",
      "step 24100, change in cost 0.000850677\n",
      "step 24110, training accuracy 0.963415\n",
      "step 24110, cost 6.75084\n",
      "step 24110, change in cost 0.000850677\n",
      "step 24120, training accuracy 0.963415\n",
      "step 24120, cost 6.75\n",
      "step 24120, change in cost 0.000844955\n",
      "step 24130, training accuracy 0.963415\n",
      "step 24130, cost 6.74916\n",
      "step 24130, change in cost 0.000842094\n",
      "step 24140, training accuracy 0.963415\n",
      "step 24140, cost 6.74831\n",
      "step 24140, change in cost 0.000844955\n",
      "step 24150, training accuracy 0.963415\n",
      "step 24150, cost 6.74747\n",
      "step 24150, change in cost 0.000840664\n",
      "step 24160, training accuracy 0.963415\n",
      "step 24160, cost 6.74664\n",
      "step 24160, change in cost 0.000836849\n",
      "step 24170, training accuracy 0.963415\n",
      "step 24170, cost 6.7458\n",
      "step 24170, change in cost 0.000837803\n",
      "step 24180, training accuracy 0.963415\n",
      "step 24180, cost 6.74496\n",
      "step 24180, change in cost 0.000835419\n",
      "step 24190, training accuracy 0.963415\n",
      "step 24190, cost 6.74413\n",
      "step 24190, change in cost 0.000833511\n",
      "step 24200, training accuracy 0.963415\n",
      "step 24200, cost 6.7433\n",
      "step 24200, change in cost 0.000831127\n",
      "step 24210, training accuracy 0.963415\n",
      "step 24210, cost 6.74247\n",
      "step 24210, change in cost 0.000827789\n",
      "step 24220, training accuracy 0.963415\n",
      "step 24220, cost 6.74164\n",
      "step 24220, change in cost 0.000827789\n",
      "step 24230, training accuracy 0.963415\n",
      "step 24230, cost 6.74082\n",
      "step 24230, change in cost 0.000824928\n",
      "step 24240, training accuracy 0.963415\n",
      "step 24240, cost 6.73999\n",
      "step 24240, change in cost 0.000823498\n",
      "step 24250, training accuracy 0.963415\n",
      "step 24250, cost 6.73917\n",
      "step 24250, change in cost 0.000821114\n",
      "step 24260, training accuracy 0.963415\n",
      "step 24260, cost 6.73836\n",
      "step 24260, change in cost 0.000817299\n",
      "step 24270, training accuracy 0.963415\n",
      "step 24270, cost 6.73754\n",
      "step 24270, change in cost 0.000818729\n",
      "step 24280, training accuracy 0.963415\n",
      "step 24280, cost 6.73672\n",
      "step 24280, change in cost 0.000815392\n",
      "step 24290, training accuracy 0.963415\n",
      "step 24290, cost 6.73591\n",
      "step 24290, change in cost 0.000815868\n",
      "step 24300, training accuracy 0.963415\n",
      "step 24300, cost 6.73509\n",
      "step 24300, change in cost 0.000813007\n",
      "step 24310, training accuracy 0.963415\n",
      "step 24310, cost 6.73428\n",
      "step 24310, change in cost 0.000809669\n",
      "step 24320, training accuracy 0.963415\n",
      "step 24320, cost 6.73347\n",
      "step 24320, change in cost 0.000808239\n",
      "step 24330, training accuracy 0.963415\n",
      "step 24330, cost 6.73267\n",
      "step 24330, change in cost 0.000805855\n",
      "step 24340, training accuracy 0.963415\n",
      "step 24340, cost 6.73186\n",
      "step 24340, change in cost 0.000806332\n",
      "step 24350, training accuracy 0.963415\n",
      "step 24350, cost 6.73106\n",
      "step 24350, change in cost 0.000804901\n",
      "step 24360, training accuracy 0.963415\n",
      "step 24360, cost 6.73026\n",
      "step 24360, change in cost 0.000801086\n",
      "step 24370, training accuracy 0.963415\n",
      "step 24370, cost 6.72946\n",
      "step 24370, change in cost 0.000797272\n",
      "step 24380, training accuracy 0.963415\n",
      "step 24380, cost 6.72866\n",
      "step 24380, change in cost 0.000799656\n",
      "step 24390, training accuracy 0.963415\n",
      "step 24390, cost 6.72786\n",
      "step 24390, change in cost 0.000795841\n",
      "step 24400, training accuracy 0.963415\n",
      "step 24400, cost 6.72707\n",
      "step 24400, change in cost 0.000793934\n",
      "step 24410, training accuracy 0.963415\n",
      "step 24410, cost 6.72628\n",
      "step 24410, change in cost 0.000793934\n",
      "step 24420, training accuracy 0.963415\n",
      "step 24420, cost 6.72548\n",
      "step 24420, change in cost 0.000791073\n",
      "step 24430, training accuracy 0.963415\n",
      "step 24430, cost 6.72469\n",
      "step 24430, change in cost 0.000790596\n",
      "step 24440, training accuracy 0.963415\n",
      "step 24440, cost 6.72391\n",
      "step 24440, change in cost 0.000787258\n",
      "step 24450, training accuracy 0.963415\n",
      "step 24450, cost 6.72312\n",
      "step 24450, change in cost 0.000786781\n",
      "step 24460, training accuracy 0.963415\n",
      "step 24460, cost 6.72233\n",
      "step 24460, change in cost 0.000784874\n",
      "step 24470, training accuracy 0.963415\n",
      "step 24470, cost 6.72155\n",
      "step 24470, change in cost 0.000780582\n",
      "step 24480, training accuracy 0.963415\n",
      "step 24480, cost 6.72077\n",
      "step 24480, change in cost 0.000780582\n",
      "step 24490, training accuracy 0.963415\n",
      "step 24490, cost 6.71999\n",
      "step 24490, change in cost 0.000782967\n",
      "step 24500, training accuracy 0.963415\n",
      "step 24500, cost 6.71921\n",
      "step 24500, change in cost 0.000778198\n",
      "step 24510, training accuracy 0.963415\n",
      "step 24510, cost 6.71844\n",
      "step 24510, change in cost 0.000775337\n",
      "step 24520, training accuracy 0.963415\n",
      "step 24520, cost 6.71766\n",
      "step 24520, change in cost 0.000775337\n",
      "step 24530, training accuracy 0.963415\n",
      "step 24530, cost 6.71689\n",
      "step 24530, change in cost 0.000773907\n",
      "step 24540, training accuracy 0.963415\n",
      "step 24540, cost 6.71612\n",
      "step 24540, change in cost 0.000771523\n",
      "step 24550, training accuracy 0.963415\n",
      "step 24550, cost 6.71535\n",
      "step 24550, change in cost 0.000770092\n",
      "step 24560, training accuracy 0.963415\n",
      "step 24560, cost 6.71458\n",
      "step 24560, change in cost 0.000769615\n",
      "step 24570, training accuracy 0.963415\n",
      "step 24570, cost 6.71381\n",
      "step 24570, change in cost 0.000768185\n",
      "step 24580, training accuracy 0.963415\n",
      "step 24580, cost 6.71305\n",
      "step 24580, change in cost 0.000762939\n",
      "step 24590, training accuracy 0.963415\n",
      "step 24590, cost 6.71228\n",
      "step 24590, change in cost 0.000766754\n",
      "step 24600, training accuracy 0.963415\n",
      "step 24600, cost 6.71152\n",
      "step 24600, change in cost 0.000762463\n",
      "step 24610, training accuracy 0.963415\n",
      "step 24610, cost 6.71076\n",
      "step 24610, change in cost 0.000761032\n",
      "step 24620, training accuracy 0.963415\n",
      "step 24620, cost 6.71\n",
      "step 24620, change in cost 0.000759125\n",
      "step 24630, training accuracy 0.963415\n",
      "step 24630, cost 6.70924\n",
      "step 24630, change in cost 0.000758171\n",
      "step 24640, training accuracy 0.963415\n",
      "step 24640, cost 6.70848\n",
      "step 24640, change in cost 0.000758171\n",
      "step 24650, training accuracy 0.963415\n",
      "step 24650, cost 6.70772\n",
      "step 24650, change in cost 0.000756264\n",
      "step 24660, training accuracy 0.963415\n",
      "step 24660, cost 6.70697\n",
      "step 24660, change in cost 0.000750542\n",
      "step 24670, training accuracy 0.963415\n",
      "step 24670, cost 6.70622\n",
      "step 24670, change in cost 0.000755787\n",
      "step 24680, training accuracy 0.963415\n",
      "step 24680, cost 6.70547\n",
      "step 24680, change in cost 0.000748634\n",
      "step 24690, training accuracy 0.963415\n",
      "step 24690, cost 6.70472\n",
      "step 24690, change in cost 0.000752449\n",
      "step 24700, training accuracy 0.963415\n",
      "step 24700, cost 6.70397\n",
      "step 24700, change in cost 0.000748158\n",
      "step 24710, training accuracy 0.963415\n",
      "step 24710, cost 6.70322\n",
      "step 24710, change in cost 0.000743866\n",
      "step 24720, training accuracy 0.963415\n",
      "step 24720, cost 6.70248\n",
      "step 24720, change in cost 0.000745773\n",
      "step 24730, training accuracy 0.963415\n",
      "step 24730, cost 6.70173\n",
      "step 24730, change in cost 0.000743866\n",
      "step 24740, training accuracy 0.963415\n",
      "step 24740, cost 6.70099\n",
      "step 24740, change in cost 0.000743866\n",
      "step 24750, training accuracy 0.963415\n",
      "step 24750, cost 6.70025\n",
      "step 24750, change in cost 0.000741482\n",
      "step 24760, training accuracy 0.963415\n",
      "step 24760, cost 6.69951\n",
      "step 24760, change in cost 0.000738621\n",
      "step 24770, training accuracy 0.963415\n",
      "step 24770, cost 6.69877\n",
      "step 24770, change in cost 0.000738144\n",
      "step 24780, training accuracy 0.963415\n",
      "step 24780, cost 6.69803\n",
      "step 24780, change in cost 0.000738621\n",
      "step 24790, training accuracy 0.963415\n",
      "step 24790, cost 6.6973\n",
      "step 24790, change in cost 0.000734806\n",
      "step 24800, training accuracy 0.963415\n",
      "step 24800, cost 6.69656\n",
      "step 24800, change in cost 0.000734329\n",
      "step 24810, training accuracy 0.963415\n",
      "step 24810, cost 6.69583\n",
      "step 24810, change in cost 0.000733852\n",
      "step 24820, training accuracy 0.963415\n",
      "step 24820, cost 6.6951\n",
      "step 24820, change in cost 0.000730991\n",
      "step 24830, training accuracy 0.963415\n",
      "step 24830, cost 6.69437\n",
      "step 24830, change in cost 0.000730038\n",
      "step 24840, training accuracy 0.963415\n",
      "step 24840, cost 6.69364\n",
      "step 24840, change in cost 0.000729561\n",
      "step 24850, training accuracy 0.963415\n",
      "step 24850, cost 6.69291\n",
      "step 24850, change in cost 0.000727654\n",
      "step 24860, training accuracy 0.963415\n",
      "step 24860, cost 6.69219\n",
      "step 24860, change in cost 0.000725746\n",
      "step 24870, training accuracy 0.963415\n",
      "step 24870, cost 6.69146\n",
      "step 24870, change in cost 0.000727177\n",
      "step 24880, training accuracy 0.963415\n",
      "step 24880, cost 6.69074\n",
      "step 24880, change in cost 0.000722885\n",
      "step 24890, training accuracy 0.963415\n",
      "step 24890, cost 6.69002\n",
      "step 24890, change in cost 0.000720501\n",
      "step 24900, training accuracy 0.963415\n",
      "step 24900, cost 6.68929\n",
      "step 24900, change in cost 0.000723362\n",
      "step 24910, training accuracy 0.963415\n",
      "step 24910, cost 6.68857\n",
      "step 24910, change in cost 0.000719547\n",
      "step 24920, training accuracy 0.963415\n",
      "step 24920, cost 6.68786\n",
      "step 24920, change in cost 0.000717163\n",
      "step 24930, training accuracy 0.963415\n",
      "step 24930, cost 6.68714\n",
      "step 24930, change in cost 0.000718117\n",
      "step 24940, training accuracy 0.963415\n",
      "step 24940, cost 6.68642\n",
      "step 24940, change in cost 0.000715733\n",
      "step 24950, training accuracy 0.963415\n",
      "step 24950, cost 6.68571\n",
      "step 24950, change in cost 0.000715733\n",
      "step 24960, training accuracy 0.963415\n",
      "step 24960, cost 6.68499\n",
      "step 24960, change in cost 0.000715733\n",
      "step 24970, training accuracy 0.963415\n",
      "step 24970, cost 6.68428\n",
      "step 24970, change in cost 0.000712872\n",
      "step 24980, training accuracy 0.963415\n",
      "step 24980, cost 6.68357\n",
      "step 24980, change in cost 0.000708103\n",
      "step 24990, training accuracy 0.963415\n",
      "step 24990, cost 6.68286\n",
      "step 24990, change in cost 0.000712395\n",
      "step 25000, training accuracy 0.963415\n",
      "step 25000, cost 6.68215\n",
      "step 25000, change in cost 0.000709057\n",
      "step 25010, training accuracy 0.963415\n",
      "step 25010, cost 6.68144\n",
      "step 25010, change in cost 0.000710011\n",
      "step 25020, training accuracy 0.963415\n",
      "step 25020, cost 6.68073\n",
      "step 25020, change in cost 0.000704765\n",
      "step 25030, training accuracy 0.963415\n",
      "step 25030, cost 6.68003\n",
      "step 25030, change in cost 0.00070715\n",
      "step 25040, training accuracy 0.963415\n",
      "step 25040, cost 6.67932\n",
      "step 25040, change in cost 0.000703335\n",
      "step 25050, training accuracy 0.963415\n",
      "step 25050, cost 6.67862\n",
      "step 25050, change in cost 0.000703812\n",
      "step 25060, training accuracy 0.963415\n",
      "step 25060, cost 6.67792\n",
      "step 25060, change in cost 0.000701904\n",
      "step 25070, training accuracy 0.963415\n",
      "step 25070, cost 6.67722\n",
      "step 25070, change in cost 0.000700951\n",
      "step 25080, training accuracy 0.963415\n",
      "step 25080, cost 6.67652\n",
      "step 25080, change in cost 0.000699043\n",
      "step 25090, training accuracy 0.963415\n",
      "step 25090, cost 6.67582\n",
      "step 25090, change in cost 0.000699043\n",
      "step 25100, training accuracy 0.963415\n",
      "step 25100, cost 6.67512\n",
      "step 25100, change in cost 0.000697613\n",
      "step 25110, training accuracy 0.963415\n",
      "step 25110, cost 6.67443\n",
      "step 25110, change in cost 0.000694275\n",
      "step 25120, training accuracy 0.963415\n",
      "step 25120, cost 6.67373\n",
      "step 25120, change in cost 0.000696659\n",
      "step 25130, training accuracy 0.963415\n",
      "step 25130, cost 6.67304\n",
      "step 25130, change in cost 0.000692368\n",
      "step 25140, training accuracy 0.963415\n",
      "step 25140, cost 6.67234\n",
      "step 25140, change in cost 0.000694752\n",
      "step 25150, training accuracy 0.963415\n",
      "step 25150, cost 6.67165\n",
      "step 25150, change in cost 0.000690937\n",
      "step 25160, training accuracy 0.963415\n",
      "step 25160, cost 6.67096\n",
      "step 25160, change in cost 0.000690937\n",
      "step 25170, training accuracy 0.963415\n",
      "step 25170, cost 6.67027\n",
      "step 25170, change in cost 0.000688076\n",
      "step 25180, training accuracy 0.963415\n",
      "step 25180, cost 6.66958\n",
      "step 25180, change in cost 0.00069046\n",
      "step 25190, training accuracy 0.963415\n",
      "step 25190, cost 6.6689\n",
      "step 25190, change in cost 0.000686646\n",
      "step 25200, training accuracy 0.963415\n",
      "step 25200, cost 6.66821\n",
      "step 25200, change in cost 0.000684738\n",
      "step 25210, training accuracy 0.963415\n",
      "step 25210, cost 6.66752\n",
      "step 25210, change in cost 0.000686169\n",
      "step 25220, training accuracy 0.963415\n",
      "step 25220, cost 6.66684\n",
      "step 25220, change in cost 0.000683308\n",
      "step 25230, training accuracy 0.963415\n",
      "step 25230, cost 6.66616\n",
      "step 25230, change in cost 0.000682354\n",
      "step 25240, training accuracy 0.963415\n",
      "step 25240, cost 6.66548\n",
      "step 25240, change in cost 0.000681877\n",
      "step 25250, training accuracy 0.963415\n",
      "step 25250, cost 6.66479\n",
      "step 25250, change in cost 0.000683308\n",
      "step 25260, training accuracy 0.963415\n",
      "step 25260, cost 6.66412\n",
      "step 25260, change in cost 0.000678539\n",
      "step 25270, training accuracy 0.963415\n",
      "step 25270, cost 6.66344\n",
      "step 25270, change in cost 0.000679016\n",
      "step 25280, training accuracy 0.963415\n",
      "step 25280, cost 6.66276\n",
      "step 25280, change in cost 0.000677586\n",
      "step 25290, training accuracy 0.963415\n",
      "step 25290, cost 6.66208\n",
      "step 25290, change in cost 0.000676632\n",
      "step 25300, training accuracy 0.963415\n",
      "step 25300, cost 6.6614\n",
      "step 25300, change in cost 0.000677586\n",
      "step 25310, training accuracy 0.963415\n",
      "step 25310, cost 6.66073\n",
      "step 25310, change in cost 0.000673294\n",
      "step 25320, training accuracy 0.963415\n",
      "step 25320, cost 6.66006\n",
      "step 25320, change in cost 0.000674248\n",
      "step 25330, training accuracy 0.963415\n",
      "step 25330, cost 6.65938\n",
      "step 25330, change in cost 0.000672817\n",
      "step 25340, training accuracy 0.963415\n",
      "step 25340, cost 6.65871\n",
      "step 25340, change in cost 0.000669479\n",
      "step 25350, training accuracy 0.963415\n",
      "step 25350, cost 6.65804\n",
      "step 25350, change in cost 0.000671387\n",
      "step 25360, training accuracy 0.963415\n",
      "step 25360, cost 6.65737\n",
      "step 25360, change in cost 0.000669956\n",
      "step 25370, training accuracy 0.963415\n",
      "step 25370, cost 6.65671\n",
      "step 25370, change in cost 0.000668049\n",
      "step 25380, training accuracy 0.963415\n",
      "step 25380, cost 6.65604\n",
      "step 25380, change in cost 0.000667095\n",
      "step 25390, training accuracy 0.963415\n",
      "step 25390, cost 6.65537\n",
      "step 25390, change in cost 0.000665665\n",
      "step 25400, training accuracy 0.963415\n",
      "step 25400, cost 6.65471\n",
      "step 25400, change in cost 0.000666618\n",
      "step 25410, training accuracy 0.963415\n",
      "step 25410, cost 6.65404\n",
      "step 25410, change in cost 0.000663757\n",
      "step 25420, training accuracy 0.963415\n",
      "step 25420, cost 6.65338\n",
      "step 25420, change in cost 0.000662804\n",
      "step 25430, training accuracy 0.963415\n",
      "step 25430, cost 6.65271\n",
      "step 25430, change in cost 0.000664711\n",
      "step 25440, training accuracy 0.963415\n",
      "step 25440, cost 6.65206\n",
      "step 25440, change in cost 0.000658989\n",
      "step 25450, training accuracy 0.963415\n",
      "step 25450, cost 6.65139\n",
      "step 25450, change in cost 0.000660896\n",
      "step 25460, training accuracy 0.963415\n",
      "step 25460, cost 6.65073\n",
      "step 25460, change in cost 0.000662327\n",
      "step 25470, training accuracy 0.963415\n",
      "step 25470, cost 6.65008\n",
      "step 25470, change in cost 0.000657082\n",
      "step 25480, training accuracy 0.963415\n",
      "step 25480, cost 6.64942\n",
      "step 25480, change in cost 0.000657082\n",
      "step 25490, training accuracy 0.963415\n",
      "step 25490, cost 6.64876\n",
      "step 25490, change in cost 0.000656128\n",
      "step 25500, training accuracy 0.963415\n",
      "step 25500, cost 6.6481\n",
      "step 25500, change in cost 0.000657558\n",
      "step 25510, training accuracy 0.963415\n",
      "step 25510, cost 6.64745\n",
      "step 25510, change in cost 0.000654221\n",
      "step 25520, training accuracy 0.963415\n",
      "step 25520, cost 6.64679\n",
      "step 25520, change in cost 0.000656128\n",
      "step 25530, training accuracy 0.963415\n",
      "step 25530, cost 6.64614\n",
      "step 25530, change in cost 0.000651836\n",
      "step 25540, training accuracy 0.963415\n",
      "step 25540, cost 6.64549\n",
      "step 25540, change in cost 0.000653744\n",
      "step 25550, training accuracy 0.963415\n",
      "step 25550, cost 6.64484\n",
      "step 25550, change in cost 0.000650883\n",
      "step 25560, training accuracy 0.963415\n",
      "step 25560, cost 6.64419\n",
      "step 25560, change in cost 0.000649929\n",
      "step 25570, training accuracy 0.963415\n",
      "step 25570, cost 6.64354\n",
      "step 25570, change in cost 0.000650406\n",
      "step 25580, training accuracy 0.963415\n",
      "step 25580, cost 6.64289\n",
      "step 25580, change in cost 0.000646591\n",
      "step 25590, training accuracy 0.963415\n",
      "step 25590, cost 6.64224\n",
      "step 25590, change in cost 0.000647068\n",
      "step 25600, training accuracy 0.963415\n",
      "step 25600, cost 6.6416\n",
      "step 25600, change in cost 0.000648499\n",
      "step 25610, training accuracy 0.963415\n",
      "step 25610, cost 6.64095\n",
      "step 25610, change in cost 0.000646591\n",
      "step 25620, training accuracy 0.963415\n",
      "step 25620, cost 6.6403\n",
      "step 25620, change in cost 0.000645638\n",
      "step 25630, training accuracy 0.963415\n",
      "step 25630, cost 6.63966\n",
      "step 25630, change in cost 0.000642776\n",
      "step 25640, training accuracy 0.963415\n",
      "step 25640, cost 6.63902\n",
      "step 25640, change in cost 0.0006423\n",
      "step 25650, training accuracy 0.963415\n",
      "step 25650, cost 6.63837\n",
      "step 25650, change in cost 0.00064373\n",
      "step 25660, training accuracy 0.963415\n",
      "step 25660, cost 6.63773\n",
      "step 25660, change in cost 0.000640869\n",
      "step 25670, training accuracy 0.963415\n",
      "step 25670, cost 6.63709\n",
      "step 25670, change in cost 0.000639439\n",
      "step 25680, training accuracy 0.963415\n",
      "step 25680, cost 6.63645\n",
      "step 25680, change in cost 0.000640392\n",
      "step 25690, training accuracy 0.963415\n",
      "step 25690, cost 6.63581\n",
      "step 25690, change in cost 0.000638962\n",
      "step 25700, training accuracy 0.963415\n",
      "step 25700, cost 6.63518\n",
      "step 25700, change in cost 0.000637054\n",
      "step 25710, training accuracy 0.963415\n",
      "step 25710, cost 6.63454\n",
      "step 25710, change in cost 0.000637531\n",
      "step 25720, training accuracy 0.963415\n",
      "step 25720, cost 6.6339\n",
      "step 25720, change in cost 0.000636101\n",
      "step 25730, training accuracy 0.963415\n",
      "step 25730, cost 6.63327\n",
      "step 25730, change in cost 0.000636578\n",
      "step 25740, training accuracy 0.963415\n",
      "step 25740, cost 6.63263\n",
      "step 25740, change in cost 0.000635147\n",
      "step 25750, training accuracy 0.963415\n",
      "step 25750, cost 6.632\n",
      "step 25750, change in cost 0.000632286\n",
      "step 25760, training accuracy 0.963415\n",
      "step 25760, cost 6.63137\n",
      "step 25760, change in cost 0.000633717\n",
      "step 25770, training accuracy 0.963415\n",
      "step 25770, cost 6.63073\n",
      "step 25770, change in cost 0.000632763\n",
      "step 25780, training accuracy 0.963415\n",
      "step 25780, cost 6.6301\n",
      "step 25780, change in cost 0.000630379\n",
      "step 25790, training accuracy 0.963415\n",
      "step 25790, cost 6.62947\n",
      "step 25790, change in cost 0.000629425\n",
      "step 25800, training accuracy 0.963415\n",
      "step 25800, cost 6.62884\n",
      "step 25800, change in cost 0.000629425\n",
      "step 25810, training accuracy 0.963415\n",
      "step 25810, cost 6.62821\n",
      "step 25810, change in cost 0.000630379\n",
      "step 25820, training accuracy 0.963415\n",
      "step 25820, cost 6.62759\n",
      "step 25820, change in cost 0.000626564\n",
      "step 25830, training accuracy 0.963415\n",
      "step 25830, cost 6.62696\n",
      "step 25830, change in cost 0.000627041\n",
      "step 25840, training accuracy 0.963415\n",
      "step 25840, cost 6.62633\n",
      "step 25840, change in cost 0.000626087\n",
      "step 25850, training accuracy 0.963415\n",
      "step 25850, cost 6.62571\n",
      "step 25850, change in cost 0.00062561\n",
      "step 25860, training accuracy 0.963415\n",
      "step 25860, cost 6.62508\n",
      "step 25860, change in cost 0.000626087\n",
      "step 25870, training accuracy 0.963415\n",
      "step 25870, cost 6.62446\n",
      "step 25870, change in cost 0.000621319\n",
      "step 25880, training accuracy 0.963415\n",
      "step 25880, cost 6.62384\n",
      "step 25880, change in cost 0.000622749\n",
      "step 25890, training accuracy 0.963415\n",
      "step 25890, cost 6.62321\n",
      "step 25890, change in cost 0.000624657\n",
      "step 25900, training accuracy 0.963415\n",
      "step 25900, cost 6.62259\n",
      "step 25900, change in cost 0.000620365\n",
      "step 25910, training accuracy 0.963415\n",
      "step 25910, cost 6.62197\n",
      "step 25910, change in cost 0.000619888\n",
      "step 25920, training accuracy 0.963415\n",
      "step 25920, cost 6.62135\n",
      "step 25920, change in cost 0.000619411\n",
      "step 25930, training accuracy 0.963415\n",
      "step 25930, cost 6.62073\n",
      "step 25930, change in cost 0.000620842\n",
      "step 25940, training accuracy 0.963415\n",
      "step 25940, cost 6.62012\n",
      "step 25940, change in cost 0.000617504\n",
      "step 25950, training accuracy 0.963415\n",
      "step 25950, cost 6.6195\n",
      "step 25950, change in cost 0.000617981\n",
      "step 25960, training accuracy 0.963415\n",
      "step 25960, cost 6.61888\n",
      "step 25960, change in cost 0.000617504\n",
      "step 25970, training accuracy 0.963415\n",
      "step 25970, cost 6.61827\n",
      "step 25970, change in cost 0.00061512\n",
      "step 25980, training accuracy 0.963415\n",
      "step 25980, cost 6.61765\n",
      "step 25980, change in cost 0.000615597\n",
      "step 25990, training accuracy 0.963415\n",
      "step 25990, cost 6.61704\n",
      "step 25990, change in cost 0.000613689\n",
      "step 26000, training accuracy 0.963415\n",
      "step 26000, cost 6.61642\n",
      "step 26000, change in cost 0.000613213\n",
      "step 26010, training accuracy 0.963415\n",
      "step 26010, cost 6.61581\n",
      "step 26010, change in cost 0.000614166\n",
      "step 26020, training accuracy 0.963415\n",
      "step 26020, cost 6.6152\n",
      "step 26020, change in cost 0.000611305\n",
      "step 26030, training accuracy 0.963415\n",
      "step 26030, cost 6.61459\n",
      "step 26030, change in cost 0.000610352\n",
      "step 26040, training accuracy 0.963415\n",
      "step 26040, cost 6.61398\n",
      "step 26040, change in cost 0.000611305\n",
      "step 26050, training accuracy 0.963415\n",
      "step 26050, cost 6.61336\n",
      "step 26050, change in cost 0.000611305\n",
      "step 26060, training accuracy 0.963415\n",
      "step 26060, cost 6.61276\n",
      "step 26060, change in cost 0.000608444\n",
      "step 26070, training accuracy 0.963415\n",
      "step 26070, cost 6.61215\n",
      "step 26070, change in cost 0.000609398\n",
      "step 26080, training accuracy 0.963415\n",
      "step 26080, cost 6.61154\n",
      "step 26080, change in cost 0.000607491\n",
      "step 26090, training accuracy 0.963415\n",
      "step 26090, cost 6.61093\n",
      "step 26090, change in cost 0.000606537\n",
      "step 26100, training accuracy 0.963415\n",
      "step 26100, cost 6.61032\n",
      "step 26100, change in cost 0.000607967\n",
      "step 26110, training accuracy 0.963415\n",
      "step 26110, cost 6.60972\n",
      "step 26110, change in cost 0.00060463\n",
      "step 26120, training accuracy 0.963415\n",
      "step 26120, cost 6.60912\n",
      "step 26120, change in cost 0.00060463\n",
      "step 26130, training accuracy 0.963415\n",
      "step 26130, cost 6.60851\n",
      "step 26130, change in cost 0.000603199\n",
      "step 26140, training accuracy 0.963415\n",
      "step 26140, cost 6.60791\n",
      "step 26140, change in cost 0.000602722\n",
      "step 26150, training accuracy 0.963415\n",
      "step 26150, cost 6.60731\n",
      "step 26150, change in cost 0.000603199\n",
      "step 26160, training accuracy 0.963415\n",
      "step 26160, cost 6.60671\n",
      "step 26160, change in cost 0.000599861\n",
      "step 26170, training accuracy 0.963415\n",
      "step 26170, cost 6.6061\n",
      "step 26170, change in cost 0.000602245\n",
      "step 26180, training accuracy 0.963415\n",
      "step 26180, cost 6.6055\n",
      "step 26180, change in cost 0.000601292\n",
      "step 26190, training accuracy 0.963415\n",
      "step 26190, cost 6.6049\n",
      "step 26190, change in cost 0.000598431\n",
      "step 26200, training accuracy 0.963415\n",
      "step 26200, cost 6.6043\n",
      "step 26200, change in cost 0.000601768\n",
      "step 26210, training accuracy 0.963415\n",
      "step 26210, cost 6.6037\n",
      "step 26210, change in cost 0.000598431\n",
      "step 26220, training accuracy 0.963415\n",
      "step 26220, cost 6.60311\n",
      "step 26220, change in cost 0.000596523\n",
      "step 26230, training accuracy 0.963415\n",
      "step 26230, cost 6.60251\n",
      "step 26230, change in cost 0.000597477\n",
      "step 26240, training accuracy 0.963415\n",
      "step 26240, cost 6.60191\n",
      "step 26240, change in cost 0.000597477\n",
      "step 26250, training accuracy 0.963415\n",
      "step 26250, cost 6.60132\n",
      "step 26250, change in cost 0.000594616\n",
      "step 26260, training accuracy 0.963415\n",
      "step 26260, cost 6.60072\n",
      "step 26260, change in cost 0.000593662\n",
      "step 26270, training accuracy 0.963415\n",
      "step 26270, cost 6.60013\n",
      "step 26270, change in cost 0.000596046\n",
      "step 26280, training accuracy 0.963415\n",
      "step 26280, cost 6.59953\n",
      "step 26280, change in cost 0.000593185\n",
      "step 26290, training accuracy 0.963415\n",
      "step 26290, cost 6.59894\n",
      "step 26290, change in cost 0.000592232\n",
      "step 26300, training accuracy 0.963415\n",
      "step 26300, cost 6.59835\n",
      "step 26300, change in cost 0.000591278\n",
      "step 26310, training accuracy 0.963415\n",
      "step 26310, cost 6.59776\n",
      "step 26310, change in cost 0.000594139\n",
      "step 26320, training accuracy 0.963415\n",
      "step 26320, cost 6.59717\n",
      "step 26320, change in cost 0.000589848\n",
      "step 26330, training accuracy 0.963415\n",
      "step 26330, cost 6.59658\n",
      "step 26330, change in cost 0.000590801\n",
      "step 26340, training accuracy 0.963415\n",
      "step 26340, cost 6.59599\n",
      "step 26340, change in cost 0.000590324\n",
      "step 26350, training accuracy 0.963415\n",
      "step 26350, cost 6.5954\n",
      "step 26350, change in cost 0.000587463\n",
      "step 26360, training accuracy 0.963415\n",
      "step 26360, cost 6.59481\n",
      "step 26360, change in cost 0.000589371\n",
      "step 26370, training accuracy 0.963415\n",
      "step 26370, cost 6.59422\n",
      "step 26370, change in cost 0.000586033\n",
      "step 26380, training accuracy 0.963415\n",
      "step 26380, cost 6.59364\n",
      "step 26380, change in cost 0.00058794\n",
      "step 26390, training accuracy 0.963415\n",
      "step 26390, cost 6.59305\n",
      "step 26390, change in cost 0.000585556\n",
      "step 26400, training accuracy 0.963415\n",
      "step 26400, cost 6.59246\n",
      "step 26400, change in cost 0.000585079\n",
      "step 26410, training accuracy 0.963415\n",
      "step 26410, cost 6.59188\n",
      "step 26410, change in cost 0.000585079\n",
      "step 26420, training accuracy 0.963415\n",
      "step 26420, cost 6.5913\n",
      "step 26420, change in cost 0.000583649\n",
      "step 26430, training accuracy 0.963415\n",
      "step 26430, cost 6.59071\n",
      "step 26430, change in cost 0.000583172\n",
      "step 26440, training accuracy 0.963415\n",
      "step 26440, cost 6.59013\n",
      "step 26440, change in cost 0.000583172\n",
      "step 26450, training accuracy 0.963415\n",
      "step 26450, cost 6.58955\n",
      "step 26450, change in cost 0.000581741\n",
      "step 26460, training accuracy 0.963415\n",
      "step 26460, cost 6.58897\n",
      "step 26460, change in cost 0.000582218\n",
      "step 26470, training accuracy 0.963415\n",
      "step 26470, cost 6.58838\n",
      "step 26470, change in cost 0.000581741\n",
      "step 26480, training accuracy 0.963415\n",
      "step 26480, cost 6.5878\n",
      "step 26480, change in cost 0.000580311\n",
      "step 26490, training accuracy 0.963415\n",
      "step 26490, cost 6.58722\n",
      "step 26490, change in cost 0.000579357\n",
      "step 26500, training accuracy 0.963415\n",
      "step 26500, cost 6.58665\n",
      "step 26500, change in cost 0.000579357\n",
      "step 26510, training accuracy 0.963415\n",
      "step 26510, cost 6.58607\n",
      "step 26510, change in cost 0.000579834\n",
      "step 26520, training accuracy 0.963415\n",
      "step 26520, cost 6.58549\n",
      "step 26520, change in cost 0.000575066\n",
      "step 26530, training accuracy 0.963415\n",
      "step 26530, cost 6.58491\n",
      "step 26530, change in cost 0.000577927\n",
      "step 26540, training accuracy 0.963415\n",
      "step 26540, cost 6.58434\n",
      "step 26540, change in cost 0.000576973\n",
      "step 26550, training accuracy 0.963415\n",
      "step 26550, cost 6.58376\n",
      "step 26550, change in cost 0.000576019\n",
      "step 26560, training accuracy 0.963415\n",
      "step 26560, cost 6.58318\n",
      "step 26560, change in cost 0.000575066\n",
      "step 26570, training accuracy 0.963415\n",
      "step 26570, cost 6.58261\n",
      "step 26570, change in cost 0.000575066\n",
      "step 26580, training accuracy 0.963415\n",
      "step 26580, cost 6.58204\n",
      "step 26580, change in cost 0.000573635\n",
      "step 26590, training accuracy 0.963415\n",
      "step 26590, cost 6.58146\n",
      "step 26590, change in cost 0.000573635\n",
      "step 26600, training accuracy 0.963415\n",
      "step 26600, cost 6.58089\n",
      "step 26600, change in cost 0.000575066\n",
      "step 26610, training accuracy 0.963415\n",
      "step 26610, cost 6.58032\n",
      "step 26610, change in cost 0.000570774\n",
      "step 26620, training accuracy 0.963415\n",
      "step 26620, cost 6.57975\n",
      "step 26620, change in cost 0.000570297\n",
      "step 26630, training accuracy 0.963415\n",
      "step 26630, cost 6.57917\n",
      "step 26630, change in cost 0.000572681\n",
      "step 26640, training accuracy 0.963415\n",
      "step 26640, cost 6.5786\n",
      "step 26640, change in cost 0.000571251\n",
      "step 26650, training accuracy 0.963415\n",
      "step 26650, cost 6.57803\n",
      "step 26650, change in cost 0.000567913\n",
      "step 26660, training accuracy 0.963415\n",
      "step 26660, cost 6.57746\n",
      "step 26660, change in cost 0.00056982\n",
      "step 26670, training accuracy 0.963415\n",
      "step 26670, cost 6.57689\n",
      "step 26670, change in cost 0.000569344\n",
      "step 26680, training accuracy 0.963415\n",
      "step 26680, cost 6.57633\n",
      "step 26680, change in cost 0.000567436\n",
      "step 26690, training accuracy 0.963415\n",
      "step 26690, cost 6.57576\n",
      "step 26690, change in cost 0.000567436\n",
      "step 26700, training accuracy 0.963415\n",
      "step 26700, cost 6.57519\n",
      "step 26700, change in cost 0.000566483\n",
      "step 26710, training accuracy 0.963415\n",
      "step 26710, cost 6.57463\n",
      "step 26710, change in cost 0.000566483\n",
      "step 26720, training accuracy 0.963415\n",
      "step 26720, cost 6.57406\n",
      "step 26720, change in cost 0.000565052\n",
      "step 26730, training accuracy 0.963415\n",
      "step 26730, cost 6.5735\n",
      "step 26730, change in cost 0.000565052\n",
      "step 26740, training accuracy 0.963415\n",
      "step 26740, cost 6.57293\n",
      "step 26740, change in cost 0.000567436\n",
      "step 26750, training accuracy 0.963415\n",
      "step 26750, cost 6.57237\n",
      "step 26750, change in cost 0.000562668\n",
      "step 26760, training accuracy 0.963415\n",
      "step 26760, cost 6.5718\n",
      "step 26760, change in cost 0.000564575\n",
      "step 26770, training accuracy 0.963415\n",
      "step 26770, cost 6.57124\n",
      "step 26770, change in cost 0.000561714\n",
      "step 26780, training accuracy 0.963415\n",
      "step 26780, cost 6.57068\n",
      "step 26780, change in cost 0.000562668\n",
      "step 26790, training accuracy 0.963415\n",
      "step 26790, cost 6.57012\n",
      "step 26790, change in cost 0.000562668\n",
      "step 26800, training accuracy 0.963415\n",
      "step 26800, cost 6.56955\n",
      "step 26800, change in cost 0.000560284\n",
      "step 26810, training accuracy 0.963415\n",
      "step 26810, cost 6.56899\n",
      "step 26810, change in cost 0.000560284\n",
      "step 26820, training accuracy 0.963415\n",
      "step 26820, cost 6.56843\n",
      "step 26820, change in cost 0.00056076\n",
      "step 26830, training accuracy 0.963415\n",
      "step 26830, cost 6.56787\n",
      "step 26830, change in cost 0.000558853\n",
      "step 26840, training accuracy 0.963415\n",
      "step 26840, cost 6.56732\n",
      "step 26840, change in cost 0.000558376\n",
      "step 26850, training accuracy 0.963415\n",
      "step 26850, cost 6.56676\n",
      "step 26850, change in cost 0.00055933\n",
      "step 26860, training accuracy 0.963415\n",
      "step 26860, cost 6.5662\n",
      "step 26860, change in cost 0.000557423\n",
      "step 26870, training accuracy 0.963415\n",
      "step 26870, cost 6.56564\n",
      "step 26870, change in cost 0.000558376\n",
      "step 26880, training accuracy 0.963415\n",
      "step 26880, cost 6.56509\n",
      "step 26880, change in cost 0.000555992\n",
      "step 26890, training accuracy 0.963415\n",
      "step 26890, cost 6.56453\n",
      "step 26890, change in cost 0.000555992\n",
      "step 26900, training accuracy 0.963415\n",
      "step 26900, cost 6.56397\n",
      "step 26900, change in cost 0.000555992\n",
      "step 26910, training accuracy 0.963415\n",
      "step 26910, cost 6.56342\n",
      "step 26910, change in cost 0.000555992\n",
      "step 26920, training accuracy 0.963415\n",
      "step 26920, cost 6.56286\n",
      "step 26920, change in cost 0.000554562\n",
      "step 26930, training accuracy 0.963415\n",
      "step 26930, cost 6.56231\n",
      "step 26930, change in cost 0.000552654\n",
      "step 26940, training accuracy 0.963415\n",
      "step 26940, cost 6.56176\n",
      "step 26940, change in cost 0.000554085\n",
      "step 26950, training accuracy 0.963415\n",
      "step 26950, cost 6.5612\n",
      "step 26950, change in cost 0.000553608\n",
      "step 26960, training accuracy 0.963415\n",
      "step 26960, cost 6.56065\n",
      "step 26960, change in cost 0.000551701\n",
      "step 26970, training accuracy 0.963415\n",
      "step 26970, cost 6.5601\n",
      "step 26970, change in cost 0.000551224\n",
      "step 26980, training accuracy 0.963415\n",
      "step 26980, cost 6.55955\n",
      "step 26980, change in cost 0.000551224\n",
      "step 26990, training accuracy 0.963415\n",
      "step 26990, cost 6.559\n",
      "step 26990, change in cost 0.00055027\n",
      "step 27000, training accuracy 0.963415\n",
      "step 27000, cost 6.55845\n",
      "step 27000, change in cost 0.00055027\n",
      "step 27010, training accuracy 0.963415\n",
      "step 27010, cost 6.5579\n",
      "step 27010, change in cost 0.000549316\n",
      "step 27020, training accuracy 0.963415\n",
      "step 27020, cost 6.55735\n",
      "step 27020, change in cost 0.000549316\n",
      "step 27030, training accuracy 0.963415\n",
      "step 27030, cost 6.5568\n",
      "step 27030, change in cost 0.000548363\n",
      "step 27040, training accuracy 0.963415\n",
      "step 27040, cost 6.55625\n",
      "step 27040, change in cost 0.000547409\n",
      "step 27050, training accuracy 0.963415\n",
      "step 27050, cost 6.5557\n",
      "step 27050, change in cost 0.00054884\n",
      "step 27060, training accuracy 0.963415\n",
      "step 27060, cost 6.55516\n",
      "step 27060, change in cost 0.000546455\n",
      "step 27070, training accuracy 0.963415\n",
      "step 27070, cost 6.55461\n",
      "step 27070, change in cost 0.000545025\n",
      "step 27080, training accuracy 0.963415\n",
      "step 27080, cost 6.55407\n",
      "step 27080, change in cost 0.000547409\n",
      "step 27090, training accuracy 0.963415\n",
      "step 27090, cost 6.55352\n",
      "step 27090, change in cost 0.000543594\n",
      "step 27100, training accuracy 0.963415\n",
      "step 27100, cost 6.55298\n",
      "step 27100, change in cost 0.000545025\n",
      "step 27110, training accuracy 0.963415\n",
      "step 27110, cost 6.55243\n",
      "step 27110, change in cost 0.000543118\n",
      "step 27120, training accuracy 0.963415\n",
      "step 27120, cost 6.55189\n",
      "step 27120, change in cost 0.000545025\n",
      "step 27130, training accuracy 0.963415\n",
      "step 27130, cost 6.55135\n",
      "step 27130, change in cost 0.000542164\n",
      "step 27140, training accuracy 0.963415\n",
      "step 27140, cost 6.5508\n",
      "step 27140, change in cost 0.000542641\n",
      "step 27150, training accuracy 0.963415\n",
      "step 27150, cost 6.55026\n",
      "step 27150, change in cost 0.000542641\n",
      "step 27160, training accuracy 0.963415\n",
      "step 27160, cost 6.54972\n",
      "step 27160, change in cost 0.000542641\n",
      "step 27170, training accuracy 0.963415\n",
      "step 27170, cost 6.54918\n",
      "step 27170, change in cost 0.000540733\n",
      "step 27180, training accuracy 0.963415\n",
      "step 27180, cost 6.54864\n",
      "step 27180, change in cost 0.000541687\n",
      "step 27190, training accuracy 0.963415\n",
      "step 27190, cost 6.5481\n",
      "step 27190, change in cost 0.000537872\n",
      "step 27200, training accuracy 0.963415\n",
      "step 27200, cost 6.54756\n",
      "step 27200, change in cost 0.00053978\n",
      "step 27210, training accuracy 0.963415\n",
      "step 27210, cost 6.54702\n",
      "step 27210, change in cost 0.000539303\n",
      "step 27220, training accuracy 0.963415\n",
      "step 27220, cost 6.54648\n",
      "step 27220, change in cost 0.000538826\n",
      "step 27230, training accuracy 0.963415\n",
      "step 27230, cost 6.54594\n",
      "step 27230, change in cost 0.000538349\n",
      "step 27240, training accuracy 0.963415\n",
      "step 27240, cost 6.54541\n",
      "step 27240, change in cost 0.000536919\n",
      "step 27250, training accuracy 0.963415\n",
      "step 27250, cost 6.54487\n",
      "step 27250, change in cost 0.000537872\n",
      "step 27260, training accuracy 0.963415\n",
      "step 27260, cost 6.54433\n",
      "step 27260, change in cost 0.000537872\n",
      "step 27270, training accuracy 0.963415\n",
      "step 27270, cost 6.5438\n",
      "step 27270, change in cost 0.000533581\n",
      "step 27280, training accuracy 0.963415\n",
      "step 27280, cost 6.54326\n",
      "step 27280, change in cost 0.000536919\n",
      "step 27290, training accuracy 0.963415\n",
      "step 27290, cost 6.54272\n",
      "step 27290, change in cost 0.000535488\n",
      "step 27300, training accuracy 0.963415\n",
      "step 27300, cost 6.54219\n",
      "step 27300, change in cost 0.000534058\n",
      "step 27310, training accuracy 0.963415\n",
      "step 27310, cost 6.54166\n",
      "step 27310, change in cost 0.000534058\n",
      "step 27320, training accuracy 0.963415\n",
      "step 27320, cost 6.54112\n",
      "step 27320, change in cost 0.000534058\n",
      "step 27330, training accuracy 0.963415\n",
      "step 27330, cost 6.54059\n",
      "step 27330, change in cost 0.000532627\n",
      "step 27340, training accuracy 0.963415\n",
      "step 27340, cost 6.54006\n",
      "step 27340, change in cost 0.000531673\n",
      "step 27350, training accuracy 0.963415\n",
      "step 27350, cost 6.53952\n",
      "step 27350, change in cost 0.000533581\n",
      "step 27360, training accuracy 0.963415\n",
      "step 27360, cost 6.53899\n",
      "step 27360, change in cost 0.000531197\n",
      "step 27370, training accuracy 0.963415\n",
      "step 27370, cost 6.53846\n",
      "step 27370, change in cost 0.000533581\n",
      "step 27380, training accuracy 0.963415\n",
      "step 27380, cost 6.53793\n",
      "step 27380, change in cost 0.000529289\n",
      "step 27390, training accuracy 0.963415\n",
      "step 27390, cost 6.5374\n",
      "step 27390, change in cost 0.000530243\n",
      "step 27400, training accuracy 0.963415\n",
      "step 27400, cost 6.53687\n",
      "step 27400, change in cost 0.000530243\n",
      "step 27410, training accuracy 0.963415\n",
      "step 27410, cost 6.53634\n",
      "step 27410, change in cost 0.000528336\n",
      "step 27420, training accuracy 0.963415\n",
      "step 27420, cost 6.53581\n",
      "step 27420, change in cost 0.000529289\n",
      "step 27430, training accuracy 0.963415\n",
      "step 27430, cost 6.53528\n",
      "step 27430, change in cost 0.000529289\n",
      "step 27440, training accuracy 0.963415\n",
      "step 27440, cost 6.53475\n",
      "step 27440, change in cost 0.000527382\n",
      "step 27450, training accuracy 0.963415\n",
      "step 27450, cost 6.53423\n",
      "step 27450, change in cost 0.000528336\n",
      "step 27460, training accuracy 0.963415\n",
      "step 27460, cost 6.5337\n",
      "step 27460, change in cost 0.000527382\n",
      "step 27470, training accuracy 0.963415\n",
      "step 27470, cost 6.53317\n",
      "step 27470, change in cost 0.000526905\n",
      "step 27480, training accuracy 0.963415\n",
      "step 27480, cost 6.53265\n",
      "step 27480, change in cost 0.000525951\n",
      "step 27490, training accuracy 0.963415\n",
      "step 27490, cost 6.53212\n",
      "step 27490, change in cost 0.000524998\n",
      "step 27500, training accuracy 0.963415\n",
      "step 27500, cost 6.5316\n",
      "step 27500, change in cost 0.000524521\n",
      "step 27510, training accuracy 0.963415\n",
      "step 27510, cost 6.53107\n",
      "step 27510, change in cost 0.000527382\n",
      "step 27520, training accuracy 0.963415\n",
      "step 27520, cost 6.53055\n",
      "step 27520, change in cost 0.000522137\n",
      "step 27530, training accuracy 0.963415\n",
      "step 27530, cost 6.53002\n",
      "step 27530, change in cost 0.000522614\n",
      "step 27540, training accuracy 0.963415\n",
      "step 27540, cost 6.5295\n",
      "step 27540, change in cost 0.000523567\n",
      "step 27550, training accuracy 0.963415\n",
      "step 27550, cost 6.52898\n",
      "step 27550, change in cost 0.00052166\n",
      "step 27560, training accuracy 0.963415\n",
      "step 27560, cost 6.52846\n",
      "step 27560, change in cost 0.000523567\n",
      "step 27570, training accuracy 0.963415\n",
      "step 27570, cost 6.52793\n",
      "step 27570, change in cost 0.000523567\n",
      "step 27580, training accuracy 0.963415\n",
      "step 27580, cost 6.52741\n",
      "step 27580, change in cost 0.00052309\n",
      "step 27590, training accuracy 0.963415\n",
      "step 27590, cost 6.52689\n",
      "step 27590, change in cost 0.000519276\n",
      "step 27600, training accuracy 0.963415\n",
      "step 27600, cost 6.52637\n",
      "step 27600, change in cost 0.000517845\n",
      "step 27610, training accuracy 0.963415\n",
      "step 27610, cost 6.52585\n",
      "step 27610, change in cost 0.000522137\n",
      "step 27620, training accuracy 0.963415\n",
      "step 27620, cost 6.52533\n",
      "step 27620, change in cost 0.000517845\n",
      "step 27630, training accuracy 0.963415\n",
      "step 27630, cost 6.52481\n",
      "step 27630, change in cost 0.000519753\n",
      "step 27640, training accuracy 0.963415\n",
      "step 27640, cost 6.52429\n",
      "step 27640, change in cost 0.000518322\n",
      "step 27650, training accuracy 0.963415\n",
      "step 27650, cost 6.52377\n",
      "step 27650, change in cost 0.000519753\n",
      "step 27660, training accuracy 0.963415\n",
      "step 27660, cost 6.52326\n",
      "step 27660, change in cost 0.000516891\n",
      "step 27670, training accuracy 0.963415\n",
      "step 27670, cost 6.52274\n",
      "step 27670, change in cost 0.000517845\n",
      "step 27680, training accuracy 0.963415\n",
      "step 27680, cost 6.52222\n",
      "step 27680, change in cost 0.000516891\n",
      "step 27690, training accuracy 0.963415\n",
      "step 27690, cost 6.52171\n",
      "step 27690, change in cost 0.000516891\n",
      "step 27700, training accuracy 0.963415\n",
      "step 27700, cost 6.52119\n",
      "step 27700, change in cost 0.000515938\n",
      "step 27710, training accuracy 0.963415\n",
      "step 27710, cost 6.52067\n",
      "step 27710, change in cost 0.000516415\n",
      "step 27720, training accuracy 0.963415\n",
      "step 27720, cost 6.52016\n",
      "step 27720, change in cost 0.0005126\n",
      "step 27730, training accuracy 0.963415\n",
      "step 27730, cost 6.51964\n",
      "step 27730, change in cost 0.000516415\n",
      "step 27740, training accuracy 0.963415\n",
      "step 27740, cost 6.51913\n",
      "step 27740, change in cost 0.00051403\n",
      "step 27750, training accuracy 0.963415\n",
      "step 27750, cost 6.51862\n",
      "step 27750, change in cost 0.000513554\n",
      "step 27760, training accuracy 0.963415\n",
      "step 27760, cost 6.5181\n",
      "step 27760, change in cost 0.00051403\n",
      "step 27770, training accuracy 0.963415\n",
      "step 27770, cost 6.51759\n",
      "step 27770, change in cost 0.000513077\n",
      "step 27780, training accuracy 0.963415\n",
      "step 27780, cost 6.51708\n",
      "step 27780, change in cost 0.000512123\n",
      "step 27790, training accuracy 0.963415\n",
      "step 27790, cost 6.51656\n",
      "step 27790, change in cost 0.000513077\n",
      "step 27800, training accuracy 0.963415\n",
      "step 27800, cost 6.51605\n",
      "step 27800, change in cost 0.000510216\n",
      "step 27810, training accuracy 0.963415\n",
      "step 27810, cost 6.51554\n",
      "step 27810, change in cost 0.000512123\n",
      "step 27820, training accuracy 0.963415\n",
      "step 27820, cost 6.51503\n",
      "step 27820, change in cost 0.000511169\n",
      "step 27830, training accuracy 0.963415\n",
      "step 27830, cost 6.51452\n",
      "step 27830, change in cost 0.000509262\n",
      "step 27840, training accuracy 0.963415\n",
      "step 27840, cost 6.51401\n",
      "step 27840, change in cost 0.000510216\n",
      "step 27850, training accuracy 0.963415\n",
      "step 27850, cost 6.5135\n",
      "step 27850, change in cost 0.000509262\n",
      "step 27860, training accuracy 0.963415\n",
      "step 27860, cost 6.51299\n",
      "step 27860, change in cost 0.000508308\n",
      "step 27870, training accuracy 0.963415\n",
      "step 27870, cost 6.51248\n",
      "step 27870, change in cost 0.000509262\n",
      "step 27880, training accuracy 0.963415\n",
      "step 27880, cost 6.51198\n",
      "step 27880, change in cost 0.000507355\n",
      "step 27890, training accuracy 0.963415\n",
      "step 27890, cost 6.51147\n",
      "step 27890, change in cost 0.000509262\n",
      "step 27900, training accuracy 0.963415\n",
      "step 27900, cost 6.51096\n",
      "step 27900, change in cost 0.000506401\n",
      "step 27910, training accuracy 0.963415\n",
      "step 27910, cost 6.51045\n",
      "step 27910, change in cost 0.000507355\n",
      "step 27920, training accuracy 0.963415\n",
      "step 27920, cost 6.50995\n",
      "step 27920, change in cost 0.000508308\n",
      "step 27930, training accuracy 0.963415\n",
      "step 27930, cost 6.50944\n",
      "step 27930, change in cost 0.000505447\n",
      "step 27940, training accuracy 0.963415\n",
      "step 27940, cost 6.50893\n",
      "step 27940, change in cost 0.000505447\n",
      "step 27950, training accuracy 0.963415\n",
      "step 27950, cost 6.50843\n",
      "step 27950, change in cost 0.000504017\n",
      "step 27960, training accuracy 0.963415\n",
      "step 27960, cost 6.50792\n",
      "step 27960, change in cost 0.000506878\n",
      "step 27970, training accuracy 0.963415\n",
      "step 27970, cost 6.50742\n",
      "step 27970, change in cost 0.00050354\n",
      "step 27980, training accuracy 0.963415\n",
      "step 27980, cost 6.50691\n",
      "step 27980, change in cost 0.000506401\n",
      "step 27990, training accuracy 0.963415\n",
      "step 27990, cost 6.50641\n",
      "step 27990, change in cost 0.00050354\n",
      "step 28000, training accuracy 0.963415\n",
      "step 28000, cost 6.50591\n",
      "step 28000, change in cost 0.00050354\n",
      "step 28010, training accuracy 0.963415\n",
      "step 28010, cost 6.5054\n",
      "step 28010, change in cost 0.000502586\n",
      "step 28020, training accuracy 0.963415\n",
      "step 28020, cost 6.5049\n",
      "step 28020, change in cost 0.000500679\n",
      "step 28030, training accuracy 0.963415\n",
      "step 28030, cost 6.5044\n",
      "step 28030, change in cost 0.00050354\n",
      "step 28040, training accuracy 0.963415\n",
      "step 28040, cost 6.5039\n",
      "step 28040, change in cost 0.00050354\n",
      "step 28050, training accuracy 0.963415\n",
      "step 28050, cost 6.5034\n",
      "step 28050, change in cost 0.000500679\n",
      "step 28060, training accuracy 0.963415\n",
      "step 28060, cost 6.5029\n",
      "step 28060, change in cost 0.000498772\n",
      "step 28070, training accuracy 0.963415\n",
      "step 28070, cost 6.5024\n",
      "step 28070, change in cost 0.00050211\n",
      "step 28080, training accuracy 0.963415\n",
      "step 28080, cost 6.5019\n",
      "step 28080, change in cost 0.000498295\n",
      "step 28090, training accuracy 0.963415\n",
      "step 28090, cost 6.5014\n",
      "step 28090, change in cost 0.000500679\n",
      "step 28100, training accuracy 0.963415\n",
      "step 28100, cost 6.5009\n",
      "step 28100, change in cost 0.000498772\n",
      "step 28110, training accuracy 0.963415\n",
      "step 28110, cost 6.5004\n",
      "step 28110, change in cost 0.000498772\n",
      "step 28120, training accuracy 0.963415\n",
      "step 28120, cost 6.4999\n",
      "step 28120, change in cost 0.000499725\n",
      "step 28130, training accuracy 0.963415\n",
      "step 28130, cost 6.4994\n",
      "step 28130, change in cost 0.000498772\n",
      "step 28140, training accuracy 0.963415\n",
      "step 28140, cost 6.4989\n",
      "step 28140, change in cost 0.000498772\n",
      "step 28150, training accuracy 0.963415\n",
      "step 28150, cost 6.4984\n",
      "step 28150, change in cost 0.000497818\n",
      "step 28160, training accuracy 0.963415\n",
      "step 28160, cost 6.49791\n",
      "step 28160, change in cost 0.000496387\n",
      "step 28170, training accuracy 0.963415\n",
      "step 28170, cost 6.49741\n",
      "step 28170, change in cost 0.000495434\n",
      "step 28180, training accuracy 0.963415\n",
      "step 28180, cost 6.49691\n",
      "step 28180, change in cost 0.000496864\n",
      "step 28190, training accuracy 0.963415\n",
      "step 28190, cost 6.49642\n",
      "step 28190, change in cost 0.000494957\n",
      "step 28200, training accuracy 0.963415\n",
      "step 28200, cost 6.49593\n",
      "step 28200, change in cost 0.000494003\n",
      "step 28210, training accuracy 0.963415\n",
      "step 28210, cost 6.49543\n",
      "step 28210, change in cost 0.000496387\n",
      "step 28220, training accuracy 0.963415\n",
      "step 28220, cost 6.49494\n",
      "step 28220, change in cost 0.000493526\n",
      "step 28230, training accuracy 0.963415\n",
      "step 28230, cost 6.49444\n",
      "step 28230, change in cost 0.000494957\n",
      "step 28240, training accuracy 0.963415\n",
      "step 28240, cost 6.49395\n",
      "step 28240, change in cost 0.000492096\n",
      "step 28250, training accuracy 0.963415\n",
      "step 28250, cost 6.49345\n",
      "step 28250, change in cost 0.00049448\n",
      "step 28260, training accuracy 0.963415\n",
      "step 28260, cost 6.49296\n",
      "step 28260, change in cost 0.00049448\n",
      "step 28270, training accuracy 0.963415\n",
      "step 28270, cost 6.49247\n",
      "step 28270, change in cost 0.000491142\n",
      "step 28280, training accuracy 0.963415\n",
      "step 28280, cost 6.49197\n",
      "step 28280, change in cost 0.000494003\n",
      "step 28290, training accuracy 0.963415\n",
      "step 28290, cost 6.49148\n",
      "step 28290, change in cost 0.000490189\n",
      "step 28300, training accuracy 0.963415\n",
      "step 28300, cost 6.49099\n",
      "step 28300, change in cost 0.000491142\n",
      "step 28310, training accuracy 0.963415\n",
      "step 28310, cost 6.4905\n",
      "step 28310, change in cost 0.000492096\n",
      "step 28320, training accuracy 0.963415\n",
      "step 28320, cost 6.49001\n",
      "step 28320, change in cost 0.000489235\n",
      "step 28330, training accuracy 0.963415\n",
      "step 28330, cost 6.48952\n",
      "step 28330, change in cost 0.000490189\n",
      "step 28340, training accuracy 0.963415\n",
      "step 28340, cost 6.48903\n",
      "step 28340, change in cost 0.000490665\n",
      "step 28350, training accuracy 0.963415\n",
      "step 28350, cost 6.48854\n",
      "step 28350, change in cost 0.000489712\n",
      "step 28360, training accuracy 0.963415\n",
      "step 28360, cost 6.48805\n",
      "step 28360, change in cost 0.000490189\n",
      "step 28370, training accuracy 0.963415\n",
      "step 28370, cost 6.48756\n",
      "step 28370, change in cost 0.000487328\n",
      "step 28380, training accuracy 0.963415\n",
      "step 28380, cost 6.48708\n",
      "step 28380, change in cost 0.000487328\n",
      "step 28390, training accuracy 0.963415\n",
      "step 28390, cost 6.48659\n",
      "step 28390, change in cost 0.000486851\n",
      "step 28400, training accuracy 0.963415\n",
      "step 28400, cost 6.4861\n",
      "step 28400, change in cost 0.000489235\n",
      "step 28410, training accuracy 0.963415\n",
      "step 28410, cost 6.48561\n",
      "step 28410, change in cost 0.000487804\n",
      "step 28420, training accuracy 0.963415\n",
      "step 28420, cost 6.48513\n",
      "step 28420, change in cost 0.00048542\n",
      "step 28430, training accuracy 0.963415\n",
      "step 28430, cost 6.48464\n",
      "step 28430, change in cost 0.000488281\n",
      "step 28440, training accuracy 0.963415\n",
      "step 28440, cost 6.48415\n",
      "step 28440, change in cost 0.00048542\n",
      "step 28450, training accuracy 0.963415\n",
      "step 28450, cost 6.48367\n",
      "step 28450, change in cost 0.000487328\n",
      "step 28460, training accuracy 0.963415\n",
      "step 28460, cost 6.48318\n",
      "step 28460, change in cost 0.00048399\n",
      "step 28470, training accuracy 0.963415\n",
      "step 28470, cost 6.4827\n",
      "step 28470, change in cost 0.00048542\n",
      "step 28480, training accuracy 0.963415\n",
      "step 28480, cost 6.48221\n",
      "step 28480, change in cost 0.00048542\n",
      "step 28490, training accuracy 0.963415\n",
      "step 28490, cost 6.48173\n",
      "step 28490, change in cost 0.00048542\n",
      "step 28500, training accuracy 0.963415\n",
      "step 28500, cost 6.48124\n",
      "step 28500, change in cost 0.00048399\n",
      "step 28510, training accuracy 0.963415\n",
      "step 28510, cost 6.48076\n",
      "step 28510, change in cost 0.000481606\n",
      "step 28520, training accuracy 0.963415\n",
      "step 28520, cost 6.48028\n",
      "step 28520, change in cost 0.000484467\n",
      "step 28530, training accuracy 0.963415\n",
      "step 28530, cost 6.47979\n",
      "step 28530, change in cost 0.000483513\n",
      "step 28540, training accuracy 0.963415\n",
      "step 28540, cost 6.47931\n",
      "step 28540, change in cost 0.000482559\n",
      "step 28550, training accuracy 0.963415\n",
      "step 28550, cost 6.47883\n",
      "step 28550, change in cost 0.000482082\n",
      "step 28560, training accuracy 0.963415\n",
      "step 28560, cost 6.47834\n",
      "step 28560, change in cost 0.000483036\n",
      "step 28570, training accuracy 0.963415\n",
      "step 28570, cost 6.47787\n",
      "step 28570, change in cost 0.000479698\n",
      "step 28580, training accuracy 0.963415\n",
      "step 28580, cost 6.47738\n",
      "step 28580, change in cost 0.000483513\n",
      "step 28590, training accuracy 0.963415\n",
      "step 28590, cost 6.4769\n",
      "step 28590, change in cost 0.000479698\n",
      "step 28600, training accuracy 0.963415\n",
      "step 28600, cost 6.47642\n",
      "step 28600, change in cost 0.000481129\n",
      "step 28610, training accuracy 0.963415\n",
      "step 28610, cost 6.47594\n",
      "step 28610, change in cost 0.000478268\n",
      "step 28620, training accuracy 0.963415\n",
      "step 28620, cost 6.47546\n",
      "step 28620, change in cost 0.000479698\n",
      "step 28630, training accuracy 0.963415\n",
      "step 28630, cost 6.47498\n",
      "step 28630, change in cost 0.000481606\n",
      "step 28640, training accuracy 0.963415\n",
      "step 28640, cost 6.4745\n",
      "step 28640, change in cost 0.000478268\n",
      "step 28650, training accuracy 0.963415\n",
      "step 28650, cost 6.47403\n",
      "step 28650, change in cost 0.000477314\n",
      "step 28660, training accuracy 0.963415\n",
      "step 28660, cost 6.47355\n",
      "step 28660, change in cost 0.000478268\n",
      "step 28670, training accuracy 0.963415\n",
      "step 28670, cost 6.47307\n",
      "step 28670, change in cost 0.000478268\n",
      "step 28680, training accuracy 0.963415\n",
      "step 28680, cost 6.47259\n",
      "step 28680, change in cost 0.000477791\n",
      "step 28690, training accuracy 0.963415\n",
      "step 28690, cost 6.47211\n",
      "step 28690, change in cost 0.000476837\n",
      "step 28700, training accuracy 0.963415\n",
      "step 28700, cost 6.47164\n",
      "step 28700, change in cost 0.000477791\n",
      "step 28710, training accuracy 0.963415\n",
      "step 28710, cost 6.47116\n",
      "step 28710, change in cost 0.000475883\n",
      "step 28720, training accuracy 0.963415\n",
      "step 28720, cost 6.47068\n",
      "step 28720, change in cost 0.00047636\n",
      "step 28730, training accuracy 0.963415\n",
      "step 28730, cost 6.47021\n",
      "step 28730, change in cost 0.00047636\n",
      "step 28740, training accuracy 0.963415\n",
      "step 28740, cost 6.46973\n",
      "step 28740, change in cost 0.00047493\n",
      "step 28750, training accuracy 0.963415\n",
      "step 28750, cost 6.46926\n",
      "step 28750, change in cost 0.00047493\n",
      "step 28760, training accuracy 0.963415\n",
      "step 28760, cost 6.46878\n",
      "step 28760, change in cost 0.000475883\n",
      "step 28770, training accuracy 0.963415\n",
      "step 28770, cost 6.46831\n",
      "step 28770, change in cost 0.00047493\n",
      "step 28780, training accuracy 0.963415\n",
      "step 28780, cost 6.46783\n",
      "step 28780, change in cost 0.000473022\n",
      "step 28790, training accuracy 0.963415\n",
      "step 28790, cost 6.46736\n",
      "step 28790, change in cost 0.000473499\n",
      "step 28800, training accuracy 0.963415\n",
      "step 28800, cost 6.46689\n",
      "step 28800, change in cost 0.000473499\n",
      "step 28810, training accuracy 0.963415\n",
      "step 28810, cost 6.46641\n",
      "step 28810, change in cost 0.000473022\n",
      "step 28820, training accuracy 0.963415\n",
      "step 28820, cost 6.46594\n",
      "step 28820, change in cost 0.000473976\n",
      "step 28830, training accuracy 0.963415\n",
      "step 28830, cost 6.46547\n",
      "step 28830, change in cost 0.000472069\n",
      "step 28840, training accuracy 0.963415\n",
      "step 28840, cost 6.465\n",
      "step 28840, change in cost 0.000471592\n",
      "step 28850, training accuracy 0.963415\n",
      "step 28850, cost 6.46452\n",
      "step 28850, change in cost 0.000472546\n",
      "step 28860, training accuracy 0.963415\n",
      "step 28860, cost 6.46405\n",
      "step 28860, change in cost 0.000470161\n",
      "step 28870, training accuracy 0.963415\n",
      "step 28870, cost 6.46358\n",
      "step 28870, change in cost 0.000473976\n",
      "step 28880, training accuracy 0.963415\n",
      "step 28880, cost 6.46311\n",
      "step 28880, change in cost 0.000467777\n",
      "step 28890, training accuracy 0.963415\n",
      "step 28890, cost 6.46264\n",
      "step 28890, change in cost 0.000471115\n",
      "step 28900, training accuracy 0.963415\n",
      "step 28900, cost 6.46217\n",
      "step 28900, change in cost 0.000468731\n",
      "step 28910, training accuracy 0.963415\n",
      "step 28910, cost 6.4617\n",
      "step 28910, change in cost 0.000471115\n",
      "step 28920, training accuracy 0.963415\n",
      "step 28920, cost 6.46123\n",
      "step 28920, change in cost 0.000469685\n",
      "step 28930, training accuracy 0.963415\n",
      "step 28930, cost 6.46076\n",
      "step 28930, change in cost 0.000468731\n",
      "step 28940, training accuracy 0.963415\n",
      "step 28940, cost 6.4603\n",
      "step 28940, change in cost 0.0004673\n",
      "step 28950, training accuracy 0.963415\n",
      "step 28950, cost 6.45983\n",
      "step 28950, change in cost 0.000469208\n",
      "step 28960, training accuracy 0.963415\n",
      "step 28960, cost 6.45936\n",
      "step 28960, change in cost 0.000469208\n",
      "step 28970, training accuracy 0.963415\n",
      "step 28970, cost 6.45889\n",
      "step 28970, change in cost 0.000468731\n",
      "step 28980, training accuracy 0.963415\n",
      "step 28980, cost 6.45842\n",
      "step 28980, change in cost 0.000466347\n",
      "step 28990, training accuracy 0.963415\n",
      "step 28990, cost 6.45796\n",
      "step 28990, change in cost 0.000466347\n",
      "step 29000, training accuracy 0.963415\n",
      "step 29000, cost 6.45749\n",
      "step 29000, change in cost 0.000466347\n",
      "step 29010, training accuracy 0.963415\n",
      "step 29010, cost 6.45702\n",
      "step 29010, change in cost 0.000466824\n",
      "step 29020, training accuracy 0.963415\n",
      "step 29020, cost 6.45656\n",
      "step 29020, change in cost 0.000465393\n",
      "step 29030, training accuracy 0.963415\n",
      "step 29030, cost 6.45609\n",
      "step 29030, change in cost 0.000464916\n",
      "step 29040, training accuracy 0.963415\n",
      "step 29040, cost 6.45563\n",
      "step 29040, change in cost 0.000466347\n",
      "step 29050, training accuracy 0.963415\n",
      "step 29050, cost 6.45516\n",
      "step 29050, change in cost 0.000464439\n",
      "step 29060, training accuracy 0.963415\n",
      "step 29060, cost 6.4547\n",
      "step 29060, change in cost 0.000464439\n",
      "step 29070, training accuracy 0.963415\n",
      "step 29070, cost 6.45423\n",
      "step 29070, change in cost 0.000464916\n",
      "step 29080, training accuracy 0.963415\n",
      "step 29080, cost 6.45377\n",
      "step 29080, change in cost 0.000462055\n",
      "step 29090, training accuracy 0.963415\n",
      "step 29090, cost 6.45331\n",
      "step 29090, change in cost 0.000464916\n",
      "step 29100, training accuracy 0.963415\n",
      "step 29100, cost 6.45284\n",
      "step 29100, change in cost 0.000463486\n",
      "step 29110, training accuracy 0.963415\n",
      "step 29110, cost 6.45238\n",
      "step 29110, change in cost 0.000462532\n",
      "step 29120, training accuracy 0.963415\n",
      "step 29120, cost 6.45192\n",
      "step 29120, change in cost 0.000461578\n",
      "step 29130, training accuracy 0.963415\n",
      "step 29130, cost 6.45146\n",
      "step 29130, change in cost 0.000462532\n",
      "step 29140, training accuracy 0.963415\n",
      "step 29140, cost 6.45099\n",
      "step 29140, change in cost 0.000463486\n",
      "step 29150, training accuracy 0.963415\n",
      "step 29150, cost 6.45053\n",
      "step 29150, change in cost 0.000462532\n",
      "step 29160, training accuracy 0.963415\n",
      "step 29160, cost 6.45007\n",
      "step 29160, change in cost 0.000461578\n",
      "step 29170, training accuracy 0.963415\n",
      "step 29170, cost 6.44961\n",
      "step 29170, change in cost 0.000461102\n",
      "step 29180, training accuracy 0.963415\n",
      "step 29180, cost 6.44915\n",
      "step 29180, change in cost 0.000460148\n",
      "step 29190, training accuracy 0.963415\n",
      "step 29190, cost 6.44869\n",
      "step 29190, change in cost 0.000460148\n",
      "step 29200, training accuracy 0.963415\n",
      "step 29200, cost 6.44823\n",
      "step 29200, change in cost 0.000460625\n",
      "step 29210, training accuracy 0.963415\n",
      "step 29210, cost 6.44777\n",
      "step 29210, change in cost 0.000459671\n",
      "step 29220, training accuracy 0.963415\n",
      "step 29220, cost 6.44731\n",
      "step 29220, change in cost 0.000460148\n",
      "step 29230, training accuracy 0.963415\n",
      "step 29230, cost 6.44685\n",
      "step 29230, change in cost 0.000458241\n",
      "step 29240, training accuracy 0.963415\n",
      "step 29240, cost 6.44639\n",
      "step 29240, change in cost 0.000460625\n",
      "step 29250, training accuracy 0.963415\n",
      "step 29250, cost 6.44593\n",
      "step 29250, change in cost 0.000458717\n",
      "step 29260, training accuracy 0.963415\n",
      "step 29260, cost 6.44547\n",
      "step 29260, change in cost 0.000459194\n",
      "step 29270, training accuracy 0.963415\n",
      "step 29270, cost 6.44501\n",
      "step 29270, change in cost 0.000457764\n",
      "step 29280, training accuracy 0.963415\n",
      "step 29280, cost 6.44455\n",
      "step 29280, change in cost 0.000456333\n",
      "step 29290, training accuracy 0.963415\n",
      "step 29290, cost 6.4441\n",
      "step 29290, change in cost 0.000457764\n",
      "step 29300, training accuracy 0.963415\n",
      "step 29300, cost 6.44364\n",
      "step 29300, change in cost 0.00045681\n",
      "step 29310, training accuracy 0.963415\n",
      "step 29310, cost 6.44318\n",
      "step 29310, change in cost 0.000458241\n",
      "step 29320, training accuracy 0.963415\n",
      "step 29320, cost 6.44273\n",
      "step 29320, change in cost 0.00045681\n",
      "step 29330, training accuracy 0.963415\n",
      "step 29330, cost 6.44227\n",
      "step 29330, change in cost 0.000454903\n",
      "step 29340, training accuracy 0.963415\n",
      "step 29340, cost 6.44181\n",
      "step 29340, change in cost 0.00045681\n",
      "step 29350, training accuracy 0.963415\n",
      "step 29350, cost 6.44136\n",
      "step 29350, change in cost 0.000453949\n",
      "step 29360, training accuracy 0.963415\n",
      "step 29360, cost 6.4409\n",
      "step 29360, change in cost 0.000456333\n",
      "step 29370, training accuracy 0.963415\n",
      "step 29370, cost 6.44045\n",
      "step 29370, change in cost 0.000455379\n",
      "step 29380, training accuracy 0.963415\n",
      "step 29380, cost 6.43999\n",
      "step 29380, change in cost 0.000454903\n",
      "step 29390, training accuracy 0.963415\n",
      "step 29390, cost 6.43954\n",
      "step 29390, change in cost 0.000453949\n",
      "step 29400, training accuracy 0.963415\n",
      "step 29400, cost 6.43908\n",
      "step 29400, change in cost 0.000454426\n",
      "step 29410, training accuracy 0.963415\n",
      "step 29410, cost 6.43863\n",
      "step 29410, change in cost 0.000453472\n",
      "step 29420, training accuracy 0.963415\n",
      "step 29420, cost 6.43818\n",
      "step 29420, change in cost 0.000450611\n",
      "step 29430, training accuracy 0.963415\n",
      "step 29430, cost 6.43772\n",
      "step 29430, change in cost 0.000457287\n",
      "step 29440, training accuracy 0.963415\n",
      "step 29440, cost 6.43727\n",
      "step 29440, change in cost 0.000450134\n",
      "step 29450, training accuracy 0.963415\n",
      "step 29450, cost 6.43682\n",
      "step 29450, change in cost 0.000453949\n",
      "step 29460, training accuracy 0.963415\n",
      "step 29460, cost 6.43637\n",
      "step 29460, change in cost 0.000452042\n",
      "step 29470, training accuracy 0.963415\n",
      "step 29470, cost 6.43591\n",
      "step 29470, change in cost 0.000452042\n",
      "step 29480, training accuracy 0.963415\n",
      "step 29480, cost 6.43546\n",
      "step 29480, change in cost 0.000452042\n",
      "step 29490, training accuracy 0.963415\n",
      "step 29490, cost 6.43501\n",
      "step 29490, change in cost 0.000450611\n",
      "step 29500, training accuracy 0.963415\n",
      "step 29500, cost 6.43456\n",
      "step 29500, change in cost 0.000451565\n",
      "step 29510, training accuracy 0.963415\n",
      "step 29510, cost 6.43411\n",
      "step 29510, change in cost 0.000448704\n",
      "step 29520, training accuracy 0.963415\n",
      "step 29520, cost 6.43366\n",
      "step 29520, change in cost 0.000451565\n",
      "step 29530, training accuracy 0.963415\n",
      "step 29530, cost 6.43321\n",
      "step 29530, change in cost 0.000449657\n",
      "step 29540, training accuracy 0.963415\n",
      "step 29540, cost 6.43276\n",
      "step 29540, change in cost 0.000450134\n",
      "step 29550, training accuracy 0.963415\n",
      "step 29550, cost 6.43231\n",
      "step 29550, change in cost 0.000449657\n",
      "step 29560, training accuracy 0.963415\n",
      "step 29560, cost 6.43186\n",
      "step 29560, change in cost 0.00044775\n",
      "step 29570, training accuracy 0.963415\n",
      "step 29570, cost 6.43141\n",
      "step 29570, change in cost 0.000449657\n",
      "step 29580, training accuracy 0.963415\n",
      "step 29580, cost 6.43097\n",
      "step 29580, change in cost 0.00044775\n",
      "step 29590, training accuracy 0.963415\n",
      "step 29590, cost 6.43052\n",
      "step 29590, change in cost 0.000449657\n",
      "step 29600, training accuracy 0.963415\n",
      "step 29600, cost 6.43007\n",
      "step 29600, change in cost 0.000448704\n",
      "step 29610, training accuracy 0.963415\n",
      "step 29610, cost 6.42962\n",
      "step 29610, change in cost 0.000446796\n",
      "step 29620, training accuracy 0.963415\n",
      "step 29620, cost 6.42917\n",
      "step 29620, change in cost 0.000446796\n",
      "step 29630, training accuracy 0.963415\n",
      "step 29630, cost 6.42873\n",
      "step 29630, change in cost 0.000447273\n",
      "step 29640, training accuracy 0.963415\n",
      "step 29640, cost 6.42828\n",
      "step 29640, change in cost 0.000446796\n",
      "step 29650, training accuracy 0.963415\n",
      "step 29650, cost 6.42783\n",
      "step 29650, change in cost 0.00044775\n",
      "step 29660, training accuracy 0.963415\n",
      "step 29660, cost 6.42739\n",
      "step 29660, change in cost 0.000445843\n",
      "step 29670, training accuracy 0.963415\n",
      "step 29670, cost 6.42694\n",
      "step 29670, change in cost 0.000445366\n",
      "step 29680, training accuracy 0.963415\n",
      "step 29680, cost 6.4265\n",
      "step 29680, change in cost 0.000445366\n",
      "step 29690, training accuracy 0.963415\n",
      "step 29690, cost 6.42605\n",
      "step 29690, change in cost 0.00044632\n",
      "step 29700, training accuracy 0.963415\n",
      "step 29700, cost 6.4256\n",
      "step 29700, change in cost 0.000444889\n",
      "step 29710, training accuracy 0.963415\n",
      "step 29710, cost 6.42516\n",
      "step 29710, change in cost 0.000444889\n",
      "step 29720, training accuracy 0.963415\n",
      "step 29720, cost 6.42472\n",
      "step 29720, change in cost 0.000444412\n",
      "step 29730, training accuracy 0.963415\n",
      "step 29730, cost 6.42427\n",
      "step 29730, change in cost 0.000445366\n",
      "step 29740, training accuracy 0.963415\n",
      "step 29740, cost 6.42383\n",
      "step 29740, change in cost 0.000443459\n",
      "step 29750, training accuracy 0.963415\n",
      "step 29750, cost 6.42338\n",
      "step 29750, change in cost 0.000443459\n",
      "step 29760, training accuracy 0.963415\n",
      "step 29760, cost 6.42294\n",
      "step 29760, change in cost 0.000445366\n",
      "step 29770, training accuracy 0.963415\n",
      "step 29770, cost 6.4225\n",
      "step 29770, change in cost 0.000441551\n",
      "step 29780, training accuracy 0.963415\n",
      "step 29780, cost 6.42205\n",
      "step 29780, change in cost 0.000443459\n",
      "step 29790, training accuracy 0.963415\n",
      "step 29790, cost 6.42161\n",
      "step 29790, change in cost 0.000441551\n",
      "step 29800, training accuracy 0.963415\n",
      "step 29800, cost 6.42117\n",
      "step 29800, change in cost 0.000442505\n",
      "step 29810, training accuracy 0.963415\n",
      "step 29810, cost 6.42073\n",
      "step 29810, change in cost 0.000440598\n",
      "step 29820, training accuracy 0.963415\n",
      "step 29820, cost 6.42029\n",
      "step 29820, change in cost 0.000441551\n",
      "step 29830, training accuracy 0.963415\n",
      "step 29830, cost 6.41984\n",
      "step 29830, change in cost 0.000441551\n",
      "step 29840, training accuracy 0.963415\n",
      "step 29840, cost 6.4194\n",
      "step 29840, change in cost 0.000441551\n",
      "step 29850, training accuracy 0.963415\n",
      "step 29850, cost 6.41896\n",
      "step 29850, change in cost 0.000440598\n",
      "step 29860, training accuracy 0.963415\n",
      "step 29860, cost 6.41852\n",
      "step 29860, change in cost 0.000440598\n",
      "step 29870, training accuracy 0.963415\n",
      "step 29870, cost 6.41808\n",
      "step 29870, change in cost 0.000440121\n",
      "step 29880, training accuracy 0.963415\n",
      "step 29880, cost 6.41764\n",
      "step 29880, change in cost 0.000439167\n",
      "step 29890, training accuracy 0.963415\n",
      "step 29890, cost 6.4172\n",
      "step 29890, change in cost 0.000440598\n",
      "step 29900, training accuracy 0.963415\n",
      "step 29900, cost 6.41676\n",
      "step 29900, change in cost 0.00043869\n",
      "step 29910, training accuracy 0.963415\n",
      "step 29910, cost 6.41632\n",
      "step 29910, change in cost 0.00043869\n",
      "step 29920, training accuracy 0.963415\n",
      "step 29920, cost 6.41588\n",
      "step 29920, change in cost 0.000440598\n",
      "step 29930, training accuracy 0.963415\n",
      "step 29930, cost 6.41545\n",
      "step 29930, change in cost 0.00043869\n",
      "step 29940, training accuracy 0.963415\n",
      "step 29940, cost 6.41501\n",
      "step 29940, change in cost 0.000436783\n",
      "step 29950, training accuracy 0.963415\n",
      "step 29950, cost 6.41457\n",
      "step 29950, change in cost 0.000437737\n",
      "step 29960, training accuracy 0.963415\n",
      "step 29960, cost 6.41413\n",
      "step 29960, change in cost 0.000436783\n",
      "step 29970, training accuracy 0.963415\n",
      "step 29970, cost 6.4137\n",
      "step 29970, change in cost 0.00043869\n",
      "step 29980, training accuracy 0.963415\n",
      "step 29980, cost 6.41326\n",
      "step 29980, change in cost 0.000436306\n",
      "step 29990, training accuracy 0.963415\n",
      "step 29990, cost 6.41282\n",
      "step 29990, change in cost 0.000438213\n",
      "step 30000, training accuracy 0.963415\n",
      "step 30000, cost 6.41238\n",
      "step 30000, change in cost 0.000435829\n",
      "step 30010, training accuracy 0.963415\n",
      "step 30010, cost 6.41195\n",
      "step 30010, change in cost 0.000436306\n",
      "step 30020, training accuracy 0.963415\n",
      "step 30020, cost 6.41151\n",
      "step 30020, change in cost 0.000435352\n",
      "step 30030, training accuracy 0.963415\n",
      "step 30030, cost 6.41108\n",
      "step 30030, change in cost 0.000436783\n",
      "step 30040, training accuracy 0.963415\n",
      "step 30040, cost 6.41064\n",
      "step 30040, change in cost 0.000435352\n",
      "step 30050, training accuracy 0.963415\n",
      "step 30050, cost 6.41021\n",
      "step 30050, change in cost 0.000434875\n",
      "step 30060, training accuracy 0.963415\n",
      "step 30060, cost 6.40977\n",
      "step 30060, change in cost 0.000435352\n",
      "step 30070, training accuracy 0.963415\n",
      "step 30070, cost 6.40933\n",
      "step 30070, change in cost 0.000436783\n",
      "step 30080, training accuracy 0.963415\n",
      "step 30080, cost 6.4089\n",
      "step 30080, change in cost 0.000433445\n",
      "step 30090, training accuracy 0.963415\n",
      "step 30090, cost 6.40847\n",
      "step 30090, change in cost 0.000432491\n",
      "step 30100, training accuracy 0.963415\n",
      "step 30100, cost 6.40803\n",
      "step 30100, change in cost 0.000435352\n",
      "step 30110, training accuracy 0.963415\n",
      "step 30110, cost 6.4076\n",
      "step 30110, change in cost 0.000433922\n",
      "step 30120, training accuracy 0.963415\n",
      "step 30120, cost 6.40717\n",
      "step 30120, change in cost 0.000432491\n",
      "step 30130, training accuracy 0.963415\n",
      "step 30130, cost 6.40673\n",
      "step 30130, change in cost 0.000433922\n",
      "step 30140, training accuracy 0.963415\n",
      "step 30140, cost 6.4063\n",
      "step 30140, change in cost 0.000432014\n",
      "step 30150, training accuracy 0.963415\n",
      "step 30150, cost 6.40587\n",
      "step 30150, change in cost 0.000432491\n",
      "step 30160, training accuracy 0.963415\n",
      "step 30160, cost 6.40543\n",
      "step 30160, change in cost 0.000433445\n",
      "step 30170, training accuracy 0.963415\n",
      "step 30170, cost 6.405\n",
      "step 30170, change in cost 0.000431538\n",
      "step 30180, training accuracy 0.963415\n",
      "step 30180, cost 6.40457\n",
      "step 30180, change in cost 0.000431538\n",
      "step 30190, training accuracy 0.963415\n",
      "step 30190, cost 6.40414\n",
      "step 30190, change in cost 0.000431538\n",
      "step 30200, training accuracy 0.963415\n",
      "step 30200, cost 6.40371\n",
      "step 30200, change in cost 0.000432014\n",
      "step 30210, training accuracy 0.963415\n",
      "step 30210, cost 6.40328\n",
      "step 30210, change in cost 0.000432491\n",
      "step 30220, training accuracy 0.963415\n",
      "step 30220, cost 6.40285\n",
      "step 30220, change in cost 0.000429153\n",
      "step 30230, training accuracy 0.963415\n",
      "step 30230, cost 6.40242\n",
      "step 30230, change in cost 0.000431061\n",
      "step 30240, training accuracy 0.963415\n",
      "step 30240, cost 6.40198\n",
      "step 30240, change in cost 0.000432014\n",
      "step 30250, training accuracy 0.963415\n",
      "step 30250, cost 6.40156\n",
      "step 30250, change in cost 0.0004282\n",
      "step 30260, training accuracy 0.963415\n",
      "step 30260, cost 6.40112\n",
      "step 30260, change in cost 0.000431538\n",
      "step 30270, training accuracy 0.963415\n",
      "step 30270, cost 6.4007\n",
      "step 30270, change in cost 0.000427723\n",
      "step 30280, training accuracy 0.963415\n",
      "step 30280, cost 6.40027\n",
      "step 30280, change in cost 0.000430107\n",
      "step 30290, training accuracy 0.963415\n",
      "step 30290, cost 6.39984\n",
      "step 30290, change in cost 0.000427723\n",
      "step 30300, training accuracy 0.963415\n",
      "step 30300, cost 6.39941\n",
      "step 30300, change in cost 0.000427723\n",
      "step 30310, training accuracy 0.963415\n",
      "step 30310, cost 6.39898\n",
      "step 30310, change in cost 0.000429153\n",
      "step 30320, training accuracy 0.963415\n",
      "step 30320, cost 6.39855\n",
      "step 30320, change in cost 0.000430107\n",
      "step 30330, training accuracy 0.963415\n",
      "step 30330, cost 6.39812\n",
      "step 30330, change in cost 0.000426292\n",
      "step 30340, training accuracy 0.963415\n",
      "step 30340, cost 6.3977\n",
      "step 30340, change in cost 0.0004282\n",
      "step 30350, training accuracy 0.963415\n",
      "step 30350, cost 6.39727\n",
      "step 30350, change in cost 0.000427246\n",
      "step 30360, training accuracy 0.963415\n",
      "step 30360, cost 6.39684\n",
      "step 30360, change in cost 0.000426292\n",
      "step 30370, training accuracy 0.963415\n",
      "step 30370, cost 6.39642\n",
      "step 30370, change in cost 0.000426292\n",
      "step 30380, training accuracy 0.963415\n",
      "step 30380, cost 6.39599\n",
      "step 30380, change in cost 0.000427246\n",
      "step 30390, training accuracy 0.963415\n",
      "step 30390, cost 6.39556\n",
      "step 30390, change in cost 0.000425339\n",
      "step 30400, training accuracy 0.963415\n",
      "step 30400, cost 6.39514\n",
      "step 30400, change in cost 0.000427246\n",
      "step 30410, training accuracy 0.963415\n",
      "step 30410, cost 6.39471\n",
      "step 30410, change in cost 0.000424862\n",
      "step 30420, training accuracy 0.963415\n",
      "step 30420, cost 6.39429\n",
      "step 30420, change in cost 0.000426292\n",
      "step 30430, training accuracy 0.963415\n",
      "step 30430, cost 6.39386\n",
      "step 30430, change in cost 0.000423908\n",
      "step 30440, training accuracy 0.963415\n",
      "step 30440, cost 6.39344\n",
      "step 30440, change in cost 0.000424385\n",
      "step 30450, training accuracy 0.963415\n",
      "step 30450, cost 6.39301\n",
      "step 30450, change in cost 0.000425339\n",
      "step 30460, training accuracy 0.963415\n",
      "step 30460, cost 6.39259\n",
      "step 30460, change in cost 0.000425339\n",
      "step 30470, training accuracy 0.963415\n",
      "step 30470, cost 6.39216\n",
      "step 30470, change in cost 0.000423431\n",
      "step 30480, training accuracy 0.963415\n",
      "step 30480, cost 6.39174\n",
      "step 30480, change in cost 0.000422478\n",
      "step 30490, training accuracy 0.963415\n",
      "step 30490, cost 6.39132\n",
      "step 30490, change in cost 0.000424862\n",
      "step 30500, training accuracy 0.963415\n",
      "step 30500, cost 6.39089\n",
      "step 30500, change in cost 0.000425339\n",
      "step 30510, training accuracy 0.963415\n",
      "step 30510, cost 6.39047\n",
      "step 30510, change in cost 0.000421047\n",
      "step 30520, training accuracy 0.963415\n",
      "step 30520, cost 6.39005\n",
      "step 30520, change in cost 0.000423908\n",
      "step 30530, training accuracy 0.963415\n",
      "step 30530, cost 6.38962\n",
      "step 30530, change in cost 0.000422001\n",
      "step 30540, training accuracy 0.963415\n",
      "step 30540, cost 6.3892\n",
      "step 30540, change in cost 0.000422478\n",
      "step 30550, training accuracy 0.963415\n",
      "step 30550, cost 6.38878\n",
      "step 30550, change in cost 0.000422478\n",
      "step 30560, training accuracy 0.963415\n",
      "step 30560, cost 6.38836\n",
      "step 30560, change in cost 0.000421047\n",
      "step 30570, training accuracy 0.963415\n",
      "step 30570, cost 6.38794\n",
      "step 30570, change in cost 0.000422001\n",
      "step 30580, training accuracy 0.963415\n",
      "step 30580, cost 6.38751\n",
      "step 30580, change in cost 0.000422001\n",
      "step 30590, training accuracy 0.963415\n",
      "step 30590, cost 6.38709\n",
      "step 30590, change in cost 0.000421047\n",
      "step 30600, training accuracy 0.963415\n",
      "step 30600, cost 6.38667\n",
      "step 30600, change in cost 0.000422478\n",
      "step 30610, training accuracy 0.963415\n",
      "step 30610, cost 6.38625\n",
      "step 30610, change in cost 0.000419617\n",
      "step 30620, training accuracy 0.963415\n",
      "step 30620, cost 6.38583\n",
      "step 30620, change in cost 0.00042057\n",
      "step 30630, training accuracy 0.963415\n",
      "step 30630, cost 6.38541\n",
      "step 30630, change in cost 0.000419617\n",
      "step 30640, training accuracy 0.963415\n",
      "step 30640, cost 6.38499\n",
      "step 30640, change in cost 0.000421047\n",
      "step 30650, training accuracy 0.963415\n",
      "step 30650, cost 6.38457\n",
      "step 30650, change in cost 0.000421047\n",
      "step 30660, training accuracy 0.963415\n",
      "step 30660, cost 6.38415\n",
      "step 30660, change in cost 0.000416756\n",
      "step 30670, training accuracy 0.963415\n",
      "step 30670, cost 6.38373\n",
      "step 30670, change in cost 0.000419617\n",
      "step 30680, training accuracy 0.963415\n",
      "step 30680, cost 6.38331\n",
      "step 30680, change in cost 0.000418663\n",
      "step 30690, training accuracy 0.963415\n",
      "step 30690, cost 6.3829\n",
      "step 30690, change in cost 0.000416756\n",
      "step 30700, training accuracy 0.963415\n",
      "step 30700, cost 6.38248\n",
      "step 30700, change in cost 0.000419617\n",
      "step 30710, training accuracy 0.963415\n",
      "step 30710, cost 6.38206\n",
      "step 30710, change in cost 0.000417709\n",
      "step 30720, training accuracy 0.963415\n",
      "step 30720, cost 6.38164\n",
      "step 30720, change in cost 0.000416756\n",
      "step 30730, training accuracy 0.963415\n",
      "step 30730, cost 6.38122\n",
      "step 30730, change in cost 0.000420094\n",
      "step 30740, training accuracy 0.963415\n",
      "step 30740, cost 6.38081\n",
      "step 30740, change in cost 0.000416279\n",
      "step 30750, training accuracy 0.963415\n",
      "step 30750, cost 6.38039\n",
      "step 30750, change in cost 0.000417709\n",
      "step 30760, training accuracy 0.963415\n",
      "step 30760, cost 6.37997\n",
      "step 30760, change in cost 0.000414371\n",
      "step 30770, training accuracy 0.963415\n",
      "step 30770, cost 6.37956\n",
      "step 30770, change in cost 0.000418186\n",
      "step 30780, training accuracy 0.963415\n",
      "step 30780, cost 6.37914\n",
      "step 30780, change in cost 0.000416756\n",
      "step 30790, training accuracy 0.963415\n",
      "step 30790, cost 6.37872\n",
      "step 30790, change in cost 0.000414848\n",
      "step 30800, training accuracy 0.963415\n",
      "step 30800, cost 6.37831\n",
      "step 30800, change in cost 0.000416279\n",
      "step 30810, training accuracy 0.963415\n",
      "step 30810, cost 6.37789\n",
      "step 30810, change in cost 0.000417233\n",
      "step 30820, training accuracy 0.963415\n",
      "step 30820, cost 6.37748\n",
      "step 30820, change in cost 0.000415325\n",
      "step 30830, training accuracy 0.963415\n",
      "step 30830, cost 6.37706\n",
      "step 30830, change in cost 0.000413895\n",
      "step 30840, training accuracy 0.963415\n",
      "step 30840, cost 6.37665\n",
      "step 30840, change in cost 0.000413895\n",
      "step 30850, training accuracy 0.963415\n",
      "step 30850, cost 6.37623\n",
      "step 30850, change in cost 0.000415325\n",
      "step 30860, training accuracy 0.963415\n",
      "step 30860, cost 6.37582\n",
      "step 30860, change in cost 0.000414848\n",
      "step 30870, training accuracy 0.963415\n",
      "step 30870, cost 6.3754\n",
      "step 30870, change in cost 0.000414848\n",
      "step 30880, training accuracy 0.963415\n",
      "step 30880, cost 6.37499\n",
      "step 30880, change in cost 0.000413895\n",
      "step 30890, training accuracy 0.963415\n",
      "step 30890, cost 6.37457\n",
      "step 30890, change in cost 0.000413895\n",
      "step 30900, training accuracy 0.963415\n",
      "step 30900, cost 6.37416\n",
      "step 30900, change in cost 0.000413895\n",
      "step 30910, training accuracy 0.963415\n",
      "step 30910, cost 6.37375\n",
      "step 30910, change in cost 0.000412941\n",
      "step 30920, training accuracy 0.963415\n",
      "step 30920, cost 6.37333\n",
      "step 30920, change in cost 0.000413895\n",
      "step 30930, training accuracy 0.963415\n",
      "step 30930, cost 6.37292\n",
      "step 30930, change in cost 0.00041151\n",
      "step 30940, training accuracy 0.963415\n",
      "step 30940, cost 6.37251\n",
      "step 30940, change in cost 0.000413418\n",
      "step 30950, training accuracy 0.963415\n",
      "step 30950, cost 6.3721\n",
      "step 30950, change in cost 0.000411987\n",
      "step 30960, training accuracy 0.963415\n",
      "step 30960, cost 6.37169\n",
      "step 30960, change in cost 0.00041008\n",
      "step 30970, training accuracy 0.963415\n",
      "step 30970, cost 6.37127\n",
      "step 30970, change in cost 0.000413895\n",
      "step 30980, training accuracy 0.963415\n",
      "step 30980, cost 6.37086\n",
      "step 30980, change in cost 0.000411987\n",
      "step 30990, training accuracy 0.963415\n",
      "step 30990, cost 6.37045\n",
      "step 30990, change in cost 0.000411987\n",
      "step 31000, training accuracy 0.963415\n",
      "step 31000, cost 6.37004\n",
      "step 31000, change in cost 0.00041008\n",
      "step 31010, training accuracy 0.963415\n",
      "step 31010, cost 6.36963\n",
      "step 31010, change in cost 0.000411034\n",
      "step 31020, training accuracy 0.963415\n",
      "step 31020, cost 6.36922\n",
      "step 31020, change in cost 0.000410557\n",
      "step 31030, training accuracy 0.963415\n",
      "step 31030, cost 6.36881\n",
      "step 31030, change in cost 0.000410557\n",
      "step 31040, training accuracy 0.963415\n",
      "step 31040, cost 6.3684\n",
      "step 31040, change in cost 0.000409603\n",
      "step 31050, training accuracy 0.963415\n",
      "step 31050, cost 6.36799\n",
      "step 31050, change in cost 0.000409126\n",
      "step 31060, training accuracy 0.963415\n",
      "step 31060, cost 6.36758\n",
      "step 31060, change in cost 0.000410557\n",
      "step 31070, training accuracy 0.963415\n",
      "step 31070, cost 6.36717\n",
      "step 31070, change in cost 0.00041008\n",
      "step 31080, training accuracy 0.963415\n",
      "step 31080, cost 6.36676\n",
      "step 31080, change in cost 0.000408173\n",
      "step 31090, training accuracy 0.963415\n",
      "step 31090, cost 6.36635\n",
      "step 31090, change in cost 0.00041008\n",
      "step 31100, training accuracy 0.963415\n",
      "step 31100, cost 6.36594\n",
      "step 31100, change in cost 0.000407696\n",
      "step 31110, training accuracy 0.963415\n",
      "step 31110, cost 6.36553\n",
      "step 31110, change in cost 0.000409603\n",
      "step 31120, training accuracy 0.963415\n",
      "step 31120, cost 6.36512\n",
      "step 31120, change in cost 0.000407696\n",
      "step 31130, training accuracy 0.963415\n",
      "step 31130, cost 6.36472\n",
      "step 31130, change in cost 0.000408649\n",
      "step 31140, training accuracy 0.963415\n",
      "step 31140, cost 6.36431\n",
      "step 31140, change in cost 0.000408173\n",
      "step 31150, training accuracy 0.963415\n",
      "step 31150, cost 6.3639\n",
      "step 31150, change in cost 0.000408173\n",
      "step 31160, training accuracy 0.963415\n",
      "step 31160, cost 6.36349\n",
      "step 31160, change in cost 0.000407219\n",
      "step 31170, training accuracy 0.963415\n",
      "step 31170, cost 6.36308\n",
      "step 31170, change in cost 0.000408173\n",
      "step 31180, training accuracy 0.963415\n",
      "step 31180, cost 6.36268\n",
      "step 31180, change in cost 0.000406742\n",
      "step 31190, training accuracy 0.963415\n",
      "step 31190, cost 6.36227\n",
      "step 31190, change in cost 0.000406265\n",
      "step 31200, training accuracy 0.963415\n",
      "step 31200, cost 6.36186\n",
      "step 31200, change in cost 0.000406742\n",
      "step 31210, training accuracy 0.963415\n",
      "step 31210, cost 6.36146\n",
      "step 31210, change in cost 0.000406265\n",
      "step 31220, training accuracy 0.963415\n",
      "step 31220, cost 6.36105\n",
      "step 31220, change in cost 0.000404835\n",
      "step 31230, training accuracy 0.963415\n",
      "step 31230, cost 6.36065\n",
      "step 31230, change in cost 0.000407696\n",
      "step 31240, training accuracy 0.963415\n",
      "step 31240, cost 6.36024\n",
      "step 31240, change in cost 0.000406265\n",
      "step 31250, training accuracy 0.963415\n",
      "step 31250, cost 6.35983\n",
      "step 31250, change in cost 0.000404358\n",
      "step 31260, training accuracy 0.963415\n",
      "step 31260, cost 6.35943\n",
      "step 31260, change in cost 0.000406265\n",
      "step 31270, training accuracy 0.963415\n",
      "step 31270, cost 6.35903\n",
      "step 31270, change in cost 0.000402451\n",
      "step 31280, training accuracy 0.963415\n",
      "step 31280, cost 6.35862\n",
      "step 31280, change in cost 0.000405312\n",
      "step 31290, training accuracy 0.963415\n",
      "step 31290, cost 6.35822\n",
      "step 31290, change in cost 0.000403404\n",
      "step 31300, training accuracy 0.963415\n",
      "step 31300, cost 6.35781\n",
      "step 31300, change in cost 0.000404835\n",
      "step 31310, training accuracy 0.963415\n",
      "step 31310, cost 6.35741\n",
      "step 31310, change in cost 0.000404835\n",
      "step 31320, training accuracy 0.963415\n",
      "step 31320, cost 6.357\n",
      "step 31320, change in cost 0.000403404\n",
      "step 31330, training accuracy 0.963415\n",
      "step 31330, cost 6.3566\n",
      "step 31330, change in cost 0.000403404\n",
      "step 31340, training accuracy 0.963415\n",
      "step 31340, cost 6.3562\n",
      "step 31340, change in cost 0.000402927\n",
      "step 31350, training accuracy 0.963415\n",
      "step 31350, cost 6.35579\n",
      "step 31350, change in cost 0.000403404\n",
      "step 31360, training accuracy 0.963415\n",
      "step 31360, cost 6.35539\n",
      "step 31360, change in cost 0.000403404\n",
      "step 31370, training accuracy 0.963415\n",
      "step 31370, cost 6.35499\n",
      "step 31370, change in cost 0.000402451\n",
      "step 31380, training accuracy 0.963415\n",
      "step 31380, cost 6.35459\n",
      "step 31380, change in cost 0.000402927\n",
      "step 31390, training accuracy 0.963415\n",
      "step 31390, cost 6.35418\n",
      "step 31390, change in cost 0.000401497\n",
      "step 31400, training accuracy 0.963415\n",
      "step 31400, cost 6.35378\n",
      "step 31400, change in cost 0.000401497\n",
      "step 31410, training accuracy 0.963415\n",
      "step 31410, cost 6.35338\n",
      "step 31410, change in cost 0.000402451\n",
      "step 31420, training accuracy 0.963415\n",
      "step 31420, cost 6.35298\n",
      "step 31420, change in cost 0.000401974\n",
      "step 31430, training accuracy 0.963415\n",
      "step 31430, cost 6.35258\n",
      "step 31430, change in cost 0.000398159\n",
      "step 31440, training accuracy 0.963415\n",
      "step 31440, cost 6.35218\n",
      "step 31440, change in cost 0.000401497\n",
      "step 31450, training accuracy 0.963415\n",
      "step 31450, cost 6.35178\n",
      "step 31450, change in cost 0.000400543\n",
      "step 31460, training accuracy 0.963415\n",
      "step 31460, cost 6.35138\n",
      "step 31460, change in cost 0.000401974\n",
      "step 31470, training accuracy 0.963415\n",
      "step 31470, cost 6.35098\n",
      "step 31470, change in cost 0.00040102\n",
      "step 31480, training accuracy 0.963415\n",
      "step 31480, cost 6.35057\n",
      "step 31480, change in cost 0.000400066\n",
      "step 31490, training accuracy 0.963415\n",
      "step 31490, cost 6.35018\n",
      "step 31490, change in cost 0.000399113\n",
      "step 31500, training accuracy 0.963415\n",
      "step 31500, cost 6.34978\n",
      "step 31500, change in cost 0.000400543\n",
      "step 31510, training accuracy 0.963415\n",
      "step 31510, cost 6.34938\n",
      "step 31510, change in cost 0.000398159\n",
      "step 31520, training accuracy 0.963415\n",
      "step 31520, cost 6.34898\n",
      "step 31520, change in cost 0.000399113\n",
      "step 31530, training accuracy 0.963415\n",
      "step 31530, cost 6.34858\n",
      "step 31530, change in cost 0.000398159\n",
      "step 31540, training accuracy 0.963415\n",
      "step 31540, cost 6.34818\n",
      "step 31540, change in cost 0.000399113\n",
      "step 31550, training accuracy 0.963415\n",
      "step 31550, cost 6.34778\n",
      "step 31550, change in cost 0.000398636\n",
      "step 31560, training accuracy 0.963415\n",
      "step 31560, cost 6.34738\n",
      "step 31560, change in cost 0.000398159\n",
      "step 31570, training accuracy 0.963415\n",
      "step 31570, cost 6.34699\n",
      "step 31570, change in cost 0.000398159\n",
      "step 31580, training accuracy 0.963415\n",
      "step 31580, cost 6.34659\n",
      "step 31580, change in cost 0.000397205\n",
      "step 31590, training accuracy 0.963415\n",
      "step 31590, cost 6.34619\n",
      "step 31590, change in cost 0.000398159\n",
      "step 31600, training accuracy 0.963415\n",
      "step 31600, cost 6.34579\n",
      "step 31600, change in cost 0.000397682\n",
      "step 31610, training accuracy 0.963415\n",
      "step 31610, cost 6.3454\n",
      "step 31610, change in cost 0.000397682\n",
      "step 31620, training accuracy 0.963415\n",
      "step 31620, cost 6.345\n",
      "step 31620, change in cost 0.000397682\n",
      "step 31630, training accuracy 0.963415\n",
      "step 31630, cost 6.3446\n",
      "step 31630, change in cost 0.000395775\n",
      "step 31640, training accuracy 0.963415\n",
      "step 31640, cost 6.3442\n",
      "step 31640, change in cost 0.000397205\n",
      "step 31650, training accuracy 0.963415\n",
      "step 31650, cost 6.34381\n",
      "step 31650, change in cost 0.000397682\n",
      "step 31660, training accuracy 0.963415\n",
      "step 31660, cost 6.34341\n",
      "step 31660, change in cost 0.000397682\n",
      "step 31670, training accuracy 0.963415\n",
      "step 31670, cost 6.34301\n",
      "step 31670, change in cost 0.000396252\n",
      "step 31680, training accuracy 0.963415\n",
      "step 31680, cost 6.34262\n",
      "step 31680, change in cost 0.000395775\n",
      "step 31690, training accuracy 0.963415\n",
      "step 31690, cost 6.34222\n",
      "step 31690, change in cost 0.000396729\n",
      "step 31700, training accuracy 0.963415\n",
      "step 31700, cost 6.34183\n",
      "step 31700, change in cost 0.000393867\n",
      "step 31710, training accuracy 0.963415\n",
      "step 31710, cost 6.34143\n",
      "step 31710, change in cost 0.000393867\n",
      "step 31720, training accuracy 0.963415\n",
      "step 31720, cost 6.34104\n",
      "step 31720, change in cost 0.000394344\n",
      "step 31730, training accuracy 0.963415\n",
      "step 31730, cost 6.34064\n",
      "step 31730, change in cost 0.000395298\n",
      "step 31740, training accuracy 0.963415\n",
      "step 31740, cost 6.34025\n",
      "step 31740, change in cost 0.000394344\n",
      "step 31750, training accuracy 0.963415\n",
      "step 31750, cost 6.33985\n",
      "step 31750, change in cost 0.000395298\n",
      "step 31760, training accuracy 0.963415\n",
      "step 31760, cost 6.33946\n",
      "step 31760, change in cost 0.000393867\n",
      "step 31770, training accuracy 0.963415\n",
      "step 31770, cost 6.33906\n",
      "step 31770, change in cost 0.000394821\n",
      "step 31780, training accuracy 0.963415\n",
      "step 31780, cost 6.33867\n",
      "step 31780, change in cost 0.000393867\n",
      "step 31790, training accuracy 0.963415\n",
      "step 31790, cost 6.33828\n",
      "step 31790, change in cost 0.000392914\n",
      "step 31800, training accuracy 0.963415\n",
      "step 31800, cost 6.33789\n",
      "step 31800, change in cost 0.00039196\n",
      "step 31810, training accuracy 0.963415\n",
      "step 31810, cost 6.33749\n",
      "step 31810, change in cost 0.000394344\n",
      "step 31820, training accuracy 0.963415\n",
      "step 31820, cost 6.3371\n",
      "step 31820, change in cost 0.00039196\n",
      "step 31830, training accuracy 0.963415\n",
      "step 31830, cost 6.33671\n",
      "step 31830, change in cost 0.000394344\n",
      "step 31840, training accuracy 0.963415\n",
      "step 31840, cost 6.33631\n",
      "step 31840, change in cost 0.00039196\n",
      "step 31850, training accuracy 0.963415\n",
      "step 31850, cost 6.33592\n",
      "step 31850, change in cost 0.000391483\n",
      "step 31860, training accuracy 0.963415\n",
      "step 31860, cost 6.33553\n",
      "step 31860, change in cost 0.000392437\n",
      "step 31870, training accuracy 0.963415\n",
      "step 31870, cost 6.33514\n",
      "step 31870, change in cost 0.000390053\n",
      "step 31880, training accuracy 0.963415\n",
      "step 31880, cost 6.33475\n",
      "step 31880, change in cost 0.00039196\n",
      "step 31890, training accuracy 0.963415\n",
      "step 31890, cost 6.33435\n",
      "step 31890, change in cost 0.000392437\n",
      "step 31900, training accuracy 0.963415\n",
      "step 31900, cost 6.33396\n",
      "step 31900, change in cost 0.000391483\n",
      "step 31910, training accuracy 0.963415\n",
      "step 31910, cost 6.33357\n",
      "step 31910, change in cost 0.000389576\n",
      "step 31920, training accuracy 0.963415\n",
      "step 31920, cost 6.33318\n",
      "step 31920, change in cost 0.000391006\n",
      "step 31930, training accuracy 0.963415\n",
      "step 31930, cost 6.33279\n",
      "step 31930, change in cost 0.00039196\n",
      "step 31940, training accuracy 0.963415\n",
      "step 31940, cost 6.3324\n",
      "step 31940, change in cost 0.000388622\n",
      "step 31950, training accuracy 0.963415\n",
      "step 31950, cost 6.33201\n",
      "step 31950, change in cost 0.000391006\n",
      "step 31960, training accuracy 0.963415\n",
      "step 31960, cost 6.33162\n",
      "step 31960, change in cost 0.000389099\n",
      "step 31970, training accuracy 0.963415\n",
      "step 31970, cost 6.33123\n",
      "step 31970, change in cost 0.000390053\n",
      "step 31980, training accuracy 0.963415\n",
      "step 31980, cost 6.33084\n",
      "step 31980, change in cost 0.000389099\n",
      "step 31990, training accuracy 0.963415\n",
      "step 31990, cost 6.33045\n",
      "step 31990, change in cost 0.00039053\n",
      "step 32000, training accuracy 0.963415\n",
      "step 32000, cost 6.33006\n",
      "step 32000, change in cost 0.000391006\n",
      "step 32010, training accuracy 0.963415\n",
      "step 32010, cost 6.32967\n",
      "step 32010, change in cost 0.000386715\n",
      "step 32020, training accuracy 0.963415\n",
      "step 32020, cost 6.32928\n",
      "step 32020, change in cost 0.000390053\n",
      "step 32030, training accuracy 0.963415\n",
      "step 32030, cost 6.3289\n",
      "step 32030, change in cost 0.000387192\n",
      "step 32040, training accuracy 0.963415\n",
      "step 32040, cost 6.32851\n",
      "step 32040, change in cost 0.000388145\n",
      "step 32050, training accuracy 0.963415\n",
      "step 32050, cost 6.32812\n",
      "step 32050, change in cost 0.000387669\n",
      "step 32060, training accuracy 0.963415\n",
      "step 32060, cost 6.32773\n",
      "step 32060, change in cost 0.000388622\n",
      "step 32070, training accuracy 0.963415\n",
      "step 32070, cost 6.32735\n",
      "step 32070, change in cost 0.000387192\n",
      "step 32080, training accuracy 0.963415\n",
      "step 32080, cost 6.32696\n",
      "step 32080, change in cost 0.000387669\n",
      "step 32090, training accuracy 0.963415\n",
      "step 32090, cost 6.32657\n",
      "step 32090, change in cost 0.000387669\n",
      "step 32100, training accuracy 0.963415\n",
      "step 32100, cost 6.32618\n",
      "step 32100, change in cost 0.000386715\n",
      "step 32110, training accuracy 0.963415\n",
      "step 32110, cost 6.3258\n",
      "step 32110, change in cost 0.000387192\n",
      "step 32120, training accuracy 0.963415\n",
      "step 32120, cost 6.32541\n",
      "step 32120, change in cost 0.000385761\n",
      "step 32130, training accuracy 0.963415\n",
      "step 32130, cost 6.32502\n",
      "step 32130, change in cost 0.000386238\n",
      "step 32140, training accuracy 0.963415\n",
      "step 32140, cost 6.32464\n",
      "step 32140, change in cost 0.000386715\n",
      "step 32150, training accuracy 0.963415\n",
      "step 32150, cost 6.32425\n",
      "step 32150, change in cost 0.000384808\n",
      "step 32160, training accuracy 0.963415\n",
      "step 32160, cost 6.32387\n",
      "step 32160, change in cost 0.000386238\n",
      "step 32170, training accuracy 0.963415\n",
      "step 32170, cost 6.32348\n",
      "step 32170, change in cost 0.000384331\n",
      "step 32180, training accuracy 0.963415\n",
      "step 32180, cost 6.3231\n",
      "step 32180, change in cost 0.000386238\n",
      "step 32190, training accuracy 0.963415\n",
      "step 32190, cost 6.32271\n",
      "step 32190, change in cost 0.000385284\n",
      "step 32200, training accuracy 0.963415\n",
      "step 32200, cost 6.32233\n",
      "step 32200, change in cost 0.000383377\n",
      "step 32210, training accuracy 0.963415\n",
      "step 32210, cost 6.32194\n",
      "step 32210, change in cost 0.000387192\n",
      "step 32220, training accuracy 0.963415\n",
      "step 32220, cost 6.32156\n",
      "step 32220, change in cost 0.000384331\n",
      "step 32230, training accuracy 0.963415\n",
      "step 32230, cost 6.32117\n",
      "step 32230, change in cost 0.000384331\n",
      "step 32240, training accuracy 0.963415\n",
      "step 32240, cost 6.32079\n",
      "step 32240, change in cost 0.000383377\n",
      "step 32250, training accuracy 0.963415\n",
      "step 32250, cost 6.3204\n",
      "step 32250, change in cost 0.000385284\n",
      "step 32260, training accuracy 0.963415\n",
      "step 32260, cost 6.32002\n",
      "step 32260, change in cost 0.0003829\n",
      "step 32270, training accuracy 0.963415\n",
      "step 32270, cost 6.31964\n",
      "step 32270, change in cost 0.000383854\n",
      "step 32280, training accuracy 0.963415\n",
      "step 32280, cost 6.31925\n",
      "step 32280, change in cost 0.000382423\n",
      "step 32290, training accuracy 0.963415\n",
      "step 32290, cost 6.31887\n",
      "step 32290, change in cost 0.000384331\n",
      "step 32300, training accuracy 0.963415\n",
      "step 32300, cost 6.31849\n",
      "step 32300, change in cost 0.000383377\n",
      "step 32310, training accuracy 0.963415\n",
      "step 32310, cost 6.3181\n",
      "step 32310, change in cost 0.00038147\n",
      "step 32320, training accuracy 0.963415\n",
      "step 32320, cost 6.31772\n",
      "step 32320, change in cost 0.000382423\n",
      "step 32330, training accuracy 0.963415\n",
      "step 32330, cost 6.31734\n",
      "step 32330, change in cost 0.000383377\n",
      "step 32340, training accuracy 0.963415\n",
      "step 32340, cost 6.31696\n",
      "step 32340, change in cost 0.00038147\n",
      "step 32350, training accuracy 0.963415\n",
      "step 32350, cost 6.31658\n",
      "step 32350, change in cost 0.00038147\n",
      "step 32360, training accuracy 0.963415\n",
      "step 32360, cost 6.31619\n",
      "step 32360, change in cost 0.00038147\n",
      "step 32370, training accuracy 0.963415\n",
      "step 32370, cost 6.31581\n",
      "step 32370, change in cost 0.000381947\n",
      "step 32380, training accuracy 0.963415\n",
      "step 32380, cost 6.31543\n",
      "step 32380, change in cost 0.000382423\n",
      "step 32390, training accuracy 0.963415\n",
      "step 32390, cost 6.31505\n",
      "step 32390, change in cost 0.000379562\n",
      "step 32400, training accuracy 0.963415\n",
      "step 32400, cost 6.31467\n",
      "step 32400, change in cost 0.000380516\n",
      "step 32410, training accuracy 0.963415\n",
      "step 32410, cost 6.31429\n",
      "step 32410, change in cost 0.0003829\n",
      "step 32420, training accuracy 0.963415\n",
      "step 32420, cost 6.31391\n",
      "step 32420, change in cost 0.000378609\n",
      "step 32430, training accuracy 0.963415\n",
      "step 32430, cost 6.31353\n",
      "step 32430, change in cost 0.00038147\n",
      "step 32440, training accuracy 0.963415\n",
      "step 32440, cost 6.31315\n",
      "step 32440, change in cost 0.000379086\n",
      "step 32450, training accuracy 0.963415\n",
      "step 32450, cost 6.31277\n",
      "step 32450, change in cost 0.000380039\n",
      "step 32460, training accuracy 0.963415\n",
      "step 32460, cost 6.31239\n",
      "step 32460, change in cost 0.000380516\n",
      "step 32470, training accuracy 0.963415\n",
      "step 32470, cost 6.31201\n",
      "step 32470, change in cost 0.000380039\n",
      "step 32480, training accuracy 0.963415\n",
      "step 32480, cost 6.31163\n",
      "step 32480, change in cost 0.000379086\n",
      "step 32490, training accuracy 0.963415\n",
      "step 32490, cost 6.31125\n",
      "step 32490, change in cost 0.000379086\n",
      "step 32500, training accuracy 0.963415\n",
      "step 32500, cost 6.31087\n",
      "step 32500, change in cost 0.000379086\n",
      "step 32510, training accuracy 0.963415\n",
      "step 32510, cost 6.31049\n",
      "step 32510, change in cost 0.000378132\n",
      "step 32520, training accuracy 0.963415\n",
      "step 32520, cost 6.31011\n",
      "step 32520, change in cost 0.000380039\n",
      "step 32530, training accuracy 0.963415\n",
      "step 32530, cost 6.30973\n",
      "step 32530, change in cost 0.000377655\n",
      "step 32540, training accuracy 0.963415\n",
      "step 32540, cost 6.30936\n",
      "step 32540, change in cost 0.000377655\n",
      "step 32550, training accuracy 0.963415\n",
      "step 32550, cost 6.30898\n",
      "step 32550, change in cost 0.000377655\n",
      "step 32560, training accuracy 0.963415\n",
      "step 32560, cost 6.3086\n",
      "step 32560, change in cost 0.000378609\n",
      "step 32570, training accuracy 0.963415\n",
      "step 32570, cost 6.30822\n",
      "step 32570, change in cost 0.000377655\n",
      "step 32580, training accuracy 0.963415\n",
      "step 32580, cost 6.30785\n",
      "step 32580, change in cost 0.000377655\n",
      "step 32590, training accuracy 0.963415\n",
      "step 32590, cost 6.30747\n",
      "step 32590, change in cost 0.000378609\n",
      "step 32600, training accuracy 0.963415\n",
      "step 32600, cost 6.30709\n",
      "step 32600, change in cost 0.000375748\n",
      "step 32610, training accuracy 0.963415\n",
      "step 32610, cost 6.30671\n",
      "step 32610, change in cost 0.000378132\n",
      "step 32620, training accuracy 0.963415\n",
      "step 32620, cost 6.30633\n",
      "step 32620, change in cost 0.000378132\n",
      "step 32630, training accuracy 0.963415\n",
      "step 32630, cost 6.30596\n",
      "step 32630, change in cost 0.000375271\n",
      "step 32640, training accuracy 0.963415\n",
      "step 32640, cost 6.30558\n",
      "step 32640, change in cost 0.000376225\n",
      "step 32650, training accuracy 0.963415\n",
      "step 32650, cost 6.30521\n",
      "step 32650, change in cost 0.000376225\n",
      "step 32660, training accuracy 0.963415\n",
      "step 32660, cost 6.30483\n",
      "step 32660, change in cost 0.000374794\n",
      "step 32670, training accuracy 0.963415\n",
      "step 32670, cost 6.30446\n",
      "step 32670, change in cost 0.000375748\n",
      "step 32680, training accuracy 0.963415\n",
      "step 32680, cost 6.30408\n",
      "step 32680, change in cost 0.000376225\n",
      "step 32690, training accuracy 0.963415\n",
      "step 32690, cost 6.3037\n",
      "step 32690, change in cost 0.000375748\n",
      "step 32700, training accuracy 0.963415\n",
      "step 32700, cost 6.30333\n",
      "step 32700, change in cost 0.000375271\n",
      "step 32710, training accuracy 0.963415\n",
      "step 32710, cost 6.30296\n",
      "step 32710, change in cost 0.000373363\n",
      "step 32720, training accuracy 0.963415\n",
      "step 32720, cost 6.30258\n",
      "step 32720, change in cost 0.000375748\n",
      "step 32730, training accuracy 0.963415\n",
      "step 32730, cost 6.30221\n",
      "step 32730, change in cost 0.000374317\n",
      "step 32740, training accuracy 0.963415\n",
      "step 32740, cost 6.30183\n",
      "step 32740, change in cost 0.000374317\n",
      "step 32750, training accuracy 0.963415\n",
      "step 32750, cost 6.30146\n",
      "step 32750, change in cost 0.000375271\n",
      "step 32760, training accuracy 0.963415\n",
      "step 32760, cost 6.30108\n",
      "step 32760, change in cost 0.00037241\n",
      "step 32770, training accuracy 0.963415\n",
      "step 32770, cost 6.30071\n",
      "step 32770, change in cost 0.00037384\n",
      "step 32780, training accuracy 0.963415\n",
      "step 32780, cost 6.30034\n",
      "step 32780, change in cost 0.00037384\n",
      "step 32790, training accuracy 0.963415\n",
      "step 32790, cost 6.29996\n",
      "step 32790, change in cost 0.00037384\n",
      "step 32800, training accuracy 0.963415\n",
      "step 32800, cost 6.29959\n",
      "step 32800, change in cost 0.000372887\n",
      "step 32810, training accuracy 0.963415\n",
      "step 32810, cost 6.29922\n",
      "step 32810, change in cost 0.000372887\n",
      "step 32820, training accuracy 0.963415\n",
      "step 32820, cost 6.29884\n",
      "step 32820, change in cost 0.00037241\n",
      "step 32830, training accuracy 0.963415\n",
      "step 32830, cost 6.29847\n",
      "step 32830, change in cost 0.000373363\n",
      "step 32840, training accuracy 0.963415\n",
      "step 32840, cost 6.2981\n",
      "step 32840, change in cost 0.000372887\n",
      "step 32850, training accuracy 0.963415\n",
      "step 32850, cost 6.29772\n",
      "step 32850, change in cost 0.00037384\n",
      "step 32860, training accuracy 0.963415\n",
      "step 32860, cost 6.29735\n",
      "step 32860, change in cost 0.000370502\n",
      "step 32870, training accuracy 0.963415\n",
      "step 32870, cost 6.29698\n",
      "step 32870, change in cost 0.000371933\n",
      "step 32880, training accuracy 0.963415\n",
      "step 32880, cost 6.29661\n",
      "step 32880, change in cost 0.000372887\n",
      "step 32890, training accuracy 0.963415\n",
      "step 32890, cost 6.29624\n",
      "step 32890, change in cost 0.000371456\n",
      "step 32900, training accuracy 0.963415\n",
      "step 32900, cost 6.29587\n",
      "step 32900, change in cost 0.000370502\n",
      "step 32910, training accuracy 0.963415\n",
      "step 32910, cost 6.2955\n",
      "step 32910, change in cost 0.000370502\n",
      "step 32920, training accuracy 0.963415\n",
      "step 32920, cost 6.29513\n",
      "step 32920, change in cost 0.000370979\n",
      "step 32930, training accuracy 0.963415\n",
      "step 32930, cost 6.29475\n",
      "step 32930, change in cost 0.000370979\n",
      "step 32940, training accuracy 0.963415\n",
      "step 32940, cost 6.29438\n",
      "step 32940, change in cost 0.000371933\n",
      "step 32950, training accuracy 0.963415\n",
      "step 32950, cost 6.29401\n",
      "step 32950, change in cost 0.000369549\n",
      "step 32960, training accuracy 0.963415\n",
      "step 32960, cost 6.29364\n",
      "step 32960, change in cost 0.000371456\n",
      "step 32970, training accuracy 0.963415\n",
      "step 32970, cost 6.29327\n",
      "step 32970, change in cost 0.000370026\n",
      "step 32980, training accuracy 0.963415\n",
      "step 32980, cost 6.2929\n",
      "step 32980, change in cost 0.000369072\n",
      "step 32990, training accuracy 0.963415\n",
      "step 32990, cost 6.29253\n",
      "step 32990, change in cost 0.000370502\n",
      "step 33000, training accuracy 0.963415\n",
      "step 33000, cost 6.29216\n",
      "step 33000, change in cost 0.000370502\n",
      "step 33010, training accuracy 0.963415\n",
      "step 33010, cost 6.29179\n",
      "step 33010, change in cost 0.000367641\n",
      "step 33020, training accuracy 0.963415\n",
      "step 33020, cost 6.29142\n",
      "step 33020, change in cost 0.000368595\n",
      "step 33030, training accuracy 0.963415\n",
      "step 33030, cost 6.29105\n",
      "step 33030, change in cost 0.000370026\n",
      "step 33040, training accuracy 0.963415\n",
      "step 33040, cost 6.29069\n",
      "step 33040, change in cost 0.000368118\n",
      "step 33050, training accuracy 0.963415\n",
      "step 33050, cost 6.29032\n",
      "step 33050, change in cost 0.000370026\n",
      "step 33060, training accuracy 0.963415\n",
      "step 33060, cost 6.28995\n",
      "step 33060, change in cost 0.000368595\n",
      "step 33070, training accuracy 0.963415\n",
      "step 33070, cost 6.28958\n",
      "step 33070, change in cost 0.000368595\n",
      "step 33080, training accuracy 0.963415\n",
      "step 33080, cost 6.28921\n",
      "step 33080, change in cost 0.000367641\n",
      "step 33090, training accuracy 0.963415\n",
      "step 33090, cost 6.28884\n",
      "step 33090, change in cost 0.000368595\n",
      "step 33100, training accuracy 0.963415\n",
      "step 33100, cost 6.28848\n",
      "step 33100, change in cost 0.000367165\n",
      "step 33110, training accuracy 0.963415\n",
      "step 33110, cost 6.28811\n",
      "step 33110, change in cost 0.000369072\n",
      "step 33120, training accuracy 0.963415\n",
      "step 33120, cost 6.28774\n",
      "step 33120, change in cost 0.000367641\n",
      "step 33130, training accuracy 0.963415\n",
      "step 33130, cost 6.28737\n",
      "step 33130, change in cost 0.000366688\n",
      "step 33140, training accuracy 0.963415\n",
      "step 33140, cost 6.287\n",
      "step 33140, change in cost 0.000368118\n",
      "step 33150, training accuracy 0.963415\n",
      "step 33150, cost 6.28664\n",
      "step 33150, change in cost 0.000367165\n",
      "step 33160, training accuracy 0.963415\n",
      "step 33160, cost 6.28627\n",
      "step 33160, change in cost 0.000367165\n",
      "step 33170, training accuracy 0.963415\n",
      "step 33170, cost 6.2859\n",
      "step 33170, change in cost 0.000366211\n",
      "step 33180, training accuracy 0.963415\n",
      "step 33180, cost 6.28554\n",
      "step 33180, change in cost 0.000365257\n",
      "step 33190, training accuracy 0.963415\n",
      "step 33190, cost 6.28517\n",
      "step 33190, change in cost 0.000367165\n",
      "step 33200, training accuracy 0.963415\n",
      "step 33200, cost 6.2848\n",
      "step 33200, change in cost 0.000367641\n",
      "step 33210, training accuracy 0.963415\n",
      "step 33210, cost 6.28444\n",
      "step 33210, change in cost 0.000364304\n",
      "step 33220, training accuracy 0.963415\n",
      "step 33220, cost 6.28407\n",
      "step 33220, change in cost 0.000365734\n",
      "step 33230, training accuracy 0.963415\n",
      "step 33230, cost 6.28371\n",
      "step 33230, change in cost 0.000366211\n",
      "step 33240, training accuracy 0.963415\n",
      "step 33240, cost 6.28334\n",
      "step 33240, change in cost 0.000364304\n",
      "step 33250, training accuracy 0.963415\n",
      "step 33250, cost 6.28298\n",
      "step 33250, change in cost 0.00036335\n",
      "step 33260, training accuracy 0.963415\n",
      "step 33260, cost 6.28261\n",
      "step 33260, change in cost 0.000365734\n",
      "step 33270, training accuracy 0.963415\n",
      "step 33270, cost 6.28225\n",
      "step 33270, change in cost 0.000365257\n",
      "step 33280, training accuracy 0.963415\n",
      "step 33280, cost 6.28188\n",
      "step 33280, change in cost 0.000364304\n",
      "step 33290, training accuracy 0.963415\n",
      "step 33290, cost 6.28152\n",
      "step 33290, change in cost 0.00036335\n",
      "step 33300, training accuracy 0.963415\n",
      "step 33300, cost 6.28116\n",
      "step 33300, change in cost 0.000366211\n",
      "step 33310, training accuracy 0.963415\n",
      "step 33310, cost 6.28079\n",
      "step 33310, change in cost 0.00036335\n",
      "step 33320, training accuracy 0.963415\n",
      "step 33320, cost 6.28043\n",
      "step 33320, change in cost 0.000362873\n",
      "step 33330, training accuracy 0.963415\n",
      "step 33330, cost 6.28006\n",
      "step 33330, change in cost 0.000364304\n",
      "step 33340, training accuracy 0.963415\n",
      "step 33340, cost 6.2797\n",
      "step 33340, change in cost 0.00036335\n",
      "step 33350, training accuracy 0.963415\n",
      "step 33350, cost 6.27934\n",
      "step 33350, change in cost 0.00036335\n",
      "step 33360, training accuracy 0.963415\n",
      "step 33360, cost 6.27898\n",
      "step 33360, change in cost 0.000362396\n",
      "step 33370, training accuracy 0.963415\n",
      "step 33370, cost 6.27861\n",
      "step 33370, change in cost 0.00036335\n",
      "step 33380, training accuracy 0.963415\n",
      "step 33380, cost 6.27825\n",
      "step 33380, change in cost 0.000362396\n",
      "step 33390, training accuracy 0.963415\n",
      "step 33390, cost 6.27789\n",
      "step 33390, change in cost 0.00036335\n",
      "step 33400, training accuracy 0.963415\n",
      "step 33400, cost 6.27752\n",
      "step 33400, change in cost 0.000362873\n",
      "step 33410, training accuracy 0.963415\n",
      "step 33410, cost 6.27716\n",
      "step 33410, change in cost 0.000360489\n",
      "step 33420, training accuracy 0.963415\n",
      "step 33420, cost 6.2768\n",
      "step 33420, change in cost 0.000362873\n",
      "step 33430, training accuracy 0.963415\n",
      "step 33430, cost 6.27644\n",
      "step 33430, change in cost 0.000362873\n",
      "step 33440, training accuracy 0.963415\n",
      "step 33440, cost 6.27608\n",
      "step 33440, change in cost 0.000361919\n",
      "step 33450, training accuracy 0.963415\n",
      "step 33450, cost 6.27571\n",
      "step 33450, change in cost 0.000361443\n",
      "step 33460, training accuracy 0.963415\n",
      "step 33460, cost 6.27535\n",
      "step 33460, change in cost 0.000360489\n",
      "step 33470, training accuracy 0.963415\n",
      "step 33470, cost 6.27499\n",
      "step 33470, change in cost 0.000361919\n",
      "step 33480, training accuracy 0.963415\n",
      "step 33480, cost 6.27463\n",
      "step 33480, change in cost 0.000360012\n",
      "step 33490, training accuracy 0.963415\n",
      "step 33490, cost 6.27427\n",
      "step 33490, change in cost 0.000361443\n",
      "step 33500, training accuracy 0.963415\n",
      "step 33500, cost 6.27391\n",
      "step 33500, change in cost 0.000361443\n",
      "step 33510, training accuracy 0.963415\n",
      "step 33510, cost 6.27355\n",
      "step 33510, change in cost 0.000360489\n",
      "step 33520, training accuracy 0.963415\n",
      "step 33520, cost 6.27319\n",
      "step 33520, change in cost 0.000360489\n",
      "step 33530, training accuracy 0.963415\n",
      "step 33530, cost 6.27283\n",
      "step 33530, change in cost 0.000359058\n",
      "step 33540, training accuracy 0.963415\n",
      "step 33540, cost 6.27247\n",
      "step 33540, change in cost 0.000360012\n",
      "step 33550, training accuracy 0.963415\n",
      "step 33550, cost 6.27211\n",
      "step 33550, change in cost 0.000359535\n",
      "step 33560, training accuracy 0.963415\n",
      "step 33560, cost 6.27175\n",
      "step 33560, change in cost 0.000359535\n",
      "step 33570, training accuracy 0.963415\n",
      "step 33570, cost 6.27139\n",
      "step 33570, change in cost 0.000360966\n",
      "step 33580, training accuracy 0.963415\n",
      "step 33580, cost 6.27103\n",
      "step 33580, change in cost 0.000357151\n",
      "step 33590, training accuracy 0.963415\n",
      "step 33590, cost 6.27067\n",
      "step 33590, change in cost 0.000360012\n",
      "step 33600, training accuracy 0.963415\n",
      "step 33600, cost 6.27031\n",
      "step 33600, change in cost 0.000358582\n",
      "step 33610, training accuracy 0.963415\n",
      "step 33610, cost 6.26995\n",
      "step 33610, change in cost 0.000358105\n",
      "step 33620, training accuracy 0.963415\n",
      "step 33620, cost 6.26959\n",
      "step 33620, change in cost 0.000360012\n",
      "step 33630, training accuracy 0.963415\n",
      "step 33630, cost 6.26924\n",
      "step 33630, change in cost 0.000358105\n",
      "step 33640, training accuracy 0.963415\n",
      "step 33640, cost 6.26888\n",
      "step 33640, change in cost 0.000357628\n",
      "step 33650, training accuracy 0.963415\n",
      "step 33650, cost 6.26852\n",
      "step 33650, change in cost 0.000357628\n",
      "step 33660, training accuracy 0.963415\n",
      "step 33660, cost 6.26816\n",
      "step 33660, change in cost 0.000358582\n",
      "step 33670, training accuracy 0.963415\n",
      "step 33670, cost 6.26781\n",
      "step 33670, change in cost 0.000355721\n",
      "step 33680, training accuracy 0.963415\n",
      "step 33680, cost 6.26745\n",
      "step 33680, change in cost 0.000359058\n",
      "step 33690, training accuracy 0.963415\n",
      "step 33690, cost 6.26709\n",
      "step 33690, change in cost 0.000356197\n",
      "step 33700, training accuracy 0.963415\n",
      "step 33700, cost 6.26673\n",
      "step 33700, change in cost 0.000359058\n",
      "step 33710, training accuracy 0.963415\n",
      "step 33710, cost 6.26638\n",
      "step 33710, change in cost 0.000356197\n",
      "step 33720, training accuracy 0.963415\n",
      "step 33720, cost 6.26602\n",
      "step 33720, change in cost 0.000357628\n",
      "step 33730, training accuracy 0.963415\n",
      "step 33730, cost 6.26566\n",
      "step 33730, change in cost 0.000356674\n",
      "step 33740, training accuracy 0.963415\n",
      "step 33740, cost 6.26531\n",
      "step 33740, change in cost 0.00035429\n",
      "step 33750, training accuracy 0.963415\n",
      "step 33750, cost 6.26495\n",
      "step 33750, change in cost 0.000357151\n",
      "step 33760, training accuracy 0.963415\n",
      "step 33760, cost 6.26459\n",
      "step 33760, change in cost 0.000356197\n",
      "step 33770, training accuracy 0.963415\n",
      "step 33770, cost 6.26424\n",
      "step 33770, change in cost 0.000355721\n",
      "step 33780, training accuracy 0.963415\n",
      "step 33780, cost 6.26388\n",
      "step 33780, change in cost 0.000355721\n",
      "step 33790, training accuracy 0.963415\n",
      "step 33790, cost 6.26353\n",
      "step 33790, change in cost 0.000355244\n",
      "step 33800, training accuracy 0.963415\n",
      "step 33800, cost 6.26317\n",
      "step 33800, change in cost 0.000355244\n",
      "step 33810, training accuracy 0.963415\n",
      "step 33810, cost 6.26282\n",
      "step 33810, change in cost 0.000355721\n",
      "step 33820, training accuracy 0.963415\n",
      "step 33820, cost 6.26246\n",
      "step 33820, change in cost 0.000356197\n",
      "step 33830, training accuracy 0.963415\n",
      "step 33830, cost 6.2621\n",
      "step 33830, change in cost 0.000355721\n",
      "step 33840, training accuracy 0.963415\n",
      "step 33840, cost 6.26175\n",
      "step 33840, change in cost 0.000355244\n",
      "step 33850, training accuracy 0.963415\n",
      "step 33850, cost 6.26139\n",
      "step 33850, change in cost 0.000354767\n",
      "step 33860, training accuracy 0.963415\n",
      "step 33860, cost 6.26104\n",
      "step 33860, change in cost 0.00035429\n",
      "step 33870, training accuracy 0.963415\n",
      "step 33870, cost 6.26069\n",
      "step 33870, change in cost 0.00035429\n",
      "step 33880, training accuracy 0.963415\n",
      "step 33880, cost 6.26033\n",
      "step 33880, change in cost 0.000355721\n",
      "step 33890, training accuracy 0.963415\n",
      "step 33890, cost 6.25998\n",
      "step 33890, change in cost 0.000353336\n",
      "step 33900, training accuracy 0.963415\n",
      "step 33900, cost 6.25962\n",
      "step 33900, change in cost 0.000353813\n",
      "step 33910, training accuracy 0.963415\n",
      "step 33910, cost 6.25927\n",
      "step 33910, change in cost 0.000353813\n",
      "step 33920, training accuracy 0.963415\n",
      "step 33920, cost 6.25892\n",
      "step 33920, change in cost 0.000353813\n",
      "step 33930, training accuracy 0.963415\n",
      "step 33930, cost 6.25856\n",
      "step 33930, change in cost 0.00035429\n",
      "step 33940, training accuracy 0.963415\n",
      "step 33940, cost 6.25821\n",
      "step 33940, change in cost 0.000351429\n",
      "step 33950, training accuracy 0.963415\n",
      "step 33950, cost 6.25786\n",
      "step 33950, change in cost 0.000354767\n",
      "step 33960, training accuracy 0.963415\n",
      "step 33960, cost 6.2575\n",
      "step 33960, change in cost 0.000352859\n",
      "step 33970, training accuracy 0.963415\n",
      "step 33970, cost 6.25715\n",
      "step 33970, change in cost 0.000352859\n",
      "step 33980, training accuracy 0.963415\n",
      "step 33980, cost 6.2568\n",
      "step 33980, change in cost 0.00035429\n",
      "step 33990, training accuracy 0.963415\n",
      "step 33990, cost 6.25644\n",
      "step 33990, change in cost 0.000351429\n",
      "step 34000, training accuracy 0.963415\n",
      "step 34000, cost 6.25609\n",
      "step 34000, change in cost 0.000352859\n",
      "step 34010, training accuracy 0.963415\n",
      "step 34010, cost 6.25574\n",
      "step 34010, change in cost 0.000351906\n",
      "step 34020, training accuracy 0.963415\n",
      "step 34020, cost 6.25539\n",
      "step 34020, change in cost 0.000352859\n",
      "step 34030, training accuracy 0.963415\n",
      "step 34030, cost 6.25503\n",
      "step 34030, change in cost 0.000351906\n",
      "step 34040, training accuracy 0.963415\n",
      "step 34040, cost 6.25468\n",
      "step 34040, change in cost 0.000351906\n",
      "step 34050, training accuracy 0.963415\n",
      "step 34050, cost 6.25433\n",
      "step 34050, change in cost 0.000351906\n",
      "step 34060, training accuracy 0.963415\n",
      "step 34060, cost 6.25398\n",
      "step 34060, change in cost 0.000349045\n",
      "step 34070, training accuracy 0.963415\n",
      "step 34070, cost 6.25363\n",
      "step 34070, change in cost 0.000351429\n",
      "step 34080, training accuracy 0.963415\n",
      "step 34080, cost 6.25328\n",
      "step 34080, change in cost 0.000350952\n",
      "step 34090, training accuracy 0.963415\n",
      "step 34090, cost 6.25293\n",
      "step 34090, change in cost 0.000351429\n",
      "step 34100, training accuracy 0.963415\n",
      "step 34100, cost 6.25258\n",
      "step 34100, change in cost 0.000350952\n",
      "step 34110, training accuracy 0.963415\n",
      "step 34110, cost 6.25223\n",
      "step 34110, change in cost 0.000350952\n",
      "step 34120, training accuracy 0.963415\n",
      "step 34120, cost 6.25188\n",
      "step 34120, change in cost 0.000350475\n",
      "step 34130, training accuracy 0.963415\n",
      "step 34130, cost 6.25153\n",
      "step 34130, change in cost 0.000349045\n",
      "step 34140, training accuracy 0.963415\n",
      "step 34140, cost 6.25117\n",
      "step 34140, change in cost 0.000351429\n",
      "step 34150, training accuracy 0.963415\n",
      "step 34150, cost 6.25083\n",
      "step 34150, change in cost 0.000348091\n",
      "step 34160, training accuracy 0.963415\n",
      "step 34160, cost 6.25048\n",
      "step 34160, change in cost 0.000348568\n",
      "step 34170, training accuracy 0.963415\n",
      "step 34170, cost 6.25013\n",
      "step 34170, change in cost 0.000350475\n",
      "step 34180, training accuracy 0.963415\n",
      "step 34180, cost 6.24978\n",
      "step 34180, change in cost 0.000349998\n",
      "step 34190, training accuracy 0.963415\n",
      "step 34190, cost 6.24943\n",
      "step 34190, change in cost 0.000349522\n",
      "step 34200, training accuracy 0.963415\n",
      "step 34200, cost 6.24908\n",
      "step 34200, change in cost 0.000348568\n",
      "step 34210, training accuracy 0.963415\n",
      "step 34210, cost 6.24873\n",
      "step 34210, change in cost 0.000348568\n",
      "step 34220, training accuracy 0.963415\n",
      "step 34220, cost 6.24838\n",
      "step 34220, change in cost 0.000349522\n",
      "step 34230, training accuracy 0.963415\n",
      "step 34230, cost 6.24803\n",
      "step 34230, change in cost 0.000348091\n",
      "step 34240, training accuracy 0.963415\n",
      "step 34240, cost 6.24769\n",
      "step 34240, change in cost 0.000348091\n",
      "step 34250, training accuracy 0.963415\n",
      "step 34250, cost 6.24734\n",
      "step 34250, change in cost 0.000348091\n",
      "step 34260, training accuracy 0.963415\n",
      "step 34260, cost 6.24699\n",
      "step 34260, change in cost 0.000346184\n",
      "step 34270, training accuracy 0.963415\n",
      "step 34270, cost 6.24664\n",
      "step 34270, change in cost 0.000347614\n",
      "step 34280, training accuracy 0.963415\n",
      "step 34280, cost 6.2463\n",
      "step 34280, change in cost 0.000347614\n",
      "step 34290, training accuracy 0.963415\n",
      "step 34290, cost 6.24595\n",
      "step 34290, change in cost 0.000349998\n",
      "step 34300, training accuracy 0.963415\n",
      "step 34300, cost 6.2456\n",
      "step 34300, change in cost 0.000346661\n",
      "step 34310, training accuracy 0.963415\n",
      "step 34310, cost 6.24525\n",
      "step 34310, change in cost 0.000347614\n",
      "step 34320, training accuracy 0.963415\n",
      "step 34320, cost 6.2449\n",
      "step 34320, change in cost 0.000347137\n",
      "step 34330, training accuracy 0.963415\n",
      "step 34330, cost 6.24456\n",
      "step 34330, change in cost 0.000347137\n",
      "step 34340, training accuracy 0.963415\n",
      "step 34340, cost 6.24421\n",
      "step 34340, change in cost 0.000346184\n",
      "step 34350, training accuracy 0.963415\n",
      "step 34350, cost 6.24387\n",
      "step 34350, change in cost 0.000346184\n",
      "step 34360, training accuracy 0.963415\n",
      "step 34360, cost 6.24352\n",
      "step 34360, change in cost 0.000346184\n",
      "step 34370, training accuracy 0.963415\n",
      "step 34370, cost 6.24317\n",
      "step 34370, change in cost 0.000346184\n",
      "step 34380, training accuracy 0.963415\n",
      "step 34380, cost 6.24283\n",
      "step 34380, change in cost 0.000345707\n",
      "step 34390, training accuracy 0.963415\n",
      "step 34390, cost 6.24248\n",
      "step 34390, change in cost 0.000346184\n",
      "step 34400, training accuracy 0.963415\n",
      "step 34400, cost 6.24214\n",
      "step 34400, change in cost 0.00034523\n",
      "step 34410, training accuracy 0.963415\n",
      "step 34410, cost 6.24179\n",
      "step 34410, change in cost 0.00034523\n",
      "step 34420, training accuracy 0.963415\n",
      "step 34420, cost 6.24144\n",
      "step 34420, change in cost 0.000346184\n",
      "step 34430, training accuracy 0.963415\n",
      "step 34430, cost 6.2411\n",
      "step 34430, change in cost 0.000345707\n",
      "step 34440, training accuracy 0.963415\n",
      "step 34440, cost 6.24075\n",
      "step 34440, change in cost 0.000344276\n",
      "step 34450, training accuracy 0.963415\n",
      "step 34450, cost 6.24041\n",
      "step 34450, change in cost 0.000346184\n",
      "step 34460, training accuracy 0.963415\n",
      "step 34460, cost 6.24006\n",
      "step 34460, change in cost 0.000344276\n",
      "step 34470, training accuracy 0.963415\n",
      "step 34470, cost 6.23972\n",
      "step 34470, change in cost 0.00034523\n",
      "step 34480, training accuracy 0.963415\n",
      "step 34480, cost 6.23938\n",
      "step 34480, change in cost 0.000343323\n",
      "step 34490, training accuracy 0.963415\n",
      "step 34490, cost 6.23903\n",
      "step 34490, change in cost 0.000344276\n",
      "step 34500, training accuracy 0.963415\n",
      "step 34500, cost 6.23869\n",
      "step 34500, change in cost 0.000344276\n",
      "step 34510, training accuracy 0.963415\n",
      "step 34510, cost 6.23834\n",
      "step 34510, change in cost 0.00034523\n",
      "step 34520, training accuracy 0.963415\n",
      "step 34520, cost 6.238\n",
      "step 34520, change in cost 0.000342369\n",
      "step 34530, training accuracy 0.963415\n",
      "step 34530, cost 6.23766\n",
      "step 34530, change in cost 0.000343323\n",
      "step 34540, training accuracy 0.963415\n",
      "step 34540, cost 6.23731\n",
      "step 34540, change in cost 0.000344753\n",
      "step 34550, training accuracy 0.963415\n",
      "step 34550, cost 6.23697\n",
      "step 34550, change in cost 0.0003438\n",
      "step 34560, training accuracy 0.963415\n",
      "step 34560, cost 6.23662\n",
      "step 34560, change in cost 0.000342369\n",
      "step 34570, training accuracy 0.963415\n",
      "step 34570, cost 6.23628\n",
      "step 34570, change in cost 0.000343323\n",
      "step 34580, training accuracy 0.963415\n",
      "step 34580, cost 6.23594\n",
      "step 34580, change in cost 0.000343323\n",
      "step 34590, training accuracy 0.963415\n",
      "step 34590, cost 6.2356\n",
      "step 34590, change in cost 0.000341415\n",
      "step 34600, training accuracy 0.963415\n",
      "step 34600, cost 6.23525\n",
      "step 34600, change in cost 0.000343323\n",
      "step 34610, training accuracy 0.963415\n",
      "step 34610, cost 6.23491\n",
      "step 34610, change in cost 0.0003438\n",
      "step 34620, training accuracy 0.963415\n",
      "step 34620, cost 6.23457\n",
      "step 34620, change in cost 0.000342369\n",
      "step 34630, training accuracy 0.963415\n",
      "step 34630, cost 6.23422\n",
      "step 34630, change in cost 0.000342369\n",
      "step 34640, training accuracy 0.963415\n",
      "step 34640, cost 6.23388\n",
      "step 34640, change in cost 0.000342846\n",
      "step 34650, training accuracy 0.963415\n",
      "step 34650, cost 6.23354\n",
      "step 34650, change in cost 0.000339508\n",
      "step 34660, training accuracy 0.963415\n",
      "step 34660, cost 6.2332\n",
      "step 34660, change in cost 0.000342369\n",
      "step 34670, training accuracy 0.963415\n",
      "step 34670, cost 6.23286\n",
      "step 34670, change in cost 0.000341415\n",
      "step 34680, training accuracy 0.963415\n",
      "step 34680, cost 6.23252\n",
      "step 34680, change in cost 0.000341892\n",
      "step 34690, training accuracy 0.963415\n",
      "step 34690, cost 6.23217\n",
      "step 34690, change in cost 0.000342369\n",
      "step 34700, training accuracy 0.963415\n",
      "step 34700, cost 6.23183\n",
      "step 34700, change in cost 0.000341415\n",
      "step 34710, training accuracy 0.963415\n",
      "step 34710, cost 6.23149\n",
      "step 34710, change in cost 0.000339508\n",
      "step 34720, training accuracy 0.963415\n",
      "step 34720, cost 6.23115\n",
      "step 34720, change in cost 0.000341892\n",
      "step 34730, training accuracy 0.963415\n",
      "step 34730, cost 6.23081\n",
      "step 34730, change in cost 0.000340462\n",
      "step 34740, training accuracy 0.963415\n",
      "step 34740, cost 6.23047\n",
      "step 34740, change in cost 0.000340462\n",
      "step 34750, training accuracy 0.963415\n",
      "step 34750, cost 6.23013\n",
      "step 34750, change in cost 0.000339508\n",
      "step 34760, training accuracy 0.963415\n",
      "step 34760, cost 6.22979\n",
      "step 34760, change in cost 0.000340462\n",
      "step 34770, training accuracy 0.963415\n",
      "step 34770, cost 6.22945\n",
      "step 34770, change in cost 0.000340462\n",
      "step 34780, training accuracy 0.963415\n",
      "step 34780, cost 6.22911\n",
      "step 34780, change in cost 0.000339508\n",
      "step 34790, training accuracy 0.963415\n",
      "step 34790, cost 6.22877\n",
      "step 34790, change in cost 0.000339508\n",
      "step 34800, training accuracy 0.963415\n",
      "step 34800, cost 6.22843\n",
      "step 34800, change in cost 0.000340462\n",
      "step 34810, training accuracy 0.963415\n",
      "step 34810, cost 6.22809\n",
      "step 34810, change in cost 0.000339508\n",
      "step 34820, training accuracy 0.963415\n",
      "step 34820, cost 6.22775\n",
      "step 34820, change in cost 0.000339508\n",
      "step 34830, training accuracy 0.963415\n",
      "step 34830, cost 6.22741\n",
      "step 34830, change in cost 0.000340462\n",
      "step 34840, training accuracy 0.963415\n",
      "step 34840, cost 6.22707\n",
      "step 34840, change in cost 0.000338554\n",
      "step 34850, training accuracy 0.963415\n",
      "step 34850, cost 6.22673\n",
      "step 34850, change in cost 0.000338078\n",
      "step 34860, training accuracy 0.963415\n",
      "step 34860, cost 6.2264\n",
      "step 34860, change in cost 0.000339508\n",
      "step 34870, training accuracy 0.963415\n",
      "step 34870, cost 6.22606\n",
      "step 34870, change in cost 0.000338078\n",
      "step 34880, training accuracy 0.963415\n",
      "step 34880, cost 6.22572\n",
      "step 34880, change in cost 0.000337601\n",
      "step 34890, training accuracy 0.963415\n",
      "step 34890, cost 6.22538\n",
      "step 34890, change in cost 0.000338554\n",
      "step 34900, training accuracy 0.963415\n",
      "step 34900, cost 6.22504\n",
      "step 34900, change in cost 0.000338554\n",
      "step 34910, training accuracy 0.963415\n",
      "step 34910, cost 6.22471\n",
      "step 34910, change in cost 0.000336647\n",
      "step 34920, training accuracy 0.963415\n",
      "step 34920, cost 6.22437\n",
      "step 34920, change in cost 0.000337601\n",
      "step 34930, training accuracy 0.963415\n",
      "step 34930, cost 6.22403\n",
      "step 34930, change in cost 0.000340462\n",
      "step 34940, training accuracy 0.963415\n",
      "step 34940, cost 6.22369\n",
      "step 34940, change in cost 0.000337601\n",
      "step 34950, training accuracy 0.963415\n",
      "step 34950, cost 6.22335\n",
      "step 34950, change in cost 0.000336647\n",
      "step 34960, training accuracy 0.963415\n",
      "step 34960, cost 6.22302\n",
      "step 34960, change in cost 0.000338078\n",
      "step 34970, training accuracy 0.963415\n",
      "step 34970, cost 6.22268\n",
      "step 34970, change in cost 0.000338078\n",
      "step 34980, training accuracy 0.963415\n",
      "step 34980, cost 6.22234\n",
      "step 34980, change in cost 0.00033474\n",
      "step 34990, training accuracy 0.963415\n",
      "step 34990, cost 6.22201\n",
      "step 34990, change in cost 0.000336647\n",
      "step 35000, training accuracy 0.963415\n",
      "step 35000, cost 6.22167\n",
      "step 35000, change in cost 0.000336647\n",
      "step 35010, training accuracy 0.963415\n",
      "step 35010, cost 6.22133\n",
      "step 35010, change in cost 0.00033617\n",
      "step 35020, training accuracy 0.963415\n",
      "step 35020, cost 6.221\n",
      "step 35020, change in cost 0.000337124\n",
      "step 35030, training accuracy 0.963415\n",
      "step 35030, cost 6.22066\n",
      "step 35030, change in cost 0.000337601\n",
      "step 35040, training accuracy 0.963415\n",
      "step 35040, cost 6.22032\n",
      "step 35040, change in cost 0.000335217\n",
      "step 35050, training accuracy 0.963415\n",
      "step 35050, cost 6.21999\n",
      "step 35050, change in cost 0.000335217\n",
      "step 35060, training accuracy 0.963415\n",
      "step 35060, cost 6.21965\n",
      "step 35060, change in cost 0.000337601\n",
      "step 35070, training accuracy 0.963415\n",
      "step 35070, cost 6.21931\n",
      "step 35070, change in cost 0.000335693\n",
      "step 35080, training accuracy 0.963415\n",
      "step 35080, cost 6.21898\n",
      "step 35080, change in cost 0.00033617\n",
      "step 35090, training accuracy 0.963415\n",
      "step 35090, cost 6.21865\n",
      "step 35090, change in cost 0.000332355\n",
      "step 35100, training accuracy 0.963415\n",
      "step 35100, cost 6.21831\n",
      "step 35100, change in cost 0.000336647\n",
      "step 35110, training accuracy 0.963415\n",
      "step 35110, cost 6.21797\n",
      "step 35110, change in cost 0.000335217\n",
      "step 35120, training accuracy 0.963415\n",
      "step 35120, cost 6.21764\n",
      "step 35120, change in cost 0.00033474\n",
      "step 35130, training accuracy 0.963415\n",
      "step 35130, cost 6.21731\n",
      "step 35130, change in cost 0.000334263\n",
      "step 35140, training accuracy 0.963415\n",
      "step 35140, cost 6.21697\n",
      "step 35140, change in cost 0.000333786\n",
      "step 35150, training accuracy 0.963415\n",
      "step 35150, cost 6.21664\n",
      "step 35150, change in cost 0.000335217\n",
      "step 35160, training accuracy 0.963415\n",
      "step 35160, cost 6.2163\n",
      "step 35160, change in cost 0.000334263\n",
      "step 35170, training accuracy 0.963415\n",
      "step 35170, cost 6.21597\n",
      "step 35170, change in cost 0.000335217\n",
      "step 35180, training accuracy 0.963415\n",
      "step 35180, cost 6.21563\n",
      "step 35180, change in cost 0.000333309\n",
      "step 35190, training accuracy 0.963415\n",
      "step 35190, cost 6.2153\n",
      "step 35190, change in cost 0.000334263\n",
      "step 35200, training accuracy 0.963415\n",
      "step 35200, cost 6.21496\n",
      "step 35200, change in cost 0.000334263\n",
      "step 35210, training accuracy 0.963415\n",
      "step 35210, cost 6.21463\n",
      "step 35210, change in cost 0.000333786\n",
      "step 35220, training accuracy 0.963415\n",
      "step 35220, cost 6.2143\n",
      "step 35220, change in cost 0.000333786\n",
      "step 35230, training accuracy 0.963415\n",
      "step 35230, cost 6.21396\n",
      "step 35230, change in cost 0.000332355\n",
      "step 35240, training accuracy 0.963415\n",
      "step 35240, cost 6.21363\n",
      "step 35240, change in cost 0.000334263\n",
      "step 35250, training accuracy 0.963415\n",
      "step 35250, cost 6.2133\n",
      "step 35250, change in cost 0.000332832\n",
      "step 35260, training accuracy 0.963415\n",
      "step 35260, cost 6.21297\n",
      "step 35260, change in cost 0.000332832\n",
      "step 35270, training accuracy 0.963415\n",
      "step 35270, cost 6.21263\n",
      "step 35270, change in cost 0.000331879\n",
      "step 35280, training accuracy 0.963415\n",
      "step 35280, cost 6.2123\n",
      "step 35280, change in cost 0.000331879\n",
      "step 35290, training accuracy 0.963415\n",
      "step 35290, cost 6.21197\n",
      "step 35290, change in cost 0.000331879\n",
      "step 35300, training accuracy 0.963415\n",
      "step 35300, cost 6.21163\n",
      "step 35300, change in cost 0.00033474\n",
      "step 35310, training accuracy 0.963415\n",
      "step 35310, cost 6.2113\n",
      "step 35310, change in cost 0.000330925\n",
      "step 35320, training accuracy 0.963415\n",
      "step 35320, cost 6.21097\n",
      "step 35320, change in cost 0.000331879\n",
      "step 35330, training accuracy 0.963415\n",
      "step 35330, cost 6.21064\n",
      "step 35330, change in cost 0.000332355\n",
      "step 35340, training accuracy 0.963415\n",
      "step 35340, cost 6.21031\n",
      "step 35340, change in cost 0.000331879\n",
      "step 35350, training accuracy 0.963415\n",
      "step 35350, cost 6.20998\n",
      "step 35350, change in cost 0.000331402\n",
      "step 35360, training accuracy 0.963415\n",
      "step 35360, cost 6.20964\n",
      "step 35360, change in cost 0.000331402\n",
      "step 35370, training accuracy 0.963415\n",
      "step 35370, cost 6.20931\n",
      "step 35370, change in cost 0.000331402\n",
      "step 35380, training accuracy 0.963415\n",
      "step 35380, cost 6.20898\n",
      "step 35380, change in cost 0.000330925\n",
      "step 35390, training accuracy 0.963415\n",
      "step 35390, cost 6.20865\n",
      "step 35390, change in cost 0.000332355\n",
      "step 35400, training accuracy 0.963415\n",
      "step 35400, cost 6.20832\n",
      "step 35400, change in cost 0.000329971\n",
      "step 35410, training accuracy 0.963415\n",
      "step 35410, cost 6.20799\n",
      "step 35410, change in cost 0.000331879\n",
      "step 35420, training accuracy 0.963415\n",
      "step 35420, cost 6.20766\n",
      "step 35420, change in cost 0.000329494\n",
      "step 35430, training accuracy 0.963415\n",
      "step 35430, cost 6.20733\n",
      "step 35430, change in cost 0.000330925\n",
      "step 35440, training accuracy 0.963415\n",
      "step 35440, cost 6.207\n",
      "step 35440, change in cost 0.000328541\n",
      "step 35450, training accuracy 0.963415\n",
      "step 35450, cost 6.20667\n",
      "step 35450, change in cost 0.000331402\n",
      "step 35460, training accuracy 0.963415\n",
      "step 35460, cost 6.20634\n",
      "step 35460, change in cost 0.000329971\n",
      "step 35470, training accuracy 0.963415\n",
      "step 35470, cost 6.20601\n",
      "step 35470, change in cost 0.000329494\n",
      "step 35480, training accuracy 0.963415\n",
      "step 35480, cost 6.20568\n",
      "step 35480, change in cost 0.000329971\n",
      "step 35490, training accuracy 0.963415\n",
      "step 35490, cost 6.20535\n",
      "step 35490, change in cost 0.000330448\n",
      "step 35500, training accuracy 0.963415\n",
      "step 35500, cost 6.20502\n",
      "step 35500, change in cost 0.000329971\n",
      "step 35510, training accuracy 0.963415\n",
      "step 35510, cost 6.20469\n",
      "step 35510, change in cost 0.000328064\n",
      "step 35520, training accuracy 0.963415\n",
      "step 35520, cost 6.20436\n",
      "step 35520, change in cost 0.000329971\n",
      "step 35530, training accuracy 0.963415\n",
      "step 35530, cost 6.20403\n",
      "step 35530, change in cost 0.000329494\n",
      "step 35540, training accuracy 0.963415\n",
      "step 35540, cost 6.2037\n",
      "step 35540, change in cost 0.000328064\n",
      "step 35550, training accuracy 0.963415\n",
      "step 35550, cost 6.20337\n",
      "step 35550, change in cost 0.000327587\n",
      "step 35560, training accuracy 0.963415\n",
      "step 35560, cost 6.20304\n",
      "step 35560, change in cost 0.000329971\n",
      "step 35570, training accuracy 0.963415\n",
      "step 35570, cost 6.20272\n",
      "step 35570, change in cost 0.00032711\n",
      "step 35580, training accuracy 0.963415\n",
      "step 35580, cost 6.20239\n",
      "step 35580, change in cost 0.000327587\n",
      "step 35590, training accuracy 0.963415\n",
      "step 35590, cost 6.20206\n",
      "step 35590, change in cost 0.000328064\n",
      "step 35600, training accuracy 0.963415\n",
      "step 35600, cost 6.20173\n",
      "step 35600, change in cost 0.000329494\n",
      "step 35610, training accuracy 0.963415\n",
      "step 35610, cost 6.2014\n",
      "step 35610, change in cost 0.000328541\n",
      "step 35620, training accuracy 0.963415\n",
      "step 35620, cost 6.20108\n",
      "step 35620, change in cost 0.00032711\n",
      "step 35630, training accuracy 0.963415\n",
      "step 35630, cost 6.20075\n",
      "step 35630, change in cost 0.000326633\n",
      "step 35640, training accuracy 0.963415\n",
      "step 35640, cost 6.20042\n",
      "step 35640, change in cost 0.000329018\n",
      "step 35650, training accuracy 0.963415\n",
      "step 35650, cost 6.20009\n",
      "step 35650, change in cost 0.000327587\n",
      "step 35660, training accuracy 0.963415\n",
      "step 35660, cost 6.19977\n",
      "step 35660, change in cost 0.000326633\n",
      "step 35670, training accuracy 0.963415\n",
      "step 35670, cost 6.19944\n",
      "step 35670, change in cost 0.000327587\n",
      "step 35680, training accuracy 0.963415\n",
      "step 35680, cost 6.19911\n",
      "step 35680, change in cost 0.00032568\n",
      "step 35690, training accuracy 0.963415\n",
      "step 35690, cost 6.19879\n",
      "step 35690, change in cost 0.000328064\n",
      "step 35700, training accuracy 0.963415\n",
      "step 35700, cost 6.19846\n",
      "step 35700, change in cost 0.000325203\n",
      "step 35710, training accuracy 0.963415\n",
      "step 35710, cost 6.19813\n",
      "step 35710, change in cost 0.000327587\n",
      "step 35720, training accuracy 0.963415\n",
      "step 35720, cost 6.19781\n",
      "step 35720, change in cost 0.00032568\n",
      "step 35730, training accuracy 0.963415\n",
      "step 35730, cost 6.19748\n",
      "step 35730, change in cost 0.00032568\n",
      "step 35740, training accuracy 0.963415\n",
      "step 35740, cost 6.19715\n",
      "step 35740, change in cost 0.000326633\n",
      "step 35750, training accuracy 0.963415\n",
      "step 35750, cost 6.19683\n",
      "step 35750, change in cost 0.000326157\n",
      "step 35760, training accuracy 0.963415\n",
      "step 35760, cost 6.1965\n",
      "step 35760, change in cost 0.000324726\n",
      "step 35770, training accuracy 0.963415\n",
      "step 35770, cost 6.19618\n",
      "step 35770, change in cost 0.00032568\n",
      "step 35780, training accuracy 0.963415\n",
      "step 35780, cost 6.19585\n",
      "step 35780, change in cost 0.000326157\n",
      "step 35790, training accuracy 0.963415\n",
      "step 35790, cost 6.19553\n",
      "step 35790, change in cost 0.000326157\n",
      "step 35800, training accuracy 0.963415\n",
      "step 35800, cost 6.1952\n",
      "step 35800, change in cost 0.000325203\n",
      "step 35810, training accuracy 0.963415\n",
      "step 35810, cost 6.19488\n",
      "step 35810, change in cost 0.000324249\n",
      "step 35820, training accuracy 0.963415\n",
      "step 35820, cost 6.19455\n",
      "step 35820, change in cost 0.00032568\n",
      "step 35830, training accuracy 0.963415\n",
      "step 35830, cost 6.19423\n",
      "step 35830, change in cost 0.00032568\n",
      "step 35840, training accuracy 0.963415\n",
      "step 35840, cost 6.1939\n",
      "step 35840, change in cost 0.000324249\n",
      "step 35850, training accuracy 0.963415\n",
      "step 35850, cost 6.19358\n",
      "step 35850, change in cost 0.000325203\n",
      "step 35860, training accuracy 0.963415\n",
      "step 35860, cost 6.19325\n",
      "step 35860, change in cost 0.000323296\n",
      "step 35870, training accuracy 0.963415\n",
      "step 35870, cost 6.19293\n",
      "step 35870, change in cost 0.000325203\n",
      "step 35880, training accuracy 0.963415\n",
      "step 35880, cost 6.1926\n",
      "step 35880, change in cost 0.000323296\n",
      "step 35890, training accuracy 0.963415\n",
      "step 35890, cost 6.19228\n",
      "step 35890, change in cost 0.000323772\n",
      "step 35900, training accuracy 0.963415\n",
      "step 35900, cost 6.19196\n",
      "step 35900, change in cost 0.000323772\n",
      "step 35910, training accuracy 0.963415\n",
      "step 35910, cost 6.19163\n",
      "step 35910, change in cost 0.000324249\n",
      "step 35920, training accuracy 0.963415\n",
      "step 35920, cost 6.19131\n",
      "step 35920, change in cost 0.000324249\n",
      "step 35930, training accuracy 0.963415\n",
      "step 35930, cost 6.19098\n",
      "step 35930, change in cost 0.000324249\n",
      "step 35940, training accuracy 0.963415\n",
      "step 35940, cost 6.19066\n",
      "step 35940, change in cost 0.000323296\n",
      "step 35950, training accuracy 0.963415\n",
      "step 35950, cost 6.19034\n",
      "step 35950, change in cost 0.000323296\n",
      "step 35960, training accuracy 0.963415\n",
      "step 35960, cost 6.19001\n",
      "step 35960, change in cost 0.000322342\n",
      "step 35970, training accuracy 0.963415\n",
      "step 35970, cost 6.18969\n",
      "step 35970, change in cost 0.000323296\n",
      "step 35980, training accuracy 0.963415\n",
      "step 35980, cost 6.18937\n",
      "step 35980, change in cost 0.000323296\n",
      "step 35990, training accuracy 0.963415\n",
      "step 35990, cost 6.18904\n",
      "step 35990, change in cost 0.000324249\n",
      "step 36000, training accuracy 0.963415\n",
      "step 36000, cost 6.18872\n",
      "step 36000, change in cost 0.000322342\n",
      "step 36010, training accuracy 0.963415\n",
      "step 36010, cost 6.1884\n",
      "step 36010, change in cost 0.000322342\n",
      "step 36020, training accuracy 0.963415\n",
      "step 36020, cost 6.18808\n",
      "step 36020, change in cost 0.000323296\n",
      "step 36030, training accuracy 0.963415\n",
      "step 36030, cost 6.18775\n",
      "step 36030, change in cost 0.000323296\n",
      "step 36040, training accuracy 0.963415\n",
      "step 36040, cost 6.18743\n",
      "step 36040, change in cost 0.000321388\n",
      "step 36050, training accuracy 0.963415\n",
      "step 36050, cost 6.18711\n",
      "step 36050, change in cost 0.000321865\n",
      "step 36060, training accuracy 0.963415\n",
      "step 36060, cost 6.18679\n",
      "step 36060, change in cost 0.000322342\n",
      "step 36070, training accuracy 0.963415\n",
      "step 36070, cost 6.18647\n",
      "step 36070, change in cost 0.000319958\n",
      "step 36080, training accuracy 0.963415\n",
      "step 36080, cost 6.18614\n",
      "step 36080, change in cost 0.000323296\n",
      "step 36090, training accuracy 0.963415\n",
      "step 36090, cost 6.18582\n",
      "step 36090, change in cost 0.000321388\n",
      "step 36100, training accuracy 0.963415\n",
      "step 36100, cost 6.1855\n",
      "step 36100, change in cost 0.000321865\n",
      "step 36110, training accuracy 0.963415\n",
      "step 36110, cost 6.18518\n",
      "step 36110, change in cost 0.000320435\n",
      "step 36120, training accuracy 0.963415\n",
      "step 36120, cost 6.18486\n",
      "step 36120, change in cost 0.000320911\n",
      "step 36130, training accuracy 0.963415\n",
      "step 36130, cost 6.18454\n",
      "step 36130, change in cost 0.000321388\n",
      "step 36140, training accuracy 0.963415\n",
      "step 36140, cost 6.18422\n",
      "step 36140, change in cost 0.000321388\n",
      "step 36150, training accuracy 0.963415\n",
      "step 36150, cost 6.1839\n",
      "step 36150, change in cost 0.000319481\n",
      "step 36160, training accuracy 0.963415\n",
      "step 36160, cost 6.18358\n",
      "step 36160, change in cost 0.000319481\n",
      "step 36170, training accuracy 0.963415\n",
      "step 36170, cost 6.18326\n",
      "step 36170, change in cost 0.000319481\n",
      "step 36180, training accuracy 0.963415\n",
      "step 36180, cost 6.18294\n",
      "step 36180, change in cost 0.000321388\n",
      "step 36190, training accuracy 0.963415\n",
      "step 36190, cost 6.18262\n",
      "step 36190, change in cost 0.000321388\n",
      "step 36200, training accuracy 0.963415\n",
      "step 36200, cost 6.1823\n",
      "step 36200, change in cost 0.000319481\n",
      "step 36210, training accuracy 0.963415\n",
      "step 36210, cost 6.18198\n",
      "step 36210, change in cost 0.000318527\n",
      "step 36220, training accuracy 0.963415\n",
      "step 36220, cost 6.18166\n",
      "step 36220, change in cost 0.000321388\n",
      "step 36230, training accuracy 0.963415\n",
      "step 36230, cost 6.18134\n",
      "step 36230, change in cost 0.000319004\n",
      "step 36240, training accuracy 0.963415\n",
      "step 36240, cost 6.18102\n",
      "step 36240, change in cost 0.000319958\n",
      "step 36250, training accuracy 0.963415\n",
      "step 36250, cost 6.1807\n",
      "step 36250, change in cost 0.000317574\n",
      "step 36260, training accuracy 0.963415\n",
      "step 36260, cost 6.18038\n",
      "step 36260, change in cost 0.000319481\n",
      "step 36270, training accuracy 0.963415\n",
      "step 36270, cost 6.18006\n",
      "step 36270, change in cost 0.000319958\n",
      "step 36280, training accuracy 0.963415\n",
      "step 36280, cost 6.17974\n",
      "step 36280, change in cost 0.000319004\n",
      "step 36290, training accuracy 0.963415\n",
      "step 36290, cost 6.17942\n",
      "step 36290, change in cost 0.000319481\n",
      "step 36300, training accuracy 0.963415\n",
      "step 36300, cost 6.1791\n",
      "step 36300, change in cost 0.000318527\n",
      "step 36310, training accuracy 0.963415\n",
      "step 36310, cost 6.17878\n",
      "step 36310, change in cost 0.00031805\n",
      "step 36320, training accuracy 0.963415\n",
      "step 36320, cost 6.17847\n",
      "step 36320, change in cost 0.00031805\n",
      "step 36330, training accuracy 0.963415\n",
      "step 36330, cost 6.17815\n",
      "step 36330, change in cost 0.00031805\n",
      "step 36340, training accuracy 0.963415\n",
      "step 36340, cost 6.17783\n",
      "step 36340, change in cost 0.000318527\n",
      "step 36350, training accuracy 0.963415\n",
      "step 36350, cost 6.17751\n",
      "step 36350, change in cost 0.000319004\n",
      "step 36360, training accuracy 0.963415\n",
      "step 36360, cost 6.17719\n",
      "step 36360, change in cost 0.000317097\n",
      "step 36370, training accuracy 0.963415\n",
      "step 36370, cost 6.17688\n",
      "step 36370, change in cost 0.000317574\n",
      "step 36380, training accuracy 0.963415\n",
      "step 36380, cost 6.17656\n",
      "step 36380, change in cost 0.000317097\n",
      "step 36390, training accuracy 0.963415\n",
      "step 36390, cost 6.17624\n",
      "step 36390, change in cost 0.000317574\n",
      "step 36400, training accuracy 0.963415\n",
      "step 36400, cost 6.17592\n",
      "step 36400, change in cost 0.000317574\n",
      "step 36410, training accuracy 0.963415\n",
      "step 36410, cost 6.17561\n",
      "step 36410, change in cost 0.00031662\n",
      "step 36420, training accuracy 0.963415\n",
      "step 36420, cost 6.17529\n",
      "step 36420, change in cost 0.000315666\n",
      "step 36430, training accuracy 0.963415\n",
      "step 36430, cost 6.17497\n",
      "step 36430, change in cost 0.000319004\n",
      "step 36440, training accuracy 0.963415\n",
      "step 36440, cost 6.17466\n",
      "step 36440, change in cost 0.000316143\n",
      "step 36450, training accuracy 0.963415\n",
      "step 36450, cost 6.17434\n",
      "step 36450, change in cost 0.00031662\n",
      "step 36460, training accuracy 0.963415\n",
      "step 36460, cost 6.17402\n",
      "step 36460, change in cost 0.000317574\n",
      "step 36470, training accuracy 0.963415\n",
      "step 36470, cost 6.17371\n",
      "step 36470, change in cost 0.000315189\n",
      "step 36480, training accuracy 0.963415\n",
      "step 36480, cost 6.17339\n",
      "step 36480, change in cost 0.00031805\n",
      "step 36490, training accuracy 0.963415\n",
      "step 36490, cost 6.17308\n",
      "step 36490, change in cost 0.000314236\n",
      "step 36500, training accuracy 0.963415\n",
      "step 36500, cost 6.17276\n",
      "step 36500, change in cost 0.000316143\n",
      "step 36510, training accuracy 0.963415\n",
      "step 36510, cost 6.17244\n",
      "step 36510, change in cost 0.000317574\n",
      "step 36520, training accuracy 0.963415\n",
      "step 36520, cost 6.17213\n",
      "step 36520, change in cost 0.000315666\n",
      "step 36530, training accuracy 0.963415\n",
      "step 36530, cost 6.17181\n",
      "step 36530, change in cost 0.00031662\n",
      "step 36540, training accuracy 0.963415\n",
      "step 36540, cost 6.17149\n",
      "step 36540, change in cost 0.000315666\n",
      "step 36550, training accuracy 0.963415\n",
      "step 36550, cost 6.17118\n",
      "step 36550, change in cost 0.000314713\n",
      "step 36560, training accuracy 0.963415\n",
      "step 36560, cost 6.17086\n",
      "step 36560, change in cost 0.000315189\n",
      "step 36570, training accuracy 0.963415\n",
      "step 36570, cost 6.17055\n",
      "step 36570, change in cost 0.000316143\n",
      "step 36580, training accuracy 0.963415\n",
      "step 36580, cost 6.17023\n",
      "step 36580, change in cost 0.000315189\n",
      "step 36590, training accuracy 0.963415\n",
      "step 36590, cost 6.16992\n",
      "step 36590, change in cost 0.000314236\n",
      "step 36600, training accuracy 0.963415\n",
      "step 36600, cost 6.1696\n",
      "step 36600, change in cost 0.000315666\n",
      "step 36610, training accuracy 0.963415\n",
      "step 36610, cost 6.16929\n",
      "step 36610, change in cost 0.000313759\n",
      "step 36620, training accuracy 0.963415\n",
      "step 36620, cost 6.16897\n",
      "step 36620, change in cost 0.000315666\n",
      "step 36630, training accuracy 0.963415\n",
      "step 36630, cost 6.16866\n",
      "step 36630, change in cost 0.000313759\n",
      "step 36640, training accuracy 0.963415\n",
      "step 36640, cost 6.16834\n",
      "step 36640, change in cost 0.000314236\n",
      "step 36650, training accuracy 0.963415\n",
      "step 36650, cost 6.16803\n",
      "step 36650, change in cost 0.000315189\n",
      "step 36660, training accuracy 0.963415\n",
      "step 36660, cost 6.16772\n",
      "step 36660, change in cost 0.000313759\n",
      "step 36670, training accuracy 0.963415\n",
      "step 36670, cost 6.1674\n",
      "step 36670, change in cost 0.000313759\n",
      "step 36680, training accuracy 0.963415\n",
      "step 36680, cost 6.16709\n",
      "step 36680, change in cost 0.000312805\n",
      "step 36690, training accuracy 0.963415\n",
      "step 36690, cost 6.16677\n",
      "step 36690, change in cost 0.000314713\n",
      "step 36700, training accuracy 0.963415\n",
      "step 36700, cost 6.16646\n",
      "step 36700, change in cost 0.000312805\n",
      "step 36710, training accuracy 0.963415\n",
      "step 36710, cost 6.16615\n",
      "step 36710, change in cost 0.000314713\n",
      "step 36720, training accuracy 0.963415\n",
      "step 36720, cost 6.16584\n",
      "step 36720, change in cost 0.000311852\n",
      "step 36730, training accuracy 0.963415\n",
      "step 36730, cost 6.16552\n",
      "step 36730, change in cost 0.000313759\n",
      "step 36740, training accuracy 0.963415\n",
      "step 36740, cost 6.16521\n",
      "step 36740, change in cost 0.000312328\n",
      "step 36750, training accuracy 0.963415\n",
      "step 36750, cost 6.1649\n",
      "step 36750, change in cost 0.000312328\n",
      "step 36760, training accuracy 0.963415\n",
      "step 36760, cost 6.16458\n",
      "step 36760, change in cost 0.000314713\n",
      "step 36770, training accuracy 0.963415\n",
      "step 36770, cost 6.16427\n",
      "step 36770, change in cost 0.000312328\n",
      "step 36780, training accuracy 0.963415\n",
      "step 36780, cost 6.16396\n",
      "step 36780, change in cost 0.000311375\n",
      "step 36790, training accuracy 0.963415\n",
      "step 36790, cost 6.16364\n",
      "step 36790, change in cost 0.000314713\n",
      "step 36800, training accuracy 0.963415\n",
      "step 36800, cost 6.16333\n",
      "step 36800, change in cost 0.000310898\n",
      "step 36810, training accuracy 0.963415\n",
      "step 36810, cost 6.16302\n",
      "step 36810, change in cost 0.000312805\n",
      "step 36820, training accuracy 0.963415\n",
      "step 36820, cost 6.16271\n",
      "step 36820, change in cost 0.000310898\n",
      "step 36830, training accuracy 0.963415\n",
      "step 36830, cost 6.1624\n",
      "step 36830, change in cost 0.000311852\n",
      "step 36840, training accuracy 0.963415\n",
      "step 36840, cost 6.16209\n",
      "step 36840, change in cost 0.000311852\n",
      "step 36850, training accuracy 0.963415\n",
      "step 36850, cost 6.16177\n",
      "step 36850, change in cost 0.000311852\n",
      "step 36860, training accuracy 0.963415\n",
      "step 36860, cost 6.16146\n",
      "step 36860, change in cost 0.000310898\n",
      "step 36870, training accuracy 0.963415\n",
      "step 36870, cost 6.16115\n",
      "step 36870, change in cost 0.000312805\n",
      "step 36880, training accuracy 0.963415\n",
      "step 36880, cost 6.16084\n",
      "step 36880, change in cost 0.000311852\n",
      "step 36890, training accuracy 0.963415\n",
      "step 36890, cost 6.16053\n",
      "step 36890, change in cost 0.000309944\n",
      "step 36900, training accuracy 0.963415\n",
      "step 36900, cost 6.16022\n",
      "step 36900, change in cost 0.000312805\n",
      "step 36910, training accuracy 0.963415\n",
      "step 36910, cost 6.15991\n",
      "step 36910, change in cost 0.000309944\n",
      "step 36920, training accuracy 0.963415\n",
      "step 36920, cost 6.15959\n",
      "step 36920, change in cost 0.000311852\n",
      "step 36930, training accuracy 0.963415\n",
      "step 36930, cost 6.15928\n",
      "step 36930, change in cost 0.000311375\n",
      "step 36940, training accuracy 0.963415\n",
      "step 36940, cost 6.15897\n",
      "step 36940, change in cost 0.000309944\n",
      "step 36950, training accuracy 0.963415\n",
      "step 36950, cost 6.15866\n",
      "step 36950, change in cost 0.000311375\n",
      "step 36960, training accuracy 0.963415\n",
      "step 36960, cost 6.15835\n",
      "step 36960, change in cost 0.000309944\n",
      "step 36970, training accuracy 0.963415\n",
      "step 36970, cost 6.15804\n",
      "step 36970, change in cost 0.000310898\n",
      "step 36980, training accuracy 0.963415\n",
      "step 36980, cost 6.15773\n",
      "step 36980, change in cost 0.000309467\n",
      "step 36990, training accuracy 0.963415\n",
      "step 36990, cost 6.15742\n",
      "step 36990, change in cost 0.000310421\n",
      "step 37000, training accuracy 0.963415\n",
      "step 37000, cost 6.15711\n",
      "step 37000, change in cost 0.000309944\n",
      "step 37010, training accuracy 0.963415\n",
      "step 37010, cost 6.1568\n",
      "step 37010, change in cost 0.00030899\n",
      "step 37020, training accuracy 0.963415\n",
      "step 37020, cost 6.15649\n",
      "step 37020, change in cost 0.000310898\n",
      "step 37030, training accuracy 0.963415\n",
      "step 37030, cost 6.15618\n",
      "step 37030, change in cost 0.000309944\n",
      "step 37040, training accuracy 0.963415\n",
      "step 37040, cost 6.15587\n",
      "step 37040, change in cost 0.00030899\n",
      "step 37050, training accuracy 0.963415\n",
      "step 37050, cost 6.15556\n",
      "step 37050, change in cost 0.000309944\n",
      "step 37060, training accuracy 0.963415\n",
      "step 37060, cost 6.15525\n",
      "step 37060, change in cost 0.00030899\n",
      "step 37070, training accuracy 0.963415\n",
      "step 37070, cost 6.15494\n",
      "step 37070, change in cost 0.00030899\n",
      "step 37080, training accuracy 0.963415\n",
      "step 37080, cost 6.15463\n",
      "step 37080, change in cost 0.00030899\n",
      "step 37090, training accuracy 0.963415\n",
      "step 37090, cost 6.15432\n",
      "step 37090, change in cost 0.000309944\n",
      "step 37100, training accuracy 0.963415\n",
      "step 37100, cost 6.15402\n",
      "step 37100, change in cost 0.000308514\n",
      "step 37110, training accuracy 0.963415\n",
      "step 37110, cost 6.15371\n",
      "step 37110, change in cost 0.000308514\n",
      "step 37120, training accuracy 0.963415\n",
      "step 37120, cost 6.1534\n",
      "step 37120, change in cost 0.00030756\n",
      "step 37130, training accuracy 0.963415\n",
      "step 37130, cost 6.15309\n",
      "step 37130, change in cost 0.00030899\n",
      "step 37140, training accuracy 0.963415\n",
      "step 37140, cost 6.15278\n",
      "step 37140, change in cost 0.000309467\n",
      "step 37150, training accuracy 0.963415\n",
      "step 37150, cost 6.15247\n",
      "step 37150, change in cost 0.000307083\n",
      "step 37160, training accuracy 0.963415\n",
      "step 37160, cost 6.15217\n",
      "step 37160, change in cost 0.000308037\n",
      "step 37170, training accuracy 0.963415\n",
      "step 37170, cost 6.15186\n",
      "step 37170, change in cost 0.000308037\n",
      "step 37180, training accuracy 0.963415\n",
      "step 37180, cost 6.15155\n",
      "step 37180, change in cost 0.000307083\n",
      "step 37190, training accuracy 0.963415\n",
      "step 37190, cost 6.15124\n",
      "step 37190, change in cost 0.000307083\n",
      "step 37200, training accuracy 0.963415\n",
      "step 37200, cost 6.15094\n",
      "step 37200, change in cost 0.000307083\n",
      "step 37210, training accuracy 0.963415\n",
      "step 37210, cost 6.15063\n",
      "step 37210, change in cost 0.00030899\n",
      "step 37220, training accuracy 0.963415\n",
      "step 37220, cost 6.15032\n",
      "step 37220, change in cost 0.000308037\n",
      "step 37230, training accuracy 0.963415\n",
      "step 37230, cost 6.15001\n",
      "step 37230, change in cost 0.000306129\n",
      "step 37240, training accuracy 0.963415\n",
      "step 37240, cost 6.14971\n",
      "step 37240, change in cost 0.000308037\n",
      "step 37250, training accuracy 0.963415\n",
      "step 37250, cost 6.1494\n",
      "step 37250, change in cost 0.000305653\n",
      "step 37260, training accuracy 0.963415\n",
      "step 37260, cost 6.14909\n",
      "step 37260, change in cost 0.00030756\n",
      "step 37270, training accuracy 0.963415\n",
      "step 37270, cost 6.14879\n",
      "step 37270, change in cost 0.000305653\n",
      "step 37280, training accuracy 0.963415\n",
      "step 37280, cost 6.14848\n",
      "step 37280, change in cost 0.000308037\n",
      "step 37290, training accuracy 0.963415\n",
      "step 37290, cost 6.14817\n",
      "step 37290, change in cost 0.000305653\n",
      "step 37300, training accuracy 0.963415\n",
      "step 37300, cost 6.14787\n",
      "step 37300, change in cost 0.000306606\n",
      "step 37310, training accuracy 0.963415\n",
      "step 37310, cost 6.14756\n",
      "step 37310, change in cost 0.00030756\n",
      "step 37320, training accuracy 0.963415\n",
      "step 37320, cost 6.14725\n",
      "step 37320, change in cost 0.000305176\n",
      "step 37330, training accuracy 0.963415\n",
      "step 37330, cost 6.14695\n",
      "step 37330, change in cost 0.000306129\n",
      "step 37340, training accuracy 0.963415\n",
      "step 37340, cost 6.14664\n",
      "step 37340, change in cost 0.000305176\n",
      "step 37350, training accuracy 0.963415\n",
      "step 37350, cost 6.14634\n",
      "step 37350, change in cost 0.000305176\n",
      "step 37360, training accuracy 0.963415\n",
      "step 37360, cost 6.14603\n",
      "step 37360, change in cost 0.000307083\n",
      "step 37370, training accuracy 0.963415\n",
      "step 37370, cost 6.14572\n",
      "step 37370, change in cost 0.000305653\n",
      "step 37380, training accuracy 0.963415\n",
      "step 37380, cost 6.14542\n",
      "step 37380, change in cost 0.000305176\n",
      "step 37390, training accuracy 0.963415\n",
      "step 37390, cost 6.14511\n",
      "step 37390, change in cost 0.000305653\n",
      "step 37400, training accuracy 0.963415\n",
      "step 37400, cost 6.14481\n",
      "step 37400, change in cost 0.000305176\n",
      "step 37410, training accuracy 0.963415\n",
      "step 37410, cost 6.1445\n",
      "step 37410, change in cost 0.000305176\n",
      "step 37420, training accuracy 0.963415\n",
      "step 37420, cost 6.1442\n",
      "step 37420, change in cost 0.000305176\n",
      "step 37430, training accuracy 0.963415\n",
      "step 37430, cost 6.14389\n",
      "step 37430, change in cost 0.000305176\n",
      "step 37440, training accuracy 0.963415\n",
      "step 37440, cost 6.14359\n",
      "step 37440, change in cost 0.000305176\n",
      "step 37450, training accuracy 0.963415\n",
      "step 37450, cost 6.14328\n",
      "step 37450, change in cost 0.000304699\n",
      "step 37460, training accuracy 0.963415\n",
      "step 37460, cost 6.14298\n",
      "step 37460, change in cost 0.000303745\n",
      "step 37470, training accuracy 0.963415\n",
      "step 37470, cost 6.14267\n",
      "step 37470, change in cost 0.000306129\n",
      "step 37480, training accuracy 0.963415\n",
      "step 37480, cost 6.14237\n",
      "step 37480, change in cost 0.000305653\n",
      "step 37490, training accuracy 0.963415\n",
      "step 37490, cost 6.14207\n",
      "step 37490, change in cost 0.000301838\n",
      "step 37500, training accuracy 0.963415\n",
      "step 37500, cost 6.14176\n",
      "step 37500, change in cost 0.000304222\n",
      "step 37510, training accuracy 0.963415\n",
      "step 37510, cost 6.14146\n",
      "step 37510, change in cost 0.000305176\n",
      "step 37520, training accuracy 0.963415\n",
      "step 37520, cost 6.14115\n",
      "step 37520, change in cost 0.000303268\n",
      "step 37530, training accuracy 0.963415\n",
      "step 37530, cost 6.14085\n",
      "step 37530, change in cost 0.000304699\n",
      "step 37540, training accuracy 0.963415\n",
      "step 37540, cost 6.14055\n",
      "step 37540, change in cost 0.000302792\n",
      "step 37550, training accuracy 0.963415\n",
      "step 37550, cost 6.14024\n",
      "step 37550, change in cost 0.000304699\n",
      "step 37560, training accuracy 0.963415\n",
      "step 37560, cost 6.13994\n",
      "step 37560, change in cost 0.000303268\n",
      "step 37570, training accuracy 0.963415\n",
      "step 37570, cost 6.13963\n",
      "step 37570, change in cost 0.000304222\n",
      "step 37580, training accuracy 0.963415\n",
      "step 37580, cost 6.13933\n",
      "step 37580, change in cost 0.000302792\n",
      "step 37590, training accuracy 0.963415\n",
      "step 37590, cost 6.13903\n",
      "step 37590, change in cost 0.000302315\n",
      "step 37600, training accuracy 0.963415\n",
      "step 37600, cost 6.13873\n",
      "step 37600, change in cost 0.000302315\n",
      "step 37610, training accuracy 0.963415\n",
      "step 37610, cost 6.13842\n",
      "step 37610, change in cost 0.000303745\n",
      "step 37620, training accuracy 0.963415\n",
      "step 37620, cost 6.13812\n",
      "step 37620, change in cost 0.000301838\n",
      "step 37630, training accuracy 0.963415\n",
      "step 37630, cost 6.13782\n",
      "step 37630, change in cost 0.000303268\n",
      "step 37640, training accuracy 0.963415\n",
      "step 37640, cost 6.13752\n",
      "step 37640, change in cost 0.000301361\n",
      "step 37650, training accuracy 0.963415\n",
      "step 37650, cost 6.13721\n",
      "step 37650, change in cost 0.000302315\n",
      "step 37660, training accuracy 0.963415\n",
      "step 37660, cost 6.13691\n",
      "step 37660, change in cost 0.000303268\n",
      "step 37670, training accuracy 0.963415\n",
      "step 37670, cost 6.13661\n",
      "step 37670, change in cost 0.000300884\n",
      "step 37680, training accuracy 0.963415\n",
      "step 37680, cost 6.13631\n",
      "step 37680, change in cost 0.000302315\n",
      "step 37690, training accuracy 0.963415\n",
      "step 37690, cost 6.13601\n",
      "step 37690, change in cost 0.000301838\n",
      "step 37700, training accuracy 0.963415\n",
      "step 37700, cost 6.1357\n",
      "step 37700, change in cost 0.000301361\n",
      "step 37710, training accuracy 0.963415\n",
      "step 37710, cost 6.1354\n",
      "step 37710, change in cost 0.000301838\n",
      "step 37720, training accuracy 0.963415\n",
      "step 37720, cost 6.1351\n",
      "step 37720, change in cost 0.000299931\n",
      "step 37730, training accuracy 0.963415\n",
      "step 37730, cost 6.1348\n",
      "step 37730, change in cost 0.000304222\n",
      "step 37740, training accuracy 0.963415\n",
      "step 37740, cost 6.1345\n",
      "step 37740, change in cost 0.0002985\n",
      "step 37750, training accuracy 0.963415\n",
      "step 37750, cost 6.1342\n",
      "step 37750, change in cost 0.000303745\n",
      "step 37760, training accuracy 0.963415\n",
      "step 37760, cost 6.13389\n",
      "step 37760, change in cost 0.000301838\n",
      "step 37770, training accuracy 0.963415\n",
      "step 37770, cost 6.1336\n",
      "step 37770, change in cost 0.0002985\n",
      "step 37780, training accuracy 0.963415\n",
      "step 37780, cost 6.13329\n",
      "step 37780, change in cost 0.000301361\n",
      "step 37790, training accuracy 0.963415\n",
      "step 37790, cost 6.13299\n",
      "step 37790, change in cost 0.000300407\n",
      "step 37800, training accuracy 0.963415\n",
      "step 37800, cost 6.13269\n",
      "step 37800, change in cost 0.000301361\n",
      "step 37810, training accuracy 0.963415\n",
      "step 37810, cost 6.13239\n",
      "step 37810, change in cost 0.000300407\n",
      "step 37820, training accuracy 0.963415\n",
      "step 37820, cost 6.13209\n",
      "step 37820, change in cost 0.000300407\n",
      "step 37830, training accuracy 0.963415\n",
      "step 37830, cost 6.13179\n",
      "step 37830, change in cost 0.000300407\n",
      "step 37840, training accuracy 0.963415\n",
      "step 37840, cost 6.13149\n",
      "step 37840, change in cost 0.000299454\n",
      "step 37850, training accuracy 0.963415\n",
      "step 37850, cost 6.13119\n",
      "step 37850, change in cost 0.000300407\n",
      "step 37860, training accuracy 0.963415\n",
      "step 37860, cost 6.13089\n",
      "step 37860, change in cost 0.000300407\n",
      "step 37870, training accuracy 0.963415\n",
      "step 37870, cost 6.13059\n",
      "step 37870, change in cost 0.000299931\n",
      "step 37880, training accuracy 0.963415\n",
      "step 37880, cost 6.13029\n",
      "step 37880, change in cost 0.000299931\n",
      "step 37890, training accuracy 0.963415\n",
      "step 37890, cost 6.12999\n",
      "step 37890, change in cost 0.000300407\n",
      "step 37900, training accuracy 0.963415\n",
      "step 37900, cost 6.12969\n",
      "step 37900, change in cost 0.000298977\n",
      "step 37910, training accuracy 0.963415\n",
      "step 37910, cost 6.12939\n",
      "step 37910, change in cost 0.000299931\n",
      "step 37920, training accuracy 0.963415\n",
      "step 37920, cost 6.12909\n",
      "step 37920, change in cost 0.000300407\n",
      "step 37930, training accuracy 0.963415\n",
      "step 37930, cost 6.12879\n",
      "step 37930, change in cost 0.0002985\n",
      "step 37940, training accuracy 0.963415\n",
      "step 37940, cost 6.12849\n",
      "step 37940, change in cost 0.000299931\n",
      "step 37950, training accuracy 0.963415\n",
      "step 37950, cost 6.12819\n",
      "step 37950, change in cost 0.000299454\n",
      "step 37960, training accuracy 0.963415\n",
      "step 37960, cost 6.12789\n",
      "step 37960, change in cost 0.000298977\n",
      "step 37970, training accuracy 0.963415\n",
      "step 37970, cost 6.1276\n",
      "step 37970, change in cost 0.0002985\n",
      "step 37980, training accuracy 0.963415\n",
      "step 37980, cost 6.1273\n",
      "step 37980, change in cost 0.000299454\n",
      "step 37990, training accuracy 0.963415\n",
      "step 37990, cost 6.127\n",
      "step 37990, change in cost 0.000299454\n",
      "step 38000, training accuracy 0.963415\n",
      "step 38000, cost 6.1267\n",
      "step 38000, change in cost 0.000297546\n",
      "step 38010, training accuracy 0.963415\n",
      "step 38010, cost 6.1264\n",
      "step 38010, change in cost 0.000298977\n",
      "step 38020, training accuracy 0.963415\n",
      "step 38020, cost 6.1261\n",
      "step 38020, change in cost 0.000299931\n",
      "step 38030, training accuracy 0.963415\n",
      "step 38030, cost 6.1258\n",
      "step 38030, change in cost 0.000296116\n",
      "step 38040, training accuracy 0.963415\n",
      "step 38040, cost 6.12551\n",
      "step 38040, change in cost 0.000298023\n",
      "step 38050, training accuracy 0.963415\n",
      "step 38050, cost 6.12521\n",
      "step 38050, change in cost 0.000298977\n",
      "step 38060, training accuracy 0.963415\n",
      "step 38060, cost 6.12491\n",
      "step 38060, change in cost 0.000296593\n",
      "step 38070, training accuracy 0.963415\n",
      "step 38070, cost 6.12461\n",
      "step 38070, change in cost 0.000298023\n",
      "step 38080, training accuracy 0.963415\n",
      "step 38080, cost 6.12431\n",
      "step 38080, change in cost 0.000298023\n",
      "step 38090, training accuracy 0.963415\n",
      "step 38090, cost 6.12402\n",
      "step 38090, change in cost 0.000297546\n",
      "step 38100, training accuracy 0.963415\n",
      "step 38100, cost 6.12372\n",
      "step 38100, change in cost 0.000298023\n",
      "step 38110, training accuracy 0.963415\n",
      "step 38110, cost 6.12342\n",
      "step 38110, change in cost 0.00029707\n",
      "step 38120, training accuracy 0.963415\n",
      "step 38120, cost 6.12313\n",
      "step 38120, change in cost 0.00029707\n",
      "step 38130, training accuracy 0.963415\n",
      "step 38130, cost 6.12283\n",
      "step 38130, change in cost 0.000298023\n",
      "step 38140, training accuracy 0.963415\n",
      "step 38140, cost 6.12253\n",
      "step 38140, change in cost 0.000297546\n",
      "step 38150, training accuracy 0.963415\n",
      "step 38150, cost 6.12223\n",
      "step 38150, change in cost 0.000295639\n",
      "step 38160, training accuracy 0.963415\n",
      "step 38160, cost 6.12194\n",
      "step 38160, change in cost 0.000297546\n",
      "step 38170, training accuracy 0.963415\n",
      "step 38170, cost 6.12164\n",
      "step 38170, change in cost 0.00029707\n",
      "step 38180, training accuracy 0.963415\n",
      "step 38180, cost 6.12134\n",
      "step 38180, change in cost 0.000296593\n",
      "step 38190, training accuracy 0.963415\n",
      "step 38190, cost 6.12105\n",
      "step 38190, change in cost 0.000296116\n",
      "step 38200, training accuracy 0.963415\n",
      "step 38200, cost 6.12075\n",
      "step 38200, change in cost 0.00029707\n",
      "step 38210, training accuracy 0.963415\n",
      "step 38210, cost 6.12045\n",
      "step 38210, change in cost 0.000295639\n",
      "step 38220, training accuracy 0.963415\n",
      "step 38220, cost 6.12016\n",
      "step 38220, change in cost 0.00029707\n",
      "step 38230, training accuracy 0.963415\n",
      "step 38230, cost 6.11986\n",
      "step 38230, change in cost 0.000296116\n",
      "step 38240, training accuracy 0.963415\n",
      "step 38240, cost 6.11957\n",
      "step 38240, change in cost 0.000295639\n",
      "step 38250, training accuracy 0.963415\n",
      "step 38250, cost 6.11927\n",
      "step 38250, change in cost 0.000295639\n",
      "step 38260, training accuracy 0.963415\n",
      "step 38260, cost 6.11897\n",
      "step 38260, change in cost 0.000295639\n",
      "step 38270, training accuracy 0.963415\n",
      "step 38270, cost 6.11868\n",
      "step 38270, change in cost 0.000294685\n",
      "step 38280, training accuracy 0.963415\n",
      "step 38280, cost 6.11838\n",
      "step 38280, change in cost 0.000297546\n",
      "step 38290, training accuracy 0.963415\n",
      "step 38290, cost 6.11809\n",
      "step 38290, change in cost 0.000293732\n",
      "step 38300, training accuracy 0.963415\n",
      "step 38300, cost 6.11779\n",
      "step 38300, change in cost 0.000296593\n",
      "step 38310, training accuracy 0.963415\n",
      "step 38310, cost 6.1175\n",
      "step 38310, change in cost 0.000295639\n",
      "step 38320, training accuracy 0.963415\n",
      "step 38320, cost 6.1172\n",
      "step 38320, change in cost 0.000295639\n",
      "step 38330, training accuracy 0.963415\n",
      "step 38330, cost 6.11691\n",
      "step 38330, change in cost 0.000294685\n",
      "step 38340, training accuracy 0.963415\n",
      "step 38340, cost 6.11661\n",
      "step 38340, change in cost 0.000293732\n",
      "step 38350, training accuracy 0.963415\n",
      "step 38350, cost 6.11632\n",
      "step 38350, change in cost 0.000294685\n",
      "step 38360, training accuracy 0.963415\n",
      "step 38360, cost 6.11602\n",
      "step 38360, change in cost 0.000295639\n",
      "step 38370, training accuracy 0.963415\n",
      "step 38370, cost 6.11573\n",
      "step 38370, change in cost 0.000295639\n",
      "step 38380, training accuracy 0.963415\n",
      "step 38380, cost 6.11543\n",
      "step 38380, change in cost 0.000293255\n",
      "step 38390, training accuracy 0.963415\n",
      "step 38390, cost 6.11514\n",
      "step 38390, change in cost 0.000295162\n",
      "step 38400, training accuracy 0.963415\n",
      "step 38400, cost 6.11484\n",
      "step 38400, change in cost 0.000294685\n",
      "step 38410, training accuracy 0.963415\n",
      "step 38410, cost 6.11455\n",
      "step 38410, change in cost 0.000292778\n",
      "step 38420, training accuracy 0.963415\n",
      "step 38420, cost 6.11425\n",
      "step 38420, change in cost 0.000295639\n",
      "step 38430, training accuracy 0.963415\n",
      "step 38430, cost 6.11396\n",
      "step 38430, change in cost 0.000293732\n",
      "step 38440, training accuracy 0.963415\n",
      "step 38440, cost 6.11367\n",
      "step 38440, change in cost 0.000293255\n",
      "step 38450, training accuracy 0.963415\n",
      "step 38450, cost 6.11337\n",
      "step 38450, change in cost 0.000295162\n",
      "step 38460, training accuracy 0.963415\n",
      "step 38460, cost 6.11308\n",
      "step 38460, change in cost 0.000294685\n",
      "step 38470, training accuracy 0.963415\n",
      "step 38470, cost 6.11278\n",
      "step 38470, change in cost 0.000292301\n",
      "step 38480, training accuracy 0.963415\n",
      "step 38480, cost 6.11249\n",
      "step 38480, change in cost 0.000292301\n",
      "step 38490, training accuracy 0.963415\n",
      "step 38490, cost 6.1122\n",
      "step 38490, change in cost 0.000295639\n",
      "step 38500, training accuracy 0.963415\n",
      "step 38500, cost 6.1119\n",
      "step 38500, change in cost 0.000292778\n",
      "step 38510, training accuracy 0.963415\n",
      "step 38510, cost 6.11161\n",
      "step 38510, change in cost 0.000293255\n",
      "step 38520, training accuracy 0.963415\n",
      "step 38520, cost 6.11132\n",
      "step 38520, change in cost 0.000293255\n",
      "step 38530, training accuracy 0.963415\n",
      "step 38530, cost 6.11102\n",
      "step 38530, change in cost 0.000292778\n",
      "step 38540, training accuracy 0.963415\n",
      "step 38540, cost 6.11073\n",
      "step 38540, change in cost 0.000293732\n",
      "step 38550, training accuracy 0.963415\n",
      "step 38550, cost 6.11044\n",
      "step 38550, change in cost 0.000292778\n",
      "step 38560, training accuracy 0.963415\n",
      "step 38560, cost 6.11015\n",
      "step 38560, change in cost 0.000292778\n",
      "step 38570, training accuracy 0.963415\n",
      "step 38570, cost 6.10985\n",
      "step 38570, change in cost 0.000292778\n",
      "step 38580, training accuracy 0.963415\n",
      "step 38580, cost 6.10956\n",
      "step 38580, change in cost 0.000293255\n",
      "step 38590, training accuracy 0.963415\n",
      "step 38590, cost 6.10927\n",
      "step 38590, change in cost 0.000292778\n",
      "step 38600, training accuracy 0.963415\n",
      "step 38600, cost 6.10897\n",
      "step 38600, change in cost 0.000291824\n",
      "step 38610, training accuracy 0.963415\n",
      "step 38610, cost 6.10868\n",
      "step 38610, change in cost 0.000293255\n",
      "step 38620, training accuracy 0.963415\n",
      "step 38620, cost 6.10839\n",
      "step 38620, change in cost 0.000291348\n",
      "step 38630, training accuracy 0.963415\n",
      "step 38630, cost 6.1081\n",
      "step 38630, change in cost 0.000292301\n",
      "step 38640, training accuracy 0.963415\n",
      "step 38640, cost 6.10781\n",
      "step 38640, change in cost 0.000290871\n",
      "step 38650, training accuracy 0.963415\n",
      "step 38650, cost 6.10751\n",
      "step 38650, change in cost 0.000292301\n",
      "step 38660, training accuracy 0.963415\n",
      "step 38660, cost 6.10722\n",
      "step 38660, change in cost 0.000293255\n",
      "step 38670, training accuracy 0.963415\n",
      "step 38670, cost 6.10693\n",
      "step 38670, change in cost 0.000290871\n",
      "step 38680, training accuracy 0.963415\n",
      "step 38680, cost 6.10664\n",
      "step 38680, change in cost 0.000291348\n",
      "step 38690, training accuracy 0.963415\n",
      "step 38690, cost 6.10635\n",
      "step 38690, change in cost 0.000290871\n",
      "step 38700, training accuracy 0.963415\n",
      "step 38700, cost 6.10606\n",
      "step 38700, change in cost 0.000291348\n",
      "step 38710, training accuracy 0.963415\n",
      "step 38710, cost 6.10577\n",
      "step 38710, change in cost 0.000291824\n",
      "step 38720, training accuracy 0.963415\n",
      "step 38720, cost 6.10547\n",
      "step 38720, change in cost 0.000290394\n",
      "step 38730, training accuracy 0.963415\n",
      "step 38730, cost 6.10518\n",
      "step 38730, change in cost 0.000291348\n",
      "step 38740, training accuracy 0.963415\n",
      "step 38740, cost 6.10489\n",
      "step 38740, change in cost 0.000291348\n",
      "step 38750, training accuracy 0.963415\n",
      "step 38750, cost 6.1046\n",
      "step 38750, change in cost 0.000291824\n",
      "step 38760, training accuracy 0.963415\n",
      "step 38760, cost 6.10431\n",
      "step 38760, change in cost 0.000290394\n",
      "step 38770, training accuracy 0.963415\n",
      "step 38770, cost 6.10402\n",
      "step 38770, change in cost 0.000291824\n",
      "step 38780, training accuracy 0.963415\n",
      "step 38780, cost 6.10373\n",
      "step 38780, change in cost 0.000290871\n",
      "step 38790, training accuracy 0.963415\n",
      "step 38790, cost 6.10344\n",
      "step 38790, change in cost 0.000289917\n",
      "step 38800, training accuracy 0.963415\n",
      "step 38800, cost 6.10315\n",
      "step 38800, change in cost 0.00028944\n",
      "step 38810, training accuracy 0.963415\n",
      "step 38810, cost 6.10286\n",
      "step 38810, change in cost 0.00028944\n",
      "step 38820, training accuracy 0.963415\n",
      "step 38820, cost 6.10257\n",
      "step 38820, change in cost 0.000290871\n",
      "step 38830, training accuracy 0.963415\n",
      "step 38830, cost 6.10228\n",
      "step 38830, change in cost 0.000290871\n",
      "step 38840, training accuracy 0.963415\n",
      "step 38840, cost 6.10199\n",
      "step 38840, change in cost 0.000289917\n",
      "step 38850, training accuracy 0.963415\n",
      "step 38850, cost 6.1017\n",
      "step 38850, change in cost 0.000289917\n",
      "step 38860, training accuracy 0.963415\n",
      "step 38860, cost 6.10141\n",
      "step 38860, change in cost 0.000288963\n",
      "step 38870, training accuracy 0.963415\n",
      "step 38870, cost 6.10112\n",
      "step 38870, change in cost 0.000289917\n",
      "step 38880, training accuracy 0.963415\n",
      "step 38880, cost 6.10083\n",
      "step 38880, change in cost 0.00028944\n",
      "step 38890, training accuracy 0.963415\n",
      "step 38890, cost 6.10054\n",
      "step 38890, change in cost 0.000288486\n",
      "step 38900, training accuracy 0.963415\n",
      "step 38900, cost 6.10025\n",
      "step 38900, change in cost 0.00028944\n",
      "step 38910, training accuracy 0.963415\n",
      "step 38910, cost 6.09996\n",
      "step 38910, change in cost 0.00028944\n",
      "step 38920, training accuracy 0.963415\n",
      "step 38920, cost 6.09967\n",
      "step 38920, change in cost 0.000288486\n",
      "step 38930, training accuracy 0.963415\n",
      "step 38930, cost 6.09939\n",
      "step 38930, change in cost 0.000287533\n",
      "step 38940, training accuracy 0.963415\n",
      "step 38940, cost 6.0991\n",
      "step 38940, change in cost 0.000289917\n",
      "step 38950, training accuracy 0.963415\n",
      "step 38950, cost 6.09881\n",
      "step 38950, change in cost 0.000288963\n",
      "step 38960, training accuracy 0.963415\n",
      "step 38960, cost 6.09852\n",
      "step 38960, change in cost 0.000288963\n",
      "step 38970, training accuracy 0.963415\n",
      "step 38970, cost 6.09823\n",
      "step 38970, change in cost 0.00028801\n",
      "step 38980, training accuracy 0.963415\n",
      "step 38980, cost 6.09794\n",
      "step 38980, change in cost 0.000289917\n",
      "step 38990, training accuracy 0.963415\n",
      "step 38990, cost 6.09765\n",
      "step 38990, change in cost 0.000287056\n",
      "step 39000, training accuracy 0.963415\n",
      "step 39000, cost 6.09736\n",
      "step 39000, change in cost 0.00028944\n",
      "step 39010, training accuracy 0.963415\n",
      "step 39010, cost 6.09708\n",
      "step 39010, change in cost 0.000286579\n",
      "step 39020, training accuracy 0.963415\n",
      "step 39020, cost 6.09679\n",
      "step 39020, change in cost 0.000288963\n",
      "step 39030, training accuracy 0.963415\n",
      "step 39030, cost 6.0965\n",
      "step 39030, change in cost 0.000288486\n",
      "step 39040, training accuracy 0.963415\n",
      "step 39040, cost 6.09621\n",
      "step 39040, change in cost 0.000288486\n",
      "step 39050, training accuracy 0.963415\n",
      "step 39050, cost 6.09592\n",
      "step 39050, change in cost 0.00028801\n",
      "step 39060, training accuracy 0.963415\n",
      "step 39060, cost 6.09563\n",
      "step 39060, change in cost 0.00028801\n",
      "step 39070, training accuracy 0.963415\n",
      "step 39070, cost 6.09535\n",
      "step 39070, change in cost 0.000286579\n",
      "step 39080, training accuracy 0.963415\n",
      "step 39080, cost 6.09506\n",
      "step 39080, change in cost 0.000287533\n",
      "step 39090, training accuracy 0.963415\n",
      "step 39090, cost 6.09477\n",
      "step 39090, change in cost 0.000288486\n",
      "step 39100, training accuracy 0.963415\n",
      "step 39100, cost 6.09448\n",
      "step 39100, change in cost 0.000287056\n",
      "step 39110, training accuracy 0.963415\n",
      "step 39110, cost 6.0942\n",
      "step 39110, change in cost 0.000286579\n",
      "step 39120, training accuracy 0.963415\n",
      "step 39120, cost 6.09391\n",
      "step 39120, change in cost 0.000287056\n",
      "step 39130, training accuracy 0.963415\n",
      "step 39130, cost 6.09362\n",
      "step 39130, change in cost 0.00028801\n",
      "step 39140, training accuracy 0.963415\n",
      "step 39140, cost 6.09334\n",
      "step 39140, change in cost 0.000287056\n",
      "step 39150, training accuracy 0.963415\n",
      "step 39150, cost 6.09305\n",
      "step 39150, change in cost 0.000287533\n",
      "step 39160, training accuracy 0.963415\n",
      "step 39160, cost 6.09276\n",
      "step 39160, change in cost 0.000285625\n",
      "step 39170, training accuracy 0.963415\n",
      "step 39170, cost 6.09247\n",
      "step 39170, change in cost 0.000288486\n",
      "step 39180, training accuracy 0.963415\n",
      "step 39180, cost 6.09219\n",
      "step 39180, change in cost 0.000284672\n",
      "step 39190, training accuracy 0.963415\n",
      "step 39190, cost 6.0919\n",
      "step 39190, change in cost 0.000287056\n",
      "step 39200, training accuracy 0.963415\n",
      "step 39200, cost 6.09162\n",
      "step 39200, change in cost 0.000287533\n",
      "step 39210, training accuracy 0.963415\n",
      "step 39210, cost 6.09133\n",
      "step 39210, change in cost 0.000285625\n",
      "step 39220, training accuracy 0.963415\n",
      "step 39220, cost 6.09104\n",
      "step 39220, change in cost 0.000287056\n",
      "step 39230, training accuracy 0.963415\n",
      "step 39230, cost 6.09076\n",
      "step 39230, change in cost 0.000285625\n",
      "step 39240, training accuracy 0.963415\n",
      "step 39240, cost 6.09047\n",
      "step 39240, change in cost 0.000287056\n",
      "step 39250, training accuracy 0.963415\n",
      "step 39250, cost 6.09019\n",
      "step 39250, change in cost 0.000284672\n",
      "step 39260, training accuracy 0.963415\n",
      "step 39260, cost 6.0899\n",
      "step 39260, change in cost 0.00028801\n",
      "step 39270, training accuracy 0.963415\n",
      "step 39270, cost 6.08961\n",
      "step 39270, change in cost 0.000284195\n",
      "step 39280, training accuracy 0.963415\n",
      "step 39280, cost 6.08933\n",
      "step 39280, change in cost 0.000286102\n",
      "step 39290, training accuracy 0.963415\n",
      "step 39290, cost 6.08904\n",
      "step 39290, change in cost 0.000285149\n",
      "step 39300, training accuracy 0.963415\n",
      "step 39300, cost 6.08875\n",
      "step 39300, change in cost 0.000287056\n",
      "step 39310, training accuracy 0.963415\n",
      "step 39310, cost 6.08847\n",
      "step 39310, change in cost 0.000285149\n",
      "step 39320, training accuracy 0.963415\n",
      "step 39320, cost 6.08818\n",
      "step 39320, change in cost 0.000285149\n",
      "step 39330, training accuracy 0.963415\n",
      "step 39330, cost 6.0879\n",
      "step 39330, change in cost 0.000287056\n",
      "step 39340, training accuracy 0.963415\n",
      "step 39340, cost 6.08761\n",
      "step 39340, change in cost 0.000285149\n",
      "step 39350, training accuracy 0.963415\n",
      "step 39350, cost 6.08733\n",
      "step 39350, change in cost 0.000284672\n",
      "step 39360, training accuracy 0.963415\n",
      "step 39360, cost 6.08704\n",
      "step 39360, change in cost 0.000285625\n",
      "step 39370, training accuracy 0.963415\n",
      "step 39370, cost 6.08676\n",
      "step 39370, change in cost 0.000285149\n",
      "step 39380, training accuracy 0.963415\n",
      "step 39380, cost 6.08647\n",
      "step 39380, change in cost 0.000285149\n",
      "step 39390, training accuracy 0.963415\n",
      "step 39390, cost 6.08619\n",
      "step 39390, change in cost 0.000283241\n",
      "step 39400, training accuracy 0.963415\n",
      "step 39400, cost 6.0859\n",
      "step 39400, change in cost 0.000284672\n",
      "step 39410, training accuracy 0.963415\n",
      "step 39410, cost 6.08562\n",
      "step 39410, change in cost 0.000286102\n",
      "step 39420, training accuracy 0.963415\n",
      "step 39420, cost 6.08533\n",
      "step 39420, change in cost 0.000283718\n",
      "step 39430, training accuracy 0.963415\n",
      "step 39430, cost 6.08505\n",
      "step 39430, change in cost 0.000283241\n",
      "step 39440, training accuracy 0.963415\n",
      "step 39440, cost 6.08477\n",
      "step 39440, change in cost 0.000284195\n",
      "step 39450, training accuracy 0.963415\n",
      "step 39450, cost 6.08448\n",
      "step 39450, change in cost 0.000284195\n",
      "step 39460, training accuracy 0.963415\n",
      "step 39460, cost 6.0842\n",
      "step 39460, change in cost 0.000284672\n",
      "step 39470, training accuracy 0.963415\n",
      "step 39470, cost 6.08391\n",
      "step 39470, change in cost 0.000282764\n",
      "step 39480, training accuracy 0.963415\n",
      "step 39480, cost 6.08363\n",
      "step 39480, change in cost 0.000285149\n",
      "step 39490, training accuracy 0.963415\n",
      "step 39490, cost 6.08335\n",
      "step 39490, change in cost 0.000283718\n",
      "step 39500, training accuracy 0.963415\n",
      "step 39500, cost 6.08306\n",
      "step 39500, change in cost 0.000284672\n",
      "step 39510, training accuracy 0.963415\n",
      "step 39510, cost 6.08278\n",
      "step 39510, change in cost 0.000284195\n",
      "step 39520, training accuracy 0.963415\n",
      "step 39520, cost 6.08249\n",
      "step 39520, change in cost 0.000283241\n",
      "step 39530, training accuracy 0.963415\n",
      "step 39530, cost 6.08221\n",
      "step 39530, change in cost 0.000282288\n",
      "step 39540, training accuracy 0.963415\n",
      "step 39540, cost 6.08193\n",
      "step 39540, change in cost 0.000284195\n",
      "step 39550, training accuracy 0.963415\n",
      "step 39550, cost 6.08164\n",
      "step 39550, change in cost 0.000283241\n",
      "step 39560, training accuracy 0.963415\n",
      "step 39560, cost 6.08136\n",
      "step 39560, change in cost 0.000283718\n",
      "step 39570, training accuracy 0.963415\n",
      "step 39570, cost 6.08108\n",
      "step 39570, change in cost 0.000283718\n",
      "step 39580, training accuracy 0.963415\n",
      "step 39580, cost 6.08079\n",
      "step 39580, change in cost 0.000283241\n",
      "step 39590, training accuracy 0.963415\n",
      "step 39590, cost 6.08051\n",
      "step 39590, change in cost 0.000282764\n",
      "step 39600, training accuracy 0.963415\n",
      "step 39600, cost 6.08023\n",
      "step 39600, change in cost 0.000283241\n",
      "step 39610, training accuracy 0.963415\n",
      "step 39610, cost 6.07994\n",
      "step 39610, change in cost 0.000282764\n",
      "step 39620, training accuracy 0.963415\n",
      "step 39620, cost 6.07966\n",
      "step 39620, change in cost 0.000284672\n",
      "step 39630, training accuracy 0.963415\n",
      "step 39630, cost 6.07938\n",
      "step 39630, change in cost 0.000280857\n",
      "step 39640, training accuracy 0.963415\n",
      "step 39640, cost 6.07909\n",
      "step 39640, change in cost 0.000284195\n",
      "step 39650, training accuracy 0.963415\n",
      "step 39650, cost 6.07881\n",
      "step 39650, change in cost 0.000282288\n",
      "step 39660, training accuracy 0.963415\n",
      "step 39660, cost 6.07853\n",
      "step 39660, change in cost 0.000281334\n",
      "step 39670, training accuracy 0.963415\n",
      "step 39670, cost 6.07825\n",
      "step 39670, change in cost 0.000283718\n",
      "step 39680, training accuracy 0.963415\n",
      "step 39680, cost 6.07797\n",
      "step 39680, change in cost 0.00028038\n",
      "step 39690, training accuracy 0.963415\n",
      "step 39690, cost 6.07768\n",
      "step 39690, change in cost 0.000283241\n",
      "step 39700, training accuracy 0.963415\n",
      "step 39700, cost 6.0774\n",
      "step 39700, change in cost 0.000281811\n",
      "step 39710, training accuracy 0.963415\n",
      "step 39710, cost 6.07712\n",
      "step 39710, change in cost 0.000282288\n",
      "step 39720, training accuracy 0.963415\n",
      "step 39720, cost 6.07684\n",
      "step 39720, change in cost 0.00028038\n",
      "step 39730, training accuracy 0.963415\n",
      "step 39730, cost 6.07656\n",
      "step 39730, change in cost 0.000281811\n",
      "step 39740, training accuracy 0.963415\n",
      "step 39740, cost 6.07628\n",
      "step 39740, change in cost 0.000282288\n",
      "step 39750, training accuracy 0.963415\n",
      "step 39750, cost 6.07599\n",
      "step 39750, change in cost 0.000281334\n",
      "step 39760, training accuracy 0.963415\n",
      "step 39760, cost 6.07571\n",
      "step 39760, change in cost 0.000282764\n",
      "step 39770, training accuracy 0.963415\n",
      "step 39770, cost 6.07543\n",
      "step 39770, change in cost 0.000281334\n",
      "step 39780, training accuracy 0.963415\n",
      "step 39780, cost 6.07515\n",
      "step 39780, change in cost 0.000281811\n",
      "step 39790, training accuracy 0.963415\n",
      "step 39790, cost 6.07487\n",
      "step 39790, change in cost 0.00028038\n",
      "step 39800, training accuracy 0.963415\n",
      "step 39800, cost 6.07459\n",
      "step 39800, change in cost 0.00028038\n",
      "step 39810, training accuracy 0.963415\n",
      "step 39810, cost 6.0743\n",
      "step 39810, change in cost 0.000282764\n",
      "step 39820, training accuracy 0.963415\n",
      "step 39820, cost 6.07403\n",
      "step 39820, change in cost 0.000279427\n",
      "step 39830, training accuracy 0.963415\n",
      "step 39830, cost 6.07374\n",
      "step 39830, change in cost 0.000282288\n",
      "step 39840, training accuracy 0.963415\n",
      "step 39840, cost 6.07346\n",
      "step 39840, change in cost 0.000279903\n",
      "step 39850, training accuracy 0.963415\n",
      "step 39850, cost 6.07318\n",
      "step 39850, change in cost 0.000280857\n",
      "step 39860, training accuracy 0.963415\n",
      "step 39860, cost 6.0729\n",
      "step 39860, change in cost 0.000281334\n",
      "step 39870, training accuracy 0.963415\n",
      "step 39870, cost 6.07262\n",
      "step 39870, change in cost 0.000280857\n",
      "step 39880, training accuracy 0.963415\n",
      "step 39880, cost 6.07234\n",
      "step 39880, change in cost 0.000281334\n",
      "step 39890, training accuracy 0.963415\n",
      "step 39890, cost 6.07206\n",
      "step 39890, change in cost 0.000280857\n",
      "step 39900, training accuracy 0.963415\n",
      "step 39900, cost 6.07178\n",
      "step 39900, change in cost 0.00027895\n",
      "step 39910, training accuracy 0.963415\n",
      "step 39910, cost 6.0715\n",
      "step 39910, change in cost 0.000279903\n",
      "step 39920, training accuracy 0.963415\n",
      "step 39920, cost 6.07122\n",
      "step 39920, change in cost 0.000281811\n",
      "step 39930, training accuracy 0.963415\n",
      "step 39930, cost 6.07094\n",
      "step 39930, change in cost 0.000279427\n",
      "step 39940, training accuracy 0.963415\n",
      "step 39940, cost 6.07066\n",
      "step 39940, change in cost 0.00028038\n",
      "step 39950, training accuracy 0.963415\n",
      "step 39950, cost 6.07038\n",
      "step 39950, change in cost 0.000280857\n",
      "step 39960, training accuracy 0.963415\n",
      "step 39960, cost 6.0701\n",
      "step 39960, change in cost 0.000278473\n",
      "step 39970, training accuracy 0.963415\n",
      "step 39970, cost 6.06982\n",
      "step 39970, change in cost 0.000282288\n",
      "step 39980, training accuracy 0.963415\n",
      "step 39980, cost 6.06954\n",
      "step 39980, change in cost 0.000279427\n",
      "step 39990, training accuracy 0.963415\n",
      "step 39990, cost 6.06926\n",
      "step 39990, change in cost 0.000278473\n",
      "step 40000, training accuracy 0.963415\n",
      "step 40000, cost 6.06898\n",
      "step 40000, change in cost 0.000279903\n",
      "step 40010, training accuracy 0.963415\n",
      "step 40010, cost 6.0687\n",
      "step 40010, change in cost 0.00027895\n",
      "step 40020, training accuracy 0.963415\n",
      "step 40020, cost 6.06842\n",
      "step 40020, change in cost 0.000279427\n",
      "step 40030, training accuracy 0.963415\n",
      "step 40030, cost 6.06814\n",
      "step 40030, change in cost 0.00028038\n",
      "step 40040, training accuracy 0.963415\n",
      "step 40040, cost 6.06786\n",
      "step 40040, change in cost 0.000279427\n",
      "step 40050, training accuracy 0.963415\n",
      "step 40050, cost 6.06758\n",
      "step 40050, change in cost 0.00027895\n",
      "step 40060, training accuracy 0.963415\n",
      "step 40060, cost 6.0673\n",
      "step 40060, change in cost 0.000279903\n",
      "step 40070, training accuracy 0.963415\n",
      "step 40070, cost 6.06702\n",
      "step 40070, change in cost 0.000278473\n",
      "step 40080, training accuracy 0.963415\n",
      "step 40080, cost 6.06674\n",
      "step 40080, change in cost 0.000279427\n",
      "step 40090, training accuracy 0.963415\n",
      "step 40090, cost 6.06646\n",
      "step 40090, change in cost 0.00028038\n",
      "step 40100, training accuracy 0.963415\n",
      "step 40100, cost 6.06618\n",
      "step 40100, change in cost 0.000277996\n",
      "step 40110, training accuracy 0.963415\n",
      "step 40110, cost 6.06591\n",
      "step 40110, change in cost 0.000277042\n",
      "step 40120, training accuracy 0.963415\n",
      "step 40120, cost 6.06563\n",
      "step 40120, change in cost 0.00027895\n",
      "step 40130, training accuracy 0.963415\n",
      "step 40130, cost 6.06535\n",
      "step 40130, change in cost 0.00027895\n",
      "step 40140, training accuracy 0.963415\n",
      "step 40140, cost 6.06507\n",
      "step 40140, change in cost 0.00027895\n",
      "step 40150, training accuracy 0.963415\n",
      "step 40150, cost 6.06479\n",
      "step 40150, change in cost 0.000279427\n",
      "step 40160, training accuracy 0.963415\n",
      "step 40160, cost 6.06451\n",
      "step 40160, change in cost 0.000277996\n",
      "step 40170, training accuracy 0.963415\n",
      "step 40170, cost 6.06423\n",
      "step 40170, change in cost 0.000278473\n",
      "step 40180, training accuracy 0.963415\n",
      "step 40180, cost 6.06396\n",
      "step 40180, change in cost 0.000277519\n",
      "step 40190, training accuracy 0.963415\n",
      "step 40190, cost 6.06368\n",
      "step 40190, change in cost 0.000278473\n",
      "step 40200, training accuracy 0.963415\n",
      "step 40200, cost 6.0634\n",
      "step 40200, change in cost 0.000277519\n",
      "step 40210, training accuracy 0.963415\n",
      "step 40210, cost 6.06312\n",
      "step 40210, change in cost 0.00027895\n",
      "step 40220, training accuracy 0.963415\n",
      "step 40220, cost 6.06285\n",
      "step 40220, change in cost 0.000276566\n",
      "step 40230, training accuracy 0.963415\n",
      "step 40230, cost 6.06257\n",
      "step 40230, change in cost 0.000277042\n",
      "step 40240, training accuracy 0.963415\n",
      "step 40240, cost 6.06229\n",
      "step 40240, change in cost 0.00027895\n",
      "step 40250, training accuracy 0.963415\n",
      "step 40250, cost 6.06201\n",
      "step 40250, change in cost 0.000277519\n",
      "step 40260, training accuracy 0.963415\n",
      "step 40260, cost 6.06174\n",
      "step 40260, change in cost 0.000277042\n",
      "step 40270, training accuracy 0.963415\n",
      "step 40270, cost 6.06146\n",
      "step 40270, change in cost 0.000277996\n",
      "step 40280, training accuracy 0.963415\n",
      "step 40280, cost 6.06118\n",
      "step 40280, change in cost 0.000277042\n",
      "step 40290, training accuracy 0.963415\n",
      "step 40290, cost 6.0609\n",
      "step 40290, change in cost 0.000276566\n",
      "step 40300, training accuracy 0.963415\n",
      "step 40300, cost 6.06063\n",
      "step 40300, change in cost 0.000277519\n",
      "step 40310, training accuracy 0.963415\n",
      "step 40310, cost 6.06035\n",
      "step 40310, change in cost 0.000278473\n",
      "step 40320, training accuracy 0.963415\n",
      "step 40320, cost 6.06007\n",
      "step 40320, change in cost 0.000276089\n",
      "step 40330, training accuracy 0.963415\n",
      "step 40330, cost 6.05979\n",
      "step 40330, change in cost 0.000277996\n",
      "step 40340, training accuracy 0.963415\n",
      "step 40340, cost 6.05952\n",
      "step 40340, change in cost 0.000275612\n",
      "step 40350, training accuracy 0.963415\n",
      "step 40350, cost 6.05924\n",
      "step 40350, change in cost 0.000277519\n",
      "step 40360, training accuracy 0.963415\n",
      "step 40360, cost 6.05896\n",
      "step 40360, change in cost 0.000276566\n",
      "step 40370, training accuracy 0.963415\n",
      "step 40370, cost 6.05869\n",
      "step 40370, change in cost 0.000276566\n",
      "step 40380, training accuracy 0.963415\n",
      "step 40380, cost 6.05841\n",
      "step 40380, change in cost 0.000275612\n",
      "step 40390, training accuracy 0.963415\n",
      "step 40390, cost 6.05813\n",
      "step 40390, change in cost 0.000277519\n",
      "step 40400, training accuracy 0.963415\n",
      "step 40400, cost 6.05786\n",
      "step 40400, change in cost 0.000275612\n",
      "step 40410, training accuracy 0.963415\n",
      "step 40410, cost 6.05758\n",
      "step 40410, change in cost 0.000276566\n",
      "step 40420, training accuracy 0.963415\n",
      "step 40420, cost 6.05731\n",
      "step 40420, change in cost 0.000276566\n",
      "step 40430, training accuracy 0.963415\n",
      "step 40430, cost 6.05703\n",
      "step 40430, change in cost 0.000274658\n",
      "step 40440, training accuracy 0.963415\n",
      "step 40440, cost 6.05675\n",
      "step 40440, change in cost 0.000276566\n",
      "step 40450, training accuracy 0.963415\n",
      "step 40450, cost 6.05648\n",
      "step 40450, change in cost 0.000275612\n",
      "step 40460, training accuracy 0.963415\n",
      "step 40460, cost 6.0562\n",
      "step 40460, change in cost 0.000276566\n",
      "step 40470, training accuracy 0.963415\n",
      "step 40470, cost 6.05593\n",
      "step 40470, change in cost 0.000276566\n",
      "step 40480, training accuracy 0.963415\n",
      "step 40480, cost 6.05565\n",
      "step 40480, change in cost 0.000276089\n",
      "step 40490, training accuracy 0.963415\n",
      "step 40490, cost 6.05537\n",
      "step 40490, change in cost 0.000276089\n",
      "step 40500, training accuracy 0.963415\n",
      "step 40500, cost 6.0551\n",
      "step 40500, change in cost 0.000275612\n",
      "step 40510, training accuracy 0.963415\n",
      "step 40510, cost 6.05482\n",
      "step 40510, change in cost 0.000275612\n",
      "step 40520, training accuracy 0.963415\n",
      "step 40520, cost 6.05455\n",
      "step 40520, change in cost 0.000275135\n",
      "step 40530, training accuracy 0.963415\n",
      "step 40530, cost 6.05427\n",
      "step 40530, change in cost 0.000275135\n",
      "step 40540, training accuracy 0.963415\n",
      "step 40540, cost 6.054\n",
      "step 40540, change in cost 0.000276089\n",
      "step 40550, training accuracy 0.963415\n",
      "step 40550, cost 6.05372\n",
      "step 40550, change in cost 0.000275135\n",
      "step 40560, training accuracy 0.963415\n",
      "step 40560, cost 6.05344\n",
      "step 40560, change in cost 0.000276089\n",
      "step 40570, training accuracy 0.963415\n",
      "step 40570, cost 6.05317\n",
      "step 40570, change in cost 0.000274658\n",
      "step 40580, training accuracy 0.963415\n",
      "step 40580, cost 6.05289\n",
      "step 40580, change in cost 0.000276089\n",
      "step 40590, training accuracy 0.963415\n",
      "step 40590, cost 6.05262\n",
      "step 40590, change in cost 0.000274181\n",
      "step 40600, training accuracy 0.963415\n",
      "step 40600, cost 6.05234\n",
      "step 40600, change in cost 0.000275135\n",
      "step 40610, training accuracy 0.963415\n",
      "step 40610, cost 6.05207\n",
      "step 40610, change in cost 0.000274658\n",
      "step 40620, training accuracy 0.963415\n",
      "step 40620, cost 6.0518\n",
      "step 40620, change in cost 0.000274658\n",
      "step 40630, training accuracy 0.963415\n",
      "step 40630, cost 6.05152\n",
      "step 40630, change in cost 0.000274658\n",
      "step 40640, training accuracy 0.963415\n",
      "step 40640, cost 6.05125\n",
      "step 40640, change in cost 0.000274658\n",
      "step 40650, training accuracy 0.963415\n",
      "step 40650, cost 6.05097\n",
      "step 40650, change in cost 0.000274658\n",
      "step 40660, training accuracy 0.963415\n",
      "step 40660, cost 6.0507\n",
      "step 40660, change in cost 0.000274658\n",
      "step 40670, training accuracy 0.963415\n",
      "step 40670, cost 6.05042\n",
      "step 40670, change in cost 0.000273705\n",
      "step 40680, training accuracy 0.963415\n",
      "step 40680, cost 6.05015\n",
      "step 40680, change in cost 0.000275135\n",
      "step 40690, training accuracy 0.963415\n",
      "step 40690, cost 6.04987\n",
      "step 40690, change in cost 0.000275135\n",
      "step 40700, training accuracy 0.963415\n",
      "step 40700, cost 6.0496\n",
      "step 40700, change in cost 0.000274181\n",
      "step 40710, training accuracy 0.963415\n",
      "step 40710, cost 6.04932\n",
      "step 40710, change in cost 0.000275135\n",
      "step 40720, training accuracy 0.963415\n",
      "step 40720, cost 6.04905\n",
      "step 40720, change in cost 0.000273705\n",
      "step 40730, training accuracy 0.963415\n",
      "step 40730, cost 6.04878\n",
      "step 40730, change in cost 0.000272751\n",
      "step 40740, training accuracy 0.963415\n",
      "step 40740, cost 6.0485\n",
      "step 40740, change in cost 0.000273705\n",
      "step 40750, training accuracy 0.963415\n",
      "step 40750, cost 6.04823\n",
      "step 40750, change in cost 0.000274658\n",
      "step 40760, training accuracy 0.963415\n",
      "step 40760, cost 6.04795\n",
      "step 40760, change in cost 0.000273705\n",
      "step 40770, training accuracy 0.963415\n",
      "step 40770, cost 6.04768\n",
      "step 40770, change in cost 0.000274181\n",
      "step 40780, training accuracy 0.963415\n",
      "step 40780, cost 6.04741\n",
      "step 40780, change in cost 0.000274181\n",
      "step 40790, training accuracy 0.963415\n",
      "step 40790, cost 6.04713\n",
      "step 40790, change in cost 0.000274658\n",
      "step 40800, training accuracy 0.963415\n",
      "step 40800, cost 6.04686\n",
      "step 40800, change in cost 0.000272751\n",
      "step 40810, training accuracy 0.963415\n",
      "step 40810, cost 6.04659\n",
      "step 40810, change in cost 0.000273228\n",
      "step 40820, training accuracy 0.963415\n",
      "step 40820, cost 6.04631\n",
      "step 40820, change in cost 0.000273705\n",
      "step 40830, training accuracy 0.963415\n",
      "step 40830, cost 6.04604\n",
      "step 40830, change in cost 0.000273228\n",
      "step 40840, training accuracy 0.963415\n",
      "step 40840, cost 6.04576\n",
      "step 40840, change in cost 0.000273705\n",
      "step 40850, training accuracy 0.963415\n",
      "step 40850, cost 6.04549\n",
      "step 40850, change in cost 0.000273228\n",
      "step 40860, training accuracy 0.963415\n",
      "step 40860, cost 6.04522\n",
      "step 40860, change in cost 0.000273228\n",
      "step 40870, training accuracy 0.963415\n",
      "step 40870, cost 6.04495\n",
      "step 40870, change in cost 0.000272751\n",
      "step 40880, training accuracy 0.963415\n",
      "step 40880, cost 6.04467\n",
      "step 40880, change in cost 0.000272751\n",
      "step 40890, training accuracy 0.963415\n",
      "step 40890, cost 6.0444\n",
      "step 40890, change in cost 0.000273705\n",
      "step 40900, training accuracy 0.963415\n",
      "step 40900, cost 6.04413\n",
      "step 40900, change in cost 0.000272274\n",
      "step 40910, training accuracy 0.963415\n",
      "step 40910, cost 6.04385\n",
      "step 40910, change in cost 0.000272274\n",
      "step 40920, training accuracy 0.963415\n",
      "step 40920, cost 6.04358\n",
      "step 40920, change in cost 0.000273228\n",
      "step 40930, training accuracy 0.963415\n",
      "step 40930, cost 6.04331\n",
      "step 40930, change in cost 0.000272751\n",
      "step 40940, training accuracy 0.963415\n",
      "step 40940, cost 6.04304\n",
      "step 40940, change in cost 0.000272274\n",
      "step 40950, training accuracy 0.963415\n",
      "step 40950, cost 6.04276\n",
      "step 40950, change in cost 0.000271797\n",
      "step 40960, training accuracy 0.963415\n",
      "step 40960, cost 6.04249\n",
      "step 40960, change in cost 0.000272751\n",
      "step 40970, training accuracy 0.963415\n",
      "step 40970, cost 6.04222\n",
      "step 40970, change in cost 0.000271797\n",
      "step 40980, training accuracy 0.963415\n",
      "step 40980, cost 6.04195\n",
      "step 40980, change in cost 0.000271797\n",
      "step 40990, training accuracy 0.963415\n",
      "step 40990, cost 6.04168\n",
      "step 40990, change in cost 0.000272274\n",
      "step 41000, training accuracy 0.963415\n",
      "step 41000, cost 6.0414\n",
      "step 41000, change in cost 0.000274658\n",
      "step 41010, training accuracy 0.963415\n",
      "step 41010, cost 6.04113\n",
      "step 41010, change in cost 0.000272274\n",
      "step 41020, training accuracy 0.963415\n",
      "step 41020, cost 6.04086\n",
      "step 41020, change in cost 0.000270844\n",
      "step 41030, training accuracy 0.963415\n",
      "step 41030, cost 6.04059\n",
      "step 41030, change in cost 0.000271797\n",
      "step 41040, training accuracy 0.963415\n",
      "step 41040, cost 6.04031\n",
      "step 41040, change in cost 0.000272274\n",
      "step 41050, training accuracy 0.963415\n",
      "step 41050, cost 6.04004\n",
      "step 41050, change in cost 0.00027132\n",
      "step 41060, training accuracy 0.963415\n",
      "step 41060, cost 6.03977\n",
      "step 41060, change in cost 0.000272274\n",
      "step 41070, training accuracy 0.963415\n",
      "step 41070, cost 6.0395\n",
      "step 41070, change in cost 0.000272274\n",
      "step 41080, training accuracy 0.963415\n",
      "step 41080, cost 6.03923\n",
      "step 41080, change in cost 0.000271797\n",
      "step 41090, training accuracy 0.963415\n",
      "step 41090, cost 6.03895\n",
      "step 41090, change in cost 0.000271797\n",
      "step 41100, training accuracy 0.963415\n",
      "step 41100, cost 6.03868\n",
      "step 41100, change in cost 0.000270367\n",
      "step 41110, training accuracy 0.963415\n",
      "step 41110, cost 6.03841\n",
      "step 41110, change in cost 0.000272751\n",
      "step 41120, training accuracy 0.963415\n",
      "step 41120, cost 6.03814\n",
      "step 41120, change in cost 0.00027132\n",
      "step 41130, training accuracy 0.963415\n",
      "step 41130, cost 6.03787\n",
      "step 41130, change in cost 0.000272274\n",
      "step 41140, training accuracy 0.963415\n",
      "step 41140, cost 6.0376\n",
      "step 41140, change in cost 0.000269413\n",
      "step 41150, training accuracy 0.963415\n",
      "step 41150, cost 6.03733\n",
      "step 41150, change in cost 0.000271797\n",
      "step 41160, training accuracy 0.963415\n",
      "step 41160, cost 6.03706\n",
      "step 41160, change in cost 0.000270844\n",
      "step 41170, training accuracy 0.963415\n",
      "step 41170, cost 6.03678\n",
      "step 41170, change in cost 0.000271797\n",
      "step 41180, training accuracy 0.963415\n",
      "step 41180, cost 6.03651\n",
      "step 41180, change in cost 0.00027132\n",
      "step 41190, training accuracy 0.963415\n",
      "step 41190, cost 6.03624\n",
      "step 41190, change in cost 0.000270367\n",
      "step 41200, training accuracy 0.963415\n",
      "step 41200, cost 6.03597\n",
      "step 41200, change in cost 0.000270844\n",
      "step 41210, training accuracy 0.963415\n",
      "step 41210, cost 6.0357\n",
      "step 41210, change in cost 0.000271797\n",
      "step 41220, training accuracy 0.963415\n",
      "step 41220, cost 6.03543\n",
      "step 41220, change in cost 0.000270844\n",
      "step 41230, training accuracy 0.963415\n",
      "step 41230, cost 6.03516\n",
      "step 41230, change in cost 0.000270844\n",
      "step 41240, training accuracy 0.963415\n",
      "step 41240, cost 6.03489\n",
      "step 41240, change in cost 0.000270367\n",
      "step 41250, training accuracy 0.963415\n",
      "step 41250, cost 6.03462\n",
      "step 41250, change in cost 0.00027132\n",
      "step 41260, training accuracy 0.963415\n",
      "step 41260, cost 6.03435\n",
      "step 41260, change in cost 0.000270844\n",
      "step 41270, training accuracy 0.963415\n",
      "step 41270, cost 6.03408\n",
      "step 41270, change in cost 0.00026989\n",
      "step 41280, training accuracy 0.963415\n",
      "step 41280, cost 6.0338\n",
      "step 41280, change in cost 0.000270844\n",
      "step 41290, training accuracy 0.963415\n",
      "step 41290, cost 6.03354\n",
      "step 41290, change in cost 0.00026989\n",
      "step 41300, training accuracy 0.963415\n",
      "step 41300, cost 6.03326\n",
      "step 41300, change in cost 0.000270844\n",
      "step 41310, training accuracy 0.963415\n",
      "step 41310, cost 6.033\n",
      "step 41310, change in cost 0.000268459\n",
      "step 41320, training accuracy 0.963415\n",
      "step 41320, cost 6.03272\n",
      "step 41320, change in cost 0.00027132\n",
      "step 41330, training accuracy 0.963415\n",
      "step 41330, cost 6.03245\n",
      "step 41330, change in cost 0.000271797\n",
      "step 41340, training accuracy 0.963415\n",
      "step 41340, cost 6.03218\n",
      "step 41340, change in cost 0.000268936\n",
      "step 41350, training accuracy 0.963415\n",
      "step 41350, cost 6.03191\n",
      "step 41350, change in cost 0.00026989\n",
      "step 41360, training accuracy 0.963415\n",
      "step 41360, cost 6.03164\n",
      "step 41360, change in cost 0.00026989\n",
      "step 41370, training accuracy 0.963415\n",
      "step 41370, cost 6.03137\n",
      "step 41370, change in cost 0.00026989\n",
      "step 41380, training accuracy 0.963415\n",
      "step 41380, cost 6.0311\n",
      "step 41380, change in cost 0.000270367\n",
      "step 41390, training accuracy 0.963415\n",
      "step 41390, cost 6.03083\n",
      "step 41390, change in cost 0.000269413\n",
      "step 41400, training accuracy 0.963415\n",
      "step 41400, cost 6.03056\n",
      "step 41400, change in cost 0.00026989\n",
      "step 41410, training accuracy 0.963415\n",
      "step 41410, cost 6.03029\n",
      "step 41410, change in cost 0.00026989\n",
      "step 41420, training accuracy 0.963415\n",
      "step 41420, cost 6.03003\n",
      "step 41420, change in cost 0.000267982\n",
      "step 41430, training accuracy 0.963415\n",
      "step 41430, cost 6.02976\n",
      "step 41430, change in cost 0.000270844\n",
      "step 41440, training accuracy 0.963415\n",
      "step 41440, cost 6.02949\n",
      "step 41440, change in cost 0.00026989\n",
      "step 41450, training accuracy 0.963415\n",
      "step 41450, cost 6.02922\n",
      "step 41450, change in cost 0.000268459\n",
      "step 41460, training accuracy 0.963415\n",
      "step 41460, cost 6.02895\n",
      "step 41460, change in cost 0.000268459\n",
      "step 41470, training accuracy 0.963415\n",
      "step 41470, cost 6.02868\n",
      "step 41470, change in cost 0.000270367\n",
      "step 41480, training accuracy 0.963415\n",
      "step 41480, cost 6.02841\n",
      "step 41480, change in cost 0.000269413\n",
      "step 41490, training accuracy 0.963415\n",
      "step 41490, cost 6.02814\n",
      "step 41490, change in cost 0.000269413\n",
      "step 41500, training accuracy 0.963415\n",
      "step 41500, cost 6.02787\n",
      "step 41500, change in cost 0.000268459\n",
      "step 41510, training accuracy 0.963415\n",
      "step 41510, cost 6.0276\n",
      "step 41510, change in cost 0.000268936\n",
      "step 41520, training accuracy 0.963415\n",
      "step 41520, cost 6.02733\n",
      "step 41520, change in cost 0.00026989\n",
      "step 41530, training accuracy 0.963415\n",
      "step 41530, cost 6.02706\n",
      "step 41530, change in cost 0.000267982\n",
      "step 41540, training accuracy 0.963415\n",
      "step 41540, cost 6.02679\n",
      "step 41540, change in cost 0.00026989\n",
      "step 41550, training accuracy 0.963415\n",
      "step 41550, cost 6.02653\n",
      "step 41550, change in cost 0.000267506\n",
      "step 41560, training accuracy 0.963415\n",
      "step 41560, cost 6.02626\n",
      "step 41560, change in cost 0.000269413\n",
      "step 41570, training accuracy 0.963415\n",
      "step 41570, cost 6.02599\n",
      "step 41570, change in cost 0.00026989\n",
      "step 41580, training accuracy 0.963415\n",
      "step 41580, cost 6.02572\n",
      "step 41580, change in cost 0.000267506\n",
      "step 41590, training accuracy 0.963415\n",
      "step 41590, cost 6.02545\n",
      "step 41590, change in cost 0.00026989\n",
      "step 41600, training accuracy 0.963415\n",
      "step 41600, cost 6.02518\n",
      "step 41600, change in cost 0.000268459\n",
      "step 41610, training accuracy 0.963415\n",
      "step 41610, cost 6.02491\n",
      "step 41610, change in cost 0.000268936\n",
      "step 41620, training accuracy 0.963415\n",
      "step 41620, cost 6.02464\n",
      "step 41620, change in cost 0.000268459\n",
      "step 41630, training accuracy 0.963415\n",
      "step 41630, cost 6.02438\n",
      "step 41630, change in cost 0.000267506\n",
      "step 41640, training accuracy 0.963415\n",
      "step 41640, cost 6.02411\n",
      "step 41640, change in cost 0.00026989\n",
      "step 41650, training accuracy 0.963415\n",
      "step 41650, cost 6.02384\n",
      "step 41650, change in cost 0.000267982\n",
      "step 41660, training accuracy 0.963415\n",
      "step 41660, cost 6.02357\n",
      "step 41660, change in cost 0.000267982\n",
      "step 41670, training accuracy 0.963415\n",
      "step 41670, cost 6.0233\n",
      "step 41670, change in cost 0.000268936\n",
      "step 41680, training accuracy 0.963415\n",
      "step 41680, cost 6.02304\n",
      "step 41680, change in cost 0.000267029\n",
      "step 41690, training accuracy 0.963415\n",
      "step 41690, cost 6.02277\n",
      "step 41690, change in cost 0.000268459\n",
      "step 41700, training accuracy 0.963415\n",
      "step 41700, cost 6.0225\n",
      "step 41700, change in cost 0.000268459\n",
      "step 41710, training accuracy 0.963415\n",
      "step 41710, cost 6.02223\n",
      "step 41710, change in cost 0.000267982\n",
      "step 41720, training accuracy 0.963415\n",
      "step 41720, cost 6.02196\n",
      "step 41720, change in cost 0.00026989\n",
      "step 41730, training accuracy 0.963415\n",
      "step 41730, cost 6.02169\n",
      "step 41730, change in cost 0.000267029\n",
      "step 41740, training accuracy 0.963415\n",
      "step 41740, cost 6.02142\n",
      "step 41740, change in cost 0.000268459\n",
      "step 41750, training accuracy 0.963415\n",
      "step 41750, cost 6.02116\n",
      "step 41750, change in cost 0.000266552\n",
      "step 41760, training accuracy 0.963415\n",
      "step 41760, cost 6.02089\n",
      "step 41760, change in cost 0.000268936\n",
      "step 41770, training accuracy 0.963415\n",
      "step 41770, cost 6.02062\n",
      "step 41770, change in cost 0.000267029\n",
      "step 41780, training accuracy 0.963415\n",
      "step 41780, cost 6.02035\n",
      "step 41780, change in cost 0.000267982\n",
      "step 41790, training accuracy 0.963415\n",
      "step 41790, cost 6.02009\n",
      "step 41790, change in cost 0.000267982\n",
      "step 41800, training accuracy 0.963415\n",
      "step 41800, cost 6.01982\n",
      "step 41800, change in cost 0.000267982\n",
      "step 41810, training accuracy 0.963415\n",
      "step 41810, cost 6.01955\n",
      "step 41810, change in cost 0.000267029\n",
      "step 41820, training accuracy 0.963415\n",
      "step 41820, cost 6.01928\n",
      "step 41820, change in cost 0.000266552\n",
      "step 41830, training accuracy 0.963415\n",
      "step 41830, cost 6.01902\n",
      "step 41830, change in cost 0.000267506\n",
      "step 41840, training accuracy 0.963415\n",
      "step 41840, cost 6.01875\n",
      "step 41840, change in cost 0.000269413\n",
      "step 41850, training accuracy 0.963415\n",
      "step 41850, cost 6.01848\n",
      "step 41850, change in cost 0.000266075\n",
      "step 41860, training accuracy 0.963415\n",
      "step 41860, cost 6.01821\n",
      "step 41860, change in cost 0.000267982\n",
      "step 41870, training accuracy 0.963415\n",
      "step 41870, cost 6.01795\n",
      "step 41870, change in cost 0.000266075\n",
      "step 41880, training accuracy 0.963415\n",
      "step 41880, cost 6.01768\n",
      "step 41880, change in cost 0.000267506\n",
      "step 41890, training accuracy 0.963415\n",
      "step 41890, cost 6.01741\n",
      "step 41890, change in cost 0.000267982\n",
      "step 41900, training accuracy 0.963415\n",
      "step 41900, cost 6.01715\n",
      "step 41900, change in cost 0.000266552\n",
      "step 41910, training accuracy 0.963415\n",
      "step 41910, cost 6.01688\n",
      "step 41910, change in cost 0.000266552\n",
      "step 41920, training accuracy 0.963415\n",
      "step 41920, cost 6.01661\n",
      "step 41920, change in cost 0.000267506\n",
      "step 41930, training accuracy 0.963415\n",
      "step 41930, cost 6.01635\n",
      "step 41930, change in cost 0.000266075\n",
      "step 41940, training accuracy 0.963415\n",
      "step 41940, cost 6.01608\n",
      "step 41940, change in cost 0.000266552\n",
      "step 41950, training accuracy 0.963415\n",
      "step 41950, cost 6.01581\n",
      "step 41950, change in cost 0.000266552\n",
      "step 41960, training accuracy 0.963415\n",
      "step 41960, cost 6.01554\n",
      "step 41960, change in cost 0.000268459\n",
      "step 41970, training accuracy 0.963415\n",
      "step 41970, cost 6.01528\n",
      "step 41970, change in cost 0.000265121\n",
      "step 41980, training accuracy 0.963415\n",
      "step 41980, cost 6.01501\n",
      "step 41980, change in cost 0.000267982\n",
      "step 41990, training accuracy 0.963415\n",
      "step 41990, cost 6.01475\n",
      "step 41990, change in cost 0.000265121\n",
      "step 42000, training accuracy 0.963415\n",
      "step 42000, cost 6.01448\n",
      "step 42000, change in cost 0.000267506\n",
      "step 42010, training accuracy 0.963415\n",
      "step 42010, cost 6.01421\n",
      "step 42010, change in cost 0.000266552\n",
      "step 42020, training accuracy 0.963415\n",
      "step 42020, cost 6.01394\n",
      "step 42020, change in cost 0.000267029\n",
      "step 42030, training accuracy 0.963415\n",
      "step 42030, cost 6.01368\n",
      "step 42030, change in cost 0.000264645\n",
      "step 42040, training accuracy 0.963415\n",
      "step 42040, cost 6.01341\n",
      "step 42040, change in cost 0.000267506\n",
      "step 42050, training accuracy 0.963415\n",
      "step 42050, cost 6.01315\n",
      "step 42050, change in cost 0.000265121\n",
      "step 42060, training accuracy 0.963415\n",
      "step 42060, cost 6.01288\n",
      "step 42060, change in cost 0.000265598\n",
      "step 42070, training accuracy 0.963415\n",
      "step 42070, cost 6.01261\n",
      "step 42070, change in cost 0.000267506\n",
      "step 42080, training accuracy 0.963415\n",
      "step 42080, cost 6.01235\n",
      "step 42080, change in cost 0.000265121\n",
      "step 42090, training accuracy 0.963415\n",
      "step 42090, cost 6.01208\n",
      "step 42090, change in cost 0.000266552\n",
      "step 42100, training accuracy 0.963415\n",
      "step 42100, cost 6.01182\n",
      "step 42100, change in cost 0.000267029\n",
      "step 42110, training accuracy 0.963415\n",
      "step 42110, cost 6.01155\n",
      "step 42110, change in cost 0.000264645\n",
      "step 42120, training accuracy 0.963415\n",
      "step 42120, cost 6.01128\n",
      "step 42120, change in cost 0.000267506\n",
      "step 42130, training accuracy 0.963415\n",
      "step 42130, cost 6.01102\n",
      "step 42130, change in cost 0.000264645\n",
      "step 42140, training accuracy 0.963415\n",
      "step 42140, cost 6.01075\n",
      "step 42140, change in cost 0.000265598\n",
      "step 42150, training accuracy 0.963415\n",
      "step 42150, cost 6.01049\n",
      "step 42150, change in cost 0.000266552\n",
      "step 42160, training accuracy 0.963415\n",
      "step 42160, cost 6.01022\n",
      "step 42160, change in cost 0.000265598\n",
      "step 42170, training accuracy 0.963415\n",
      "step 42170, cost 6.00995\n",
      "step 42170, change in cost 0.000266552\n",
      "step 42180, training accuracy 0.963415\n",
      "step 42180, cost 6.00969\n",
      "step 42180, change in cost 0.000265598\n",
      "step 42190, training accuracy 0.963415\n",
      "step 42190, cost 6.00942\n",
      "step 42190, change in cost 0.000265598\n",
      "step 42200, training accuracy 0.963415\n",
      "step 42200, cost 6.00916\n",
      "step 42200, change in cost 0.000266075\n",
      "step 42210, training accuracy 0.963415\n",
      "step 42210, cost 6.00889\n",
      "step 42210, change in cost 0.000265121\n",
      "step 42220, training accuracy 0.963415\n",
      "step 42220, cost 6.00863\n",
      "step 42220, change in cost 0.000266075\n",
      "step 42230, training accuracy 0.963415\n",
      "step 42230, cost 6.00836\n",
      "step 42230, change in cost 0.000266552\n",
      "step 42240, training accuracy 0.963415\n",
      "step 42240, cost 6.00809\n",
      "step 42240, change in cost 0.000266552\n",
      "step 42250, training accuracy 0.963415\n",
      "step 42250, cost 6.00783\n",
      "step 42250, change in cost 0.000264168\n",
      "step 42260, training accuracy 0.963415\n",
      "step 42260, cost 6.00756\n",
      "step 42260, change in cost 0.000264168\n",
      "step 42270, training accuracy 0.963415\n",
      "step 42270, cost 6.0073\n",
      "step 42270, change in cost 0.000266552\n",
      "step 42280, training accuracy 0.963415\n",
      "step 42280, cost 6.00703\n",
      "step 42280, change in cost 0.000266552\n",
      "step 42290, training accuracy 0.963415\n",
      "step 42290, cost 6.00677\n",
      "step 42290, change in cost 0.000264645\n",
      "step 42300, training accuracy 0.963415\n",
      "step 42300, cost 6.0065\n",
      "step 42300, change in cost 0.000263691\n",
      "step 42310, training accuracy 0.963415\n",
      "step 42310, cost 6.00624\n",
      "step 42310, change in cost 0.000265598\n",
      "step 42320, training accuracy 0.963415\n",
      "step 42320, cost 6.00597\n",
      "step 42320, change in cost 0.000265121\n",
      "step 42330, training accuracy 0.963415\n",
      "step 42330, cost 6.00571\n",
      "step 42330, change in cost 0.000266552\n",
      "step 42340, training accuracy 0.963415\n",
      "step 42340, cost 6.00544\n",
      "step 42340, change in cost 0.000265598\n",
      "step 42350, training accuracy 0.963415\n",
      "step 42350, cost 6.00518\n",
      "step 42350, change in cost 0.000264645\n",
      "step 42360, training accuracy 0.963415\n",
      "step 42360, cost 6.00491\n",
      "step 42360, change in cost 0.000266075\n",
      "step 42370, training accuracy 0.963415\n",
      "step 42370, cost 6.00465\n",
      "step 42370, change in cost 0.000264168\n",
      "step 42380, training accuracy 0.963415\n",
      "step 42380, cost 6.00438\n",
      "step 42380, change in cost 0.000265121\n",
      "step 42390, training accuracy 0.963415\n",
      "step 42390, cost 6.00411\n",
      "step 42390, change in cost 0.000266075\n",
      "step 42400, training accuracy 0.963415\n",
      "step 42400, cost 6.00385\n",
      "step 42400, change in cost 0.000264168\n",
      "step 42410, training accuracy 0.963415\n",
      "step 42410, cost 6.00358\n",
      "step 42410, change in cost 0.000267029\n",
      "step 42420, training accuracy 0.963415\n",
      "step 42420, cost 6.00332\n",
      "step 42420, change in cost 0.000264168\n",
      "step 42430, training accuracy 0.963415\n",
      "step 42430, cost 6.00306\n",
      "step 42430, change in cost 0.000263214\n",
      "step 42440, training accuracy 0.963415\n",
      "step 42440, cost 6.00279\n",
      "step 42440, change in cost 0.000267982\n",
      "step 42450, training accuracy 0.963415\n",
      "step 42450, cost 6.00253\n",
      "step 42450, change in cost 0.00026226\n",
      "step 42460, training accuracy 0.963415\n",
      "step 42460, cost 6.00226\n",
      "step 42460, change in cost 0.000267029\n",
      "step 42470, training accuracy 0.963415\n",
      "step 42470, cost 6.00199\n",
      "step 42470, change in cost 0.000263691\n",
      "step 42480, training accuracy 0.963415\n",
      "step 42480, cost 6.00173\n",
      "step 42480, change in cost 0.000265598\n",
      "step 42490, training accuracy 0.963415\n",
      "step 42490, cost 6.00146\n",
      "step 42490, change in cost 0.000264168\n",
      "step 42500, training accuracy 0.963415\n",
      "step 42500, cost 6.0012\n",
      "step 42500, change in cost 0.000263214\n",
      "step 42510, training accuracy 0.963415\n",
      "step 42510, cost 6.00094\n",
      "step 42510, change in cost 0.000265121\n",
      "step 42520, training accuracy 0.963415\n",
      "step 42520, cost 6.00067\n",
      "step 42520, change in cost 0.000266075\n",
      "step 42530, training accuracy 0.963415\n",
      "step 42530, cost 6.00041\n",
      "step 42530, change in cost 0.000264168\n",
      "step 42540, training accuracy 0.963415\n",
      "step 42540, cost 6.00014\n",
      "step 42540, change in cost 0.000264168\n",
      "step 42550, training accuracy 0.963415\n",
      "step 42550, cost 5.99988\n",
      "step 42550, change in cost 0.000264168\n",
      "step 42560, training accuracy 0.963415\n",
      "step 42560, cost 5.99961\n",
      "step 42560, change in cost 0.000265121\n",
      "step 42570, training accuracy 0.963415\n",
      "step 42570, cost 5.99935\n",
      "step 42570, change in cost 0.000265121\n",
      "step 42580, training accuracy 0.963415\n",
      "step 42580, cost 5.99908\n",
      "step 42580, change in cost 0.000263214\n",
      "step 42590, training accuracy 0.963415\n",
      "step 42590, cost 5.99882\n",
      "step 42590, change in cost 0.000264168\n",
      "step 42600, training accuracy 0.963415\n",
      "step 42600, cost 5.99856\n",
      "step 42600, change in cost 0.000264168\n",
      "step 42610, training accuracy 0.963415\n",
      "step 42610, cost 5.99829\n",
      "step 42610, change in cost 0.000265121\n",
      "step 42620, training accuracy 0.963415\n",
      "step 42620, cost 5.99803\n",
      "step 42620, change in cost 0.000265121\n",
      "step 42630, training accuracy 0.963415\n",
      "step 42630, cost 5.99776\n",
      "step 42630, change in cost 0.000263691\n",
      "step 42640, training accuracy 0.963415\n",
      "step 42640, cost 5.9975\n",
      "step 42640, change in cost 0.000264645\n",
      "step 42650, training accuracy 0.963415\n",
      "step 42650, cost 5.99723\n",
      "step 42650, change in cost 0.000264645\n",
      "step 42660, training accuracy 0.963415\n",
      "step 42660, cost 5.99697\n",
      "step 42660, change in cost 0.000263691\n",
      "step 42670, training accuracy 0.963415\n",
      "step 42670, cost 5.99671\n",
      "step 42670, change in cost 0.000263214\n",
      "step 42680, training accuracy 0.963415\n",
      "step 42680, cost 5.99644\n",
      "step 42680, change in cost 0.000264168\n",
      "step 42690, training accuracy 0.963415\n",
      "step 42690, cost 5.99618\n",
      "step 42690, change in cost 0.000265121\n",
      "step 42700, training accuracy 0.963415\n",
      "step 42700, cost 5.99591\n",
      "step 42700, change in cost 0.000263691\n",
      "step 42710, training accuracy 0.963415\n",
      "step 42710, cost 5.99565\n",
      "step 42710, change in cost 0.000264645\n",
      "step 42720, training accuracy 0.963415\n",
      "step 42720, cost 5.99539\n",
      "step 42720, change in cost 0.000262737\n",
      "step 42730, training accuracy 0.963415\n",
      "step 42730, cost 5.99512\n",
      "step 42730, change in cost 0.000264645\n",
      "step 42740, training accuracy 0.963415\n",
      "step 42740, cost 5.99486\n",
      "step 42740, change in cost 0.000264168\n",
      "step 42750, training accuracy 0.963415\n",
      "step 42750, cost 5.99459\n",
      "step 42750, change in cost 0.000265598\n",
      "step 42760, training accuracy 0.963415\n",
      "step 42760, cost 5.99433\n",
      "step 42760, change in cost 0.000262737\n",
      "step 42770, training accuracy 0.963415\n",
      "step 42770, cost 5.99406\n",
      "step 42770, change in cost 0.000265121\n",
      "step 42780, training accuracy 0.963415\n",
      "step 42780, cost 5.9938\n",
      "step 42780, change in cost 0.000264168\n",
      "step 42790, training accuracy 0.963415\n",
      "step 42790, cost 5.99354\n",
      "step 42790, change in cost 0.000263691\n",
      "step 42800, training accuracy 0.963415\n",
      "step 42800, cost 5.99327\n",
      "step 42800, change in cost 0.000264168\n",
      "step 42810, training accuracy 0.963415\n",
      "step 42810, cost 5.99301\n",
      "step 42810, change in cost 0.000262737\n",
      "step 42820, training accuracy 0.963415\n",
      "step 42820, cost 5.99275\n",
      "step 42820, change in cost 0.000262737\n",
      "step 42830, training accuracy 0.963415\n",
      "step 42830, cost 5.99248\n",
      "step 42830, change in cost 0.000265598\n",
      "step 42840, training accuracy 0.963415\n",
      "step 42840, cost 5.99222\n",
      "step 42840, change in cost 0.00026226\n",
      "step 42850, training accuracy 0.963415\n",
      "step 42850, cost 5.99195\n",
      "step 42850, change in cost 0.000265121\n",
      "step 42860, training accuracy 0.963415\n",
      "step 42860, cost 5.99169\n",
      "step 42860, change in cost 0.000263214\n",
      "step 42870, training accuracy 0.963415\n",
      "step 42870, cost 5.99143\n",
      "step 42870, change in cost 0.000263691\n",
      "step 42880, training accuracy 0.963415\n",
      "step 42880, cost 5.99116\n",
      "step 42880, change in cost 0.000264645\n",
      "step 42890, training accuracy 0.963415\n",
      "step 42890, cost 5.9909\n",
      "step 42890, change in cost 0.00026226\n",
      "step 42900, training accuracy 0.963415\n",
      "step 42900, cost 5.99063\n",
      "step 42900, change in cost 0.000264168\n",
      "step 42910, training accuracy 0.963415\n",
      "step 42910, cost 5.99037\n",
      "step 42910, change in cost 0.000264168\n",
      "step 42920, training accuracy 0.963415\n",
      "step 42920, cost 5.99011\n",
      "step 42920, change in cost 0.00026226\n",
      "step 42930, training accuracy 0.963415\n",
      "step 42930, cost 5.98985\n",
      "step 42930, change in cost 0.000263214\n",
      "step 42940, training accuracy 0.963415\n",
      "step 42940, cost 5.98958\n",
      "step 42940, change in cost 0.000266552\n",
      "step 42950, training accuracy 0.963415\n",
      "step 42950, cost 5.98932\n",
      "step 42950, change in cost 0.00026226\n",
      "step 42960, training accuracy 0.963415\n",
      "step 42960, cost 5.98905\n",
      "step 42960, change in cost 0.000263214\n",
      "step 42970, training accuracy 0.963415\n",
      "step 42970, cost 5.98879\n",
      "step 42970, change in cost 0.000264168\n",
      "step 42980, training accuracy 0.963415\n",
      "step 42980, cost 5.98853\n",
      "step 42980, change in cost 0.000262737\n",
      "step 42990, training accuracy 0.963415\n",
      "step 42990, cost 5.98826\n",
      "step 42990, change in cost 0.000262737\n",
      "step 43000, training accuracy 0.963415\n",
      "step 43000, cost 5.988\n",
      "step 43000, change in cost 0.000264168\n",
      "step 43010, training accuracy 0.963415\n",
      "step 43010, cost 5.98774\n",
      "step 43010, change in cost 0.000262737\n",
      "step 43020, training accuracy 0.963415\n",
      "step 43020, cost 5.98747\n",
      "step 43020, change in cost 0.000263214\n",
      "step 43030, training accuracy 0.963415\n",
      "step 43030, cost 5.98721\n",
      "step 43030, change in cost 0.000265121\n",
      "step 43040, training accuracy 0.963415\n",
      "step 43040, cost 5.98695\n",
      "step 43040, change in cost 0.000263214\n",
      "step 43050, training accuracy 0.963415\n",
      "step 43050, cost 5.98668\n",
      "step 43050, change in cost 0.000264168\n",
      "step 43060, training accuracy 0.963415\n",
      "step 43060, cost 5.98642\n",
      "step 43060, change in cost 0.000263214\n",
      "step 43070, training accuracy 0.963415\n",
      "step 43070, cost 5.98616\n",
      "step 43070, change in cost 0.00026226\n",
      "step 43080, training accuracy 0.963415\n",
      "step 43080, cost 5.98589\n",
      "step 43080, change in cost 0.000263691\n",
      "step 43090, training accuracy 0.963415\n",
      "step 43090, cost 5.98563\n",
      "step 43090, change in cost 0.000263214\n",
      "step 43100, training accuracy 0.963415\n",
      "step 43100, cost 5.98536\n",
      "step 43100, change in cost 0.000263691\n",
      "step 43110, training accuracy 0.963415\n",
      "step 43110, cost 5.9851\n",
      "step 43110, change in cost 0.000262737\n",
      "step 43120, training accuracy 0.963415\n",
      "step 43120, cost 5.98484\n",
      "step 43120, change in cost 0.000262737\n",
      "step 43130, training accuracy 0.963415\n",
      "step 43130, cost 5.98458\n",
      "step 43130, change in cost 0.000264168\n",
      "step 43140, training accuracy 0.963415\n",
      "step 43140, cost 5.98431\n",
      "step 43140, change in cost 0.000264168\n",
      "step 43150, training accuracy 0.963415\n",
      "step 43150, cost 5.98405\n",
      "step 43150, change in cost 0.00026226\n",
      "step 43160, training accuracy 0.963415\n",
      "step 43160, cost 5.98379\n",
      "step 43160, change in cost 0.000263214\n",
      "step 43170, training accuracy 0.963415\n",
      "step 43170, cost 5.98352\n",
      "step 43170, change in cost 0.00026226\n",
      "step 43180, training accuracy 0.963415\n",
      "step 43180, cost 5.98326\n",
      "step 43180, change in cost 0.000263214\n",
      "step 43190, training accuracy 0.963415\n",
      "step 43190, cost 5.983\n",
      "step 43190, change in cost 0.000264645\n",
      "step 43200, training accuracy 0.963415\n",
      "step 43200, cost 5.98273\n",
      "step 43200, change in cost 0.00026226\n",
      "step 43210, training accuracy 0.963415\n",
      "step 43210, cost 5.98247\n",
      "step 43210, change in cost 0.000264168\n",
      "step 43220, training accuracy 0.963415\n",
      "step 43220, cost 5.98221\n",
      "step 43220, change in cost 0.000261784\n",
      "step 43230, training accuracy 0.963415\n",
      "step 43230, cost 5.98194\n",
      "step 43230, change in cost 0.000263214\n",
      "step 43240, training accuracy 0.963415\n",
      "step 43240, cost 5.98168\n",
      "step 43240, change in cost 0.000262737\n",
      "step 43250, training accuracy 0.963415\n",
      "step 43250, cost 5.98142\n",
      "step 43250, change in cost 0.000264168\n",
      "step 43260, training accuracy 0.963415\n",
      "step 43260, cost 5.98115\n",
      "step 43260, change in cost 0.00026226\n",
      "step 43270, training accuracy 0.963415\n",
      "step 43270, cost 5.98089\n",
      "step 43270, change in cost 0.000262737\n",
      "step 43280, training accuracy 0.963415\n",
      "step 43280, cost 5.98063\n",
      "step 43280, change in cost 0.00026226\n",
      "step 43290, training accuracy 0.963415\n",
      "step 43290, cost 5.98037\n",
      "step 43290, change in cost 0.000262737\n",
      "step 43300, training accuracy 0.963415\n",
      "step 43300, cost 5.9801\n",
      "step 43300, change in cost 0.000262737\n",
      "step 43310, training accuracy 0.963415\n",
      "step 43310, cost 5.97984\n",
      "step 43310, change in cost 0.000264168\n",
      "step 43320, training accuracy 0.963415\n",
      "step 43320, cost 5.97958\n",
      "step 43320, change in cost 0.000263214\n",
      "step 43330, training accuracy 0.963415\n",
      "step 43330, cost 5.97931\n",
      "step 43330, change in cost 0.000264168\n",
      "step 43340, training accuracy 0.963415\n",
      "step 43340, cost 5.97905\n",
      "step 43340, change in cost 0.000262737\n",
      "step 43350, training accuracy 0.963415\n",
      "step 43350, cost 5.97879\n",
      "step 43350, change in cost 0.000262737\n",
      "step 43360, training accuracy 0.963415\n",
      "step 43360, cost 5.97853\n",
      "step 43360, change in cost 0.00026226\n",
      "step 43370, training accuracy 0.963415\n",
      "step 43370, cost 5.97826\n",
      "step 43370, change in cost 0.000263214\n",
      "step 43380, training accuracy 0.963415\n",
      "step 43380, cost 5.978\n",
      "step 43380, change in cost 0.000264168\n",
      "step 43390, training accuracy 0.963415\n",
      "step 43390, cost 5.97774\n",
      "step 43390, change in cost 0.000261307\n",
      "step 43400, training accuracy 0.963415\n",
      "step 43400, cost 5.97747\n",
      "step 43400, change in cost 0.000263214\n",
      "step 43410, training accuracy 0.963415\n",
      "step 43410, cost 5.97721\n",
      "step 43410, change in cost 0.00026226\n",
      "step 43420, training accuracy 0.963415\n",
      "step 43420, cost 5.97695\n",
      "step 43420, change in cost 0.00026226\n",
      "step 43430, training accuracy 0.963415\n",
      "step 43430, cost 5.97668\n",
      "step 43430, change in cost 0.000264168\n",
      "step 43440, training accuracy 0.963415\n",
      "step 43440, cost 5.97642\n",
      "step 43440, change in cost 0.000262737\n",
      "step 43450, training accuracy 0.963415\n",
      "step 43450, cost 5.97616\n",
      "step 43450, change in cost 0.000263214\n",
      "step 43460, training accuracy 0.963415\n",
      "step 43460, cost 5.9759\n",
      "step 43460, change in cost 0.000262737\n",
      "step 43470, training accuracy 0.963415\n",
      "step 43470, cost 5.97563\n",
      "step 43470, change in cost 0.000262737\n",
      "step 43480, training accuracy 0.963415\n",
      "step 43480, cost 5.97537\n",
      "step 43480, change in cost 0.000263214\n",
      "step 43490, training accuracy 0.963415\n",
      "step 43490, cost 5.97511\n",
      "step 43490, change in cost 0.000262737\n",
      "step 43500, training accuracy 0.963415\n",
      "step 43500, cost 5.97484\n",
      "step 43500, change in cost 0.000264168\n",
      "step 43510, training accuracy 0.963415\n",
      "step 43510, cost 5.97458\n",
      "step 43510, change in cost 0.000263214\n",
      "step 43520, training accuracy 0.963415\n",
      "step 43520, cost 5.97432\n",
      "step 43520, change in cost 0.00026226\n",
      "step 43530, training accuracy 0.963415\n",
      "step 43530, cost 5.97405\n",
      "step 43530, change in cost 0.000263214\n",
      "step 43540, training accuracy 0.963415\n",
      "step 43540, cost 5.97379\n",
      "step 43540, change in cost 0.000263214\n",
      "step 43550, training accuracy 0.963415\n",
      "step 43550, cost 5.97353\n",
      "step 43550, change in cost 0.000262737\n",
      "step 43560, training accuracy 0.963415\n",
      "step 43560, cost 5.97327\n",
      "step 43560, change in cost 0.000262737\n",
      "step 43570, training accuracy 0.963415\n",
      "step 43570, cost 5.973\n",
      "step 43570, change in cost 0.000263214\n",
      "step 43580, training accuracy 0.963415\n",
      "step 43580, cost 5.97274\n",
      "step 43580, change in cost 0.000263214\n",
      "step 43590, training accuracy 0.963415\n",
      "step 43590, cost 5.97248\n",
      "step 43590, change in cost 0.00026226\n",
      "step 43600, training accuracy 0.963415\n",
      "step 43600, cost 5.97221\n",
      "step 43600, change in cost 0.000264168\n",
      "step 43610, training accuracy 0.963415\n",
      "step 43610, cost 5.97195\n",
      "step 43610, change in cost 0.000261784\n",
      "step 43620, training accuracy 0.963415\n",
      "step 43620, cost 5.97169\n",
      "step 43620, change in cost 0.000263691\n",
      "step 43630, training accuracy 0.963415\n",
      "step 43630, cost 5.97142\n",
      "step 43630, change in cost 0.000264168\n",
      "step 43640, training accuracy 0.963415\n",
      "step 43640, cost 5.97116\n",
      "step 43640, change in cost 0.000261307\n",
      "step 43650, training accuracy 0.963415\n",
      "step 43650, cost 5.9709\n",
      "step 43650, change in cost 0.000263691\n",
      "step 43660, training accuracy 0.963415\n",
      "step 43660, cost 5.97064\n",
      "step 43660, change in cost 0.000262737\n",
      "step 43670, training accuracy 0.963415\n",
      "step 43670, cost 5.97037\n",
      "step 43670, change in cost 0.000264645\n",
      "step 43680, training accuracy 0.963415\n",
      "step 43680, cost 5.97011\n",
      "step 43680, change in cost 0.000262737\n",
      "step 43690, training accuracy 0.963415\n",
      "step 43690, cost 5.96984\n",
      "step 43690, change in cost 0.000263691\n",
      "step 43700, training accuracy 0.963415\n",
      "step 43700, cost 5.96958\n",
      "step 43700, change in cost 0.000262737\n",
      "step 43710, training accuracy 0.963415\n",
      "step 43710, cost 5.96932\n",
      "step 43710, change in cost 0.000263691\n",
      "step 43720, training accuracy 0.963415\n",
      "step 43720, cost 5.96906\n",
      "step 43720, change in cost 0.000262737\n",
      "step 43730, training accuracy 0.963415\n",
      "step 43730, cost 5.96879\n",
      "step 43730, change in cost 0.000264168\n",
      "step 43740, training accuracy 0.963415\n",
      "step 43740, cost 5.96853\n",
      "step 43740, change in cost 0.000262737\n",
      "step 43750, training accuracy 0.963415\n",
      "step 43750, cost 5.96827\n",
      "step 43750, change in cost 0.000263214\n",
      "step 43760, training accuracy 0.963415\n",
      "step 43760, cost 5.968\n",
      "step 43760, change in cost 0.000263214\n",
      "step 43770, training accuracy 0.963415\n",
      "step 43770, cost 5.96774\n",
      "step 43770, change in cost 0.000264168\n",
      "step 43780, training accuracy 0.963415\n",
      "step 43780, cost 5.96747\n",
      "step 43780, change in cost 0.000264168\n",
      "step 43790, training accuracy 0.963415\n",
      "step 43790, cost 5.96721\n",
      "step 43790, change in cost 0.00026226\n",
      "step 43800, training accuracy 0.963415\n",
      "step 43800, cost 5.96695\n",
      "step 43800, change in cost 0.000262737\n",
      "step 43810, training accuracy 0.963415\n",
      "step 43810, cost 5.96669\n",
      "step 43810, change in cost 0.000263214\n",
      "step 43820, training accuracy 0.963415\n",
      "step 43820, cost 5.96642\n",
      "step 43820, change in cost 0.000265121\n",
      "step 43830, training accuracy 0.963415\n",
      "step 43830, cost 5.96616\n",
      "step 43830, change in cost 0.00026226\n",
      "step 43840, training accuracy 0.963415\n",
      "step 43840, cost 5.96589\n",
      "step 43840, change in cost 0.000264168\n",
      "step 43850, training accuracy 0.963415\n",
      "step 43850, cost 5.96563\n",
      "step 43850, change in cost 0.000263214\n",
      "step 43860, training accuracy 0.963415\n",
      "step 43860, cost 5.96537\n",
      "step 43860, change in cost 0.000263214\n",
      "step 43870, training accuracy 0.963415\n",
      "step 43870, cost 5.9651\n",
      "step 43870, change in cost 0.000263691\n",
      "step 43880, training accuracy 0.963415\n",
      "step 43880, cost 5.96484\n",
      "step 43880, change in cost 0.000264645\n",
      "step 43890, training accuracy 0.963415\n",
      "step 43890, cost 5.96458\n",
      "step 43890, change in cost 0.00026226\n",
      "step 43900, training accuracy 0.963415\n",
      "step 43900, cost 5.96431\n",
      "step 43900, change in cost 0.00026226\n",
      "step 43910, training accuracy 0.963415\n",
      "step 43910, cost 5.96405\n",
      "step 43910, change in cost 0.000264645\n",
      "step 43920, training accuracy 0.963415\n",
      "step 43920, cost 5.96379\n",
      "step 43920, change in cost 0.000264168\n",
      "step 43930, training accuracy 0.963415\n",
      "step 43930, cost 5.96352\n",
      "step 43930, change in cost 0.000263691\n",
      "step 43940, training accuracy 0.963415\n",
      "step 43940, cost 5.96326\n",
      "step 43940, change in cost 0.000263691\n",
      "step 43950, training accuracy 0.963415\n",
      "step 43950, cost 5.963\n",
      "step 43950, change in cost 0.000262737\n",
      "step 43960, training accuracy 0.963415\n",
      "step 43960, cost 5.96273\n",
      "step 43960, change in cost 0.000263691\n",
      "step 43970, training accuracy 0.963415\n",
      "step 43970, cost 5.96247\n",
      "step 43970, change in cost 0.000263691\n",
      "step 43980, training accuracy 0.963415\n",
      "step 43980, cost 5.96221\n",
      "step 43980, change in cost 0.000262737\n",
      "step 43990, training accuracy 0.963415\n",
      "step 43990, cost 5.96194\n",
      "step 43990, change in cost 0.000264645\n",
      "step 44000, training accuracy 0.963415\n",
      "step 44000, cost 5.96168\n",
      "step 44000, change in cost 0.000263691\n",
      "step 44010, training accuracy 0.963415\n",
      "step 44010, cost 5.96141\n",
      "step 44010, change in cost 0.000263691\n",
      "step 44020, training accuracy 0.963415\n",
      "step 44020, cost 5.96115\n",
      "step 44020, change in cost 0.000264168\n",
      "step 44030, training accuracy 0.963415\n",
      "step 44030, cost 5.96089\n",
      "step 44030, change in cost 0.000263214\n",
      "step 44040, training accuracy 0.963415\n",
      "step 44040, cost 5.96062\n",
      "step 44040, change in cost 0.000264168\n",
      "step 44050, training accuracy 0.963415\n",
      "step 44050, cost 5.96036\n",
      "step 44050, change in cost 0.000263214\n",
      "step 44060, training accuracy 0.963415\n",
      "step 44060, cost 5.96009\n",
      "step 44060, change in cost 0.000264168\n",
      "step 44070, training accuracy 0.963415\n",
      "step 44070, cost 5.95983\n",
      "step 44070, change in cost 0.000265598\n",
      "step 44080, training accuracy 0.963415\n",
      "step 44080, cost 5.95957\n",
      "step 44080, change in cost 0.000262737\n",
      "step 44090, training accuracy 0.963415\n",
      "step 44090, cost 5.9593\n",
      "step 44090, change in cost 0.000265121\n",
      "step 44100, training accuracy 0.963415\n",
      "step 44100, cost 5.95904\n",
      "step 44100, change in cost 0.000262737\n",
      "step 44110, training accuracy 0.963415\n",
      "step 44110, cost 5.95877\n",
      "step 44110, change in cost 0.000264645\n",
      "step 44120, training accuracy 0.963415\n",
      "step 44120, cost 5.95851\n",
      "step 44120, change in cost 0.000263214\n",
      "step 44130, training accuracy 0.963415\n",
      "step 44130, cost 5.95825\n",
      "step 44130, change in cost 0.000265121\n",
      "step 44140, training accuracy 0.963415\n",
      "step 44140, cost 5.95798\n",
      "step 44140, change in cost 0.000263214\n",
      "step 44150, training accuracy 0.963415\n",
      "step 44150, cost 5.95772\n",
      "step 44150, change in cost 0.000265121\n",
      "step 44160, training accuracy 0.963415\n",
      "step 44160, cost 5.95745\n",
      "step 44160, change in cost 0.000262737\n",
      "step 44170, training accuracy 0.963415\n",
      "step 44170, cost 5.95719\n",
      "step 44170, change in cost 0.000265121\n",
      "step 44180, training accuracy 0.963415\n",
      "step 44180, cost 5.95692\n",
      "step 44180, change in cost 0.000265598\n",
      "step 44190, training accuracy 0.963415\n",
      "step 44190, cost 5.95666\n",
      "step 44190, change in cost 0.000263214\n",
      "step 44200, training accuracy 0.963415\n",
      "step 44200, cost 5.9564\n",
      "step 44200, change in cost 0.000264645\n",
      "step 44210, training accuracy 0.963415\n",
      "step 44210, cost 5.95613\n",
      "step 44210, change in cost 0.000264645\n",
      "step 44220, training accuracy 0.963415\n",
      "step 44220, cost 5.95587\n",
      "step 44220, change in cost 0.000265121\n",
      "step 44230, training accuracy 0.963415\n",
      "step 44230, cost 5.9556\n",
      "step 44230, change in cost 0.000263214\n",
      "step 44240, training accuracy 0.963415\n",
      "step 44240, cost 5.95534\n",
      "step 44240, change in cost 0.000264645\n",
      "step 44250, training accuracy 0.963415\n",
      "step 44250, cost 5.95507\n",
      "step 44250, change in cost 0.000264645\n",
      "step 44260, training accuracy 0.963415\n",
      "step 44260, cost 5.95481\n",
      "step 44260, change in cost 0.000264168\n",
      "step 44270, training accuracy 0.963415\n",
      "step 44270, cost 5.95454\n",
      "step 44270, change in cost 0.000264645\n",
      "step 44280, training accuracy 0.963415\n",
      "step 44280, cost 5.95428\n",
      "step 44280, change in cost 0.000265121\n",
      "step 44290, training accuracy 0.963415\n",
      "step 44290, cost 5.95402\n",
      "step 44290, change in cost 0.000263214\n",
      "step 44300, training accuracy 0.963415\n",
      "step 44300, cost 5.95375\n",
      "step 44300, change in cost 0.000264645\n",
      "step 44310, training accuracy 0.963415\n",
      "step 44310, cost 5.95348\n",
      "step 44310, change in cost 0.000267029\n",
      "step 44320, training accuracy 0.963415\n",
      "step 44320, cost 5.95322\n",
      "step 44320, change in cost 0.000264168\n",
      "step 44330, training accuracy 0.963415\n",
      "step 44330, cost 5.95296\n",
      "step 44330, change in cost 0.000265121\n",
      "step 44340, training accuracy 0.963415\n",
      "step 44340, cost 5.95269\n",
      "step 44340, change in cost 0.000265121\n",
      "step 44350, training accuracy 0.963415\n",
      "step 44350, cost 5.95243\n",
      "step 44350, change in cost 0.000262737\n",
      "step 44360, training accuracy 0.963415\n",
      "step 44360, cost 5.95216\n",
      "step 44360, change in cost 0.000267029\n",
      "step 44370, training accuracy 0.963415\n",
      "step 44370, cost 5.9519\n",
      "step 44370, change in cost 0.000265121\n",
      "step 44380, training accuracy 0.963415\n",
      "step 44380, cost 5.95163\n",
      "step 44380, change in cost 0.000264645\n",
      "step 44390, training accuracy 0.963415\n",
      "step 44390, cost 5.95137\n",
      "step 44390, change in cost 0.000265121\n",
      "step 44400, training accuracy 0.963415\n",
      "step 44400, cost 5.9511\n",
      "step 44400, change in cost 0.000267506\n",
      "step 44410, training accuracy 0.963415\n",
      "step 44410, cost 5.95083\n",
      "step 44410, change in cost 0.000263691\n",
      "step 44420, training accuracy 0.963415\n",
      "step 44420, cost 5.95057\n",
      "step 44420, change in cost 0.000266552\n",
      "step 44430, training accuracy 0.963415\n",
      "step 44430, cost 5.9503\n",
      "step 44430, change in cost 0.000264645\n",
      "step 44440, training accuracy 0.963415\n",
      "step 44440, cost 5.95004\n",
      "step 44440, change in cost 0.000266075\n",
      "step 44450, training accuracy 0.963415\n",
      "step 44450, cost 5.94977\n",
      "step 44450, change in cost 0.000265121\n",
      "step 44460, training accuracy 0.963415\n",
      "step 44460, cost 5.94951\n",
      "step 44460, change in cost 0.000266075\n",
      "step 44470, training accuracy 0.963415\n",
      "step 44470, cost 5.94924\n",
      "step 44470, change in cost 0.000265121\n",
      "step 44480, training accuracy 0.963415\n",
      "step 44480, cost 5.94897\n",
      "step 44480, change in cost 0.000266075\n",
      "step 44490, training accuracy 0.963415\n",
      "step 44490, cost 5.94871\n",
      "step 44490, change in cost 0.000267029\n",
      "step 44500, training accuracy 0.963415\n",
      "step 44500, cost 5.94844\n",
      "step 44500, change in cost 0.000264168\n",
      "step 44510, training accuracy 0.963415\n",
      "step 44510, cost 5.94818\n",
      "step 44510, change in cost 0.000267029\n",
      "step 44520, training accuracy 0.963415\n",
      "step 44520, cost 5.94791\n",
      "step 44520, change in cost 0.000265121\n",
      "step 44530, training accuracy 0.963415\n",
      "step 44530, cost 5.94764\n",
      "step 44530, change in cost 0.000267029\n",
      "step 44540, training accuracy 0.963415\n",
      "step 44540, cost 5.94738\n",
      "step 44540, change in cost 0.000268459\n",
      "step 44550, training accuracy 0.963415\n",
      "step 44550, cost 5.94711\n",
      "step 44550, change in cost 0.000264645\n",
      "step 44560, training accuracy 0.963415\n",
      "step 44560, cost 5.94684\n",
      "step 44560, change in cost 0.000267029\n",
      "step 44570, training accuracy 0.963415\n",
      "step 44570, cost 5.94658\n",
      "step 44570, change in cost 0.000266075\n",
      "step 44580, training accuracy 0.963415\n",
      "step 44580, cost 5.94631\n",
      "step 44580, change in cost 0.000266075\n",
      "step 44590, training accuracy 0.963415\n",
      "step 44590, cost 5.94605\n",
      "step 44590, change in cost 0.000266552\n",
      "step 44600, training accuracy 0.963415\n",
      "step 44600, cost 5.94578\n",
      "step 44600, change in cost 0.000267029\n",
      "step 44610, training accuracy 0.963415\n",
      "step 44610, cost 5.94551\n",
      "step 44610, change in cost 0.000268459\n",
      "step 44620, training accuracy 0.963415\n",
      "step 44620, cost 5.94524\n",
      "step 44620, change in cost 0.000266075\n",
      "step 44630, training accuracy 0.963415\n",
      "step 44630, cost 5.94498\n",
      "step 44630, change in cost 0.000266075\n",
      "step 44640, training accuracy 0.963415\n",
      "step 44640, cost 5.94471\n",
      "step 44640, change in cost 0.000266552\n",
      "step 44650, training accuracy 0.963415\n",
      "step 44650, cost 5.94444\n",
      "step 44650, change in cost 0.000266552\n",
      "step 44660, training accuracy 0.963415\n",
      "step 44660, cost 5.94418\n",
      "step 44660, change in cost 0.000267506\n",
      "step 44670, training accuracy 0.963415\n",
      "step 44670, cost 5.94391\n",
      "step 44670, change in cost 0.000266552\n",
      "step 44680, training accuracy 0.963415\n",
      "step 44680, cost 5.94364\n",
      "step 44680, change in cost 0.000268459\n",
      "step 44690, training accuracy 0.963415\n",
      "step 44690, cost 5.94338\n",
      "step 44690, change in cost 0.000267029\n",
      "step 44700, training accuracy 0.963415\n",
      "step 44700, cost 5.94311\n",
      "step 44700, change in cost 0.000267506\n",
      "step 44710, training accuracy 0.963415\n",
      "step 44710, cost 5.94284\n",
      "step 44710, change in cost 0.000267029\n",
      "step 44720, training accuracy 0.963415\n",
      "step 44720, cost 5.94257\n",
      "step 44720, change in cost 0.000267982\n",
      "step 44730, training accuracy 0.963415\n",
      "step 44730, cost 5.94231\n",
      "step 44730, change in cost 0.000267029\n",
      "step 44740, training accuracy 0.963415\n",
      "step 44740, cost 5.94204\n",
      "step 44740, change in cost 0.000267029\n",
      "step 44750, training accuracy 0.963415\n",
      "step 44750, cost 5.94177\n",
      "step 44750, change in cost 0.000268936\n",
      "step 44760, training accuracy 0.963415\n",
      "step 44760, cost 5.9415\n",
      "step 44760, change in cost 0.000267029\n",
      "step 44770, training accuracy 0.963415\n",
      "step 44770, cost 5.94124\n",
      "step 44770, change in cost 0.000267029\n",
      "step 44780, training accuracy 0.963415\n",
      "step 44780, cost 5.94097\n",
      "step 44780, change in cost 0.000268936\n",
      "step 44790, training accuracy 0.963415\n",
      "step 44790, cost 5.9407\n",
      "step 44790, change in cost 0.000268936\n",
      "step 44800, training accuracy 0.963415\n",
      "step 44800, cost 5.94043\n",
      "step 44800, change in cost 0.000267982\n",
      "step 44810, training accuracy 0.963415\n",
      "step 44810, cost 5.94016\n",
      "step 44810, change in cost 0.000267982\n",
      "step 44820, training accuracy 0.963415\n",
      "step 44820, cost 5.93989\n",
      "step 44820, change in cost 0.000268936\n",
      "step 44830, training accuracy 0.963415\n",
      "step 44830, cost 5.93962\n",
      "step 44830, change in cost 0.000269413\n",
      "step 44840, training accuracy 0.963415\n",
      "step 44840, cost 5.93936\n",
      "step 44840, change in cost 0.000267506\n",
      "step 44850, training accuracy 0.963415\n",
      "step 44850, cost 5.93909\n",
      "step 44850, change in cost 0.000268936\n",
      "step 44860, training accuracy 0.963415\n",
      "step 44860, cost 5.93882\n",
      "step 44860, change in cost 0.000267982\n",
      "step 44870, training accuracy 0.963415\n",
      "step 44870, cost 5.93855\n",
      "step 44870, change in cost 0.000268936\n",
      "step 44880, training accuracy 0.963415\n",
      "step 44880, cost 5.93828\n",
      "step 44880, change in cost 0.000267982\n",
      "step 44890, training accuracy 0.963415\n",
      "step 44890, cost 5.93801\n",
      "step 44890, change in cost 0.000268936\n",
      "step 44900, training accuracy 0.963415\n",
      "step 44900, cost 5.93774\n",
      "step 44900, change in cost 0.00026989\n",
      "step 44910, training accuracy 0.963415\n",
      "step 44910, cost 5.93747\n",
      "step 44910, change in cost 0.000268936\n",
      "step 44920, training accuracy 0.963415\n",
      "step 44920, cost 5.9372\n",
      "step 44920, change in cost 0.00026989\n",
      "step 44930, training accuracy 0.963415\n",
      "step 44930, cost 5.93693\n",
      "step 44930, change in cost 0.00026989\n",
      "step 44940, training accuracy 0.963415\n",
      "step 44940, cost 5.93667\n",
      "step 44940, change in cost 0.000268936\n",
      "step 44950, training accuracy 0.963415\n",
      "step 44950, cost 5.9364\n",
      "step 44950, change in cost 0.00026989\n",
      "step 44960, training accuracy 0.963415\n",
      "step 44960, cost 5.93613\n",
      "step 44960, change in cost 0.00026989\n",
      "step 44970, training accuracy 0.963415\n",
      "step 44970, cost 5.93586\n",
      "step 44970, change in cost 0.00026989\n",
      "step 44980, training accuracy 0.963415\n",
      "step 44980, cost 5.93559\n",
      "step 44980, change in cost 0.000268936\n",
      "step 44990, training accuracy 0.963415\n",
      "step 44990, cost 5.93532\n",
      "step 44990, change in cost 0.00026989\n",
      "step 45000, training accuracy 0.963415\n",
      "step 45000, cost 5.93505\n",
      "step 45000, change in cost 0.00026989\n",
      "step 45010, training accuracy 0.963415\n",
      "step 45010, cost 5.93478\n",
      "step 45010, change in cost 0.000270367\n",
      "step 45020, training accuracy 0.963415\n",
      "step 45020, cost 5.93451\n",
      "step 45020, change in cost 0.000270367\n",
      "step 45030, training accuracy 0.963415\n",
      "step 45030, cost 5.93424\n",
      "step 45030, change in cost 0.00027132\n",
      "step 45040, training accuracy 0.963415\n",
      "step 45040, cost 5.93396\n",
      "step 45040, change in cost 0.000270844\n",
      "step 45050, training accuracy 0.963415\n",
      "step 45050, cost 5.93369\n",
      "step 45050, change in cost 0.000270844\n",
      "step 45060, training accuracy 0.963415\n",
      "step 45060, cost 5.93342\n",
      "step 45060, change in cost 0.000270844\n",
      "step 45070, training accuracy 0.963415\n",
      "step 45070, cost 5.93315\n",
      "step 45070, change in cost 0.000270844\n",
      "step 45080, training accuracy 0.963415\n",
      "step 45080, cost 5.93288\n",
      "step 45080, change in cost 0.000270367\n",
      "step 45090, training accuracy 0.963415\n",
      "step 45090, cost 5.93261\n",
      "step 45090, change in cost 0.000271797\n",
      "step 45100, training accuracy 0.963415\n",
      "step 45100, cost 5.93234\n",
      "step 45100, change in cost 0.000272274\n",
      "step 45110, training accuracy 0.963415\n",
      "step 45110, cost 5.93207\n",
      "step 45110, change in cost 0.000270367\n",
      "step 45120, training accuracy 0.963415\n",
      "step 45120, cost 5.9318\n",
      "step 45120, change in cost 0.00027132\n",
      "step 45130, training accuracy 0.963415\n",
      "step 45130, cost 5.93152\n",
      "step 45130, change in cost 0.000273228\n",
      "step 45140, training accuracy 0.963415\n",
      "step 45140, cost 5.93125\n",
      "step 45140, change in cost 0.00027132\n",
      "step 45150, training accuracy 0.963415\n",
      "step 45150, cost 5.93098\n",
      "step 45150, change in cost 0.000270367\n",
      "step 45160, training accuracy 0.963415\n",
      "step 45160, cost 5.93071\n",
      "step 45160, change in cost 0.000272274\n",
      "step 45170, training accuracy 0.963415\n",
      "step 45170, cost 5.93043\n",
      "step 45170, change in cost 0.000273705\n",
      "step 45180, training accuracy 0.963415\n",
      "step 45180, cost 5.93016\n",
      "step 45180, change in cost 0.000272274\n",
      "step 45190, training accuracy 0.963415\n",
      "step 45190, cost 5.92989\n",
      "step 45190, change in cost 0.000272751\n",
      "step 45200, training accuracy 0.963415\n",
      "step 45200, cost 5.92962\n",
      "step 45200, change in cost 0.000272274\n",
      "step 45210, training accuracy 0.963415\n",
      "step 45210, cost 5.92935\n",
      "step 45210, change in cost 0.000272274\n",
      "step 45220, training accuracy 0.963415\n",
      "step 45220, cost 5.92907\n",
      "step 45220, change in cost 0.000273705\n",
      "step 45230, training accuracy 0.963415\n",
      "step 45230, cost 5.9288\n",
      "step 45230, change in cost 0.000272274\n",
      "step 45240, training accuracy 0.963415\n",
      "step 45240, cost 5.92853\n",
      "step 45240, change in cost 0.000273228\n",
      "step 45250, training accuracy 0.963415\n",
      "step 45250, cost 5.92825\n",
      "step 45250, change in cost 0.000272751\n",
      "step 45260, training accuracy 0.963415\n",
      "step 45260, cost 5.92798\n",
      "step 45260, change in cost 0.000273705\n",
      "step 45270, training accuracy 0.963415\n",
      "step 45270, cost 5.92771\n",
      "step 45270, change in cost 0.000273228\n",
      "step 45280, training accuracy 0.963415\n",
      "step 45280, cost 5.92743\n",
      "step 45280, change in cost 0.000273705\n",
      "step 45290, training accuracy 0.963415\n",
      "step 45290, cost 5.92716\n",
      "step 45290, change in cost 0.000275135\n",
      "step 45300, training accuracy 0.963415\n",
      "step 45300, cost 5.92688\n",
      "step 45300, change in cost 0.000273228\n",
      "step 45310, training accuracy 0.963415\n",
      "step 45310, cost 5.92661\n",
      "step 45310, change in cost 0.000274181\n",
      "step 45320, training accuracy 0.963415\n",
      "step 45320, cost 5.92634\n",
      "step 45320, change in cost 0.000273228\n",
      "step 45330, training accuracy 0.963415\n",
      "step 45330, cost 5.92606\n",
      "step 45330, change in cost 0.000274181\n",
      "step 45340, training accuracy 0.963415\n",
      "step 45340, cost 5.92579\n",
      "step 45340, change in cost 0.000275612\n",
      "step 45350, training accuracy 0.963415\n",
      "step 45350, cost 5.92551\n",
      "step 45350, change in cost 0.000273705\n",
      "step 45360, training accuracy 0.963415\n",
      "step 45360, cost 5.92524\n",
      "step 45360, change in cost 0.000274658\n",
      "step 45370, training accuracy 0.963415\n",
      "step 45370, cost 5.92496\n",
      "step 45370, change in cost 0.000275612\n",
      "step 45380, training accuracy 0.963415\n",
      "step 45380, cost 5.92469\n",
      "step 45380, change in cost 0.000276566\n",
      "step 45390, training accuracy 0.963415\n",
      "step 45390, cost 5.92441\n",
      "step 45390, change in cost 0.000274658\n",
      "step 45400, training accuracy 0.963415\n",
      "step 45400, cost 5.92414\n",
      "step 45400, change in cost 0.000275612\n",
      "step 45410, training accuracy 0.963415\n",
      "step 45410, cost 5.92386\n",
      "step 45410, change in cost 0.000274658\n",
      "step 45420, training accuracy 0.963415\n",
      "step 45420, cost 5.92358\n",
      "step 45420, change in cost 0.000276566\n",
      "step 45430, training accuracy 0.963415\n",
      "step 45430, cost 5.92331\n",
      "step 45430, change in cost 0.000276566\n",
      "step 45440, training accuracy 0.963415\n",
      "step 45440, cost 5.92303\n",
      "step 45440, change in cost 0.000275135\n",
      "step 45450, training accuracy 0.963415\n",
      "step 45450, cost 5.92276\n",
      "step 45450, change in cost 0.000277042\n",
      "step 45460, training accuracy 0.963415\n",
      "step 45460, cost 5.92248\n",
      "step 45460, change in cost 0.000276566\n",
      "step 45470, training accuracy 0.963415\n",
      "step 45470, cost 5.9222\n",
      "step 45470, change in cost 0.000277042\n",
      "step 45480, training accuracy 0.963415\n",
      "step 45480, cost 5.92193\n",
      "step 45480, change in cost 0.000276566\n",
      "step 45490, training accuracy 0.963415\n",
      "step 45490, cost 5.92165\n",
      "step 45490, change in cost 0.000276566\n",
      "step 45500, training accuracy 0.963415\n",
      "step 45500, cost 5.92137\n",
      "step 45500, change in cost 0.000277042\n",
      "step 45510, training accuracy 0.963415\n",
      "step 45510, cost 5.92109\n",
      "step 45510, change in cost 0.000277519\n",
      "step 45520, training accuracy 0.963415\n",
      "step 45520, cost 5.92082\n",
      "step 45520, change in cost 0.000277996\n",
      "step 45530, training accuracy 0.963415\n",
      "step 45530, cost 5.92054\n",
      "step 45530, change in cost 0.000277519\n",
      "step 45540, training accuracy 0.963415\n",
      "step 45540, cost 5.92026\n",
      "step 45540, change in cost 0.000277042\n",
      "step 45550, training accuracy 0.963415\n",
      "step 45550, cost 5.91998\n",
      "step 45550, change in cost 0.000278473\n",
      "step 45560, training accuracy 0.963415\n",
      "step 45560, cost 5.9197\n",
      "step 45560, change in cost 0.00027895\n",
      "step 45570, training accuracy 0.963415\n",
      "step 45570, cost 5.91943\n",
      "step 45570, change in cost 0.000277996\n",
      "step 45580, training accuracy 0.963415\n",
      "step 45580, cost 5.91915\n",
      "step 45580, change in cost 0.000278473\n",
      "step 45590, training accuracy 0.963415\n",
      "step 45590, cost 5.91887\n",
      "step 45590, change in cost 0.000278473\n",
      "step 45600, training accuracy 0.963415\n",
      "step 45600, cost 5.91859\n",
      "step 45600, change in cost 0.000278473\n",
      "step 45610, training accuracy 0.963415\n",
      "step 45610, cost 5.91831\n",
      "step 45610, change in cost 0.00028038\n",
      "step 45620, training accuracy 0.963415\n",
      "step 45620, cost 5.91803\n",
      "step 45620, change in cost 0.00027895\n",
      "step 45630, training accuracy 0.963415\n",
      "step 45630, cost 5.91775\n",
      "step 45630, change in cost 0.000280857\n",
      "step 45640, training accuracy 0.963415\n",
      "step 45640, cost 5.91747\n",
      "step 45640, change in cost 0.00027895\n",
      "step 45650, training accuracy 0.963415\n",
      "step 45650, cost 5.91719\n",
      "step 45650, change in cost 0.00028038\n",
      "step 45660, training accuracy 0.963415\n",
      "step 45660, cost 5.91691\n",
      "step 45660, change in cost 0.00027895\n",
      "step 45670, training accuracy 0.963415\n",
      "step 45670, cost 5.91663\n",
      "step 45670, change in cost 0.000279427\n",
      "step 45680, training accuracy 0.963415\n",
      "step 45680, cost 5.91635\n",
      "step 45680, change in cost 0.000281334\n",
      "step 45690, training accuracy 0.963415\n",
      "step 45690, cost 5.91607\n",
      "step 45690, change in cost 0.000279427\n",
      "step 45700, training accuracy 0.963415\n",
      "step 45700, cost 5.91579\n",
      "step 45700, change in cost 0.000281334\n",
      "step 45710, training accuracy 0.963415\n",
      "step 45710, cost 5.91551\n",
      "step 45710, change in cost 0.00028038\n",
      "step 45720, training accuracy 0.963415\n",
      "step 45720, cost 5.91523\n",
      "step 45720, change in cost 0.000283718\n",
      "step 45730, training accuracy 0.963415\n",
      "step 45730, cost 5.91495\n",
      "step 45730, change in cost 0.000280857\n",
      "step 45740, training accuracy 0.963415\n",
      "step 45740, cost 5.91467\n",
      "step 45740, change in cost 0.000281334\n",
      "step 45750, training accuracy 0.963415\n",
      "step 45750, cost 5.91438\n",
      "step 45750, change in cost 0.000281334\n",
      "step 45760, training accuracy 0.963415\n",
      "step 45760, cost 5.9141\n",
      "step 45760, change in cost 0.000281334\n",
      "step 45770, training accuracy 0.963415\n",
      "step 45770, cost 5.91382\n",
      "step 45770, change in cost 0.000283241\n",
      "step 45780, training accuracy 0.963415\n",
      "step 45780, cost 5.91354\n",
      "step 45780, change in cost 0.000283241\n",
      "step 45790, training accuracy 0.963415\n",
      "step 45790, cost 5.91325\n",
      "step 45790, change in cost 0.000283241\n",
      "step 45800, training accuracy 0.963415\n",
      "step 45800, cost 5.91297\n",
      "step 45800, change in cost 0.000282288\n",
      "step 45810, training accuracy 0.963415\n",
      "step 45810, cost 5.91269\n",
      "step 45810, change in cost 0.000284195\n",
      "step 45820, training accuracy 0.963415\n",
      "step 45820, cost 5.9124\n",
      "step 45820, change in cost 0.000283241\n",
      "step 45830, training accuracy 0.963415\n",
      "step 45830, cost 5.91212\n",
      "step 45830, change in cost 0.000283241\n",
      "step 45840, training accuracy 0.963415\n",
      "step 45840, cost 5.91184\n",
      "step 45840, change in cost 0.000284672\n",
      "step 45850, training accuracy 0.963415\n",
      "step 45850, cost 5.91155\n",
      "step 45850, change in cost 0.000284195\n",
      "step 45860, training accuracy 0.963415\n",
      "step 45860, cost 5.91127\n",
      "step 45860, change in cost 0.000285149\n",
      "step 45870, training accuracy 0.963415\n",
      "step 45870, cost 5.91098\n",
      "step 45870, change in cost 0.000283718\n",
      "step 45880, training accuracy 0.963415\n",
      "step 45880, cost 5.9107\n",
      "step 45880, change in cost 0.000286102\n",
      "step 45890, training accuracy 0.963415\n",
      "step 45890, cost 5.91041\n",
      "step 45890, change in cost 0.000284195\n",
      "step 45900, training accuracy 0.963415\n",
      "step 45900, cost 5.91013\n",
      "step 45900, change in cost 0.000286102\n",
      "step 45910, training accuracy 0.963415\n",
      "step 45910, cost 5.90984\n",
      "step 45910, change in cost 0.000286579\n",
      "step 45920, training accuracy 0.963415\n",
      "step 45920, cost 5.90955\n",
      "step 45920, change in cost 0.000286579\n",
      "step 45930, training accuracy 0.963415\n",
      "step 45930, cost 5.90927\n",
      "step 45930, change in cost 0.000284672\n",
      "step 45940, training accuracy 0.963415\n",
      "step 45940, cost 5.90898\n",
      "step 45940, change in cost 0.000287056\n",
      "step 45950, training accuracy 0.963415\n",
      "step 45950, cost 5.90869\n",
      "step 45950, change in cost 0.000286102\n",
      "step 45960, training accuracy 0.963415\n",
      "step 45960, cost 5.90841\n",
      "step 45960, change in cost 0.000286579\n",
      "step 45970, training accuracy 0.963415\n",
      "step 45970, cost 5.90812\n",
      "step 45970, change in cost 0.00028801\n",
      "step 45980, training accuracy 0.963415\n",
      "step 45980, cost 5.90783\n",
      "step 45980, change in cost 0.000287056\n",
      "step 45990, training accuracy 0.963415\n",
      "step 45990, cost 5.90755\n",
      "step 45990, change in cost 0.000287533\n",
      "step 46000, training accuracy 0.963415\n",
      "step 46000, cost 5.90726\n",
      "step 46000, change in cost 0.00028944\n",
      "step 46010, training accuracy 0.963415\n",
      "step 46010, cost 5.90697\n",
      "step 46010, change in cost 0.000287533\n",
      "step 46020, training accuracy 0.963415\n",
      "step 46020, cost 5.90668\n",
      "step 46020, change in cost 0.000287533\n",
      "step 46030, training accuracy 0.963415\n",
      "step 46030, cost 5.90639\n",
      "step 46030, change in cost 0.000288963\n",
      "step 46040, training accuracy 0.963415\n",
      "step 46040, cost 5.9061\n",
      "step 46040, change in cost 0.000288963\n",
      "step 46050, training accuracy 0.963415\n",
      "step 46050, cost 5.90581\n",
      "step 46050, change in cost 0.000290394\n",
      "step 46060, training accuracy 0.963415\n",
      "step 46060, cost 5.90552\n",
      "step 46060, change in cost 0.000288486\n",
      "step 46070, training accuracy 0.963415\n",
      "step 46070, cost 5.90523\n",
      "step 46070, change in cost 0.000290394\n",
      "step 46080, training accuracy 0.963415\n",
      "step 46080, cost 5.90494\n",
      "step 46080, change in cost 0.000290394\n",
      "step 46090, training accuracy 0.963415\n",
      "step 46090, cost 5.90465\n",
      "step 46090, change in cost 0.000290871\n",
      "step 46100, training accuracy 0.963415\n",
      "step 46100, cost 5.90436\n",
      "step 46100, change in cost 0.000291824\n",
      "step 46110, training accuracy 0.963415\n",
      "step 46110, cost 5.90407\n",
      "step 46110, change in cost 0.000289917\n",
      "step 46120, training accuracy 0.963415\n",
      "step 46120, cost 5.90378\n",
      "step 46120, change in cost 0.000292778\n",
      "step 46130, training accuracy 0.963415\n",
      "step 46130, cost 5.90349\n",
      "step 46130, change in cost 0.000290871\n",
      "step 46140, training accuracy 0.963415\n",
      "step 46140, cost 5.9032\n",
      "step 46140, change in cost 0.000289917\n",
      "step 46150, training accuracy 0.963415\n",
      "step 46150, cost 5.9029\n",
      "step 46150, change in cost 0.000293732\n",
      "step 46160, training accuracy 0.963415\n",
      "step 46160, cost 5.90261\n",
      "step 46160, change in cost 0.000291824\n",
      "step 46170, training accuracy 0.963415\n",
      "step 46170, cost 5.90232\n",
      "step 46170, change in cost 0.000294685\n",
      "step 46180, training accuracy 0.963415\n",
      "step 46180, cost 5.90202\n",
      "step 46180, change in cost 0.000293732\n",
      "step 46190, training accuracy 0.963415\n",
      "step 46190, cost 5.90173\n",
      "step 46190, change in cost 0.000292778\n",
      "step 46200, training accuracy 0.963415\n",
      "step 46200, cost 5.90144\n",
      "step 46200, change in cost 0.000294685\n",
      "step 46210, training accuracy 0.963415\n",
      "step 46210, cost 5.90114\n",
      "step 46210, change in cost 0.000292778\n",
      "step 46220, training accuracy 0.963415\n",
      "step 46220, cost 5.90085\n",
      "step 46220, change in cost 0.000295639\n",
      "step 46230, training accuracy 0.963415\n",
      "step 46230, cost 5.90055\n",
      "step 46230, change in cost 0.000295639\n",
      "step 46240, training accuracy 0.963415\n",
      "step 46240, cost 5.90026\n",
      "step 46240, change in cost 0.000294685\n",
      "step 46250, training accuracy 0.963415\n",
      "step 46250, cost 5.89996\n",
      "step 46250, change in cost 0.000296116\n",
      "step 46260, training accuracy 0.963415\n",
      "step 46260, cost 5.89967\n",
      "step 46260, change in cost 0.000294209\n",
      "step 46270, training accuracy 0.963415\n",
      "step 46270, cost 5.89937\n",
      "step 46270, change in cost 0.000295639\n",
      "step 46280, training accuracy 0.963415\n",
      "step 46280, cost 5.89907\n",
      "step 46280, change in cost 0.00029707\n",
      "step 46290, training accuracy 0.963415\n",
      "step 46290, cost 5.89878\n",
      "step 46290, change in cost 0.00029707\n",
      "step 46300, training accuracy 0.963415\n",
      "step 46300, cost 5.89848\n",
      "step 46300, change in cost 0.000296593\n",
      "step 46310, training accuracy 0.963415\n",
      "step 46310, cost 5.89818\n",
      "step 46310, change in cost 0.000298977\n",
      "step 46320, training accuracy 0.963415\n",
      "step 46320, cost 5.89788\n",
      "step 46320, change in cost 0.000298023\n",
      "step 46330, training accuracy 0.963415\n",
      "step 46330, cost 5.89758\n",
      "step 46330, change in cost 0.0002985\n",
      "step 46340, training accuracy 0.963415\n",
      "step 46340, cost 5.89729\n",
      "step 46340, change in cost 0.000298023\n",
      "step 46350, training accuracy 0.963415\n",
      "step 46350, cost 5.89699\n",
      "step 46350, change in cost 0.000298977\n",
      "step 46360, training accuracy 0.963415\n",
      "step 46360, cost 5.89669\n",
      "step 46360, change in cost 0.000299454\n",
      "step 46370, training accuracy 0.963415\n",
      "step 46370, cost 5.89639\n",
      "step 46370, change in cost 0.000300407\n",
      "step 46380, training accuracy 0.963415\n",
      "step 46380, cost 5.89609\n",
      "step 46380, change in cost 0.000299454\n",
      "step 46390, training accuracy 0.963415\n",
      "step 46390, cost 5.89579\n",
      "step 46390, change in cost 0.000299454\n",
      "step 46400, training accuracy 0.963415\n",
      "step 46400, cost 5.89549\n",
      "step 46400, change in cost 0.000301361\n",
      "step 46410, training accuracy 0.963415\n",
      "step 46410, cost 5.89519\n",
      "step 46410, change in cost 0.000301838\n",
      "step 46420, training accuracy 0.963415\n",
      "step 46420, cost 5.89489\n",
      "step 46420, change in cost 0.000300407\n",
      "step 46430, training accuracy 0.963415\n",
      "step 46430, cost 5.89458\n",
      "step 46430, change in cost 0.000301838\n",
      "step 46440, training accuracy 0.963415\n",
      "step 46440, cost 5.89428\n",
      "step 46440, change in cost 0.000302792\n",
      "step 46450, training accuracy 0.963415\n",
      "step 46450, cost 5.89398\n",
      "step 46450, change in cost 0.000303268\n",
      "step 46460, training accuracy 0.963415\n",
      "step 46460, cost 5.89367\n",
      "step 46460, change in cost 0.000303268\n",
      "step 46470, training accuracy 0.963415\n",
      "step 46470, cost 5.89337\n",
      "step 46470, change in cost 0.000305653\n",
      "step 46480, training accuracy 0.963415\n",
      "step 46480, cost 5.89307\n",
      "step 46480, change in cost 0.000303268\n",
      "step 46490, training accuracy 0.963415\n",
      "step 46490, cost 5.89276\n",
      "step 46490, change in cost 0.000304699\n",
      "step 46500, training accuracy 0.963415\n",
      "step 46500, cost 5.89246\n",
      "step 46500, change in cost 0.000305653\n",
      "step 46510, training accuracy 0.963415\n",
      "step 46510, cost 5.89215\n",
      "step 46510, change in cost 0.000304222\n",
      "step 46520, training accuracy 0.963415\n",
      "step 46520, cost 5.89185\n",
      "step 46520, change in cost 0.000305653\n",
      "step 46530, training accuracy 0.963415\n",
      "step 46530, cost 5.89154\n",
      "step 46530, change in cost 0.000305653\n",
      "step 46540, training accuracy 0.963415\n",
      "step 46540, cost 5.89123\n",
      "step 46540, change in cost 0.000308037\n",
      "step 46550, training accuracy 0.963415\n",
      "step 46550, cost 5.89092\n",
      "step 46550, change in cost 0.000307083\n",
      "step 46560, training accuracy 0.963415\n",
      "step 46560, cost 5.89062\n",
      "step 46560, change in cost 0.000307083\n",
      "step 46570, training accuracy 0.963415\n",
      "step 46570, cost 5.89031\n",
      "step 46570, change in cost 0.000308037\n",
      "step 46580, training accuracy 0.963415\n",
      "step 46580, cost 5.89\n",
      "step 46580, change in cost 0.00030899\n",
      "step 46590, training accuracy 0.963415\n",
      "step 46590, cost 5.88969\n",
      "step 46590, change in cost 0.00030756\n",
      "step 46600, training accuracy 0.963415\n",
      "step 46600, cost 5.88938\n",
      "step 46600, change in cost 0.000310421\n",
      "step 46610, training accuracy 0.963415\n",
      "step 46610, cost 5.88907\n",
      "step 46610, change in cost 0.000308514\n",
      "step 46620, training accuracy 0.963415\n",
      "step 46620, cost 5.88876\n",
      "step 46620, change in cost 0.000310898\n",
      "step 46630, training accuracy 0.963415\n",
      "step 46630, cost 5.88845\n",
      "step 46630, change in cost 0.000309944\n",
      "step 46640, training accuracy 0.963415\n",
      "step 46640, cost 5.88814\n",
      "step 46640, change in cost 0.000311375\n",
      "step 46650, training accuracy 0.963415\n",
      "step 46650, cost 5.88783\n",
      "step 46650, change in cost 0.000311852\n",
      "step 46660, training accuracy 0.963415\n",
      "step 46660, cost 5.88752\n",
      "step 46660, change in cost 0.000311852\n",
      "step 46670, training accuracy 0.963415\n",
      "step 46670, cost 5.8872\n",
      "step 46670, change in cost 0.000313759\n",
      "step 46680, training accuracy 0.963415\n",
      "step 46680, cost 5.88689\n",
      "step 46680, change in cost 0.000311852\n",
      "step 46690, training accuracy 0.963415\n",
      "step 46690, cost 5.88658\n",
      "step 46690, change in cost 0.000314713\n",
      "step 46700, training accuracy 0.963415\n",
      "step 46700, cost 5.88626\n",
      "step 46700, change in cost 0.000313282\n",
      "step 46710, training accuracy 0.963415\n",
      "step 46710, cost 5.88595\n",
      "step 46710, change in cost 0.000314713\n",
      "step 46720, training accuracy 0.963415\n",
      "step 46720, cost 5.88563\n",
      "step 46720, change in cost 0.000315189\n",
      "step 46730, training accuracy 0.963415\n",
      "step 46730, cost 5.88532\n",
      "step 46730, change in cost 0.000314713\n",
      "step 46740, training accuracy 0.963415\n",
      "step 46740, cost 5.885\n",
      "step 46740, change in cost 0.00031662\n",
      "step 46750, training accuracy 0.963415\n",
      "step 46750, cost 5.88469\n",
      "step 46750, change in cost 0.00031662\n",
      "step 46760, training accuracy 0.963415\n",
      "step 46760, cost 5.88437\n",
      "step 46760, change in cost 0.00031805\n",
      "step 46770, training accuracy 0.963415\n",
      "step 46770, cost 5.88405\n",
      "step 46770, change in cost 0.000316143\n",
      "step 46780, training accuracy 0.963415\n",
      "step 46780, cost 5.88373\n",
      "step 46780, change in cost 0.000319958\n",
      "step 46790, training accuracy 0.963415\n",
      "step 46790, cost 5.88341\n",
      "step 46790, change in cost 0.00031805\n",
      "step 46800, training accuracy 0.963415\n",
      "step 46800, cost 5.88309\n",
      "step 46800, change in cost 0.000319481\n",
      "step 46810, training accuracy 0.963415\n",
      "step 46810, cost 5.88277\n",
      "step 46810, change in cost 0.000320435\n",
      "step 46820, training accuracy 0.963415\n",
      "step 46820, cost 5.88245\n",
      "step 46820, change in cost 0.000319481\n",
      "step 46830, training accuracy 0.963415\n",
      "step 46830, cost 5.88213\n",
      "step 46830, change in cost 0.000321388\n",
      "step 46840, training accuracy 0.963415\n",
      "step 46840, cost 5.88181\n",
      "step 46840, change in cost 0.000321865\n",
      "step 46850, training accuracy 0.963415\n",
      "step 46850, cost 5.88149\n",
      "step 46850, change in cost 0.000321865\n",
      "step 46860, training accuracy 0.963415\n",
      "step 46860, cost 5.88117\n",
      "step 46860, change in cost 0.000322342\n",
      "step 46870, training accuracy 0.963415\n",
      "step 46870, cost 5.88084\n",
      "step 46870, change in cost 0.000323772\n",
      "step 46880, training accuracy 0.963415\n",
      "step 46880, cost 5.88052\n",
      "step 46880, change in cost 0.000324726\n",
      "step 46890, training accuracy 0.963415\n",
      "step 46890, cost 5.8802\n",
      "step 46890, change in cost 0.000322342\n",
      "step 46900, training accuracy 0.963415\n",
      "step 46900, cost 5.87987\n",
      "step 46900, change in cost 0.000325203\n",
      "step 46910, training accuracy 0.963415\n",
      "step 46910, cost 5.87954\n",
      "step 46910, change in cost 0.00032711\n",
      "step 46920, training accuracy 0.963415\n",
      "step 46920, cost 5.87922\n",
      "step 46920, change in cost 0.000325203\n",
      "step 46930, training accuracy 0.963415\n",
      "step 46930, cost 5.87889\n",
      "step 46930, change in cost 0.00032711\n",
      "step 46940, training accuracy 0.963415\n",
      "step 46940, cost 5.87856\n",
      "step 46940, change in cost 0.00032711\n",
      "step 46950, training accuracy 0.963415\n",
      "step 46950, cost 5.87824\n",
      "step 46950, change in cost 0.00032711\n",
      "step 46960, training accuracy 0.963415\n",
      "step 46960, cost 5.87791\n",
      "step 46960, change in cost 0.000329018\n",
      "step 46970, training accuracy 0.963415\n",
      "step 46970, cost 5.87758\n",
      "step 46970, change in cost 0.000329018\n",
      "step 46980, training accuracy 0.963415\n",
      "step 46980, cost 5.87725\n",
      "step 46980, change in cost 0.000329018\n",
      "step 46990, training accuracy 0.963415\n",
      "step 46990, cost 5.87692\n",
      "step 46990, change in cost 0.000330925\n",
      "step 47000, training accuracy 0.963415\n",
      "step 47000, cost 5.87659\n",
      "step 47000, change in cost 0.000330925\n",
      "step 47010, training accuracy 0.963415\n",
      "step 47010, cost 5.87626\n",
      "step 47010, change in cost 0.000332832\n",
      "step 47020, training accuracy 0.963415\n",
      "step 47020, cost 5.87592\n",
      "step 47020, change in cost 0.000331402\n",
      "step 47030, training accuracy 0.963415\n",
      "step 47030, cost 5.87559\n",
      "step 47030, change in cost 0.000333309\n",
      "step 47040, training accuracy 0.963415\n",
      "step 47040, cost 5.87526\n",
      "step 47040, change in cost 0.00033474\n",
      "step 47050, training accuracy 0.963415\n",
      "step 47050, cost 5.87492\n",
      "step 47050, change in cost 0.000333786\n",
      "step 47060, training accuracy 0.963415\n",
      "step 47060, cost 5.87459\n",
      "step 47060, change in cost 0.000335693\n",
      "step 47070, training accuracy 0.963415\n",
      "step 47070, cost 5.87425\n",
      "step 47070, change in cost 0.00033617\n",
      "step 47080, training accuracy 0.963415\n",
      "step 47080, cost 5.87392\n",
      "step 47080, change in cost 0.000335217\n",
      "step 47090, training accuracy 0.963415\n",
      "step 47090, cost 5.87358\n",
      "step 47090, change in cost 0.000336647\n",
      "step 47100, training accuracy 0.963415\n",
      "step 47100, cost 5.87324\n",
      "step 47100, change in cost 0.000338554\n",
      "step 47110, training accuracy 0.963415\n",
      "step 47110, cost 5.8729\n",
      "step 47110, change in cost 0.000338554\n",
      "step 47120, training accuracy 0.963415\n",
      "step 47120, cost 5.87256\n",
      "step 47120, change in cost 0.000338554\n",
      "step 47130, training accuracy 0.963415\n",
      "step 47130, cost 5.87222\n",
      "step 47130, change in cost 0.000341415\n",
      "step 47140, training accuracy 0.963415\n",
      "step 47140, cost 5.87188\n",
      "step 47140, change in cost 0.000341415\n",
      "step 47150, training accuracy 0.963415\n",
      "step 47150, cost 5.87154\n",
      "step 47150, change in cost 0.000342369\n",
      "step 47160, training accuracy 0.963415\n",
      "step 47160, cost 5.8712\n",
      "step 47160, change in cost 0.000340939\n",
      "step 47170, training accuracy 0.963415\n",
      "step 47170, cost 5.87085\n",
      "step 47170, change in cost 0.000344276\n",
      "step 47180, training accuracy 0.963415\n",
      "step 47180, cost 5.87051\n",
      "step 47180, change in cost 0.0003438\n",
      "step 47190, training accuracy 0.963415\n",
      "step 47190, cost 5.87016\n",
      "step 47190, change in cost 0.000344276\n",
      "step 47200, training accuracy 0.963415\n",
      "step 47200, cost 5.86982\n",
      "step 47200, change in cost 0.000344753\n",
      "step 47210, training accuracy 0.963415\n",
      "step 47210, cost 5.86947\n",
      "step 47210, change in cost 0.000346184\n",
      "step 47220, training accuracy 0.963415\n",
      "step 47220, cost 5.86913\n",
      "step 47220, change in cost 0.000345707\n",
      "step 47230, training accuracy 0.963415\n",
      "step 47230, cost 5.86878\n",
      "step 47230, change in cost 0.000347137\n",
      "step 47240, training accuracy 0.963415\n",
      "step 47240, cost 5.86843\n",
      "step 47240, change in cost 0.000349522\n",
      "step 47250, training accuracy 0.963415\n",
      "step 47250, cost 5.86808\n",
      "step 47250, change in cost 0.000350475\n",
      "step 47260, training accuracy 0.963415\n",
      "step 47260, cost 5.86773\n",
      "step 47260, change in cost 0.000349522\n",
      "step 47270, training accuracy 0.963415\n",
      "step 47270, cost 5.86738\n",
      "step 47270, change in cost 0.000350475\n",
      "step 47280, training accuracy 0.963415\n",
      "step 47280, cost 5.86703\n",
      "step 47280, change in cost 0.000352383\n",
      "step 47290, training accuracy 0.963415\n",
      "step 47290, cost 5.86668\n",
      "step 47290, change in cost 0.000352383\n",
      "step 47300, training accuracy 0.963415\n",
      "step 47300, cost 5.86632\n",
      "step 47300, change in cost 0.000351906\n",
      "step 47310, training accuracy 0.963415\n",
      "step 47310, cost 5.86597\n",
      "step 47310, change in cost 0.000356197\n",
      "step 47320, training accuracy 0.963415\n",
      "step 47320, cost 5.86561\n",
      "step 47320, change in cost 0.00035429\n",
      "step 47330, training accuracy 0.963415\n",
      "step 47330, cost 5.86526\n",
      "step 47330, change in cost 0.000356674\n",
      "step 47340, training accuracy 0.963415\n",
      "step 47340, cost 5.8649\n",
      "step 47340, change in cost 0.000357151\n",
      "step 47350, training accuracy 0.963415\n",
      "step 47350, cost 5.86454\n",
      "step 47350, change in cost 0.000357628\n",
      "step 47360, training accuracy 0.963415\n",
      "step 47360, cost 5.86418\n",
      "step 47360, change in cost 0.000360489\n",
      "step 47370, training accuracy 0.963415\n",
      "step 47370, cost 5.86382\n",
      "step 47370, change in cost 0.000359058\n",
      "step 47380, training accuracy 0.963415\n",
      "step 47380, cost 5.86346\n",
      "step 47380, change in cost 0.000361443\n",
      "step 47390, training accuracy 0.963415\n",
      "step 47390, cost 5.8631\n",
      "step 47390, change in cost 0.000361443\n",
      "step 47400, training accuracy 0.963415\n",
      "step 47400, cost 5.86274\n",
      "step 47400, change in cost 0.000361919\n",
      "step 47410, training accuracy 0.963415\n",
      "step 47410, cost 5.86238\n",
      "step 47410, change in cost 0.000362396\n",
      "step 47420, training accuracy 0.963415\n",
      "step 47420, cost 5.86201\n",
      "step 47420, change in cost 0.00036478\n",
      "step 47430, training accuracy 0.963415\n",
      "step 47430, cost 5.86165\n",
      "step 47430, change in cost 0.000365257\n",
      "step 47440, training accuracy 0.963415\n",
      "step 47440, cost 5.86128\n",
      "step 47440, change in cost 0.000366211\n",
      "step 47450, training accuracy 0.963415\n",
      "step 47450, cost 5.86091\n",
      "step 47450, change in cost 0.000368118\n",
      "step 47460, training accuracy 0.963415\n",
      "step 47460, cost 5.86054\n",
      "step 47460, change in cost 0.000369072\n",
      "step 47470, training accuracy 0.963415\n",
      "step 47470, cost 5.86017\n",
      "step 47470, change in cost 0.000369072\n",
      "step 47480, training accuracy 0.963415\n",
      "step 47480, cost 5.8598\n",
      "step 47480, change in cost 0.000370979\n",
      "step 47490, training accuracy 0.963415\n",
      "step 47490, cost 5.85943\n",
      "step 47490, change in cost 0.000370502\n",
      "step 47500, training accuracy 0.963415\n",
      "step 47500, cost 5.85906\n",
      "step 47500, change in cost 0.000371456\n",
      "step 47510, training accuracy 0.963415\n",
      "step 47510, cost 5.85869\n",
      "step 47510, change in cost 0.00037384\n",
      "step 47520, training accuracy 0.963415\n",
      "step 47520, cost 5.85831\n",
      "step 47520, change in cost 0.000375748\n",
      "step 47530, training accuracy 0.963415\n",
      "step 47530, cost 5.85794\n",
      "step 47530, change in cost 0.00037384\n",
      "step 47540, training accuracy 0.963415\n",
      "step 47540, cost 5.85756\n",
      "step 47540, change in cost 0.000377178\n",
      "step 47550, training accuracy 0.963415\n",
      "step 47550, cost 5.85718\n",
      "step 47550, change in cost 0.000377655\n",
      "step 47560, training accuracy 0.963415\n",
      "step 47560, cost 5.8568\n",
      "step 47560, change in cost 0.000379562\n",
      "step 47570, training accuracy 0.963415\n",
      "step 47570, cost 5.85642\n",
      "step 47570, change in cost 0.000379086\n",
      "step 47580, training accuracy 0.963415\n",
      "step 47580, cost 5.85604\n",
      "step 47580, change in cost 0.000380516\n",
      "step 47590, training accuracy 0.963415\n",
      "step 47590, cost 5.85566\n",
      "step 47590, change in cost 0.000382423\n",
      "step 47600, training accuracy 0.963415\n",
      "step 47600, cost 5.85528\n",
      "step 47600, change in cost 0.000382423\n",
      "step 47610, training accuracy 0.963415\n",
      "step 47610, cost 5.85489\n",
      "step 47610, change in cost 0.000383377\n",
      "step 47620, training accuracy 0.963415\n",
      "step 47620, cost 5.85451\n",
      "step 47620, change in cost 0.000386238\n",
      "step 47630, training accuracy 0.963415\n",
      "step 47630, cost 5.85412\n",
      "step 47630, change in cost 0.000386238\n",
      "step 47640, training accuracy 0.963415\n",
      "step 47640, cost 5.85373\n",
      "step 47640, change in cost 0.000387192\n",
      "step 47650, training accuracy 0.963415\n",
      "step 47650, cost 5.85335\n",
      "step 47650, change in cost 0.000389099\n",
      "step 47660, training accuracy 0.963415\n",
      "step 47660, cost 5.85295\n",
      "step 47660, change in cost 0.000391006\n",
      "step 47670, training accuracy 0.963415\n",
      "step 47670, cost 5.85256\n",
      "step 47670, change in cost 0.00039053\n",
      "step 47680, training accuracy 0.963415\n",
      "step 47680, cost 5.85217\n",
      "step 47680, change in cost 0.000392437\n",
      "step 47690, training accuracy 0.963415\n",
      "step 47690, cost 5.85178\n",
      "step 47690, change in cost 0.000394821\n",
      "step 47700, training accuracy 0.963415\n",
      "step 47700, cost 5.85138\n",
      "step 47700, change in cost 0.000394821\n",
      "step 47710, training accuracy 0.963415\n",
      "step 47710, cost 5.85099\n",
      "step 47710, change in cost 0.000395775\n",
      "step 47720, training accuracy 0.963415\n",
      "step 47720, cost 5.85059\n",
      "step 47720, change in cost 0.000396729\n",
      "step 47730, training accuracy 0.963415\n",
      "step 47730, cost 5.85019\n",
      "step 47730, change in cost 0.00039959\n",
      "step 47740, training accuracy 0.963415\n",
      "step 47740, cost 5.84979\n",
      "step 47740, change in cost 0.000398636\n",
      "step 47750, training accuracy 0.963415\n",
      "step 47750, cost 5.84939\n",
      "step 47750, change in cost 0.000401497\n",
      "step 47760, training accuracy 0.963415\n",
      "step 47760, cost 5.84899\n",
      "step 47760, change in cost 0.000402927\n",
      "step 47770, training accuracy 0.963415\n",
      "step 47770, cost 5.84858\n",
      "step 47770, change in cost 0.000403404\n",
      "step 47780, training accuracy 0.963415\n",
      "step 47780, cost 5.84818\n",
      "step 47780, change in cost 0.000404835\n",
      "step 47790, training accuracy 0.963415\n",
      "step 47790, cost 5.84777\n",
      "step 47790, change in cost 0.000407696\n",
      "step 47800, training accuracy 0.963415\n",
      "step 47800, cost 5.84736\n",
      "step 47800, change in cost 0.000406742\n",
      "step 47810, training accuracy 0.963415\n",
      "step 47810, cost 5.84695\n",
      "step 47810, change in cost 0.00041008\n",
      "step 47820, training accuracy 0.963415\n",
      "step 47820, cost 5.84654\n",
      "step 47820, change in cost 0.000410557\n",
      "step 47830, training accuracy 0.963415\n",
      "step 47830, cost 5.84613\n",
      "step 47830, change in cost 0.000412941\n",
      "step 47840, training accuracy 0.963415\n",
      "step 47840, cost 5.84572\n",
      "step 47840, change in cost 0.000414371\n",
      "step 47850, training accuracy 0.963415\n",
      "step 47850, cost 5.8453\n",
      "step 47850, change in cost 0.000414371\n",
      "step 47860, training accuracy 0.963415\n",
      "step 47860, cost 5.84489\n",
      "step 47860, change in cost 0.000416279\n",
      "step 47870, training accuracy 0.963415\n",
      "step 47870, cost 5.84447\n",
      "step 47870, change in cost 0.000417709\n",
      "step 47880, training accuracy 0.963415\n",
      "step 47880, cost 5.84405\n",
      "step 47880, change in cost 0.000420094\n",
      "step 47890, training accuracy 0.963415\n",
      "step 47890, cost 5.84363\n",
      "step 47890, change in cost 0.000421524\n",
      "step 47900, training accuracy 0.963415\n",
      "step 47900, cost 5.84321\n",
      "step 47900, change in cost 0.000421047\n",
      "step 47910, training accuracy 0.963415\n",
      "step 47910, cost 5.84278\n",
      "step 47910, change in cost 0.000423431\n",
      "step 47920, training accuracy 0.963415\n",
      "step 47920, cost 5.84236\n",
      "step 47920, change in cost 0.000425816\n",
      "step 47930, training accuracy 0.963415\n",
      "step 47930, cost 5.84193\n",
      "step 47930, change in cost 0.000426292\n",
      "step 47940, training accuracy 0.963415\n",
      "step 47940, cost 5.8415\n",
      "step 47940, change in cost 0.000428677\n",
      "step 47950, training accuracy 0.963415\n",
      "step 47950, cost 5.84107\n",
      "step 47950, change in cost 0.000430107\n",
      "step 47960, training accuracy 0.963415\n",
      "step 47960, cost 5.84064\n",
      "step 47960, change in cost 0.000432491\n",
      "step 47970, training accuracy 0.963415\n",
      "step 47970, cost 5.84021\n",
      "step 47970, change in cost 0.000432014\n",
      "step 47980, training accuracy 0.963415\n",
      "step 47980, cost 5.83977\n",
      "step 47980, change in cost 0.000435829\n",
      "step 47990, training accuracy 0.963415\n",
      "step 47990, cost 5.83933\n",
      "step 47990, change in cost 0.000436306\n",
      "step 48000, training accuracy 0.963415\n",
      "step 48000, cost 5.8389\n",
      "step 48000, change in cost 0.00043869\n",
      "step 48010, training accuracy 0.963415\n",
      "step 48010, cost 5.83846\n",
      "step 48010, change in cost 0.000439644\n",
      "step 48020, training accuracy 0.963415\n",
      "step 48020, cost 5.83801\n",
      "step 48020, change in cost 0.000442505\n",
      "step 48030, training accuracy 0.963415\n",
      "step 48030, cost 5.83757\n",
      "step 48030, change in cost 0.000442028\n",
      "step 48040, training accuracy 0.963415\n",
      "step 48040, cost 5.83713\n",
      "step 48040, change in cost 0.000445366\n",
      "step 48050, training accuracy 0.963415\n",
      "step 48050, cost 5.83668\n",
      "step 48050, change in cost 0.000446796\n",
      "step 48060, training accuracy 0.963415\n",
      "step 48060, cost 5.83623\n",
      "step 48060, change in cost 0.000448704\n",
      "step 48070, training accuracy 0.963415\n",
      "step 48070, cost 5.83578\n",
      "step 48070, change in cost 0.000450611\n",
      "step 48080, training accuracy 0.963415\n",
      "step 48080, cost 5.83533\n",
      "step 48080, change in cost 0.000452042\n",
      "step 48090, training accuracy 0.963415\n",
      "step 48090, cost 5.83487\n",
      "step 48090, change in cost 0.000453949\n",
      "step 48100, training accuracy 0.963415\n",
      "step 48100, cost 5.83442\n",
      "step 48100, change in cost 0.000455379\n",
      "step 48110, training accuracy 0.963415\n",
      "step 48110, cost 5.83396\n",
      "step 48110, change in cost 0.000457764\n",
      "step 48120, training accuracy 0.963415\n",
      "step 48120, cost 5.8335\n",
      "step 48120, change in cost 0.000459194\n",
      "step 48130, training accuracy 0.963415\n",
      "step 48130, cost 5.83304\n",
      "step 48130, change in cost 0.000460148\n",
      "step 48140, training accuracy 0.963415\n",
      "step 48140, cost 5.83258\n",
      "step 48140, change in cost 0.000462532\n",
      "step 48150, training accuracy 0.963415\n",
      "step 48150, cost 5.83211\n",
      "step 48150, change in cost 0.000466347\n",
      "step 48160, training accuracy 0.963415\n",
      "step 48160, cost 5.83165\n",
      "step 48160, change in cost 0.00046587\n",
      "step 48170, training accuracy 0.963415\n",
      "step 48170, cost 5.83118\n",
      "step 48170, change in cost 0.000469208\n",
      "step 48180, training accuracy 0.963415\n",
      "step 48180, cost 5.83071\n",
      "step 48180, change in cost 0.000471592\n",
      "step 48190, training accuracy 0.963415\n",
      "step 48190, cost 5.83023\n",
      "step 48190, change in cost 0.000473499\n",
      "step 48200, training accuracy 0.963415\n",
      "step 48200, cost 5.82976\n",
      "step 48200, change in cost 0.000473976\n",
      "step 48210, training accuracy 0.963415\n",
      "step 48210, cost 5.82928\n",
      "step 48210, change in cost 0.000477791\n",
      "step 48220, training accuracy 0.963415\n",
      "step 48220, cost 5.8288\n",
      "step 48220, change in cost 0.000479221\n",
      "step 48230, training accuracy 0.963415\n",
      "step 48230, cost 5.82832\n",
      "step 48230, change in cost 0.000481129\n",
      "step 48240, training accuracy 0.963415\n",
      "step 48240, cost 5.82784\n",
      "step 48240, change in cost 0.000482559\n",
      "step 48250, training accuracy 0.963415\n",
      "step 48250, cost 5.82735\n",
      "step 48250, change in cost 0.000484467\n",
      "step 48260, training accuracy 0.963415\n",
      "step 48260, cost 5.82687\n",
      "step 48260, change in cost 0.000488281\n",
      "step 48270, training accuracy 0.963415\n",
      "step 48270, cost 5.82638\n",
      "step 48270, change in cost 0.000489712\n",
      "step 48280, training accuracy 0.963415\n",
      "step 48280, cost 5.82589\n",
      "step 48280, change in cost 0.000489712\n",
      "step 48290, training accuracy 0.963415\n",
      "step 48290, cost 5.82539\n",
      "step 48290, change in cost 0.000494957\n",
      "step 48300, training accuracy 0.963415\n",
      "step 48300, cost 5.82489\n",
      "step 48300, change in cost 0.000495911\n",
      "step 48310, training accuracy 0.963415\n",
      "step 48310, cost 5.8244\n",
      "step 48310, change in cost 0.000497818\n",
      "step 48320, training accuracy 0.963415\n",
      "step 48320, cost 5.82389\n",
      "step 48320, change in cost 0.00050211\n",
      "step 48330, training accuracy 0.963415\n",
      "step 48330, cost 5.82339\n",
      "step 48330, change in cost 0.000500679\n",
      "step 48340, training accuracy 0.963415\n",
      "step 48340, cost 5.82289\n",
      "step 48340, change in cost 0.000505924\n",
      "step 48350, training accuracy 0.963415\n",
      "step 48350, cost 5.82238\n",
      "step 48350, change in cost 0.000508308\n",
      "step 48360, training accuracy 0.963415\n",
      "step 48360, cost 5.82187\n",
      "step 48360, change in cost 0.000508308\n",
      "step 48370, training accuracy 0.963415\n",
      "step 48370, cost 5.82136\n",
      "step 48370, change in cost 0.000510216\n",
      "step 48380, training accuracy 0.963415\n",
      "step 48380, cost 5.82085\n",
      "step 48380, change in cost 0.000515461\n",
      "step 48390, training accuracy 0.963415\n",
      "step 48390, cost 5.82033\n",
      "step 48390, change in cost 0.000517368\n",
      "step 48400, training accuracy 0.963415\n",
      "step 48400, cost 5.81981\n",
      "step 48400, change in cost 0.000519753\n",
      "step 48410, training accuracy 0.963415\n",
      "step 48410, cost 5.81929\n",
      "step 48410, change in cost 0.00052166\n",
      "step 48420, training accuracy 0.963415\n",
      "step 48420, cost 5.81876\n",
      "step 48420, change in cost 0.000524044\n",
      "step 48430, training accuracy 0.963415\n",
      "step 48430, cost 5.81824\n",
      "step 48430, change in cost 0.000526905\n",
      "step 48440, training accuracy 0.963415\n",
      "step 48440, cost 5.81771\n",
      "step 48440, change in cost 0.000528336\n",
      "step 48450, training accuracy 0.963415\n",
      "step 48450, cost 5.81718\n",
      "step 48450, change in cost 0.000531673\n",
      "step 48460, training accuracy 0.963415\n",
      "step 48460, cost 5.81664\n",
      "step 48460, change in cost 0.000534534\n",
      "step 48470, training accuracy 0.963415\n",
      "step 48470, cost 5.8161\n",
      "step 48470, change in cost 0.000536919\n",
      "step 48480, training accuracy 0.963415\n",
      "step 48480, cost 5.81557\n",
      "step 48480, change in cost 0.000538826\n",
      "step 48490, training accuracy 0.963415\n",
      "step 48490, cost 5.81502\n",
      "step 48490, change in cost 0.000542164\n",
      "step 48500, training accuracy 0.963415\n",
      "step 48500, cost 5.81448\n",
      "step 48500, change in cost 0.000546932\n",
      "step 48510, training accuracy 0.963415\n",
      "step 48510, cost 5.81393\n",
      "step 48510, change in cost 0.000545502\n",
      "step 48520, training accuracy 0.963415\n",
      "step 48520, cost 5.81338\n",
      "step 48520, change in cost 0.000549793\n",
      "step 48530, training accuracy 0.963415\n",
      "step 48530, cost 5.81283\n",
      "step 48530, change in cost 0.000552177\n",
      "step 48540, training accuracy 0.963415\n",
      "step 48540, cost 5.81227\n",
      "step 48540, change in cost 0.000556946\n",
      "step 48550, training accuracy 0.963415\n",
      "step 48550, cost 5.81172\n",
      "step 48550, change in cost 0.000556946\n",
      "step 48560, training accuracy 0.963415\n",
      "step 48560, cost 5.81116\n",
      "step 48560, change in cost 0.000560284\n",
      "step 48570, training accuracy 0.963415\n",
      "step 48570, cost 5.81059\n",
      "step 48570, change in cost 0.000565052\n",
      "step 48580, training accuracy 0.963415\n",
      "step 48580, cost 5.81002\n",
      "step 48580, change in cost 0.000566959\n",
      "step 48590, training accuracy 0.963415\n",
      "step 48590, cost 5.80945\n",
      "step 48590, change in cost 0.000570297\n",
      "step 48600, training accuracy 0.963415\n",
      "step 48600, cost 5.80888\n",
      "step 48600, change in cost 0.000572681\n",
      "step 48610, training accuracy 0.963415\n",
      "step 48610, cost 5.8083\n",
      "step 48610, change in cost 0.000576019\n",
      "step 48620, training accuracy 0.963415\n",
      "step 48620, cost 5.80773\n",
      "step 48620, change in cost 0.000578403\n",
      "step 48630, training accuracy 0.963415\n",
      "step 48630, cost 5.80715\n",
      "step 48630, change in cost 0.000580788\n",
      "step 48640, training accuracy 0.963415\n",
      "step 48640, cost 5.80656\n",
      "step 48640, change in cost 0.000585556\n",
      "step 48650, training accuracy 0.963415\n",
      "step 48650, cost 5.80597\n",
      "step 48650, change in cost 0.00058651\n",
      "step 48660, training accuracy 0.963415\n",
      "step 48660, cost 5.80538\n",
      "step 48660, change in cost 0.000591278\n",
      "step 48670, training accuracy 0.963415\n",
      "step 48670, cost 5.80479\n",
      "step 48670, change in cost 0.000594139\n",
      "step 48680, training accuracy 0.963415\n",
      "step 48680, cost 5.80419\n",
      "step 48680, change in cost 0.000595093\n",
      "step 48690, training accuracy 0.963415\n",
      "step 48690, cost 5.80359\n",
      "step 48690, change in cost 0.000600815\n",
      "step 48700, training accuracy 0.963415\n",
      "step 48700, cost 5.80299\n",
      "step 48700, change in cost 0.000604153\n",
      "step 48710, training accuracy 0.963415\n",
      "step 48710, cost 5.80238\n",
      "step 48710, change in cost 0.000604153\n",
      "step 48720, training accuracy 0.963415\n",
      "step 48720, cost 5.80177\n",
      "step 48720, change in cost 0.000611305\n",
      "step 48730, training accuracy 0.963415\n",
      "step 48730, cost 5.80116\n",
      "step 48730, change in cost 0.000612259\n",
      "step 48740, training accuracy 0.963415\n",
      "step 48740, cost 5.80054\n",
      "step 48740, change in cost 0.000617027\n",
      "step 48750, training accuracy 0.963415\n",
      "step 48750, cost 5.79992\n",
      "step 48750, change in cost 0.000618935\n",
      "step 48760, training accuracy 0.963415\n",
      "step 48760, cost 5.7993\n",
      "step 48760, change in cost 0.000620842\n",
      "step 48770, training accuracy 0.963415\n",
      "step 48770, cost 5.79868\n",
      "step 48770, change in cost 0.000626564\n",
      "step 48780, training accuracy 0.963415\n",
      "step 48780, cost 5.79805\n",
      "step 48780, change in cost 0.000629425\n",
      "step 48790, training accuracy 0.963415\n",
      "step 48790, cost 5.79741\n",
      "step 48790, change in cost 0.00063324\n",
      "step 48800, training accuracy 0.963415\n",
      "step 48800, cost 5.79678\n",
      "step 48800, change in cost 0.000636101\n",
      "step 48810, training accuracy 0.963415\n",
      "step 48810, cost 5.79614\n",
      "step 48810, change in cost 0.000639915\n",
      "step 48820, training accuracy 0.963415\n",
      "step 48820, cost 5.79549\n",
      "step 48820, change in cost 0.00064373\n",
      "step 48830, training accuracy 0.963415\n",
      "step 48830, cost 5.79485\n",
      "step 48830, change in cost 0.000646591\n",
      "step 48840, training accuracy 0.963415\n",
      "step 48840, cost 5.7942\n",
      "step 48840, change in cost 0.000649929\n",
      "step 48850, training accuracy 0.963415\n",
      "step 48850, cost 5.79354\n",
      "step 48850, change in cost 0.000654221\n",
      "step 48860, training accuracy 0.963415\n",
      "step 48860, cost 5.79289\n",
      "step 48860, change in cost 0.000656605\n",
      "step 48870, training accuracy 0.963415\n",
      "step 48870, cost 5.79222\n",
      "step 48870, change in cost 0.000662327\n",
      "step 48880, training accuracy 0.963415\n",
      "step 48880, cost 5.79156\n",
      "step 48880, change in cost 0.000663757\n",
      "step 48890, training accuracy 0.963415\n",
      "step 48890, cost 5.79089\n",
      "step 48890, change in cost 0.000668526\n",
      "step 48900, training accuracy 0.963415\n",
      "step 48900, cost 5.79022\n",
      "step 48900, change in cost 0.00067234\n",
      "step 48910, training accuracy 0.963415\n",
      "step 48910, cost 5.78954\n",
      "step 48910, change in cost 0.000676155\n",
      "step 48920, training accuracy 0.963415\n",
      "step 48920, cost 5.78886\n",
      "step 48920, change in cost 0.000679493\n",
      "step 48930, training accuracy 0.963415\n",
      "step 48930, cost 5.78818\n",
      "step 48930, change in cost 0.000683784\n",
      "step 48940, training accuracy 0.963415\n",
      "step 48940, cost 5.78749\n",
      "step 48940, change in cost 0.00068903\n",
      "step 48950, training accuracy 0.963415\n",
      "step 48950, cost 5.7868\n",
      "step 48950, change in cost 0.000689983\n",
      "step 48960, training accuracy 0.963415\n",
      "step 48960, cost 5.78611\n",
      "step 48960, change in cost 0.000694752\n",
      "step 48970, training accuracy 0.963415\n",
      "step 48970, cost 5.78541\n",
      "step 48970, change in cost 0.000698566\n",
      "step 48980, training accuracy 0.963415\n",
      "step 48980, cost 5.7847\n",
      "step 48980, change in cost 0.000703812\n",
      "step 48990, training accuracy 0.963415\n",
      "step 48990, cost 5.784\n",
      "step 48990, change in cost 0.000704765\n",
      "step 49000, training accuracy 0.963415\n",
      "step 49000, cost 5.78329\n",
      "step 49000, change in cost 0.000711441\n",
      "step 49010, training accuracy 0.963415\n",
      "step 49010, cost 5.78257\n",
      "step 49010, change in cost 0.000715733\n",
      "step 49020, training accuracy 0.963415\n",
      "step 49020, cost 5.78185\n",
      "step 49020, change in cost 0.000718117\n",
      "step 49030, training accuracy 0.963415\n",
      "step 49030, cost 5.78113\n",
      "step 49030, change in cost 0.000723362\n",
      "step 49040, training accuracy 0.963415\n",
      "step 49040, cost 5.7804\n",
      "step 49040, change in cost 0.000726223\n",
      "step 49050, training accuracy 0.963415\n",
      "step 49050, cost 5.77967\n",
      "step 49050, change in cost 0.000730991\n",
      "step 49060, training accuracy 0.963415\n",
      "step 49060, cost 5.77894\n",
      "step 49060, change in cost 0.000736237\n",
      "step 49070, training accuracy 0.963415\n",
      "step 49070, cost 5.7782\n",
      "step 49070, change in cost 0.000738621\n",
      "step 49080, training accuracy 0.963415\n",
      "step 49080, cost 5.77746\n",
      "step 49080, change in cost 0.000742912\n",
      "step 49090, training accuracy 0.963415\n",
      "step 49090, cost 5.77671\n",
      "step 49090, change in cost 0.000748634\n",
      "step 49100, training accuracy 0.963415\n",
      "step 49100, cost 5.77596\n",
      "step 49100, change in cost 0.000751019\n",
      "step 49110, training accuracy 0.963415\n",
      "step 49110, cost 5.7752\n",
      "step 49110, change in cost 0.000756741\n",
      "step 49120, training accuracy 0.963415\n",
      "step 49120, cost 5.77444\n",
      "step 49120, change in cost 0.000759602\n",
      "step 49130, training accuracy 0.963415\n",
      "step 49130, cost 5.77368\n",
      "step 49130, change in cost 0.000763893\n",
      "step 49140, training accuracy 0.963415\n",
      "step 49140, cost 5.77291\n",
      "step 49140, change in cost 0.000769138\n",
      "step 49150, training accuracy 0.963415\n",
      "step 49150, cost 5.77213\n",
      "step 49150, change in cost 0.000773907\n",
      "step 49160, training accuracy 0.963415\n",
      "step 49160, cost 5.77136\n",
      "step 49160, change in cost 0.000777721\n",
      "step 49170, training accuracy 0.963415\n",
      "step 49170, cost 5.77057\n",
      "step 49170, change in cost 0.000782013\n",
      "step 49180, training accuracy 0.963415\n",
      "step 49180, cost 5.76979\n",
      "step 49180, change in cost 0.000786781\n",
      "step 49190, training accuracy 0.963415\n",
      "step 49190, cost 5.769\n",
      "step 49190, change in cost 0.000789642\n",
      "step 49200, training accuracy 0.963415\n",
      "step 49200, cost 5.7682\n",
      "step 49200, change in cost 0.000793934\n",
      "step 49210, training accuracy 0.963415\n",
      "step 49210, cost 5.7674\n",
      "step 49210, change in cost 0.000799179\n",
      "step 49220, training accuracy 0.963415\n",
      "step 49220, cost 5.7666\n",
      "step 49220, change in cost 0.000804901\n",
      "step 49230, training accuracy 0.963415\n",
      "step 49230, cost 5.76579\n",
      "step 49230, change in cost 0.000807762\n",
      "step 49240, training accuracy 0.963415\n",
      "step 49240, cost 5.76498\n",
      "step 49240, change in cost 0.000813484\n",
      "step 49250, training accuracy 0.963415\n",
      "step 49250, cost 5.76416\n",
      "step 49250, change in cost 0.000816345\n",
      "step 49260, training accuracy 0.963415\n",
      "step 49260, cost 5.76334\n",
      "step 49260, change in cost 0.000822067\n",
      "step 49270, training accuracy 0.963415\n",
      "step 49270, cost 5.76251\n",
      "step 49270, change in cost 0.000824928\n",
      "step 49280, training accuracy 0.963415\n",
      "step 49280, cost 5.76168\n",
      "step 49280, change in cost 0.000831604\n",
      "step 49290, training accuracy 0.963415\n",
      "step 49290, cost 5.76085\n",
      "step 49290, change in cost 0.000835419\n",
      "step 49300, training accuracy 0.963415\n",
      "step 49300, cost 5.76001\n",
      "step 49300, change in cost 0.000840187\n",
      "step 49310, training accuracy 0.963415\n",
      "step 49310, cost 5.75916\n",
      "step 49310, change in cost 0.000843525\n",
      "step 49320, training accuracy 0.963415\n",
      "step 49320, cost 5.75831\n",
      "step 49320, change in cost 0.000849247\n",
      "step 49330, training accuracy 0.963415\n",
      "step 49330, cost 5.75746\n",
      "step 49330, change in cost 0.000852108\n",
      "step 49340, training accuracy 0.963415\n",
      "step 49340, cost 5.7566\n",
      "step 49340, change in cost 0.000858784\n",
      "step 49350, training accuracy 0.963415\n",
      "step 49350, cost 5.75574\n",
      "step 49350, change in cost 0.000860214\n",
      "step 49360, training accuracy 0.963415\n",
      "step 49360, cost 5.75488\n",
      "step 49360, change in cost 0.000866413\n",
      "step 49370, training accuracy 0.963415\n",
      "step 49370, cost 5.754\n",
      "step 49370, change in cost 0.000872135\n",
      "step 49380, training accuracy 0.963415\n",
      "step 49380, cost 5.75313\n",
      "step 49380, change in cost 0.00087738\n",
      "step 49390, training accuracy 0.963415\n",
      "step 49390, cost 5.75225\n",
      "step 49390, change in cost 0.000878811\n",
      "step 49400, training accuracy 0.963415\n",
      "step 49400, cost 5.75136\n",
      "step 49400, change in cost 0.000885963\n",
      "step 49410, training accuracy 0.96748\n",
      "step 49410, cost 5.75047\n",
      "step 49410, change in cost 0.000891209\n",
      "step 49420, training accuracy 0.96748\n",
      "step 49420, cost 5.74958\n",
      "step 49420, change in cost 0.000892162\n",
      "step 49430, training accuracy 0.96748\n",
      "step 49430, cost 5.74868\n",
      "step 49430, change in cost 0.000899792\n",
      "step 49440, training accuracy 0.96748\n",
      "step 49440, cost 5.74778\n",
      "step 49440, change in cost 0.00090313\n",
      "step 49450, training accuracy 0.96748\n",
      "step 49450, cost 5.74687\n",
      "step 49450, change in cost 0.000905991\n",
      "step 49460, training accuracy 0.96748\n",
      "step 49460, cost 5.74596\n",
      "step 49460, change in cost 0.000911713\n",
      "step 49470, training accuracy 0.96748\n",
      "step 49470, cost 5.74504\n",
      "step 49470, change in cost 0.000918388\n",
      "step 49480, training accuracy 0.96748\n",
      "step 49480, cost 5.74412\n",
      "step 49480, change in cost 0.000920296\n",
      "step 49490, training accuracy 0.96748\n",
      "step 49490, cost 5.74319\n",
      "step 49490, change in cost 0.000926018\n",
      "step 49500, training accuracy 0.96748\n",
      "step 49500, cost 5.74226\n",
      "step 49500, change in cost 0.000929832\n",
      "step 49510, training accuracy 0.96748\n",
      "step 49510, cost 5.74133\n",
      "step 49510, change in cost 0.000934601\n",
      "step 49520, training accuracy 0.96748\n",
      "step 49520, cost 5.74039\n",
      "step 49520, change in cost 0.000938416\n",
      "step 49530, training accuracy 0.96748\n",
      "step 49530, cost 5.73945\n",
      "step 49530, change in cost 0.000943184\n",
      "step 49540, training accuracy 0.96748\n",
      "step 49540, cost 5.7385\n",
      "step 49540, change in cost 0.000947952\n",
      "step 49550, training accuracy 0.96748\n",
      "step 49550, cost 5.73755\n",
      "step 49550, change in cost 0.000951767\n",
      "step 49560, training accuracy 0.96748\n",
      "step 49560, cost 5.73659\n",
      "step 49560, change in cost 0.000956059\n",
      "step 49570, training accuracy 0.96748\n",
      "step 49570, cost 5.73563\n",
      "step 49570, change in cost 0.000960827\n",
      "step 49580, training accuracy 0.96748\n",
      "step 49580, cost 5.73466\n",
      "step 49580, change in cost 0.000966072\n",
      "step 49590, training accuracy 0.96748\n",
      "step 49590, cost 5.7337\n",
      "step 49590, change in cost 0.00096941\n",
      "step 49600, training accuracy 0.96748\n",
      "step 49600, cost 5.73272\n",
      "step 49600, change in cost 0.000973225\n",
      "step 49610, training accuracy 0.96748\n",
      "step 49610, cost 5.73174\n",
      "step 49610, change in cost 0.000977993\n",
      "step 49620, training accuracy 0.96748\n",
      "step 49620, cost 5.73076\n",
      "step 49620, change in cost 0.000983715\n",
      "step 49630, training accuracy 0.96748\n",
      "step 49630, cost 5.72978\n",
      "step 49630, change in cost 0.000984669\n",
      "step 49640, training accuracy 0.96748\n",
      "step 49640, cost 5.72879\n",
      "step 49640, change in cost 0.000989914\n",
      "step 49650, training accuracy 0.96748\n",
      "step 49650, cost 5.72779\n",
      "step 49650, change in cost 0.000994205\n",
      "step 49660, training accuracy 0.96748\n",
      "step 49660, cost 5.72679\n",
      "step 49660, change in cost 0.000997543\n",
      "step 49670, training accuracy 0.96748\n",
      "step 49670, cost 5.72579\n",
      "step 49670, change in cost 0.00100183\n",
      "step 49680, training accuracy 0.96748\n",
      "step 49680, cost 5.72479\n",
      "step 49680, change in cost 0.0010066\n",
      "step 49690, training accuracy 0.96748\n",
      "step 49690, cost 5.72378\n",
      "step 49690, change in cost 0.00100946\n",
      "step 49700, training accuracy 0.96748\n",
      "step 49700, cost 5.72276\n",
      "step 49700, change in cost 0.00101423\n",
      "step 49710, training accuracy 0.96748\n",
      "step 49710, cost 5.72175\n",
      "step 49710, change in cost 0.00101709\n",
      "step 49720, training accuracy 0.96748\n",
      "step 49720, cost 5.72072\n",
      "step 49720, change in cost 0.00102139\n",
      "step 49730, training accuracy 0.96748\n",
      "step 49730, cost 5.7197\n",
      "step 49730, change in cost 0.00102615\n",
      "step 49740, training accuracy 0.96748\n",
      "step 49740, cost 5.71867\n",
      "step 49740, change in cost 0.00102854\n",
      "step 49750, training accuracy 0.96748\n",
      "step 49750, cost 5.71764\n",
      "step 49750, change in cost 0.00103283\n",
      "step 49760, training accuracy 0.96748\n",
      "step 49760, cost 5.7166\n",
      "step 49760, change in cost 0.00103569\n",
      "step 49770, training accuracy 0.96748\n",
      "step 49770, cost 5.71556\n",
      "step 49770, change in cost 0.00103855\n",
      "step 49780, training accuracy 0.96748\n",
      "step 49780, cost 5.71452\n",
      "step 49780, change in cost 0.00104237\n",
      "step 49790, training accuracy 0.96748\n",
      "step 49790, cost 5.71347\n",
      "step 49790, change in cost 0.00104761\n",
      "step 49800, training accuracy 0.96748\n",
      "step 49800, cost 5.71242\n",
      "step 49800, change in cost 0.00104856\n",
      "step 49810, training accuracy 0.96748\n",
      "step 49810, cost 5.71137\n",
      "step 49810, change in cost 0.00105381\n",
      "step 49820, training accuracy 0.96748\n",
      "step 49820, cost 5.71031\n",
      "step 49820, change in cost 0.00105619\n",
      "step 49830, training accuracy 0.96748\n",
      "step 49830, cost 5.70925\n",
      "step 49830, change in cost 0.00106001\n",
      "step 49840, training accuracy 0.96748\n",
      "step 49840, cost 5.70819\n",
      "step 49840, change in cost 0.00106192\n",
      "step 49850, training accuracy 0.96748\n",
      "step 49850, cost 5.70713\n",
      "step 49850, change in cost 0.00106573\n",
      "step 49860, training accuracy 0.96748\n",
      "step 49860, cost 5.70606\n",
      "step 49860, change in cost 0.00106907\n",
      "step 49870, training accuracy 0.96748\n",
      "step 49870, cost 5.70499\n",
      "step 49870, change in cost 0.0010705\n",
      "step 49880, training accuracy 0.96748\n",
      "step 49880, cost 5.70391\n",
      "step 49880, change in cost 0.00107431\n",
      "step 49890, training accuracy 0.96748\n",
      "step 49890, cost 5.70283\n",
      "step 49890, change in cost 0.00107765\n",
      "step 49900, training accuracy 0.96748\n",
      "step 49900, cost 5.70176\n",
      "step 49900, change in cost 0.00107861\n",
      "step 49910, training accuracy 0.96748\n",
      "step 49910, cost 5.70067\n",
      "step 49910, change in cost 0.00108337\n",
      "step 49920, training accuracy 0.96748\n",
      "step 49920, cost 5.69959\n",
      "step 49920, change in cost 0.00108528\n",
      "step 49930, training accuracy 0.96748\n",
      "step 49930, cost 5.6985\n",
      "step 49930, change in cost 0.00108671\n",
      "step 49940, training accuracy 0.96748\n",
      "step 49940, cost 5.69741\n",
      "step 49940, change in cost 0.00108957\n",
      "step 49950, training accuracy 0.96748\n",
      "step 49950, cost 5.69632\n",
      "step 49950, change in cost 0.00109243\n",
      "step 49960, training accuracy 0.96748\n",
      "step 49960, cost 5.69522\n",
      "step 49960, change in cost 0.00109434\n",
      "step 49970, training accuracy 0.96748\n",
      "step 49970, cost 5.69413\n",
      "step 49970, change in cost 0.00109625\n",
      "step 49980, training accuracy 0.96748\n",
      "step 49980, cost 5.69303\n",
      "step 49980, change in cost 0.00110006\n",
      "step 49990, training accuracy 0.96748\n",
      "step 49990, cost 5.69193\n",
      "step 49990, change in cost 0.00109959\n",
      "step 50000, training accuracy 0.96748\n",
      "step 50000, cost 5.69082\n",
      "step 50000, change in cost 0.00110435\n",
      "step 50010, training accuracy 0.96748\n",
      "step 50010, cost 5.68972\n",
      "step 50010, change in cost 0.0011034\n",
      "step 50020, training accuracy 0.96748\n",
      "step 50020, cost 5.68861\n",
      "step 50020, change in cost 0.00110626\n",
      "step 50030, training accuracy 0.96748\n",
      "step 50030, cost 5.68751\n",
      "step 50030, change in cost 0.00110817\n",
      "step 50040, training accuracy 0.96748\n",
      "step 50040, cost 5.6864\n",
      "step 50040, change in cost 0.00110865\n",
      "step 50050, training accuracy 0.96748\n",
      "step 50050, cost 5.68529\n",
      "step 50050, change in cost 0.00111198\n",
      "step 50060, training accuracy 0.96748\n",
      "step 50060, cost 5.68417\n",
      "step 50060, change in cost 0.00111389\n",
      "step 50070, training accuracy 0.96748\n",
      "step 50070, cost 5.68306\n",
      "step 50070, change in cost 0.00111294\n",
      "step 50080, training accuracy 0.96748\n",
      "step 50080, cost 5.68194\n",
      "step 50080, change in cost 0.00111532\n",
      "step 50090, training accuracy 0.96748\n",
      "step 50090, cost 5.68083\n",
      "step 50090, change in cost 0.00111628\n",
      "step 50100, training accuracy 0.96748\n",
      "step 50100, cost 5.67971\n",
      "step 50100, change in cost 0.00111866\n",
      "step 50110, training accuracy 0.96748\n",
      "step 50110, cost 5.67859\n",
      "step 50110, change in cost 0.00111866\n",
      "step 50120, training accuracy 0.96748\n",
      "step 50120, cost 5.67747\n",
      "step 50120, change in cost 0.00111914\n",
      "step 50130, training accuracy 0.96748\n",
      "step 50130, cost 5.67635\n",
      "step 50130, change in cost 0.00112057\n",
      "step 50140, training accuracy 0.96748\n",
      "step 50140, cost 5.67523\n",
      "step 50140, change in cost 0.00112057\n",
      "step 50150, training accuracy 0.96748\n",
      "step 50150, cost 5.67411\n",
      "step 50150, change in cost 0.00112343\n",
      "step 50160, training accuracy 0.96748\n",
      "step 50160, cost 5.67298\n",
      "step 50160, change in cost 0.00112247\n",
      "step 50170, training accuracy 0.96748\n",
      "step 50170, cost 5.67186\n",
      "step 50170, change in cost 0.00112295\n",
      "step 50180, training accuracy 0.96748\n",
      "step 50180, cost 5.67074\n",
      "step 50180, change in cost 0.00112343\n",
      "step 50190, training accuracy 0.96748\n",
      "step 50190, cost 5.66961\n",
      "step 50190, change in cost 0.00112486\n",
      "step 50200, training accuracy 0.96748\n",
      "step 50200, cost 5.66849\n",
      "step 50200, change in cost 0.00112438\n",
      "step 50210, training accuracy 0.96748\n",
      "step 50210, cost 5.66736\n",
      "step 50210, change in cost 0.00112438\n",
      "step 50220, training accuracy 0.96748\n",
      "step 50220, cost 5.66624\n",
      "step 50220, change in cost 0.00112486\n",
      "step 50230, training accuracy 0.96748\n",
      "step 50230, cost 5.66511\n",
      "step 50230, change in cost 0.00112581\n",
      "step 50240, training accuracy 0.96748\n",
      "step 50240, cost 5.66399\n",
      "step 50240, change in cost 0.00112438\n",
      "step 50250, training accuracy 0.96748\n",
      "step 50250, cost 5.66286\n",
      "step 50250, change in cost 0.00112534\n",
      "step 50260, training accuracy 0.96748\n",
      "step 50260, cost 5.66174\n",
      "step 50260, change in cost 0.00112438\n",
      "step 50270, training accuracy 0.96748\n",
      "step 50270, cost 5.66061\n",
      "step 50270, change in cost 0.00112438\n",
      "step 50280, training accuracy 0.96748\n",
      "step 50280, cost 5.65949\n",
      "step 50280, change in cost 0.00112438\n",
      "step 50290, training accuracy 0.96748\n",
      "step 50290, cost 5.65837\n",
      "step 50290, change in cost 0.00112247\n",
      "step 50300, training accuracy 0.96748\n",
      "step 50300, cost 5.65724\n",
      "step 50300, change in cost 0.00112247\n",
      "step 50310, training accuracy 0.96748\n",
      "step 50310, cost 5.65612\n",
      "step 50310, change in cost 0.00112247\n",
      "step 50320, training accuracy 0.96748\n",
      "step 50320, cost 5.655\n",
      "step 50320, change in cost 0.00112295\n",
      "step 50330, training accuracy 0.96748\n",
      "step 50330, cost 5.65388\n",
      "step 50330, change in cost 0.00112009\n",
      "step 50340, training accuracy 0.96748\n",
      "step 50340, cost 5.65276\n",
      "step 50340, change in cost 0.00112057\n",
      "step 50350, training accuracy 0.96748\n",
      "step 50350, cost 5.65164\n",
      "step 50350, change in cost 0.00112009\n",
      "step 50360, training accuracy 0.96748\n",
      "step 50360, cost 5.65052\n",
      "step 50360, change in cost 0.00111723\n",
      "step 50370, training accuracy 0.96748\n",
      "step 50370, cost 5.6494\n",
      "step 50370, change in cost 0.00111818\n",
      "step 50380, training accuracy 0.96748\n",
      "step 50380, cost 5.64829\n",
      "step 50380, change in cost 0.00111532\n",
      "step 50390, training accuracy 0.96748\n",
      "step 50390, cost 5.64717\n",
      "step 50390, change in cost 0.0011158\n",
      "step 50400, training accuracy 0.96748\n",
      "step 50400, cost 5.64606\n",
      "step 50400, change in cost 0.00111485\n",
      "step 50410, training accuracy 0.96748\n",
      "step 50410, cost 5.64494\n",
      "step 50410, change in cost 0.00111246\n",
      "step 50420, training accuracy 0.96748\n",
      "step 50420, cost 5.64383\n",
      "step 50420, change in cost 0.00111103\n",
      "step 50430, training accuracy 0.96748\n",
      "step 50430, cost 5.64272\n",
      "step 50430, change in cost 0.0011096\n",
      "step 50440, training accuracy 0.96748\n",
      "step 50440, cost 5.64162\n",
      "step 50440, change in cost 0.00110865\n",
      "step 50450, training accuracy 0.96748\n",
      "step 50450, cost 5.64051\n",
      "step 50450, change in cost 0.00110674\n",
      "step 50460, training accuracy 0.96748\n",
      "step 50460, cost 5.6394\n",
      "step 50460, change in cost 0.00110626\n",
      "step 50470, training accuracy 0.96748\n",
      "step 50470, cost 5.6383\n",
      "step 50470, change in cost 0.00110292\n",
      "step 50480, training accuracy 0.96748\n",
      "step 50480, cost 5.6372\n",
      "step 50480, change in cost 0.00110197\n",
      "step 50490, training accuracy 0.96748\n",
      "step 50490, cost 5.6361\n",
      "step 50490, change in cost 0.00110054\n",
      "step 50500, training accuracy 0.96748\n",
      "step 50500, cost 5.635\n",
      "step 50500, change in cost 0.00109673\n",
      "step 50510, training accuracy 0.96748\n",
      "step 50510, cost 5.6339\n",
      "step 50510, change in cost 0.0010972\n",
      "step 50520, training accuracy 0.96748\n",
      "step 50520, cost 5.63281\n",
      "step 50520, change in cost 0.00109482\n",
      "step 50530, training accuracy 0.96748\n",
      "step 50530, cost 5.63172\n",
      "step 50530, change in cost 0.00109148\n",
      "step 50540, training accuracy 0.96748\n",
      "step 50540, cost 5.63063\n",
      "step 50540, change in cost 0.00109005\n",
      "step 50550, training accuracy 0.96748\n",
      "step 50550, cost 5.62954\n",
      "step 50550, change in cost 0.00108767\n",
      "step 50560, training accuracy 0.96748\n",
      "step 50560, cost 5.62845\n",
      "step 50560, change in cost 0.00108671\n",
      "step 50570, training accuracy 0.96748\n",
      "step 50570, cost 5.62737\n",
      "step 50570, change in cost 0.00108242\n",
      "step 50580, training accuracy 0.96748\n",
      "step 50580, cost 5.62629\n",
      "step 50580, change in cost 0.00108147\n",
      "step 50590, training accuracy 0.96748\n",
      "step 50590, cost 5.62521\n",
      "step 50590, change in cost 0.00107861\n",
      "step 50600, training accuracy 0.96748\n",
      "step 50600, cost 5.62413\n",
      "step 50600, change in cost 0.0010767\n",
      "step 50610, training accuracy 0.96748\n",
      "step 50610, cost 5.62306\n",
      "step 50610, change in cost 0.00107384\n",
      "step 50620, training accuracy 0.96748\n",
      "step 50620, cost 5.62199\n",
      "step 50620, change in cost 0.00107241\n",
      "step 50630, training accuracy 0.96748\n",
      "step 50630, cost 5.62092\n",
      "step 50630, change in cost 0.00106955\n",
      "step 50640, training accuracy 0.96748\n",
      "step 50640, cost 5.61985\n",
      "step 50640, change in cost 0.00106573\n",
      "step 50650, training accuracy 0.96748\n",
      "step 50650, cost 5.61879\n",
      "step 50650, change in cost 0.00106525\n",
      "step 50660, training accuracy 0.96748\n",
      "step 50660, cost 5.61772\n",
      "step 50660, change in cost 0.00106192\n",
      "step 50670, training accuracy 0.96748\n",
      "step 50670, cost 5.61667\n",
      "step 50670, change in cost 0.00105858\n",
      "step 50680, training accuracy 0.96748\n",
      "step 50680, cost 5.61561\n",
      "step 50680, change in cost 0.00105572\n",
      "step 50690, training accuracy 0.96748\n",
      "step 50690, cost 5.61456\n",
      "step 50690, change in cost 0.00105333\n",
      "step 50700, training accuracy 0.96748\n",
      "step 50700, cost 5.6135\n",
      "step 50700, change in cost 0.0010519\n",
      "step 50710, training accuracy 0.96748\n",
      "step 50710, cost 5.61246\n",
      "step 50710, change in cost 0.00104809\n",
      "step 50720, training accuracy 0.96748\n",
      "step 50720, cost 5.61141\n",
      "step 50720, change in cost 0.00104427\n",
      "step 50730, training accuracy 0.96748\n",
      "step 50730, cost 5.61037\n",
      "step 50730, change in cost 0.00104189\n",
      "step 50740, training accuracy 0.96748\n",
      "step 50740, cost 5.60933\n",
      "step 50740, change in cost 0.00103951\n",
      "step 50750, training accuracy 0.96748\n",
      "step 50750, cost 5.6083\n",
      "step 50750, change in cost 0.00103569\n",
      "step 50760, training accuracy 0.96748\n",
      "step 50760, cost 5.60726\n",
      "step 50760, change in cost 0.00103474\n",
      "step 50770, training accuracy 0.96748\n",
      "step 50770, cost 5.60623\n",
      "step 50770, change in cost 0.00102949\n",
      "step 50780, training accuracy 0.96748\n",
      "step 50780, cost 5.6052\n",
      "step 50780, change in cost 0.00102711\n",
      "step 50790, training accuracy 0.96748\n",
      "step 50790, cost 5.60418\n",
      "step 50790, change in cost 0.00102568\n",
      "step 50800, training accuracy 0.96748\n",
      "step 50800, cost 5.60316\n",
      "step 50800, change in cost 0.00102043\n",
      "step 50810, training accuracy 0.96748\n",
      "step 50810, cost 5.60214\n",
      "step 50810, change in cost 0.00101852\n",
      "step 50820, training accuracy 0.96748\n",
      "step 50820, cost 5.60112\n",
      "step 50820, change in cost 0.00101566\n",
      "step 50830, training accuracy 0.96748\n",
      "step 50830, cost 5.60011\n",
      "step 50830, change in cost 0.00101089\n",
      "step 50840, training accuracy 0.96748\n",
      "step 50840, cost 5.5991\n",
      "step 50840, change in cost 0.00100994\n",
      "step 50850, training accuracy 0.96748\n",
      "step 50850, cost 5.5981\n",
      "step 50850, change in cost 0.00100517\n",
      "step 50860, training accuracy 0.96748\n",
      "step 50860, cost 5.59709\n",
      "step 50860, change in cost 0.00100374\n",
      "step 50870, training accuracy 0.96748\n",
      "step 50870, cost 5.5961\n",
      "step 50870, change in cost 0.000998974\n",
      "step 50880, training accuracy 0.96748\n",
      "step 50880, cost 5.5951\n",
      "step 50880, change in cost 0.000995636\n",
      "step 50890, training accuracy 0.96748\n",
      "step 50890, cost 5.59411\n",
      "step 50890, change in cost 0.000992775\n",
      "step 50900, training accuracy 0.96748\n",
      "step 50900, cost 5.59312\n",
      "step 50900, change in cost 0.000990868\n",
      "step 50910, training accuracy 0.96748\n",
      "step 50910, cost 5.59213\n",
      "step 50910, change in cost 0.000987053\n",
      "step 50920, training accuracy 0.96748\n",
      "step 50920, cost 5.59115\n",
      "step 50920, change in cost 0.000982285\n",
      "step 50930, training accuracy 0.96748\n",
      "step 50930, cost 5.59017\n",
      "step 50930, change in cost 0.000980377\n",
      "step 50940, training accuracy 0.96748\n",
      "step 50940, cost 5.58919\n",
      "step 50940, change in cost 0.000976086\n",
      "step 50950, training accuracy 0.96748\n",
      "step 50950, cost 5.58822\n",
      "step 50950, change in cost 0.000974178\n",
      "step 50960, training accuracy 0.96748\n",
      "step 50960, cost 5.58725\n",
      "step 50960, change in cost 0.000969887\n",
      "step 50970, training accuracy 0.96748\n",
      "step 50970, cost 5.58628\n",
      "step 50970, change in cost 0.000966072\n",
      "step 50980, training accuracy 0.96748\n",
      "step 50980, cost 5.58532\n",
      "step 50980, change in cost 0.000964165\n",
      "step 50990, training accuracy 0.96748\n",
      "step 50990, cost 5.58435\n",
      "step 50990, change in cost 0.000960827\n",
      "step 51000, training accuracy 0.96748\n",
      "step 51000, cost 5.5834\n",
      "step 51000, change in cost 0.000957012\n",
      "step 51010, training accuracy 0.96748\n",
      "step 51010, cost 5.58244\n",
      "step 51010, change in cost 0.000954151\n",
      "step 51020, training accuracy 0.96748\n",
      "step 51020, cost 5.58149\n",
      "step 51020, change in cost 0.000950336\n",
      "step 51030, training accuracy 0.96748\n",
      "step 51030, cost 5.58055\n",
      "step 51030, change in cost 0.000946522\n",
      "step 51040, training accuracy 0.96748\n",
      "step 51040, cost 5.5796\n",
      "step 51040, change in cost 0.00094223\n",
      "step 51050, training accuracy 0.96748\n",
      "step 51050, cost 5.57866\n",
      "step 51050, change in cost 0.0009408\n",
      "step 51060, training accuracy 0.96748\n",
      "step 51060, cost 5.57773\n",
      "step 51060, change in cost 0.000936508\n",
      "step 51070, training accuracy 0.96748\n",
      "step 51070, cost 5.57679\n",
      "step 51070, change in cost 0.000934124\n",
      "step 51080, training accuracy 0.96748\n",
      "step 51080, cost 5.57586\n",
      "step 51080, change in cost 0.000930309\n",
      "step 51090, training accuracy 0.96748\n",
      "step 51090, cost 5.57494\n",
      "step 51090, change in cost 0.000926018\n",
      "step 51100, training accuracy 0.96748\n",
      "step 51100, cost 5.57401\n",
      "step 51100, change in cost 0.000923157\n",
      "step 51110, training accuracy 0.96748\n",
      "step 51110, cost 5.57309\n",
      "step 51110, change in cost 0.000920773\n",
      "step 51120, training accuracy 0.96748\n",
      "step 51120, cost 5.57218\n",
      "step 51120, change in cost 0.000916004\n",
      "step 51130, training accuracy 0.96748\n",
      "step 51130, cost 5.57126\n",
      "step 51130, change in cost 0.000913143\n",
      "step 51140, training accuracy 0.96748\n",
      "step 51140, cost 5.57035\n",
      "step 51140, change in cost 0.000910282\n",
      "step 51150, training accuracy 0.96748\n",
      "step 51150, cost 5.56945\n",
      "step 51150, change in cost 0.000905991\n",
      "step 51160, training accuracy 0.96748\n",
      "step 51160, cost 5.56854\n",
      "step 51160, change in cost 0.000904083\n",
      "step 51170, training accuracy 0.96748\n",
      "step 51170, cost 5.56764\n",
      "step 51170, change in cost 0.000900269\n",
      "step 51180, training accuracy 0.96748\n",
      "step 51180, cost 5.56675\n",
      "step 51180, change in cost 0.000896454\n",
      "step 51190, training accuracy 0.96748\n",
      "step 51190, cost 5.56585\n",
      "step 51190, change in cost 0.00089407\n",
      "step 51200, training accuracy 0.96748\n",
      "step 51200, cost 5.56496\n",
      "step 51200, change in cost 0.000890732\n",
      "step 51210, training accuracy 0.96748\n",
      "step 51210, cost 5.56408\n",
      "step 51210, change in cost 0.00088644\n",
      "step 51220, training accuracy 0.96748\n",
      "step 51220, cost 5.56319\n",
      "step 51220, change in cost 0.000882626\n",
      "step 51230, training accuracy 0.96748\n",
      "step 51230, cost 5.56231\n",
      "step 51230, change in cost 0.000879765\n",
      "step 51240, training accuracy 0.96748\n",
      "step 51240, cost 5.56144\n",
      "step 51240, change in cost 0.00087738\n",
      "step 51250, training accuracy 0.96748\n",
      "step 51250, cost 5.56056\n",
      "step 51250, change in cost 0.000872612\n",
      "step 51260, training accuracy 0.96748\n",
      "step 51260, cost 5.55969\n",
      "step 51260, change in cost 0.000871658\n",
      "step 51270, training accuracy 0.96748\n",
      "step 51270, cost 5.55882\n",
      "step 51270, change in cost 0.00086689\n",
      "step 51280, training accuracy 0.96748\n",
      "step 51280, cost 5.55796\n",
      "step 51280, change in cost 0.000864029\n",
      "step 51290, training accuracy 0.96748\n",
      "step 51290, cost 5.5571\n",
      "step 51290, change in cost 0.000859261\n",
      "step 51300, training accuracy 0.96748\n",
      "step 51300, cost 5.55624\n",
      "step 51300, change in cost 0.000858307\n",
      "step 51310, training accuracy 0.96748\n",
      "step 51310, cost 5.55539\n",
      "step 51310, change in cost 0.000853539\n",
      "step 51320, training accuracy 0.96748\n",
      "step 51320, cost 5.55454\n",
      "step 51320, change in cost 0.000851631\n",
      "step 51330, training accuracy 0.96748\n",
      "step 51330, cost 5.55369\n",
      "step 51330, change in cost 0.000845909\n",
      "step 51340, training accuracy 0.96748\n",
      "step 51340, cost 5.55285\n",
      "step 51340, change in cost 0.000844479\n",
      "step 51350, training accuracy 0.96748\n",
      "step 51350, cost 5.55201\n",
      "step 51350, change in cost 0.00083971\n",
      "step 51360, training accuracy 0.96748\n",
      "step 51360, cost 5.55117\n",
      "step 51360, change in cost 0.000838757\n",
      "step 51370, training accuracy 0.96748\n",
      "step 51370, cost 5.55033\n",
      "step 51370, change in cost 0.000835896\n",
      "step 51380, training accuracy 0.96748\n",
      "step 51380, cost 5.5495\n",
      "step 51380, change in cost 0.00083065\n",
      "step 51390, training accuracy 0.96748\n",
      "step 51390, cost 5.54867\n",
      "step 51390, change in cost 0.000827789\n",
      "step 51400, training accuracy 0.96748\n",
      "step 51400, cost 5.54785\n",
      "step 51400, change in cost 0.000823975\n",
      "step 51410, training accuracy 0.96748\n",
      "step 51410, cost 5.54703\n",
      "step 51410, change in cost 0.000822067\n",
      "step 51420, training accuracy 0.96748\n",
      "step 51420, cost 5.54621\n",
      "step 51420, change in cost 0.000818253\n",
      "step 51430, training accuracy 0.96748\n",
      "step 51430, cost 5.5454\n",
      "step 51430, change in cost 0.000814438\n",
      "step 51440, training accuracy 0.96748\n",
      "step 51440, cost 5.54458\n",
      "step 51440, change in cost 0.000813484\n",
      "step 51450, training accuracy 0.96748\n",
      "step 51450, cost 5.54377\n",
      "step 51450, change in cost 0.000808716\n",
      "step 51460, training accuracy 0.96748\n",
      "step 51460, cost 5.54297\n",
      "step 51460, change in cost 0.000805855\n",
      "step 51470, training accuracy 0.96748\n",
      "step 51470, cost 5.54216\n",
      "step 51470, change in cost 0.000803947\n",
      "step 51480, training accuracy 0.96748\n",
      "step 51480, cost 5.54136\n",
      "step 51480, change in cost 0.000799179\n",
      "step 51490, training accuracy 0.96748\n",
      "step 51490, cost 5.54057\n",
      "step 51490, change in cost 0.000797272\n",
      "step 51500, training accuracy 0.96748\n",
      "step 51500, cost 5.53977\n",
      "step 51500, change in cost 0.000794411\n",
      "step 51510, training accuracy 0.96748\n",
      "step 51510, cost 5.53898\n",
      "step 51510, change in cost 0.000790119\n",
      "step 51520, training accuracy 0.96748\n",
      "step 51520, cost 5.5382\n",
      "step 51520, change in cost 0.000787258\n",
      "step 51530, training accuracy 0.96748\n",
      "step 51530, cost 5.53741\n",
      "step 51530, change in cost 0.000785828\n",
      "step 51540, training accuracy 0.96748\n",
      "step 51540, cost 5.53663\n",
      "step 51540, change in cost 0.000782013\n",
      "step 51550, training accuracy 0.96748\n",
      "step 51550, cost 5.53585\n",
      "step 51550, change in cost 0.000779152\n",
      "step 51560, training accuracy 0.96748\n",
      "step 51560, cost 5.53507\n",
      "step 51560, change in cost 0.000776291\n",
      "step 51570, training accuracy 0.96748\n",
      "step 51570, cost 5.5343\n",
      "step 51570, change in cost 0.000772953\n",
      "step 51580, training accuracy 0.96748\n",
      "step 51580, cost 5.53353\n",
      "step 51580, change in cost 0.000769138\n",
      "step 51590, training accuracy 0.96748\n",
      "step 51590, cost 5.53276\n",
      "step 51590, change in cost 0.000766754\n",
      "step 51600, training accuracy 0.96748\n",
      "step 51600, cost 5.532\n",
      "step 51600, change in cost 0.000763893\n",
      "step 51610, training accuracy 0.96748\n",
      "step 51610, cost 5.53124\n",
      "step 51610, change in cost 0.000761032\n",
      "step 51620, training accuracy 0.96748\n",
      "step 51620, cost 5.53048\n",
      "step 51620, change in cost 0.000760078\n",
      "step 51630, training accuracy 0.96748\n",
      "step 51630, cost 5.52972\n",
      "step 51630, change in cost 0.000754356\n",
      "step 51640, training accuracy 0.96748\n",
      "step 51640, cost 5.52897\n",
      "step 51640, change in cost 0.000751972\n",
      "step 51650, training accuracy 0.96748\n",
      "step 51650, cost 5.52822\n",
      "step 51650, change in cost 0.000749588\n",
      "step 51660, training accuracy 0.96748\n",
      "step 51660, cost 5.52748\n",
      "step 51660, change in cost 0.000747204\n",
      "step 51670, training accuracy 0.96748\n",
      "step 51670, cost 5.52673\n",
      "step 51670, change in cost 0.000742912\n",
      "step 51680, training accuracy 0.96748\n",
      "step 51680, cost 5.52599\n",
      "step 51680, change in cost 0.000742912\n",
      "step 51690, training accuracy 0.96748\n",
      "step 51690, cost 5.52525\n",
      "step 51690, change in cost 0.000737667\n",
      "step 51700, training accuracy 0.96748\n",
      "step 51700, cost 5.52452\n",
      "step 51700, change in cost 0.00073576\n",
      "step 51710, training accuracy 0.96748\n",
      "step 51710, cost 5.52378\n",
      "step 51710, change in cost 0.000731945\n",
      "step 51720, training accuracy 0.96748\n",
      "step 51720, cost 5.52305\n",
      "step 51720, change in cost 0.000731945\n",
      "step 51730, training accuracy 0.96748\n",
      "step 51730, cost 5.52233\n",
      "step 51730, change in cost 0.0007267\n",
      "step 51740, training accuracy 0.96748\n",
      "step 51740, cost 5.5216\n",
      "step 51740, change in cost 0.000724792\n",
      "step 51750, training accuracy 0.96748\n",
      "step 51750, cost 5.52088\n",
      "step 51750, change in cost 0.000722885\n",
      "step 51760, training accuracy 0.96748\n",
      "step 51760, cost 5.52016\n",
      "step 51760, change in cost 0.000718594\n",
      "step 51770, training accuracy 0.96748\n",
      "step 51770, cost 5.51944\n",
      "step 51770, change in cost 0.000717163\n",
      "step 51780, training accuracy 0.96748\n",
      "step 51780, cost 5.51873\n",
      "step 51780, change in cost 0.000713825\n",
      "step 51790, training accuracy 0.96748\n",
      "step 51790, cost 5.51802\n",
      "step 51790, change in cost 0.000711441\n",
      "step 51800, training accuracy 0.96748\n",
      "step 51800, cost 5.51731\n",
      "step 51800, change in cost 0.00070858\n",
      "step 51810, training accuracy 0.96748\n",
      "step 51810, cost 5.5166\n",
      "step 51810, change in cost 0.000705719\n",
      "step 51820, training accuracy 0.96748\n",
      "step 51820, cost 5.5159\n",
      "step 51820, change in cost 0.000703335\n",
      "step 51830, training accuracy 0.96748\n",
      "step 51830, cost 5.5152\n",
      "step 51830, change in cost 0.000700474\n",
      "step 51840, training accuracy 0.96748\n",
      "step 51840, cost 5.5145\n",
      "step 51840, change in cost 0.000699043\n",
      "step 51850, training accuracy 0.96748\n",
      "step 51850, cost 5.5138\n",
      "step 51850, change in cost 0.000696182\n",
      "step 51860, training accuracy 0.96748\n",
      "step 51860, cost 5.51311\n",
      "step 51860, change in cost 0.000692844\n",
      "step 51870, training accuracy 0.96748\n",
      "step 51870, cost 5.51242\n",
      "step 51870, change in cost 0.00069046\n",
      "step 51880, training accuracy 0.96748\n",
      "step 51880, cost 5.51173\n",
      "step 51880, change in cost 0.000688076\n",
      "step 51890, training accuracy 0.96748\n",
      "step 51890, cost 5.51105\n",
      "step 51890, change in cost 0.000685692\n",
      "step 51900, training accuracy 0.96748\n",
      "step 51900, cost 5.51036\n",
      "step 51900, change in cost 0.000682831\n",
      "step 51910, training accuracy 0.96748\n",
      "step 51910, cost 5.50968\n",
      "step 51910, change in cost 0.000680923\n",
      "step 51920, training accuracy 0.96748\n",
      "step 51920, cost 5.50901\n",
      "step 51920, change in cost 0.000677586\n",
      "step 51930, training accuracy 0.96748\n",
      "step 51930, cost 5.50833\n",
      "step 51930, change in cost 0.000675678\n",
      "step 51940, training accuracy 0.96748\n",
      "step 51940, cost 5.50766\n",
      "step 51940, change in cost 0.000673294\n",
      "step 51950, training accuracy 0.96748\n",
      "step 51950, cost 5.50698\n",
      "step 51950, change in cost 0.000671864\n",
      "step 51960, training accuracy 0.96748\n",
      "step 51960, cost 5.50632\n",
      "step 51960, change in cost 0.000667572\n",
      "step 51970, training accuracy 0.96748\n",
      "step 51970, cost 5.50565\n",
      "step 51970, change in cost 0.000665665\n",
      "step 51980, training accuracy 0.96748\n",
      "step 51980, cost 5.50499\n",
      "step 51980, change in cost 0.000663757\n",
      "step 51990, training accuracy 0.96748\n",
      "step 51990, cost 5.50433\n",
      "step 51990, change in cost 0.000660419\n",
      "step 52000, training accuracy 0.96748\n",
      "step 52000, cost 5.50367\n",
      "step 52000, change in cost 0.000658989\n",
      "step 52010, training accuracy 0.96748\n",
      "step 52010, cost 5.50301\n",
      "step 52010, change in cost 0.000657082\n",
      "step 52020, training accuracy 0.96748\n",
      "step 52020, cost 5.50236\n",
      "step 52020, change in cost 0.000654221\n",
      "step 52030, training accuracy 0.96748\n",
      "step 52030, cost 5.50171\n",
      "step 52030, change in cost 0.000650406\n",
      "step 52040, training accuracy 0.96748\n",
      "step 52040, cost 5.50106\n",
      "step 52040, change in cost 0.000650883\n",
      "step 52050, training accuracy 0.96748\n",
      "step 52050, cost 5.50041\n",
      "step 52050, change in cost 0.000647068\n",
      "step 52060, training accuracy 0.96748\n",
      "step 52060, cost 5.49976\n",
      "step 52060, change in cost 0.000645638\n",
      "step 52070, training accuracy 0.96748\n",
      "step 52070, cost 5.49912\n",
      "step 52070, change in cost 0.000641346\n",
      "step 52080, training accuracy 0.96748\n",
      "step 52080, cost 5.49848\n",
      "step 52080, change in cost 0.000640392\n",
      "step 52090, training accuracy 0.96748\n",
      "step 52090, cost 5.49784\n",
      "step 52090, change in cost 0.000638485\n",
      "step 52100, training accuracy 0.96748\n",
      "step 52100, cost 5.49721\n",
      "step 52100, change in cost 0.000636578\n",
      "step 52110, training accuracy 0.96748\n",
      "step 52110, cost 5.49657\n",
      "step 52110, change in cost 0.000632763\n",
      "step 52120, training accuracy 0.96748\n",
      "step 52120, cost 5.49594\n",
      "step 52120, change in cost 0.000632763\n",
      "step 52130, training accuracy 0.96748\n",
      "step 52130, cost 5.49531\n",
      "step 52130, change in cost 0.000629902\n",
      "step 52140, training accuracy 0.96748\n",
      "step 52140, cost 5.49468\n",
      "step 52140, change in cost 0.000626564\n",
      "step 52150, training accuracy 0.96748\n",
      "step 52150, cost 5.49406\n",
      "step 52150, change in cost 0.000625134\n",
      "step 52160, training accuracy 0.96748\n",
      "step 52160, cost 5.49343\n",
      "step 52160, change in cost 0.000623703\n",
      "step 52170, training accuracy 0.96748\n",
      "step 52170, cost 5.49281\n",
      "step 52170, change in cost 0.000620365\n",
      "step 52180, training accuracy 0.96748\n",
      "step 52180, cost 5.4922\n",
      "step 52180, change in cost 0.000618458\n",
      "step 52190, training accuracy 0.96748\n",
      "step 52190, cost 5.49158\n",
      "step 52190, change in cost 0.000616074\n",
      "step 52200, training accuracy 0.96748\n",
      "step 52200, cost 5.49097\n",
      "step 52200, change in cost 0.000614166\n",
      "step 52210, training accuracy 0.96748\n",
      "step 52210, cost 5.49035\n",
      "step 52210, change in cost 0.000611305\n",
      "step 52220, training accuracy 0.96748\n",
      "step 52220, cost 5.48974\n",
      "step 52220, change in cost 0.000611305\n",
      "step 52230, training accuracy 0.96748\n",
      "step 52230, cost 5.48913\n",
      "step 52230, change in cost 0.000608444\n",
      "step 52240, training accuracy 0.96748\n",
      "step 52240, cost 5.48853\n",
      "step 52240, change in cost 0.00060606\n",
      "step 52250, training accuracy 0.96748\n",
      "step 52250, cost 5.48793\n",
      "step 52250, change in cost 0.000603199\n",
      "step 52260, training accuracy 0.96748\n",
      "step 52260, cost 5.48732\n",
      "step 52260, change in cost 0.000602722\n",
      "step 52270, training accuracy 0.96748\n",
      "step 52270, cost 5.48672\n",
      "step 52270, change in cost 0.000599861\n",
      "step 52280, training accuracy 0.96748\n",
      "step 52280, cost 5.48612\n",
      "step 52280, change in cost 0.000597954\n",
      "step 52290, training accuracy 0.96748\n",
      "step 52290, cost 5.48553\n",
      "step 52290, change in cost 0.000596046\n",
      "step 52300, training accuracy 0.96748\n",
      "step 52300, cost 5.48493\n",
      "step 52300, change in cost 0.000594139\n",
      "step 52310, training accuracy 0.96748\n",
      "step 52310, cost 5.48434\n",
      "step 52310, change in cost 0.000592232\n",
      "step 52320, training accuracy 0.96748\n",
      "step 52320, cost 5.48375\n",
      "step 52320, change in cost 0.000591278\n",
      "step 52330, training accuracy 0.96748\n",
      "step 52330, cost 5.48317\n",
      "step 52330, change in cost 0.000586033\n",
      "step 52340, training accuracy 0.96748\n",
      "step 52340, cost 5.48258\n",
      "step 52340, change in cost 0.000586987\n",
      "step 52350, training accuracy 0.96748\n",
      "step 52350, cost 5.48199\n",
      "step 52350, change in cost 0.000584126\n",
      "step 52360, training accuracy 0.96748\n",
      "step 52360, cost 5.48141\n",
      "step 52360, change in cost 0.000583172\n",
      "step 52370, training accuracy 0.96748\n",
      "step 52370, cost 5.48083\n",
      "step 52370, change in cost 0.00057888\n",
      "step 52380, training accuracy 0.96748\n",
      "step 52380, cost 5.48025\n",
      "step 52380, change in cost 0.00057888\n",
      "step 52390, training accuracy 0.96748\n",
      "step 52390, cost 5.47968\n",
      "step 52390, change in cost 0.000577927\n",
      "step 52400, training accuracy 0.96748\n",
      "step 52400, cost 5.4791\n",
      "step 52400, change in cost 0.000573158\n",
      "step 52410, training accuracy 0.96748\n",
      "step 52410, cost 5.47853\n",
      "step 52410, change in cost 0.000572205\n",
      "step 52420, training accuracy 0.96748\n",
      "step 52420, cost 5.47796\n",
      "step 52420, change in cost 0.000571728\n",
      "step 52430, training accuracy 0.96748\n",
      "step 52430, cost 5.47739\n",
      "step 52430, change in cost 0.000568867\n",
      "step 52440, training accuracy 0.96748\n",
      "step 52440, cost 5.47682\n",
      "step 52440, change in cost 0.000566483\n",
      "step 52450, training accuracy 0.96748\n",
      "step 52450, cost 5.47626\n",
      "step 52450, change in cost 0.000567436\n",
      "step 52460, training accuracy 0.96748\n",
      "step 52460, cost 5.47569\n",
      "step 52460, change in cost 0.000563622\n",
      "step 52470, training accuracy 0.96748\n",
      "step 52470, cost 5.47513\n",
      "step 52470, change in cost 0.000561237\n",
      "step 52480, training accuracy 0.96748\n",
      "step 52480, cost 5.47457\n",
      "step 52480, change in cost 0.000560284\n",
      "step 52490, training accuracy 0.96748\n",
      "step 52490, cost 5.47401\n",
      "step 52490, change in cost 0.000557899\n",
      "step 52500, training accuracy 0.96748\n",
      "step 52500, cost 5.47346\n",
      "step 52500, change in cost 0.000556946\n",
      "step 52510, training accuracy 0.96748\n",
      "step 52510, cost 5.4729\n",
      "step 52510, change in cost 0.000555038\n",
      "step 52520, training accuracy 0.96748\n",
      "step 52520, cost 5.47235\n",
      "step 52520, change in cost 0.000553131\n",
      "step 52530, training accuracy 0.96748\n",
      "step 52530, cost 5.4718\n",
      "step 52530, change in cost 0.000551224\n",
      "step 52540, training accuracy 0.96748\n",
      "step 52540, cost 5.47125\n",
      "step 52540, change in cost 0.000549316\n",
      "step 52550, training accuracy 0.96748\n",
      "step 52550, cost 5.4707\n",
      "step 52550, change in cost 0.000546455\n",
      "step 52560, training accuracy 0.96748\n",
      "step 52560, cost 5.47015\n",
      "step 52560, change in cost 0.000547409\n",
      "step 52570, training accuracy 0.96748\n",
      "step 52570, cost 5.46961\n",
      "step 52570, change in cost 0.000544548\n",
      "step 52580, training accuracy 0.96748\n",
      "step 52580, cost 5.46907\n",
      "step 52580, change in cost 0.000541687\n",
      "step 52590, training accuracy 0.96748\n",
      "step 52590, cost 5.46853\n",
      "step 52590, change in cost 0.00054121\n",
      "step 52600, training accuracy 0.96748\n",
      "step 52600, cost 5.46799\n",
      "step 52600, change in cost 0.000539303\n",
      "step 52610, training accuracy 0.96748\n",
      "step 52610, cost 5.46745\n",
      "step 52610, change in cost 0.000538349\n",
      "step 52620, training accuracy 0.96748\n",
      "step 52620, cost 5.46691\n",
      "step 52620, change in cost 0.000535011\n",
      "step 52630, training accuracy 0.96748\n",
      "step 52630, cost 5.46638\n",
      "step 52630, change in cost 0.000534058\n",
      "step 52640, training accuracy 0.96748\n",
      "step 52640, cost 5.46585\n",
      "step 52640, change in cost 0.000533581\n",
      "step 52650, training accuracy 0.96748\n",
      "step 52650, cost 5.46531\n",
      "step 52650, change in cost 0.000531197\n",
      "step 52660, training accuracy 0.96748\n",
      "step 52660, cost 5.46478\n",
      "step 52660, change in cost 0.000529289\n",
      "step 52670, training accuracy 0.96748\n",
      "step 52670, cost 5.46426\n",
      "step 52670, change in cost 0.000528812\n",
      "step 52680, training accuracy 0.96748\n",
      "step 52680, cost 5.46373\n",
      "step 52680, change in cost 0.000525475\n",
      "step 52690, training accuracy 0.96748\n",
      "step 52690, cost 5.46321\n",
      "step 52690, change in cost 0.000524998\n",
      "step 52700, training accuracy 0.96748\n",
      "step 52700, cost 5.46268\n",
      "step 52700, change in cost 0.000523567\n",
      "step 52710, training accuracy 0.96748\n",
      "step 52710, cost 5.46216\n",
      "step 52710, change in cost 0.00052166\n",
      "step 52720, training accuracy 0.96748\n",
      "step 52720, cost 5.46164\n",
      "step 52720, change in cost 0.000520706\n",
      "step 52730, training accuracy 0.96748\n",
      "step 52730, cost 5.46112\n",
      "step 52730, change in cost 0.000517845\n",
      "step 52740, training accuracy 0.96748\n",
      "step 52740, cost 5.4606\n",
      "step 52740, change in cost 0.000516891\n",
      "step 52750, training accuracy 0.96748\n",
      "step 52750, cost 5.46009\n",
      "step 52750, change in cost 0.000514984\n",
      "step 52760, training accuracy 0.96748\n",
      "step 52760, cost 5.45958\n",
      "step 52760, change in cost 0.00051403\n",
      "step 52770, training accuracy 0.96748\n",
      "step 52770, cost 5.45906\n",
      "step 52770, change in cost 0.000513077\n",
      "step 52780, training accuracy 0.96748\n",
      "step 52780, cost 5.45855\n",
      "step 52780, change in cost 0.000509262\n",
      "step 52790, training accuracy 0.96748\n",
      "step 52790, cost 5.45804\n",
      "step 52790, change in cost 0.000509739\n",
      "step 52800, training accuracy 0.96748\n",
      "step 52800, cost 5.45754\n",
      "step 52800, change in cost 0.000507355\n",
      "step 52810, training accuracy 0.96748\n",
      "step 52810, cost 5.45703\n",
      "step 52810, change in cost 0.000507355\n",
      "step 52820, training accuracy 0.96748\n",
      "step 52820, cost 5.45652\n",
      "step 52820, change in cost 0.000504494\n",
      "step 52830, training accuracy 0.96748\n",
      "step 52830, cost 5.45602\n",
      "step 52830, change in cost 0.000503063\n",
      "step 52840, training accuracy 0.96748\n",
      "step 52840, cost 5.45552\n",
      "step 52840, change in cost 0.00050211\n",
      "step 52850, training accuracy 0.96748\n",
      "step 52850, cost 5.45502\n",
      "step 52850, change in cost 0.000500202\n",
      "step 52860, training accuracy 0.96748\n",
      "step 52860, cost 5.45452\n",
      "step 52860, change in cost 0.000499725\n",
      "step 52870, training accuracy 0.96748\n",
      "step 52870, cost 5.45402\n",
      "step 52870, change in cost 0.000496387\n",
      "step 52880, training accuracy 0.96748\n",
      "step 52880, cost 5.45353\n",
      "step 52880, change in cost 0.000495434\n",
      "step 52890, training accuracy 0.96748\n",
      "step 52890, cost 5.45303\n",
      "step 52890, change in cost 0.000495911\n",
      "step 52900, training accuracy 0.96748\n",
      "step 52900, cost 5.45254\n",
      "step 52900, change in cost 0.00049305\n",
      "step 52910, training accuracy 0.96748\n",
      "step 52910, cost 5.45205\n",
      "step 52910, change in cost 0.000491619\n",
      "step 52920, training accuracy 0.96748\n",
      "step 52920, cost 5.45156\n",
      "step 52920, change in cost 0.000490189\n",
      "step 52930, training accuracy 0.96748\n",
      "step 52930, cost 5.45107\n",
      "step 52930, change in cost 0.000490189\n",
      "step 52940, training accuracy 0.96748\n",
      "step 52940, cost 5.45058\n",
      "step 52940, change in cost 0.000486851\n",
      "step 52950, training accuracy 0.96748\n",
      "step 52950, cost 5.45009\n",
      "step 52950, change in cost 0.00048542\n",
      "step 52960, training accuracy 0.96748\n",
      "step 52960, cost 5.44961\n",
      "step 52960, change in cost 0.000485897\n",
      "step 52970, training accuracy 0.96748\n",
      "step 52970, cost 5.44912\n",
      "step 52970, change in cost 0.00048399\n",
      "step 52980, training accuracy 0.96748\n",
      "step 52980, cost 5.44864\n",
      "step 52980, change in cost 0.000481129\n",
      "step 52990, training accuracy 0.96748\n",
      "step 52990, cost 5.44816\n",
      "step 52990, change in cost 0.000481129\n",
      "step 53000, training accuracy 0.96748\n",
      "step 53000, cost 5.44768\n",
      "step 53000, change in cost 0.000479221\n",
      "step 53010, training accuracy 0.96748\n",
      "step 53010, cost 5.44721\n",
      "step 53010, change in cost 0.000477791\n",
      "step 53020, training accuracy 0.96748\n",
      "step 53020, cost 5.44673\n",
      "step 53020, change in cost 0.000478268\n",
      "step 53030, training accuracy 0.96748\n",
      "step 53030, cost 5.44625\n",
      "step 53030, change in cost 0.00047493\n",
      "step 53040, training accuracy 0.96748\n",
      "step 53040, cost 5.44578\n",
      "step 53040, change in cost 0.000473976\n",
      "step 53050, training accuracy 0.96748\n",
      "step 53050, cost 5.4453\n",
      "step 53050, change in cost 0.000473499\n",
      "step 53060, training accuracy 0.96748\n",
      "step 53060, cost 5.44483\n",
      "step 53060, change in cost 0.000470638\n",
      "step 53070, training accuracy 0.96748\n",
      "step 53070, cost 5.44436\n",
      "step 53070, change in cost 0.000469685\n",
      "step 53080, training accuracy 0.96748\n",
      "step 53080, cost 5.4439\n",
      "step 53080, change in cost 0.000468731\n",
      "step 53090, training accuracy 0.96748\n",
      "step 53090, cost 5.44343\n",
      "step 53090, change in cost 0.000468731\n",
      "step 53100, training accuracy 0.96748\n",
      "step 53100, cost 5.44296\n",
      "step 53100, change in cost 0.00046587\n",
      "step 53110, training accuracy 0.96748\n",
      "step 53110, cost 5.44249\n",
      "step 53110, change in cost 0.000466347\n",
      "step 53120, training accuracy 0.96748\n",
      "step 53120, cost 5.44203\n",
      "step 53120, change in cost 0.000463486\n",
      "step 53130, training accuracy 0.96748\n",
      "step 53130, cost 5.44157\n",
      "step 53130, change in cost 0.000463009\n",
      "step 53140, training accuracy 0.96748\n",
      "step 53140, cost 5.44111\n",
      "step 53140, change in cost 0.000460625\n",
      "step 53150, training accuracy 0.96748\n",
      "step 53150, cost 5.44065\n",
      "step 53150, change in cost 0.000460625\n",
      "step 53160, training accuracy 0.96748\n",
      "step 53160, cost 5.44019\n",
      "step 53160, change in cost 0.000459671\n",
      "step 53170, training accuracy 0.96748\n",
      "step 53170, cost 5.43973\n",
      "step 53170, change in cost 0.000456333\n",
      "step 53180, training accuracy 0.96748\n",
      "step 53180, cost 5.43927\n",
      "step 53180, change in cost 0.000457764\n",
      "step 53190, training accuracy 0.96748\n",
      "step 53190, cost 5.43882\n",
      "step 53190, change in cost 0.000454426\n",
      "step 53200, training accuracy 0.96748\n",
      "step 53200, cost 5.43836\n",
      "step 53200, change in cost 0.000454903\n",
      "step 53210, training accuracy 0.96748\n",
      "step 53210, cost 5.43791\n",
      "step 53210, change in cost 0.000452995\n",
      "step 53220, training accuracy 0.96748\n",
      "step 53220, cost 5.43746\n",
      "step 53220, change in cost 0.000451565\n",
      "step 53230, training accuracy 0.96748\n",
      "step 53230, cost 5.43701\n",
      "step 53230, change in cost 0.000451088\n",
      "step 53240, training accuracy 0.96748\n",
      "step 53240, cost 5.43656\n",
      "step 53240, change in cost 0.000450134\n",
      "step 53250, training accuracy 0.96748\n",
      "step 53250, cost 5.43611\n",
      "step 53250, change in cost 0.000448704\n",
      "step 53260, training accuracy 0.96748\n",
      "step 53260, cost 5.43566\n",
      "step 53260, change in cost 0.000445843\n",
      "step 53270, training accuracy 0.96748\n",
      "step 53270, cost 5.43522\n",
      "step 53270, change in cost 0.000447273\n",
      "step 53280, training accuracy 0.96748\n",
      "step 53280, cost 5.43477\n",
      "step 53280, change in cost 0.000443459\n",
      "step 53290, training accuracy 0.96748\n",
      "step 53290, cost 5.43433\n",
      "step 53290, change in cost 0.000444412\n",
      "step 53300, training accuracy 0.96748\n",
      "step 53300, cost 5.43389\n",
      "step 53300, change in cost 0.000442028\n",
      "step 53310, training accuracy 0.96748\n",
      "step 53310, cost 5.43345\n",
      "step 53310, change in cost 0.000440121\n",
      "step 53320, training accuracy 0.96748\n",
      "step 53320, cost 5.433\n",
      "step 53320, change in cost 0.000441551\n",
      "step 53330, training accuracy 0.96748\n",
      "step 53330, cost 5.43257\n",
      "step 53330, change in cost 0.00043869\n",
      "step 53340, training accuracy 0.96748\n",
      "step 53340, cost 5.43213\n",
      "step 53340, change in cost 0.00043726\n",
      "step 53350, training accuracy 0.96748\n",
      "step 53350, cost 5.43169\n",
      "step 53350, change in cost 0.00043726\n",
      "step 53360, training accuracy 0.96748\n",
      "step 53360, cost 5.43125\n",
      "step 53360, change in cost 0.000436306\n",
      "step 53370, training accuracy 0.96748\n",
      "step 53370, cost 5.43082\n",
      "step 53370, change in cost 0.000436306\n",
      "step 53380, training accuracy 0.96748\n",
      "step 53380, cost 5.43039\n",
      "step 53380, change in cost 0.000432014\n",
      "step 53390, training accuracy 0.96748\n",
      "step 53390, cost 5.42995\n",
      "step 53390, change in cost 0.000432968\n",
      "step 53400, training accuracy 0.96748\n",
      "step 53400, cost 5.42952\n",
      "step 53400, change in cost 0.000431061\n",
      "step 53410, training accuracy 0.96748\n",
      "step 53410, cost 5.42909\n",
      "step 53410, change in cost 0.00042963\n",
      "step 53420, training accuracy 0.96748\n",
      "step 53420, cost 5.42866\n",
      "step 53420, change in cost 0.000430584\n",
      "step 53430, training accuracy 0.96748\n",
      "step 53430, cost 5.42823\n",
      "step 53430, change in cost 0.0004282\n",
      "step 53440, training accuracy 0.96748\n",
      "step 53440, cost 5.42781\n",
      "step 53440, change in cost 0.000426769\n",
      "step 53450, training accuracy 0.96748\n",
      "step 53450, cost 5.42738\n",
      "step 53450, change in cost 0.000426769\n",
      "step 53460, training accuracy 0.96748\n",
      "step 53460, cost 5.42696\n",
      "step 53460, change in cost 0.000424385\n",
      "step 53470, training accuracy 0.96748\n",
      "step 53470, cost 5.42653\n",
      "step 53470, change in cost 0.000424862\n",
      "step 53480, training accuracy 0.96748\n",
      "step 53480, cost 5.42611\n",
      "step 53480, change in cost 0.000423431\n",
      "step 53490, training accuracy 0.96748\n",
      "step 53490, cost 5.42569\n",
      "step 53490, change in cost 0.000421047\n",
      "step 53500, training accuracy 0.96748\n",
      "step 53500, cost 5.42527\n",
      "step 53500, change in cost 0.000421524\n",
      "step 53510, training accuracy 0.96748\n",
      "step 53510, cost 5.42484\n",
      "step 53510, change in cost 0.00042057\n",
      "step 53520, training accuracy 0.96748\n",
      "step 53520, cost 5.42443\n",
      "step 53520, change in cost 0.000417709\n",
      "step 53530, training accuracy 0.96748\n",
      "step 53530, cost 5.42401\n",
      "step 53530, change in cost 0.000417709\n",
      "step 53540, training accuracy 0.96748\n",
      "step 53540, cost 5.42359\n",
      "step 53540, change in cost 0.000417709\n",
      "step 53550, training accuracy 0.96748\n",
      "step 53550, cost 5.42318\n",
      "step 53550, change in cost 0.000414848\n",
      "step 53560, training accuracy 0.96748\n",
      "step 53560, cost 5.42276\n",
      "step 53560, change in cost 0.000413895\n",
      "step 53570, training accuracy 0.96748\n",
      "step 53570, cost 5.42235\n",
      "step 53570, change in cost 0.000413895\n",
      "step 53580, training accuracy 0.96748\n",
      "step 53580, cost 5.42193\n",
      "step 53580, change in cost 0.000414371\n",
      "step 53590, training accuracy 0.96748\n",
      "step 53590, cost 5.42152\n",
      "step 53590, change in cost 0.00041151\n",
      "step 53600, training accuracy 0.96748\n",
      "step 53600, cost 5.42111\n",
      "step 53600, change in cost 0.000411034\n",
      "step 53610, training accuracy 0.96748\n",
      "step 53610, cost 5.4207\n",
      "step 53610, change in cost 0.00041008\n",
      "step 53620, training accuracy 0.96748\n",
      "step 53620, cost 5.42029\n",
      "step 53620, change in cost 0.000410557\n",
      "step 53630, training accuracy 0.96748\n",
      "step 53630, cost 5.41988\n",
      "step 53630, change in cost 0.000406742\n",
      "step 53640, training accuracy 0.96748\n",
      "step 53640, cost 5.41948\n",
      "step 53640, change in cost 0.000408649\n",
      "step 53650, training accuracy 0.96748\n",
      "step 53650, cost 5.41907\n",
      "step 53650, change in cost 0.000405788\n",
      "step 53660, training accuracy 0.96748\n",
      "step 53660, cost 5.41867\n",
      "step 53660, change in cost 0.000404358\n",
      "step 53670, training accuracy 0.96748\n",
      "step 53670, cost 5.41826\n",
      "step 53670, change in cost 0.000404358\n",
      "step 53680, training accuracy 0.96748\n",
      "step 53680, cost 5.41786\n",
      "step 53680, change in cost 0.000404835\n",
      "step 53690, training accuracy 0.96748\n",
      "step 53690, cost 5.41745\n",
      "step 53690, change in cost 0.000401974\n",
      "step 53700, training accuracy 0.96748\n",
      "step 53700, cost 5.41705\n",
      "step 53700, change in cost 0.000401974\n",
      "step 53710, training accuracy 0.96748\n",
      "step 53710, cost 5.41665\n",
      "step 53710, change in cost 0.000400066\n",
      "step 53720, training accuracy 0.96748\n",
      "step 53720, cost 5.41625\n",
      "step 53720, change in cost 0.000399113\n",
      "step 53730, training accuracy 0.96748\n",
      "step 53730, cost 5.41586\n",
      "step 53730, change in cost 0.000398159\n",
      "step 53740, training accuracy 0.96748\n",
      "step 53740, cost 5.41546\n",
      "step 53740, change in cost 0.000398636\n",
      "step 53750, training accuracy 0.96748\n",
      "step 53750, cost 5.41506\n",
      "step 53750, change in cost 0.000397682\n",
      "step 53760, training accuracy 0.96748\n",
      "step 53760, cost 5.41466\n",
      "step 53760, change in cost 0.000396252\n",
      "step 53770, training accuracy 0.96748\n",
      "step 53770, cost 5.41427\n",
      "step 53770, change in cost 0.000395298\n",
      "step 53780, training accuracy 0.96748\n",
      "step 53780, cost 5.41387\n",
      "step 53780, change in cost 0.000394821\n",
      "step 53790, training accuracy 0.96748\n",
      "step 53790, cost 5.41348\n",
      "step 53790, change in cost 0.00039196\n",
      "step 53800, training accuracy 0.96748\n",
      "step 53800, cost 5.41309\n",
      "step 53800, change in cost 0.000392437\n",
      "step 53810, training accuracy 0.96748\n",
      "step 53810, cost 5.4127\n",
      "step 53810, change in cost 0.000391483\n",
      "step 53820, training accuracy 0.96748\n",
      "step 53820, cost 5.4123\n",
      "step 53820, change in cost 0.000392437\n",
      "step 53830, training accuracy 0.96748\n",
      "step 53830, cost 5.41192\n",
      "step 53830, change in cost 0.000389099\n",
      "step 53840, training accuracy 0.96748\n",
      "step 53840, cost 5.41153\n",
      "step 53840, change in cost 0.000388622\n",
      "step 53850, training accuracy 0.96748\n",
      "step 53850, cost 5.41114\n",
      "step 53850, change in cost 0.000387192\n",
      "step 53860, training accuracy 0.96748\n",
      "step 53860, cost 5.41075\n",
      "step 53860, change in cost 0.000388145\n",
      "step 53870, training accuracy 0.96748\n",
      "step 53870, cost 5.41036\n",
      "step 53870, change in cost 0.000386715\n",
      "step 53880, training accuracy 0.96748\n",
      "step 53880, cost 5.40998\n",
      "step 53880, change in cost 0.000384808\n",
      "step 53890, training accuracy 0.96748\n",
      "step 53890, cost 5.40959\n",
      "step 53890, change in cost 0.000385284\n",
      "step 53900, training accuracy 0.96748\n",
      "step 53900, cost 5.40921\n",
      "step 53900, change in cost 0.000384331\n",
      "step 53910, training accuracy 0.96748\n",
      "step 53910, cost 5.40883\n",
      "step 53910, change in cost 0.000382423\n",
      "step 53920, training accuracy 0.96748\n",
      "step 53920, cost 5.40844\n",
      "step 53920, change in cost 0.000383377\n",
      "step 53930, training accuracy 0.96748\n",
      "step 53930, cost 5.40806\n",
      "step 53930, change in cost 0.00038147\n",
      "step 53940, training accuracy 0.96748\n",
      "step 53940, cost 5.40768\n",
      "step 53940, change in cost 0.000380516\n",
      "step 53950, training accuracy 0.96748\n",
      "step 53950, cost 5.4073\n",
      "step 53950, change in cost 0.000380516\n",
      "step 53960, training accuracy 0.96748\n",
      "step 53960, cost 5.40692\n",
      "step 53960, change in cost 0.000378132\n",
      "step 53970, training accuracy 0.96748\n",
      "step 53970, cost 5.40655\n",
      "step 53970, change in cost 0.000377655\n",
      "step 53980, training accuracy 0.96748\n",
      "step 53980, cost 5.40617\n",
      "step 53980, change in cost 0.000377178\n",
      "step 53990, training accuracy 0.96748\n",
      "step 53990, cost 5.40579\n",
      "step 53990, change in cost 0.000377178\n",
      "step 54000, training accuracy 0.96748\n",
      "step 54000, cost 5.40542\n",
      "step 54000, change in cost 0.000375748\n",
      "step 54010, training accuracy 0.96748\n",
      "step 54010, cost 5.40504\n",
      "step 54010, change in cost 0.000375271\n",
      "step 54020, training accuracy 0.96748\n",
      "step 54020, cost 5.40467\n",
      "step 54020, change in cost 0.000372887\n",
      "step 54030, training accuracy 0.96748\n",
      "step 54030, cost 5.40429\n",
      "step 54030, change in cost 0.000374794\n",
      "step 54040, training accuracy 0.96748\n",
      "step 54040, cost 5.40392\n",
      "step 54040, change in cost 0.000370979\n",
      "step 54050, training accuracy 0.96748\n",
      "step 54050, cost 5.40355\n",
      "step 54050, change in cost 0.000371933\n",
      "step 54060, training accuracy 0.96748\n",
      "step 54060, cost 5.40318\n",
      "step 54060, change in cost 0.000371456\n",
      "step 54070, training accuracy 0.96748\n",
      "step 54070, cost 5.40281\n",
      "step 54070, change in cost 0.000370502\n",
      "step 54080, training accuracy 0.96748\n",
      "step 54080, cost 5.40244\n",
      "step 54080, change in cost 0.000369072\n",
      "step 54090, training accuracy 0.96748\n",
      "step 54090, cost 5.40207\n",
      "step 54090, change in cost 0.000370026\n",
      "step 54100, training accuracy 0.96748\n",
      "step 54100, cost 5.4017\n",
      "step 54100, change in cost 0.000367165\n",
      "step 54110, training accuracy 0.96748\n",
      "step 54110, cost 5.40133\n",
      "step 54110, change in cost 0.000367165\n",
      "step 54120, training accuracy 0.96748\n",
      "step 54120, cost 5.40097\n",
      "step 54120, change in cost 0.000366211\n",
      "step 54130, training accuracy 0.96748\n",
      "step 54130, cost 5.4006\n",
      "step 54130, change in cost 0.000365257\n",
      "step 54140, training accuracy 0.96748\n",
      "step 54140, cost 5.40024\n",
      "step 54140, change in cost 0.00036478\n",
      "step 54150, training accuracy 0.96748\n",
      "step 54150, cost 5.39987\n",
      "step 54150, change in cost 0.00036478\n",
      "step 54160, training accuracy 0.96748\n",
      "step 54160, cost 5.39951\n",
      "step 54160, change in cost 0.000362396\n",
      "step 54170, training accuracy 0.96748\n",
      "step 54170, cost 5.39915\n",
      "step 54170, change in cost 0.000365257\n",
      "step 54180, training accuracy 0.96748\n",
      "step 54180, cost 5.39879\n",
      "step 54180, change in cost 0.000360489\n",
      "step 54190, training accuracy 0.96748\n",
      "step 54190, cost 5.39842\n",
      "step 54190, change in cost 0.000360966\n",
      "step 54200, training accuracy 0.96748\n",
      "step 54200, cost 5.39806\n",
      "step 54200, change in cost 0.000360966\n",
      "step 54210, training accuracy 0.96748\n",
      "step 54210, cost 5.3977\n",
      "step 54210, change in cost 0.000359058\n",
      "step 54220, training accuracy 0.96748\n",
      "step 54220, cost 5.39734\n",
      "step 54220, change in cost 0.000360489\n",
      "step 54230, training accuracy 0.96748\n",
      "step 54230, cost 5.39699\n",
      "step 54230, change in cost 0.000357151\n",
      "step 54240, training accuracy 0.96748\n",
      "step 54240, cost 5.39663\n",
      "step 54240, change in cost 0.000358582\n",
      "step 54250, training accuracy 0.96748\n",
      "step 54250, cost 5.39627\n",
      "step 54250, change in cost 0.000355244\n",
      "step 54260, training accuracy 0.96748\n",
      "step 54260, cost 5.39592\n",
      "step 54260, change in cost 0.000356197\n",
      "step 54270, training accuracy 0.96748\n",
      "step 54270, cost 5.39556\n",
      "step 54270, change in cost 0.000355721\n",
      "step 54280, training accuracy 0.96748\n",
      "step 54280, cost 5.39521\n",
      "step 54280, change in cost 0.000355244\n",
      "step 54290, training accuracy 0.96748\n",
      "step 54290, cost 5.39485\n",
      "step 54290, change in cost 0.000353336\n",
      "step 54300, training accuracy 0.96748\n",
      "step 54300, cost 5.3945\n",
      "step 54300, change in cost 0.000352859\n",
      "step 54310, training accuracy 0.96748\n",
      "step 54310, cost 5.39415\n",
      "step 54310, change in cost 0.000353813\n",
      "step 54320, training accuracy 0.96748\n",
      "step 54320, cost 5.3938\n",
      "step 54320, change in cost 0.000350952\n",
      "step 54330, training accuracy 0.96748\n",
      "step 54330, cost 5.39344\n",
      "step 54330, change in cost 0.000351906\n",
      "step 54340, training accuracy 0.96748\n",
      "step 54340, cost 5.39309\n",
      "step 54340, change in cost 0.000349522\n",
      "step 54350, training accuracy 0.96748\n",
      "step 54350, cost 5.39274\n",
      "step 54350, change in cost 0.000349522\n",
      "step 54360, training accuracy 0.96748\n",
      "step 54360, cost 5.3924\n",
      "step 54360, change in cost 0.000348091\n",
      "step 54370, training accuracy 0.96748\n",
      "step 54370, cost 5.39205\n",
      "step 54370, change in cost 0.000349522\n",
      "step 54380, training accuracy 0.96748\n",
      "step 54380, cost 5.3917\n",
      "step 54380, change in cost 0.000347614\n",
      "step 54390, training accuracy 0.96748\n",
      "step 54390, cost 5.39135\n",
      "step 54390, change in cost 0.000347137\n",
      "step 54400, training accuracy 0.96748\n",
      "step 54400, cost 5.39101\n",
      "step 54400, change in cost 0.000345707\n",
      "step 54410, training accuracy 0.96748\n",
      "step 54410, cost 5.39066\n",
      "step 54410, change in cost 0.000345707\n",
      "step 54420, training accuracy 0.96748\n",
      "step 54420, cost 5.39032\n",
      "step 54420, change in cost 0.000344276\n",
      "step 54430, training accuracy 0.96748\n",
      "step 54430, cost 5.38997\n",
      "step 54430, change in cost 0.0003438\n",
      "step 54440, training accuracy 0.96748\n",
      "step 54440, cost 5.38963\n",
      "step 54440, change in cost 0.0003438\n",
      "step 54450, training accuracy 0.96748\n",
      "step 54450, cost 5.38929\n",
      "step 54450, change in cost 0.000342369\n",
      "step 54460, training accuracy 0.96748\n",
      "step 54460, cost 5.38894\n",
      "step 54460, change in cost 0.000343323\n",
      "step 54470, training accuracy 0.96748\n",
      "step 54470, cost 5.3886\n",
      "step 54470, change in cost 0.000340462\n",
      "step 54480, training accuracy 0.96748\n",
      "step 54480, cost 5.38826\n",
      "step 54480, change in cost 0.000341892\n",
      "step 54490, training accuracy 0.96748\n",
      "step 54490, cost 5.38792\n",
      "step 54490, change in cost 0.000339985\n",
      "step 54500, training accuracy 0.96748\n",
      "step 54500, cost 5.38758\n",
      "step 54500, change in cost 0.000339508\n",
      "step 54510, training accuracy 0.96748\n",
      "step 54510, cost 5.38724\n",
      "step 54510, change in cost 0.000338554\n",
      "step 54520, training accuracy 0.96748\n",
      "step 54520, cost 5.3869\n",
      "step 54520, change in cost 0.000338554\n",
      "step 54530, training accuracy 0.96748\n",
      "step 54530, cost 5.38657\n",
      "step 54530, change in cost 0.000338554\n",
      "step 54540, training accuracy 0.96748\n",
      "step 54540, cost 5.38623\n",
      "step 54540, change in cost 0.000337124\n",
      "step 54550, training accuracy 0.96748\n",
      "step 54550, cost 5.38589\n",
      "step 54550, change in cost 0.00033617\n",
      "step 54560, training accuracy 0.96748\n",
      "step 54560, cost 5.38556\n",
      "step 54560, change in cost 0.000335693\n",
      "step 54570, training accuracy 0.96748\n",
      "step 54570, cost 5.38522\n",
      "step 54570, change in cost 0.000337601\n",
      "step 54580, training accuracy 0.96748\n",
      "step 54580, cost 5.38488\n",
      "step 54580, change in cost 0.000333786\n",
      "step 54590, training accuracy 0.96748\n",
      "step 54590, cost 5.38455\n",
      "step 54590, change in cost 0.000334263\n",
      "step 54600, training accuracy 0.96748\n",
      "step 54600, cost 5.38422\n",
      "step 54600, change in cost 0.000333309\n",
      "step 54610, training accuracy 0.96748\n",
      "step 54610, cost 5.38388\n",
      "step 54610, change in cost 0.000333786\n",
      "step 54620, training accuracy 0.96748\n",
      "step 54620, cost 5.38355\n",
      "step 54620, change in cost 0.000332832\n",
      "step 54630, training accuracy 0.96748\n",
      "step 54630, cost 5.38322\n",
      "step 54630, change in cost 0.000330925\n",
      "step 54640, training accuracy 0.96748\n",
      "step 54640, cost 5.38289\n",
      "step 54640, change in cost 0.000330925\n",
      "step 54650, training accuracy 0.96748\n",
      "step 54650, cost 5.38256\n",
      "step 54650, change in cost 0.000329971\n",
      "step 54660, training accuracy 0.96748\n",
      "step 54660, cost 5.38223\n",
      "step 54660, change in cost 0.000329494\n",
      "step 54670, training accuracy 0.96748\n",
      "step 54670, cost 5.3819\n",
      "step 54670, change in cost 0.000329494\n",
      "step 54680, training accuracy 0.96748\n",
      "step 54680, cost 5.38157\n",
      "step 54680, change in cost 0.000328064\n",
      "step 54690, training accuracy 0.96748\n",
      "step 54690, cost 5.38124\n",
      "step 54690, change in cost 0.000327587\n",
      "step 54700, training accuracy 0.96748\n",
      "step 54700, cost 5.38092\n",
      "step 54700, change in cost 0.000328541\n",
      "step 54710, training accuracy 0.96748\n",
      "step 54710, cost 5.38059\n",
      "step 54710, change in cost 0.00032711\n",
      "step 54720, training accuracy 0.96748\n",
      "step 54720, cost 5.38026\n",
      "step 54720, change in cost 0.000326157\n",
      "step 54730, training accuracy 0.96748\n",
      "step 54730, cost 5.37994\n",
      "step 54730, change in cost 0.000325203\n",
      "step 54740, training accuracy 0.96748\n",
      "step 54740, cost 5.37961\n",
      "step 54740, change in cost 0.000325203\n",
      "step 54750, training accuracy 0.96748\n",
      "step 54750, cost 5.37929\n",
      "step 54750, change in cost 0.000324726\n",
      "step 54760, training accuracy 0.96748\n",
      "step 54760, cost 5.37896\n",
      "step 54760, change in cost 0.000324726\n",
      "step 54770, training accuracy 0.96748\n",
      "step 54770, cost 5.37864\n",
      "step 54770, change in cost 0.000323296\n",
      "step 54780, training accuracy 0.96748\n",
      "step 54780, cost 5.37832\n",
      "step 54780, change in cost 0.000322819\n",
      "step 54790, training accuracy 0.96748\n",
      "step 54790, cost 5.37799\n",
      "step 54790, change in cost 0.000322819\n",
      "step 54800, training accuracy 0.96748\n",
      "step 54800, cost 5.37767\n",
      "step 54800, change in cost 0.000322342\n",
      "step 54810, training accuracy 0.96748\n",
      "step 54810, cost 5.37735\n",
      "step 54810, change in cost 0.000320435\n",
      "step 54820, training accuracy 0.96748\n",
      "step 54820, cost 5.37703\n",
      "step 54820, change in cost 0.000320911\n",
      "step 54830, training accuracy 0.96748\n",
      "step 54830, cost 5.37671\n",
      "step 54830, change in cost 0.000319958\n",
      "step 54840, training accuracy 0.96748\n",
      "step 54840, cost 5.37639\n",
      "step 54840, change in cost 0.000320435\n",
      "step 54850, training accuracy 0.96748\n",
      "step 54850, cost 5.37607\n",
      "step 54850, change in cost 0.000318527\n",
      "step 54860, training accuracy 0.96748\n",
      "step 54860, cost 5.37575\n",
      "step 54860, change in cost 0.000318527\n",
      "step 54870, training accuracy 0.96748\n",
      "step 54870, cost 5.37543\n",
      "step 54870, change in cost 0.000317574\n",
      "step 54880, training accuracy 0.96748\n",
      "step 54880, cost 5.37512\n",
      "step 54880, change in cost 0.000317574\n",
      "step 54890, training accuracy 0.96748\n",
      "step 54890, cost 5.3748\n",
      "step 54890, change in cost 0.000317574\n",
      "step 54900, training accuracy 0.96748\n",
      "step 54900, cost 5.37449\n",
      "step 54900, change in cost 0.000314713\n",
      "step 54910, training accuracy 0.96748\n",
      "step 54910, cost 5.37417\n",
      "step 54910, change in cost 0.00031662\n",
      "step 54920, training accuracy 0.96748\n",
      "step 54920, cost 5.37385\n",
      "step 54920, change in cost 0.000314713\n",
      "step 54930, training accuracy 0.96748\n",
      "step 54930, cost 5.37354\n",
      "step 54930, change in cost 0.000315666\n",
      "step 54940, training accuracy 0.96748\n",
      "step 54940, cost 5.37322\n",
      "step 54940, change in cost 0.000314713\n",
      "step 54950, training accuracy 0.96748\n",
      "step 54950, cost 5.37291\n",
      "step 54950, change in cost 0.000313759\n",
      "step 54960, training accuracy 0.96748\n",
      "step 54960, cost 5.3726\n",
      "step 54960, change in cost 0.000312328\n",
      "step 54970, training accuracy 0.96748\n",
      "step 54970, cost 5.37228\n",
      "step 54970, change in cost 0.000314236\n",
      "step 54980, training accuracy 0.96748\n",
      "step 54980, cost 5.37197\n",
      "step 54980, change in cost 0.000311852\n",
      "step 54990, training accuracy 0.96748\n",
      "step 54990, cost 5.37166\n",
      "step 54990, change in cost 0.000311375\n",
      "step 55000, training accuracy 0.96748\n",
      "step 55000, cost 5.37135\n",
      "step 55000, change in cost 0.000311852\n",
      "step 55010, training accuracy 0.96748\n",
      "step 55010, cost 5.37104\n",
      "step 55010, change in cost 0.000310421\n",
      "step 55020, training accuracy 0.96748\n",
      "step 55020, cost 5.37073\n",
      "step 55020, change in cost 0.00030899\n",
      "step 55030, training accuracy 0.96748\n",
      "step 55030, cost 5.37042\n",
      "step 55030, change in cost 0.000309944\n",
      "step 55040, training accuracy 0.96748\n",
      "step 55040, cost 5.37011\n",
      "step 55040, change in cost 0.00030899\n",
      "step 55050, training accuracy 0.96748\n",
      "step 55050, cost 5.3698\n",
      "step 55050, change in cost 0.00030899\n",
      "step 55060, training accuracy 0.96748\n",
      "step 55060, cost 5.36949\n",
      "step 55060, change in cost 0.00030756\n",
      "step 55070, training accuracy 0.96748\n",
      "step 55070, cost 5.36919\n",
      "step 55070, change in cost 0.00030756\n",
      "step 55080, training accuracy 0.96748\n",
      "step 55080, cost 5.36888\n",
      "step 55080, change in cost 0.000306606\n",
      "step 55090, training accuracy 0.96748\n",
      "step 55090, cost 5.36857\n",
      "step 55090, change in cost 0.000305653\n",
      "step 55100, training accuracy 0.96748\n",
      "step 55100, cost 5.36827\n",
      "step 55100, change in cost 0.000306129\n",
      "step 55110, training accuracy 0.96748\n",
      "step 55110, cost 5.36796\n",
      "step 55110, change in cost 0.000305653\n",
      "step 55120, training accuracy 0.96748\n",
      "step 55120, cost 5.36766\n",
      "step 55120, change in cost 0.000304699\n",
      "step 55130, training accuracy 0.96748\n",
      "step 55130, cost 5.36735\n",
      "step 55130, change in cost 0.000305653\n",
      "step 55140, training accuracy 0.96748\n",
      "step 55140, cost 5.36705\n",
      "step 55140, change in cost 0.000304222\n",
      "step 55150, training accuracy 0.96748\n",
      "step 55150, cost 5.36674\n",
      "step 55150, change in cost 0.000302792\n",
      "step 55160, training accuracy 0.96748\n",
      "step 55160, cost 5.36644\n",
      "step 55160, change in cost 0.000304699\n",
      "step 55170, training accuracy 0.96748\n",
      "step 55170, cost 5.36614\n",
      "step 55170, change in cost 0.000301361\n",
      "step 55180, training accuracy 0.96748\n",
      "step 55180, cost 5.36584\n",
      "step 55180, change in cost 0.000301838\n",
      "step 55190, training accuracy 0.96748\n",
      "step 55190, cost 5.36553\n",
      "step 55190, change in cost 0.000301361\n",
      "step 55200, training accuracy 0.96748\n",
      "step 55200, cost 5.36523\n",
      "step 55200, change in cost 0.000302315\n",
      "step 55210, training accuracy 0.96748\n",
      "step 55210, cost 5.36493\n",
      "step 55210, change in cost 0.000299931\n",
      "step 55220, training accuracy 0.96748\n",
      "step 55220, cost 5.36463\n",
      "step 55220, change in cost 0.000300884\n",
      "step 55230, training accuracy 0.96748\n",
      "step 55230, cost 5.36433\n",
      "step 55230, change in cost 0.000299931\n",
      "step 55240, training accuracy 0.96748\n",
      "step 55240, cost 5.36403\n",
      "step 55240, change in cost 0.000298023\n",
      "step 55250, training accuracy 0.96748\n",
      "step 55250, cost 5.36373\n",
      "step 55250, change in cost 0.000298977\n",
      "step 55260, training accuracy 0.96748\n",
      "step 55260, cost 5.36344\n",
      "step 55260, change in cost 0.000297546\n",
      "step 55270, training accuracy 0.96748\n",
      "step 55270, cost 5.36314\n",
      "step 55270, change in cost 0.000299931\n",
      "step 55280, training accuracy 0.96748\n",
      "step 55280, cost 5.36284\n",
      "step 55280, change in cost 0.000296593\n",
      "step 55290, training accuracy 0.96748\n",
      "step 55290, cost 5.36254\n",
      "step 55290, change in cost 0.00029707\n",
      "step 55300, training accuracy 0.96748\n",
      "step 55300, cost 5.36225\n",
      "step 55300, change in cost 0.000296116\n",
      "step 55310, training accuracy 0.96748\n",
      "step 55310, cost 5.36195\n",
      "step 55310, change in cost 0.000296593\n",
      "step 55320, training accuracy 0.96748\n",
      "step 55320, cost 5.36166\n",
      "step 55320, change in cost 0.000294685\n",
      "step 55330, training accuracy 0.96748\n",
      "step 55330, cost 5.36136\n",
      "step 55330, change in cost 0.000295162\n",
      "step 55340, training accuracy 0.96748\n",
      "step 55340, cost 5.36107\n",
      "step 55340, change in cost 0.000295639\n",
      "step 55350, training accuracy 0.96748\n",
      "step 55350, cost 5.36077\n",
      "step 55350, change in cost 0.000293255\n",
      "step 55360, training accuracy 0.96748\n",
      "step 55360, cost 5.36048\n",
      "step 55360, change in cost 0.000292778\n",
      "step 55370, training accuracy 0.96748\n",
      "step 55370, cost 5.36019\n",
      "step 55370, change in cost 0.000294209\n",
      "step 55380, training accuracy 0.96748\n",
      "step 55380, cost 5.35989\n",
      "step 55380, change in cost 0.000293255\n",
      "step 55390, training accuracy 0.96748\n",
      "step 55390, cost 5.3596\n",
      "step 55390, change in cost 0.000291824\n",
      "step 55400, training accuracy 0.96748\n",
      "step 55400, cost 5.35931\n",
      "step 55400, change in cost 0.000292301\n",
      "step 55410, training accuracy 0.96748\n",
      "step 55410, cost 5.35902\n",
      "step 55410, change in cost 0.000291348\n",
      "step 55420, training accuracy 0.96748\n",
      "step 55420, cost 5.35873\n",
      "step 55420, change in cost 0.000290871\n",
      "step 55430, training accuracy 0.96748\n",
      "step 55430, cost 5.35843\n",
      "step 55430, change in cost 0.000291348\n",
      "step 55440, training accuracy 0.96748\n",
      "step 55440, cost 5.35814\n",
      "step 55440, change in cost 0.000290871\n",
      "step 55450, training accuracy 0.96748\n",
      "step 55450, cost 5.35785\n",
      "step 55450, change in cost 0.000289917\n",
      "step 55460, training accuracy 0.96748\n",
      "step 55460, cost 5.35756\n",
      "step 55460, change in cost 0.00028944\n",
      "step 55470, training accuracy 0.96748\n",
      "step 55470, cost 5.35728\n",
      "step 55470, change in cost 0.00028801\n",
      "step 55480, training accuracy 0.96748\n",
      "step 55480, cost 5.35699\n",
      "step 55480, change in cost 0.00028801\n",
      "step 55490, training accuracy 0.96748\n",
      "step 55490, cost 5.3567\n",
      "step 55490, change in cost 0.000288486\n",
      "step 55500, training accuracy 0.96748\n",
      "step 55500, cost 5.35641\n",
      "step 55500, change in cost 0.000287533\n",
      "step 55510, training accuracy 0.96748\n",
      "step 55510, cost 5.35612\n",
      "step 55510, change in cost 0.000288486\n",
      "step 55520, training accuracy 0.96748\n",
      "step 55520, cost 5.35584\n",
      "step 55520, change in cost 0.000286579\n",
      "step 55530, training accuracy 0.96748\n",
      "step 55530, cost 5.35555\n",
      "step 55530, change in cost 0.000286579\n",
      "step 55540, training accuracy 0.96748\n",
      "step 55540, cost 5.35526\n",
      "step 55540, change in cost 0.000286102\n",
      "step 55550, training accuracy 0.96748\n",
      "step 55550, cost 5.35498\n",
      "step 55550, change in cost 0.000285625\n",
      "step 55560, training accuracy 0.96748\n",
      "step 55560, cost 5.35469\n",
      "step 55560, change in cost 0.000285149\n",
      "step 55570, training accuracy 0.96748\n",
      "step 55570, cost 5.35441\n",
      "step 55570, change in cost 0.000284195\n",
      "step 55580, training accuracy 0.96748\n",
      "step 55580, cost 5.35412\n",
      "step 55580, change in cost 0.000285149\n",
      "step 55590, training accuracy 0.96748\n",
      "step 55590, cost 5.35384\n",
      "step 55590, change in cost 0.000283718\n",
      "step 55600, training accuracy 0.96748\n",
      "step 55600, cost 5.35356\n",
      "step 55600, change in cost 0.000282764\n",
      "step 55610, training accuracy 0.96748\n",
      "step 55610, cost 5.35327\n",
      "step 55610, change in cost 0.000283718\n",
      "step 55620, training accuracy 0.96748\n",
      "step 55620, cost 5.35299\n",
      "step 55620, change in cost 0.000283718\n",
      "step 55630, training accuracy 0.96748\n",
      "step 55630, cost 5.35271\n",
      "step 55630, change in cost 0.000282288\n",
      "step 55640, training accuracy 0.96748\n",
      "step 55640, cost 5.35243\n",
      "step 55640, change in cost 0.000279903\n",
      "step 55650, training accuracy 0.96748\n",
      "step 55650, cost 5.35215\n",
      "step 55650, change in cost 0.000281334\n",
      "step 55660, training accuracy 0.96748\n",
      "step 55660, cost 5.35186\n",
      "step 55660, change in cost 0.000281811\n",
      "step 55670, training accuracy 0.96748\n",
      "step 55670, cost 5.35158\n",
      "step 55670, change in cost 0.00028038\n",
      "step 55680, training accuracy 0.96748\n",
      "step 55680, cost 5.3513\n",
      "step 55680, change in cost 0.00028038\n",
      "step 55690, training accuracy 0.96748\n",
      "step 55690, cost 5.35102\n",
      "step 55690, change in cost 0.000279903\n",
      "step 55700, training accuracy 0.96748\n",
      "step 55700, cost 5.35074\n",
      "step 55700, change in cost 0.000279903\n",
      "step 55710, training accuracy 0.96748\n",
      "step 55710, cost 5.35047\n",
      "step 55710, change in cost 0.000278473\n",
      "step 55720, training accuracy 0.96748\n",
      "step 55720, cost 5.35019\n",
      "step 55720, change in cost 0.000278473\n",
      "step 55730, training accuracy 0.96748\n",
      "step 55730, cost 5.34991\n",
      "step 55730, change in cost 0.000279427\n",
      "step 55740, training accuracy 0.96748\n",
      "step 55740, cost 5.34963\n",
      "step 55740, change in cost 0.000278473\n",
      "step 55750, training accuracy 0.96748\n",
      "step 55750, cost 5.34935\n",
      "step 55750, change in cost 0.000276566\n",
      "step 55760, training accuracy 0.96748\n",
      "step 55760, cost 5.34908\n",
      "step 55760, change in cost 0.000276566\n",
      "step 55770, training accuracy 0.96748\n",
      "step 55770, cost 5.3488\n",
      "step 55770, change in cost 0.000277519\n",
      "step 55780, training accuracy 0.96748\n",
      "step 55780, cost 5.34852\n",
      "step 55780, change in cost 0.000276089\n",
      "step 55790, training accuracy 0.96748\n",
      "step 55790, cost 5.34825\n",
      "step 55790, change in cost 0.000276089\n",
      "step 55800, training accuracy 0.96748\n",
      "step 55800, cost 5.34797\n",
      "step 55800, change in cost 0.000275612\n",
      "step 55810, training accuracy 0.96748\n",
      "step 55810, cost 5.3477\n",
      "step 55810, change in cost 0.000275612\n",
      "step 55820, training accuracy 0.96748\n",
      "step 55820, cost 5.34742\n",
      "step 55820, change in cost 0.000276089\n",
      "step 55830, training accuracy 0.96748\n",
      "step 55830, cost 5.34715\n",
      "step 55830, change in cost 0.000274181\n",
      "step 55840, training accuracy 0.96748\n",
      "step 55840, cost 5.34687\n",
      "step 55840, change in cost 0.000274658\n",
      "step 55850, training accuracy 0.96748\n",
      "step 55850, cost 5.3466\n",
      "step 55850, change in cost 0.000272751\n",
      "step 55860, training accuracy 0.96748\n",
      "step 55860, cost 5.34632\n",
      "step 55860, change in cost 0.000273705\n",
      "step 55870, training accuracy 0.96748\n",
      "step 55870, cost 5.34605\n",
      "step 55870, change in cost 0.000272274\n",
      "step 55880, training accuracy 0.96748\n",
      "step 55880, cost 5.34578\n",
      "step 55880, change in cost 0.000272751\n",
      "step 55890, training accuracy 0.96748\n",
      "step 55890, cost 5.34551\n",
      "step 55890, change in cost 0.000273228\n",
      "step 55900, training accuracy 0.96748\n",
      "step 55900, cost 5.34523\n",
      "step 55900, change in cost 0.000271797\n",
      "step 55910, training accuracy 0.96748\n",
      "step 55910, cost 5.34496\n",
      "step 55910, change in cost 0.000272751\n",
      "step 55920, training accuracy 0.96748\n",
      "step 55920, cost 5.34469\n",
      "step 55920, change in cost 0.000270844\n",
      "step 55930, training accuracy 0.96748\n",
      "step 55930, cost 5.34442\n",
      "step 55930, change in cost 0.00026989\n",
      "step 55940, training accuracy 0.96748\n",
      "step 55940, cost 5.34415\n",
      "step 55940, change in cost 0.00027132\n",
      "step 55950, training accuracy 0.96748\n",
      "step 55950, cost 5.34388\n",
      "step 55950, change in cost 0.000270367\n",
      "step 55960, training accuracy 0.96748\n",
      "step 55960, cost 5.34361\n",
      "step 55960, change in cost 0.000270844\n",
      "step 55970, training accuracy 0.96748\n",
      "step 55970, cost 5.34334\n",
      "step 55970, change in cost 0.000269413\n",
      "step 55980, training accuracy 0.96748\n",
      "step 55980, cost 5.34307\n",
      "step 55980, change in cost 0.000268459\n",
      "step 55990, training accuracy 0.96748\n",
      "step 55990, cost 5.3428\n",
      "step 55990, change in cost 0.00026989\n",
      "step 56000, training accuracy 0.96748\n",
      "step 56000, cost 5.34253\n",
      "step 56000, change in cost 0.000267982\n",
      "step 56010, training accuracy 0.96748\n",
      "step 56010, cost 5.34226\n",
      "step 56010, change in cost 0.000269413\n",
      "step 56020, training accuracy 0.96748\n",
      "step 56020, cost 5.342\n",
      "step 56020, change in cost 0.000267506\n",
      "step 56030, training accuracy 0.96748\n",
      "step 56030, cost 5.34173\n",
      "step 56030, change in cost 0.000267506\n",
      "step 56040, training accuracy 0.96748\n",
      "step 56040, cost 5.34146\n",
      "step 56040, change in cost 0.000267506\n",
      "step 56050, training accuracy 0.96748\n",
      "step 56050, cost 5.34119\n",
      "step 56050, change in cost 0.000266075\n",
      "step 56060, training accuracy 0.96748\n",
      "step 56060, cost 5.34093\n",
      "step 56060, change in cost 0.000267029\n",
      "step 56070, training accuracy 0.96748\n",
      "step 56070, cost 5.34066\n",
      "step 56070, change in cost 0.000266075\n",
      "step 56080, training accuracy 0.96748\n",
      "step 56080, cost 5.34039\n",
      "step 56080, change in cost 0.000266075\n",
      "step 56090, training accuracy 0.96748\n",
      "step 56090, cost 5.34013\n",
      "step 56090, change in cost 0.000266552\n",
      "step 56100, training accuracy 0.96748\n",
      "step 56100, cost 5.33986\n",
      "step 56100, change in cost 0.000265598\n",
      "step 56110, training accuracy 0.96748\n",
      "step 56110, cost 5.3396\n",
      "step 56110, change in cost 0.000263691\n",
      "step 56120, training accuracy 0.96748\n",
      "step 56120, cost 5.33933\n",
      "step 56120, change in cost 0.000265121\n",
      "step 56130, training accuracy 0.96748\n",
      "step 56130, cost 5.33907\n",
      "step 56130, change in cost 0.000263691\n",
      "step 56140, training accuracy 0.96748\n",
      "step 56140, cost 5.33881\n",
      "step 56140, change in cost 0.000262737\n",
      "step 56150, training accuracy 0.96748\n",
      "step 56150, cost 5.33854\n",
      "step 56150, change in cost 0.000263691\n",
      "step 56160, training accuracy 0.96748\n",
      "step 56160, cost 5.33828\n",
      "step 56160, change in cost 0.000263691\n",
      "step 56170, training accuracy 0.96748\n",
      "step 56170, cost 5.33802\n",
      "step 56170, change in cost 0.00026226\n",
      "step 56180, training accuracy 0.96748\n",
      "step 56180, cost 5.33775\n",
      "step 56180, change in cost 0.000263214\n",
      "step 56190, training accuracy 0.96748\n",
      "step 56190, cost 5.33749\n",
      "step 56190, change in cost 0.000261307\n",
      "step 56200, training accuracy 0.96748\n",
      "step 56200, cost 5.33723\n",
      "step 56200, change in cost 0.00026226\n",
      "step 56210, training accuracy 0.96748\n",
      "step 56210, cost 5.33697\n",
      "step 56210, change in cost 0.000261307\n",
      "step 56220, training accuracy 0.96748\n",
      "step 56220, cost 5.33671\n",
      "step 56220, change in cost 0.00026083\n",
      "step 56230, training accuracy 0.96748\n",
      "step 56230, cost 5.33645\n",
      "step 56230, change in cost 0.00026226\n",
      "step 56240, training accuracy 0.96748\n",
      "step 56240, cost 5.33619\n",
      "step 56240, change in cost 0.000260353\n",
      "step 56250, training accuracy 0.96748\n",
      "step 56250, cost 5.33593\n",
      "step 56250, change in cost 0.000260353\n",
      "step 56260, training accuracy 0.96748\n",
      "step 56260, cost 5.33567\n",
      "step 56260, change in cost 0.000260353\n",
      "step 56270, training accuracy 0.96748\n",
      "step 56270, cost 5.33541\n",
      "step 56270, change in cost 0.000259399\n",
      "step 56280, training accuracy 0.96748\n",
      "step 56280, cost 5.33515\n",
      "step 56280, change in cost 0.000258446\n",
      "step 56290, training accuracy 0.96748\n",
      "step 56290, cost 5.33489\n",
      "step 56290, change in cost 0.000259399\n",
      "step 56300, training accuracy 0.96748\n",
      "step 56300, cost 5.33463\n",
      "step 56300, change in cost 0.000258446\n",
      "step 56310, training accuracy 0.96748\n",
      "step 56310, cost 5.33437\n",
      "step 56310, change in cost 0.000258923\n",
      "step 56320, training accuracy 0.96748\n",
      "step 56320, cost 5.33411\n",
      "step 56320, change in cost 0.000257492\n",
      "step 56330, training accuracy 0.96748\n",
      "step 56330, cost 5.33386\n",
      "step 56330, change in cost 0.000257969\n",
      "step 56340, training accuracy 0.96748\n",
      "step 56340, cost 5.3336\n",
      "step 56340, change in cost 0.000257492\n",
      "step 56350, training accuracy 0.96748\n",
      "step 56350, cost 5.33334\n",
      "step 56350, change in cost 0.000257492\n",
      "step 56360, training accuracy 0.96748\n",
      "step 56360, cost 5.33309\n",
      "step 56360, change in cost 0.000255585\n",
      "step 56370, training accuracy 0.96748\n",
      "step 56370, cost 5.33283\n",
      "step 56370, change in cost 0.000257015\n",
      "step 56380, training accuracy 0.96748\n",
      "step 56380, cost 5.33257\n",
      "step 56380, change in cost 0.000256062\n",
      "step 56390, training accuracy 0.96748\n",
      "step 56390, cost 5.33232\n",
      "step 56390, change in cost 0.000255585\n",
      "step 56400, training accuracy 0.96748\n",
      "step 56400, cost 5.33206\n",
      "step 56400, change in cost 0.000253677\n",
      "step 56410, training accuracy 0.96748\n",
      "step 56410, cost 5.33181\n",
      "step 56410, change in cost 0.000256062\n",
      "step 56420, training accuracy 0.96748\n",
      "step 56420, cost 5.33155\n",
      "step 56420, change in cost 0.000254154\n",
      "step 56430, training accuracy 0.96748\n",
      "step 56430, cost 5.3313\n",
      "step 56430, change in cost 0.000255585\n",
      "step 56440, training accuracy 0.96748\n",
      "step 56440, cost 5.33104\n",
      "step 56440, change in cost 0.000253677\n",
      "step 56450, training accuracy 0.96748\n",
      "step 56450, cost 5.33079\n",
      "step 56450, change in cost 0.000255585\n",
      "step 56460, training accuracy 0.96748\n",
      "step 56460, cost 5.33054\n",
      "step 56460, change in cost 0.00025177\n",
      "step 56470, training accuracy 0.96748\n",
      "step 56470, cost 5.33028\n",
      "step 56470, change in cost 0.000254631\n",
      "step 56480, training accuracy 0.96748\n",
      "step 56480, cost 5.33003\n",
      "step 56480, change in cost 0.000253201\n",
      "step 56490, training accuracy 0.96748\n",
      "step 56490, cost 5.32978\n",
      "step 56490, change in cost 0.000252247\n",
      "step 56500, training accuracy 0.96748\n",
      "step 56500, cost 5.32952\n",
      "step 56500, change in cost 0.000252247\n",
      "step 56510, training accuracy 0.96748\n",
      "step 56510, cost 5.32927\n",
      "step 56510, change in cost 0.00025177\n",
      "step 56520, training accuracy 0.96748\n",
      "step 56520, cost 5.32902\n",
      "step 56520, change in cost 0.000252247\n",
      "step 56530, training accuracy 0.96748\n",
      "step 56530, cost 5.32877\n",
      "step 56530, change in cost 0.00025177\n",
      "step 56540, training accuracy 0.96748\n",
      "step 56540, cost 5.32852\n",
      "step 56540, change in cost 0.000250816\n",
      "step 56550, training accuracy 0.96748\n",
      "step 56550, cost 5.32827\n",
      "step 56550, change in cost 0.00025177\n",
      "step 56560, training accuracy 0.96748\n",
      "step 56560, cost 5.32801\n",
      "step 56560, change in cost 0.000250816\n",
      "step 56570, training accuracy 0.96748\n",
      "step 56570, cost 5.32777\n",
      "step 56570, change in cost 0.000248909\n",
      "step 56580, training accuracy 0.96748\n",
      "step 56580, cost 5.32751\n",
      "step 56580, change in cost 0.00025177\n",
      "step 56590, training accuracy 0.96748\n",
      "step 56590, cost 5.32726\n",
      "step 56590, change in cost 0.000249386\n",
      "step 56600, training accuracy 0.96748\n",
      "step 56600, cost 5.32701\n",
      "step 56600, change in cost 0.000249386\n",
      "step 56610, training accuracy 0.96748\n",
      "step 56610, cost 5.32677\n",
      "step 56610, change in cost 0.000248909\n",
      "step 56620, training accuracy 0.96748\n",
      "step 56620, cost 5.32652\n",
      "step 56620, change in cost 0.000248909\n",
      "step 56630, training accuracy 0.96748\n",
      "step 56630, cost 5.32627\n",
      "step 56630, change in cost 0.000248909\n",
      "step 56640, training accuracy 0.96748\n",
      "step 56640, cost 5.32602\n",
      "step 56640, change in cost 0.000248432\n",
      "step 56650, training accuracy 0.96748\n",
      "step 56650, cost 5.32577\n",
      "step 56650, change in cost 0.000247955\n",
      "step 56660, training accuracy 0.96748\n",
      "step 56660, cost 5.32552\n",
      "step 56660, change in cost 0.000248909\n",
      "step 56670, training accuracy 0.96748\n",
      "step 56670, cost 5.32528\n",
      "step 56670, change in cost 0.000246525\n",
      "step 56680, training accuracy 0.96748\n",
      "step 56680, cost 5.32503\n",
      "step 56680, change in cost 0.000247955\n",
      "step 56690, training accuracy 0.96748\n",
      "step 56690, cost 5.32478\n",
      "step 56690, change in cost 0.000247002\n",
      "step 56700, training accuracy 0.96748\n",
      "step 56700, cost 5.32453\n",
      "step 56700, change in cost 0.000246525\n",
      "step 56710, training accuracy 0.96748\n",
      "step 56710, cost 5.32429\n",
      "step 56710, change in cost 0.000246525\n",
      "step 56720, training accuracy 0.96748\n",
      "step 56720, cost 5.32404\n",
      "step 56720, change in cost 0.000247002\n",
      "step 56730, training accuracy 0.96748\n",
      "step 56730, cost 5.3238\n",
      "step 56730, change in cost 0.000245094\n",
      "step 56740, training accuracy 0.96748\n",
      "step 56740, cost 5.32355\n",
      "step 56740, change in cost 0.000245571\n",
      "step 56750, training accuracy 0.96748\n",
      "step 56750, cost 5.3233\n",
      "step 56750, change in cost 0.000246525\n",
      "step 56760, training accuracy 0.96748\n",
      "step 56760, cost 5.32306\n",
      "step 56760, change in cost 0.000243664\n",
      "step 56770, training accuracy 0.96748\n",
      "step 56770, cost 5.32281\n",
      "step 56770, change in cost 0.000245571\n",
      "step 56780, training accuracy 0.96748\n",
      "step 56780, cost 5.32257\n",
      "step 56780, change in cost 0.000244617\n",
      "step 56790, training accuracy 0.96748\n",
      "step 56790, cost 5.32233\n",
      "step 56790, change in cost 0.000244617\n",
      "step 56800, training accuracy 0.96748\n",
      "step 56800, cost 5.32208\n",
      "step 56800, change in cost 0.000244141\n",
      "step 56810, training accuracy 0.96748\n",
      "step 56810, cost 5.32184\n",
      "step 56810, change in cost 0.000244141\n",
      "step 56820, training accuracy 0.96748\n",
      "step 56820, cost 5.32159\n",
      "step 56820, change in cost 0.000243187\n",
      "step 56830, training accuracy 0.96748\n",
      "step 56830, cost 5.32135\n",
      "step 56830, change in cost 0.000243664\n",
      "step 56840, training accuracy 0.96748\n",
      "step 56840, cost 5.32111\n",
      "step 56840, change in cost 0.00024271\n",
      "step 56850, training accuracy 0.96748\n",
      "step 56850, cost 5.32087\n",
      "step 56850, change in cost 0.00024128\n",
      "step 56860, training accuracy 0.96748\n",
      "step 56860, cost 5.32062\n",
      "step 56860, change in cost 0.000243187\n",
      "step 56870, training accuracy 0.96748\n",
      "step 56870, cost 5.32038\n",
      "step 56870, change in cost 0.000242233\n",
      "step 56880, training accuracy 0.96748\n",
      "step 56880, cost 5.32014\n",
      "step 56880, change in cost 0.000241756\n",
      "step 56890, training accuracy 0.96748\n",
      "step 56890, cost 5.3199\n",
      "step 56890, change in cost 0.000241756\n",
      "step 56900, training accuracy 0.96748\n",
      "step 56900, cost 5.31966\n",
      "step 56900, change in cost 0.000241756\n",
      "step 56910, training accuracy 0.96748\n",
      "step 56910, cost 5.31942\n",
      "step 56910, change in cost 0.000240803\n",
      "step 56920, training accuracy 0.96748\n",
      "step 56920, cost 5.31917\n",
      "step 56920, change in cost 0.000240803\n",
      "step 56930, training accuracy 0.96748\n",
      "step 56930, cost 5.31893\n",
      "step 56930, change in cost 0.000240326\n",
      "step 56940, training accuracy 0.96748\n",
      "step 56940, cost 5.31869\n",
      "step 56940, change in cost 0.00024128\n",
      "step 56950, training accuracy 0.96748\n",
      "step 56950, cost 5.31845\n",
      "step 56950, change in cost 0.000238419\n",
      "step 56960, training accuracy 0.96748\n",
      "step 56960, cost 5.31821\n",
      "step 56960, change in cost 0.000240803\n",
      "step 56970, training accuracy 0.96748\n",
      "step 56970, cost 5.31797\n",
      "step 56970, change in cost 0.000238895\n",
      "step 56980, training accuracy 0.96748\n",
      "step 56980, cost 5.31774\n",
      "step 56980, change in cost 0.000239372\n",
      "step 56990, training accuracy 0.96748\n",
      "step 56990, cost 5.3175\n",
      "step 56990, change in cost 0.000238895\n",
      "step 57000, training accuracy 0.96748\n",
      "step 57000, cost 5.31726\n",
      "step 57000, change in cost 0.000238895\n",
      "step 57010, training accuracy 0.96748\n",
      "step 57010, cost 5.31702\n",
      "step 57010, change in cost 0.000238895\n",
      "step 57020, training accuracy 0.96748\n",
      "step 57020, cost 5.31678\n",
      "step 57020, change in cost 0.000236988\n",
      "step 57030, training accuracy 0.96748\n",
      "step 57030, cost 5.31654\n",
      "step 57030, change in cost 0.000238895\n",
      "step 57040, training accuracy 0.96748\n",
      "step 57040, cost 5.3163\n",
      "step 57040, change in cost 0.000238419\n",
      "step 57050, training accuracy 0.96748\n",
      "step 57050, cost 5.31607\n",
      "step 57050, change in cost 0.000237465\n",
      "step 57060, training accuracy 0.96748\n",
      "step 57060, cost 5.31583\n",
      "step 57060, change in cost 0.000238895\n",
      "step 57070, training accuracy 0.96748\n",
      "step 57070, cost 5.31559\n",
      "step 57070, change in cost 0.000236988\n",
      "step 57080, training accuracy 0.96748\n",
      "step 57080, cost 5.31535\n",
      "step 57080, change in cost 0.000236034\n",
      "step 57090, training accuracy 0.96748\n",
      "step 57090, cost 5.31512\n",
      "step 57090, change in cost 0.000236988\n",
      "step 57100, training accuracy 0.96748\n",
      "step 57100, cost 5.31488\n",
      "step 57100, change in cost 0.000236988\n",
      "step 57110, training accuracy 0.96748\n",
      "step 57110, cost 5.31465\n",
      "step 57110, change in cost 0.000235081\n",
      "step 57120, training accuracy 0.96748\n",
      "step 57120, cost 5.31441\n",
      "step 57120, change in cost 0.000237465\n",
      "step 57130, training accuracy 0.96748\n",
      "step 57130, cost 5.31417\n",
      "step 57130, change in cost 0.000235081\n",
      "step 57140, training accuracy 0.96748\n",
      "step 57140, cost 5.31394\n",
      "step 57140, change in cost 0.000236034\n",
      "step 57150, training accuracy 0.96748\n",
      "step 57150, cost 5.3137\n",
      "step 57150, change in cost 0.000234604\n",
      "step 57160, training accuracy 0.96748\n",
      "step 57160, cost 5.31347\n",
      "step 57160, change in cost 0.000234604\n",
      "step 57170, training accuracy 0.96748\n",
      "step 57170, cost 5.31323\n",
      "step 57170, change in cost 0.000235558\n",
      "step 57180, training accuracy 0.96748\n",
      "step 57180, cost 5.313\n",
      "step 57180, change in cost 0.000234604\n",
      "step 57190, training accuracy 0.96748\n",
      "step 57190, cost 5.31276\n",
      "step 57190, change in cost 0.00023365\n",
      "step 57200, training accuracy 0.96748\n",
      "step 57200, cost 5.31253\n",
      "step 57200, change in cost 0.000234604\n",
      "step 57210, training accuracy 0.96748\n",
      "step 57210, cost 5.3123\n",
      "step 57210, change in cost 0.000233173\n",
      "step 57220, training accuracy 0.96748\n",
      "step 57220, cost 5.31206\n",
      "step 57220, change in cost 0.000234127\n",
      "step 57230, training accuracy 0.96748\n",
      "step 57230, cost 5.31183\n",
      "step 57230, change in cost 0.000232697\n",
      "step 57240, training accuracy 0.96748\n",
      "step 57240, cost 5.3116\n",
      "step 57240, change in cost 0.000232697\n",
      "step 57250, training accuracy 0.96748\n",
      "step 57250, cost 5.31136\n",
      "step 57250, change in cost 0.000232697\n",
      "step 57260, training accuracy 0.96748\n",
      "step 57260, cost 5.31113\n",
      "step 57260, change in cost 0.000233173\n",
      "step 57270, training accuracy 0.96748\n",
      "step 57270, cost 5.3109\n",
      "step 57270, change in cost 0.00023222\n",
      "step 57280, training accuracy 0.96748\n",
      "step 57280, cost 5.31067\n",
      "step 57280, change in cost 0.000232697\n",
      "step 57290, training accuracy 0.96748\n",
      "step 57290, cost 5.31043\n",
      "step 57290, change in cost 0.000231743\n",
      "step 57300, training accuracy 0.96748\n",
      "step 57300, cost 5.3102\n",
      "step 57300, change in cost 0.000232697\n",
      "step 57310, training accuracy 0.96748\n",
      "step 57310, cost 5.30997\n",
      "step 57310, change in cost 0.000230789\n",
      "step 57320, training accuracy 0.96748\n",
      "step 57320, cost 5.30974\n",
      "step 57320, change in cost 0.000230789\n",
      "step 57330, training accuracy 0.96748\n",
      "step 57330, cost 5.30951\n",
      "step 57330, change in cost 0.000230789\n",
      "step 57340, training accuracy 0.96748\n",
      "step 57340, cost 5.30928\n",
      "step 57340, change in cost 0.000231743\n",
      "step 57350, training accuracy 0.96748\n",
      "step 57350, cost 5.30905\n",
      "step 57350, change in cost 0.000229836\n",
      "step 57360, training accuracy 0.96748\n",
      "step 57360, cost 5.30882\n",
      "step 57360, change in cost 0.000231743\n",
      "step 57370, training accuracy 0.96748\n",
      "step 57370, cost 5.30859\n",
      "step 57370, change in cost 0.000230312\n",
      "step 57380, training accuracy 0.96748\n",
      "step 57380, cost 5.30836\n",
      "step 57380, change in cost 0.000229359\n",
      "step 57390, training accuracy 0.96748\n",
      "step 57390, cost 5.30813\n",
      "step 57390, change in cost 0.000229836\n",
      "step 57400, training accuracy 0.96748\n",
      "step 57400, cost 5.3079\n",
      "step 57400, change in cost 0.000229359\n",
      "step 57410, training accuracy 0.96748\n",
      "step 57410, cost 5.30767\n",
      "step 57410, change in cost 0.000229359\n",
      "step 57420, training accuracy 0.96748\n",
      "step 57420, cost 5.30744\n",
      "step 57420, change in cost 0.000228882\n",
      "step 57430, training accuracy 0.96748\n",
      "step 57430, cost 5.30721\n",
      "step 57430, change in cost 0.000228882\n",
      "step 57440, training accuracy 0.96748\n",
      "step 57440, cost 5.30698\n",
      "step 57440, change in cost 0.000229359\n",
      "step 57450, training accuracy 0.96748\n",
      "step 57450, cost 5.30675\n",
      "step 57450, change in cost 0.000227451\n",
      "step 57460, training accuracy 0.96748\n",
      "step 57460, cost 5.30652\n",
      "step 57460, change in cost 0.000228882\n",
      "step 57470, training accuracy 0.96748\n",
      "step 57470, cost 5.3063\n",
      "step 57470, change in cost 0.000228882\n",
      "step 57480, training accuracy 0.96748\n",
      "step 57480, cost 5.30607\n",
      "step 57480, change in cost 0.000226974\n",
      "step 57490, training accuracy 0.96748\n",
      "step 57490, cost 5.30584\n",
      "step 57490, change in cost 0.000226974\n",
      "step 57500, training accuracy 0.96748\n",
      "step 57500, cost 5.30561\n",
      "step 57500, change in cost 0.000227928\n",
      "step 57510, training accuracy 0.96748\n",
      "step 57510, cost 5.30539\n",
      "step 57510, change in cost 0.000225067\n",
      "step 57520, training accuracy 0.96748\n",
      "step 57520, cost 5.30516\n",
      "step 57520, change in cost 0.000228405\n",
      "step 57530, training accuracy 0.96748\n",
      "step 57530, cost 5.30493\n",
      "step 57530, change in cost 0.000226498\n",
      "step 57540, training accuracy 0.96748\n",
      "step 57540, cost 5.30471\n",
      "step 57540, change in cost 0.000226974\n",
      "step 57550, training accuracy 0.96748\n",
      "step 57550, cost 5.30448\n",
      "step 57550, change in cost 0.000226021\n",
      "step 57560, training accuracy 0.96748\n",
      "step 57560, cost 5.30426\n",
      "step 57560, change in cost 0.000225067\n",
      "step 57570, training accuracy 0.96748\n",
      "step 57570, cost 5.30403\n",
      "step 57570, change in cost 0.000226021\n",
      "step 57580, training accuracy 0.96748\n",
      "step 57580, cost 5.3038\n",
      "step 57580, change in cost 0.000226974\n",
      "step 57590, training accuracy 0.96748\n",
      "step 57590, cost 5.30358\n",
      "step 57590, change in cost 0.000225544\n",
      "step 57600, training accuracy 0.96748\n",
      "step 57600, cost 5.30335\n",
      "step 57600, change in cost 0.00022459\n",
      "step 57610, training accuracy 0.96748\n",
      "step 57610, cost 5.30313\n",
      "step 57610, change in cost 0.000225067\n",
      "step 57620, training accuracy 0.96748\n",
      "step 57620, cost 5.3029\n",
      "step 57620, change in cost 0.000224113\n",
      "step 57630, training accuracy 0.96748\n",
      "step 57630, cost 5.30268\n",
      "step 57630, change in cost 0.000225067\n",
      "step 57640, training accuracy 0.96748\n",
      "step 57640, cost 5.30245\n",
      "step 57640, change in cost 0.000224113\n",
      "step 57650, training accuracy 0.96748\n",
      "step 57650, cost 5.30223\n",
      "step 57650, change in cost 0.000223637\n",
      "step 57660, training accuracy 0.96748\n",
      "step 57660, cost 5.30201\n",
      "step 57660, change in cost 0.000223637\n",
      "step 57670, training accuracy 0.96748\n",
      "step 57670, cost 5.30178\n",
      "step 57670, change in cost 0.00022459\n",
      "step 57680, training accuracy 0.96748\n",
      "step 57680, cost 5.30156\n",
      "step 57680, change in cost 0.000223637\n",
      "step 57690, training accuracy 0.96748\n",
      "step 57690, cost 5.30133\n",
      "step 57690, change in cost 0.000224113\n",
      "step 57700, training accuracy 0.96748\n",
      "step 57700, cost 5.30111\n",
      "step 57700, change in cost 0.00022316\n",
      "step 57710, training accuracy 0.96748\n",
      "step 57710, cost 5.30089\n",
      "step 57710, change in cost 0.000222206\n",
      "step 57720, training accuracy 0.96748\n",
      "step 57720, cost 5.30067\n",
      "step 57720, change in cost 0.000222206\n",
      "step 57730, training accuracy 0.96748\n",
      "step 57730, cost 5.30044\n",
      "step 57730, change in cost 0.000222206\n",
      "step 57740, training accuracy 0.96748\n",
      "step 57740, cost 5.30022\n",
      "step 57740, change in cost 0.000222683\n",
      "step 57750, training accuracy 0.96748\n",
      "step 57750, cost 5.3\n",
      "step 57750, change in cost 0.000222683\n",
      "step 57760, training accuracy 0.96748\n",
      "step 57760, cost 5.29978\n",
      "step 57760, change in cost 0.000221252\n",
      "step 57770, training accuracy 0.96748\n",
      "step 57770, cost 5.29955\n",
      "step 57770, change in cost 0.00022316\n",
      "step 57780, training accuracy 0.96748\n",
      "step 57780, cost 5.29934\n",
      "step 57780, change in cost 0.000219822\n",
      "step 57790, training accuracy 0.96748\n",
      "step 57790, cost 5.29911\n",
      "step 57790, change in cost 0.000222683\n",
      "step 57800, training accuracy 0.96748\n",
      "step 57800, cost 5.29889\n",
      "step 57800, change in cost 0.000221252\n",
      "step 57810, training accuracy 0.96748\n",
      "step 57810, cost 5.29867\n",
      "step 57810, change in cost 0.000219345\n",
      "step 57820, training accuracy 0.96748\n",
      "step 57820, cost 5.29845\n",
      "step 57820, change in cost 0.000219822\n",
      "step 57830, training accuracy 0.96748\n",
      "step 57830, cost 5.29823\n",
      "step 57830, change in cost 0.000222683\n",
      "step 57840, training accuracy 0.96748\n",
      "step 57840, cost 5.29801\n",
      "step 57840, change in cost 0.000218391\n",
      "step 57850, training accuracy 0.96748\n",
      "step 57850, cost 5.29779\n",
      "step 57850, change in cost 0.000219345\n",
      "step 57860, training accuracy 0.96748\n",
      "step 57860, cost 5.29757\n",
      "step 57860, change in cost 0.000221252\n",
      "step 57870, training accuracy 0.96748\n",
      "step 57870, cost 5.29735\n",
      "step 57870, change in cost 0.000219822\n",
      "step 57880, training accuracy 0.96748\n",
      "step 57880, cost 5.29713\n",
      "step 57880, change in cost 0.000219822\n",
      "step 57890, training accuracy 0.96748\n",
      "step 57890, cost 5.29691\n",
      "step 57890, change in cost 0.000219345\n",
      "step 57900, training accuracy 0.96748\n",
      "step 57900, cost 5.29669\n",
      "step 57900, change in cost 0.000217438\n",
      "step 57910, training accuracy 0.96748\n",
      "step 57910, cost 5.29647\n",
      "step 57910, change in cost 0.000220299\n",
      "step 57920, training accuracy 0.96748\n",
      "step 57920, cost 5.29626\n",
      "step 57920, change in cost 0.000218391\n",
      "step 57930, training accuracy 0.96748\n",
      "step 57930, cost 5.29604\n",
      "step 57930, change in cost 0.000218868\n",
      "step 57940, training accuracy 0.96748\n",
      "step 57940, cost 5.29582\n",
      "step 57940, change in cost 0.000217915\n",
      "step 57950, training accuracy 0.96748\n",
      "step 57950, cost 5.2956\n",
      "step 57950, change in cost 0.000218391\n",
      "step 57960, training accuracy 0.96748\n",
      "step 57960, cost 5.29538\n",
      "step 57960, change in cost 0.000217915\n",
      "step 57970, training accuracy 0.96748\n",
      "step 57970, cost 5.29516\n",
      "step 57970, change in cost 0.000218868\n",
      "step 57980, training accuracy 0.96748\n",
      "step 57980, cost 5.29495\n",
      "step 57980, change in cost 0.000214577\n",
      "step 57990, training accuracy 0.96748\n",
      "step 57990, cost 5.29473\n",
      "step 57990, change in cost 0.000218391\n",
      "step 58000, training accuracy 0.96748\n",
      "step 58000, cost 5.29451\n",
      "step 58000, change in cost 0.000216961\n",
      "step 58010, training accuracy 0.96748\n",
      "step 58010, cost 5.2943\n",
      "step 58010, change in cost 0.000217438\n",
      "step 58020, training accuracy 0.96748\n",
      "step 58020, cost 5.29408\n",
      "step 58020, change in cost 0.000216961\n",
      "step 58030, training accuracy 0.96748\n",
      "step 58030, cost 5.29386\n",
      "step 58030, change in cost 0.000216961\n",
      "step 58040, training accuracy 0.96748\n",
      "step 58040, cost 5.29365\n",
      "step 58040, change in cost 0.000216007\n",
      "step 58050, training accuracy 0.96748\n",
      "step 58050, cost 5.29343\n",
      "step 58050, change in cost 0.000216484\n",
      "step 58060, training accuracy 0.96748\n",
      "step 58060, cost 5.29321\n",
      "step 58060, change in cost 0.000216484\n",
      "step 58070, training accuracy 0.96748\n",
      "step 58070, cost 5.293\n",
      "step 58070, change in cost 0.00021553\n",
      "step 58080, training accuracy 0.96748\n",
      "step 58080, cost 5.29278\n",
      "step 58080, change in cost 0.000216961\n",
      "step 58090, training accuracy 0.96748\n",
      "step 58090, cost 5.29257\n",
      "step 58090, change in cost 0.000215054\n",
      "step 58100, training accuracy 0.96748\n",
      "step 58100, cost 5.29235\n",
      "step 58100, change in cost 0.000215054\n",
      "step 58110, training accuracy 0.96748\n",
      "step 58110, cost 5.29213\n",
      "step 58110, change in cost 0.000216007\n",
      "step 58120, training accuracy 0.96748\n",
      "step 58120, cost 5.29192\n",
      "step 58120, change in cost 0.0002141\n",
      "step 58130, training accuracy 0.96748\n",
      "step 58130, cost 5.29171\n",
      "step 58130, change in cost 0.0002141\n",
      "step 58140, training accuracy 0.96748\n",
      "step 58140, cost 5.29149\n",
      "step 58140, change in cost 0.000215054\n",
      "step 58150, training accuracy 0.96748\n",
      "step 58150, cost 5.29128\n",
      "step 58150, change in cost 0.000215054\n",
      "step 58160, training accuracy 0.96748\n",
      "step 58160, cost 5.29106\n",
      "step 58160, change in cost 0.000213623\n",
      "step 58170, training accuracy 0.96748\n",
      "step 58170, cost 5.29085\n",
      "step 58170, change in cost 0.000214577\n",
      "step 58180, training accuracy 0.96748\n",
      "step 58180, cost 5.29063\n",
      "step 58180, change in cost 0.000213623\n",
      "step 58190, training accuracy 0.96748\n",
      "step 58190, cost 5.29042\n",
      "step 58190, change in cost 0.000213623\n",
      "step 58200, training accuracy 0.96748\n",
      "step 58200, cost 5.29021\n",
      "step 58200, change in cost 0.000214577\n",
      "step 58210, training accuracy 0.96748\n",
      "step 58210, cost 5.28999\n",
      "step 58210, change in cost 0.000212669\n",
      "step 58220, training accuracy 0.96748\n",
      "step 58220, cost 5.28978\n",
      "step 58220, change in cost 0.000212193\n",
      "step 58230, training accuracy 0.96748\n",
      "step 58230, cost 5.28957\n",
      "step 58230, change in cost 0.000213146\n",
      "step 58240, training accuracy 0.96748\n",
      "step 58240, cost 5.28935\n",
      "step 58240, change in cost 0.000213146\n",
      "step 58250, training accuracy 0.96748\n",
      "step 58250, cost 5.28914\n",
      "step 58250, change in cost 0.000211716\n",
      "step 58260, training accuracy 0.96748\n",
      "step 58260, cost 5.28893\n",
      "step 58260, change in cost 0.0002141\n",
      "step 58270, training accuracy 0.96748\n",
      "step 58270, cost 5.28872\n",
      "step 58270, change in cost 0.000210762\n",
      "step 58280, training accuracy 0.96748\n",
      "step 58280, cost 5.2885\n",
      "step 58280, change in cost 0.000213623\n",
      "step 58290, training accuracy 0.96748\n",
      "step 58290, cost 5.28829\n",
      "step 58290, change in cost 0.000211716\n",
      "step 58300, training accuracy 0.96748\n",
      "step 58300, cost 5.28808\n",
      "step 58300, change in cost 0.000211716\n",
      "step 58310, training accuracy 0.96748\n",
      "step 58310, cost 5.28787\n",
      "step 58310, change in cost 0.000211239\n",
      "step 58320, training accuracy 0.96748\n",
      "step 58320, cost 5.28766\n",
      "step 58320, change in cost 0.000211716\n",
      "step 58330, training accuracy 0.96748\n",
      "step 58330, cost 5.28745\n",
      "step 58330, change in cost 0.000211239\n",
      "step 58340, training accuracy 0.96748\n",
      "step 58340, cost 5.28724\n",
      "step 58340, change in cost 0.000211239\n",
      "step 58350, training accuracy 0.96748\n",
      "step 58350, cost 5.28702\n",
      "step 58350, change in cost 0.000212193\n",
      "step 58360, training accuracy 0.96748\n",
      "step 58360, cost 5.28681\n",
      "step 58360, change in cost 0.000208855\n",
      "step 58370, training accuracy 0.96748\n",
      "step 58370, cost 5.2866\n",
      "step 58370, change in cost 0.000212669\n",
      "step 58380, training accuracy 0.96748\n",
      "step 58380, cost 5.28639\n",
      "step 58380, change in cost 0.000209332\n",
      "step 58390, training accuracy 0.96748\n",
      "step 58390, cost 5.28618\n",
      "step 58390, change in cost 0.000210285\n",
      "step 58400, training accuracy 0.96748\n",
      "step 58400, cost 5.28597\n",
      "step 58400, change in cost 0.000210762\n",
      "step 58410, training accuracy 0.96748\n",
      "step 58410, cost 5.28576\n",
      "step 58410, change in cost 0.000210762\n",
      "step 58420, training accuracy 0.96748\n",
      "step 58420, cost 5.28555\n",
      "step 58420, change in cost 0.000208855\n",
      "step 58430, training accuracy 0.96748\n",
      "step 58430, cost 5.28534\n",
      "step 58430, change in cost 0.000210762\n",
      "step 58440, training accuracy 0.96748\n",
      "step 58440, cost 5.28513\n",
      "step 58440, change in cost 0.000208855\n",
      "step 58450, training accuracy 0.96748\n",
      "step 58450, cost 5.28492\n",
      "step 58450, change in cost 0.000209332\n",
      "step 58460, training accuracy 0.96748\n",
      "step 58460, cost 5.28471\n",
      "step 58460, change in cost 0.000209332\n",
      "step 58470, training accuracy 0.96748\n",
      "step 58470, cost 5.28451\n",
      "step 58470, change in cost 0.000207901\n",
      "step 58480, training accuracy 0.96748\n",
      "step 58480, cost 5.2843\n",
      "step 58480, change in cost 0.000207901\n",
      "step 58490, training accuracy 0.96748\n",
      "step 58490, cost 5.28409\n",
      "step 58490, change in cost 0.000209808\n",
      "step 58500, training accuracy 0.96748\n",
      "step 58500, cost 5.28388\n",
      "step 58500, change in cost 0.000208378\n",
      "step 58510, training accuracy 0.96748\n",
      "step 58510, cost 5.28367\n",
      "step 58510, change in cost 0.000208378\n",
      "step 58520, training accuracy 0.96748\n",
      "step 58520, cost 5.28346\n",
      "step 58520, change in cost 0.000207424\n",
      "step 58530, training accuracy 0.96748\n",
      "step 58530, cost 5.28326\n",
      "step 58530, change in cost 0.000208855\n",
      "step 58540, training accuracy 0.96748\n",
      "step 58540, cost 5.28305\n",
      "step 58540, change in cost 0.000208378\n",
      "step 58550, training accuracy 0.96748\n",
      "step 58550, cost 5.28284\n",
      "step 58550, change in cost 0.000206947\n",
      "step 58560, training accuracy 0.96748\n",
      "step 58560, cost 5.28263\n",
      "step 58560, change in cost 0.000207901\n",
      "step 58570, training accuracy 0.96748\n",
      "step 58570, cost 5.28242\n",
      "step 58570, change in cost 0.000206947\n",
      "step 58580, training accuracy 0.96748\n",
      "step 58580, cost 5.28222\n",
      "step 58580, change in cost 0.000206947\n",
      "step 58590, training accuracy 0.96748\n",
      "step 58590, cost 5.28201\n",
      "step 58590, change in cost 0.000206947\n",
      "step 58600, training accuracy 0.96748\n",
      "step 58600, cost 5.28181\n",
      "step 58600, change in cost 0.000205994\n",
      "step 58610, training accuracy 0.96748\n",
      "step 58610, cost 5.2816\n",
      "step 58610, change in cost 0.000207901\n",
      "step 58620, training accuracy 0.96748\n",
      "step 58620, cost 5.28139\n",
      "step 58620, change in cost 0.000205994\n",
      "step 58630, training accuracy 0.96748\n",
      "step 58630, cost 5.28119\n",
      "step 58630, change in cost 0.00020504\n",
      "step 58640, training accuracy 0.96748\n",
      "step 58640, cost 5.28098\n",
      "step 58640, change in cost 0.000207901\n",
      "step 58650, training accuracy 0.96748\n",
      "step 58650, cost 5.28077\n",
      "step 58650, change in cost 0.000205517\n",
      "step 58660, training accuracy 0.96748\n",
      "step 58660, cost 5.28057\n",
      "step 58660, change in cost 0.000205517\n",
      "step 58670, training accuracy 0.96748\n",
      "step 58670, cost 5.28036\n",
      "step 58670, change in cost 0.000204563\n",
      "step 58680, training accuracy 0.96748\n",
      "step 58680, cost 5.28016\n",
      "step 58680, change in cost 0.000205517\n",
      "step 58690, training accuracy 0.96748\n",
      "step 58690, cost 5.27995\n",
      "step 58690, change in cost 0.000205994\n",
      "step 58700, training accuracy 0.96748\n",
      "step 58700, cost 5.27975\n",
      "step 58700, change in cost 0.00020504\n",
      "step 58710, training accuracy 0.96748\n",
      "step 58710, cost 5.27954\n",
      "step 58710, change in cost 0.000204563\n",
      "step 58720, training accuracy 0.96748\n",
      "step 58720, cost 5.27934\n",
      "step 58720, change in cost 0.000204563\n",
      "step 58730, training accuracy 0.96748\n",
      "step 58730, cost 5.27913\n",
      "step 58730, change in cost 0.000204563\n",
      "step 58740, training accuracy 0.96748\n",
      "step 58740, cost 5.27893\n",
      "step 58740, change in cost 0.000204563\n",
      "step 58750, training accuracy 0.96748\n",
      "step 58750, cost 5.27872\n",
      "step 58750, change in cost 0.00020504\n",
      "step 58760, training accuracy 0.96748\n",
      "step 58760, cost 5.27852\n",
      "step 58760, change in cost 0.000204086\n",
      "step 58770, training accuracy 0.96748\n",
      "step 58770, cost 5.27832\n",
      "step 58770, change in cost 0.000203133\n",
      "step 58780, training accuracy 0.96748\n",
      "step 58780, cost 5.27811\n",
      "step 58780, change in cost 0.00020504\n",
      "step 58790, training accuracy 0.96748\n",
      "step 58790, cost 5.27791\n",
      "step 58790, change in cost 0.000204086\n",
      "step 58800, training accuracy 0.96748\n",
      "step 58800, cost 5.2777\n",
      "step 58800, change in cost 0.000203133\n",
      "step 58810, training accuracy 0.96748\n",
      "step 58810, cost 5.2775\n",
      "step 58810, change in cost 0.000203133\n",
      "step 58820, training accuracy 0.96748\n",
      "step 58820, cost 5.2773\n",
      "step 58820, change in cost 0.000203609\n",
      "step 58830, training accuracy 0.96748\n",
      "step 58830, cost 5.27709\n",
      "step 58830, change in cost 0.000203609\n",
      "step 58840, training accuracy 0.96748\n",
      "step 58840, cost 5.27689\n",
      "step 58840, change in cost 0.000202179\n",
      "step 58850, training accuracy 0.96748\n",
      "step 58850, cost 5.27669\n",
      "step 58850, change in cost 0.000203133\n",
      "step 58860, training accuracy 0.96748\n",
      "step 58860, cost 5.27648\n",
      "step 58860, change in cost 0.000203133\n",
      "step 58870, training accuracy 0.96748\n",
      "step 58870, cost 5.27628\n",
      "step 58870, change in cost 0.000203133\n",
      "step 58880, training accuracy 0.96748\n",
      "step 58880, cost 5.27608\n",
      "step 58880, change in cost 0.000201225\n",
      "step 58890, training accuracy 0.96748\n",
      "step 58890, cost 5.27588\n",
      "step 58890, change in cost 0.000202656\n",
      "step 58900, training accuracy 0.96748\n",
      "step 58900, cost 5.27567\n",
      "step 58900, change in cost 0.000202656\n",
      "step 58910, training accuracy 0.96748\n",
      "step 58910, cost 5.27547\n",
      "step 58910, change in cost 0.000202179\n",
      "step 58920, training accuracy 0.96748\n",
      "step 58920, cost 5.27527\n",
      "step 58920, change in cost 0.000201225\n",
      "step 58930, training accuracy 0.96748\n",
      "step 58930, cost 5.27507\n",
      "step 58930, change in cost 0.000202179\n",
      "step 58940, training accuracy 0.96748\n",
      "step 58940, cost 5.27487\n",
      "step 58940, change in cost 0.000202179\n",
      "step 58950, training accuracy 0.96748\n",
      "step 58950, cost 5.27467\n",
      "step 58950, change in cost 0.000201702\n",
      "step 58960, training accuracy 0.96748\n",
      "step 58960, cost 5.27446\n",
      "step 58960, change in cost 0.000200748\n",
      "step 58970, training accuracy 0.96748\n",
      "step 58970, cost 5.27426\n",
      "step 58970, change in cost 0.000201225\n",
      "step 58980, training accuracy 0.96748\n",
      "step 58980, cost 5.27406\n",
      "step 58980, change in cost 0.000201225\n",
      "step 58990, training accuracy 0.96748\n",
      "step 58990, cost 5.27386\n",
      "step 58990, change in cost 0.000200272\n",
      "step 59000, training accuracy 0.96748\n",
      "step 59000, cost 5.27366\n",
      "step 59000, change in cost 0.000201702\n",
      "step 59010, training accuracy 0.96748\n",
      "step 59010, cost 5.27346\n",
      "step 59010, change in cost 0.000201225\n",
      "step 59020, training accuracy 0.96748\n",
      "step 59020, cost 5.27326\n",
      "step 59020, change in cost 0.000198841\n",
      "step 59030, training accuracy 0.96748\n",
      "step 59030, cost 5.27306\n",
      "step 59030, change in cost 0.000201225\n",
      "step 59040, training accuracy 0.96748\n",
      "step 59040, cost 5.27286\n",
      "step 59040, change in cost 0.000199318\n",
      "step 59050, training accuracy 0.96748\n",
      "step 59050, cost 5.27266\n",
      "step 59050, change in cost 0.000201225\n",
      "step 59060, training accuracy 0.96748\n",
      "step 59060, cost 5.27246\n",
      "step 59060, change in cost 0.000199318\n",
      "step 59070, training accuracy 0.96748\n",
      "step 59070, cost 5.27226\n",
      "step 59070, change in cost 0.000199318\n",
      "step 59080, training accuracy 0.96748\n",
      "step 59080, cost 5.27206\n",
      "step 59080, change in cost 0.000200272\n",
      "step 59090, training accuracy 0.96748\n",
      "step 59090, cost 5.27186\n",
      "step 59090, change in cost 0.000200272\n",
      "step 59100, training accuracy 0.96748\n",
      "step 59100, cost 5.27166\n",
      "step 59100, change in cost 0.000198364\n",
      "step 59110, training accuracy 0.96748\n",
      "step 59110, cost 5.27146\n",
      "step 59110, change in cost 0.000199318\n",
      "step 59120, training accuracy 0.96748\n",
      "step 59120, cost 5.27126\n",
      "step 59120, change in cost 0.000199318\n",
      "step 59130, training accuracy 0.96748\n",
      "step 59130, cost 5.27106\n",
      "step 59130, change in cost 0.000198364\n",
      "step 59140, training accuracy 0.96748\n",
      "step 59140, cost 5.27086\n",
      "step 59140, change in cost 0.000198841\n",
      "step 59150, training accuracy 0.96748\n",
      "step 59150, cost 5.27067\n",
      "step 59150, change in cost 0.000197411\n",
      "step 59160, training accuracy 0.96748\n",
      "step 59160, cost 5.27047\n",
      "step 59160, change in cost 0.000199795\n",
      "step 59170, training accuracy 0.96748\n",
      "step 59170, cost 5.27027\n",
      "step 59170, change in cost 0.000197411\n",
      "step 59180, training accuracy 0.96748\n",
      "step 59180, cost 5.27007\n",
      "step 59180, change in cost 0.000198364\n",
      "step 59190, training accuracy 0.96748\n",
      "step 59190, cost 5.26987\n",
      "step 59190, change in cost 0.000198364\n",
      "step 59200, training accuracy 0.96748\n",
      "step 59200, cost 5.26968\n",
      "step 59200, change in cost 0.000197411\n",
      "step 59210, training accuracy 0.96748\n",
      "step 59210, cost 5.26948\n",
      "step 59210, change in cost 0.000196457\n",
      "step 59220, training accuracy 0.96748\n",
      "step 59220, cost 5.26928\n",
      "step 59220, change in cost 0.000200272\n",
      "step 59230, training accuracy 0.96748\n",
      "step 59230, cost 5.26908\n",
      "step 59230, change in cost 0.000196457\n",
      "step 59240, training accuracy 0.96748\n",
      "step 59240, cost 5.26889\n",
      "step 59240, change in cost 0.000197411\n",
      "step 59250, training accuracy 0.96748\n",
      "step 59250, cost 5.26869\n",
      "step 59250, change in cost 0.000196457\n",
      "step 59260, training accuracy 0.96748\n",
      "step 59260, cost 5.26849\n",
      "step 59260, change in cost 0.000196457\n",
      "step 59270, training accuracy 0.96748\n",
      "step 59270, cost 5.2683\n",
      "step 59270, change in cost 0.000197411\n",
      "step 59280, training accuracy 0.96748\n",
      "step 59280, cost 5.2681\n",
      "step 59280, change in cost 0.000195503\n",
      "step 59290, training accuracy 0.96748\n",
      "step 59290, cost 5.2679\n",
      "step 59290, change in cost 0.000196934\n",
      "step 59300, training accuracy 0.96748\n",
      "step 59300, cost 5.26771\n",
      "step 59300, change in cost 0.000197411\n",
      "step 59310, training accuracy 0.96748\n",
      "step 59310, cost 5.26751\n",
      "step 59310, change in cost 0.00019598\n",
      "step 59320, training accuracy 0.96748\n",
      "step 59320, cost 5.26731\n",
      "step 59320, change in cost 0.000196457\n",
      "step 59330, training accuracy 0.96748\n",
      "step 59330, cost 5.26712\n",
      "step 59330, change in cost 0.000195026\n",
      "step 59340, training accuracy 0.96748\n",
      "step 59340, cost 5.26692\n",
      "step 59340, change in cost 0.00019598\n",
      "step 59350, training accuracy 0.96748\n",
      "step 59350, cost 5.26673\n",
      "step 59350, change in cost 0.000196457\n",
      "step 59360, training accuracy 0.96748\n",
      "step 59360, cost 5.26653\n",
      "step 59360, change in cost 0.000196457\n",
      "step 59370, training accuracy 0.96748\n",
      "step 59370, cost 5.26633\n",
      "step 59370, change in cost 0.00019455\n",
      "step 59380, training accuracy 0.96748\n",
      "step 59380, cost 5.26614\n",
      "step 59380, change in cost 0.000195503\n",
      "step 59390, training accuracy 0.96748\n",
      "step 59390, cost 5.26594\n",
      "step 59390, change in cost 0.000195503\n",
      "step 59400, training accuracy 0.96748\n",
      "step 59400, cost 5.26575\n",
      "step 59400, change in cost 0.000195503\n",
      "step 59410, training accuracy 0.96748\n",
      "step 59410, cost 5.26555\n",
      "step 59410, change in cost 0.000193119\n",
      "step 59420, training accuracy 0.96748\n",
      "step 59420, cost 5.26536\n",
      "step 59420, change in cost 0.00019598\n",
      "step 59430, training accuracy 0.96748\n",
      "step 59430, cost 5.26516\n",
      "step 59430, change in cost 0.00019455\n",
      "step 59440, training accuracy 0.96748\n",
      "step 59440, cost 5.26497\n",
      "step 59440, change in cost 0.000195026\n",
      "step 59450, training accuracy 0.96748\n",
      "step 59450, cost 5.26478\n",
      "step 59450, change in cost 0.000194073\n",
      "step 59460, training accuracy 0.96748\n",
      "step 59460, cost 5.26458\n",
      "step 59460, change in cost 0.00019455\n",
      "step 59470, training accuracy 0.96748\n",
      "step 59470, cost 5.26439\n",
      "step 59470, change in cost 0.000193119\n",
      "step 59480, training accuracy 0.96748\n",
      "step 59480, cost 5.26419\n",
      "step 59480, change in cost 0.000195503\n",
      "step 59490, training accuracy 0.96748\n",
      "step 59490, cost 5.264\n",
      "step 59490, change in cost 0.000193596\n",
      "step 59500, training accuracy 0.96748\n",
      "step 59500, cost 5.2638\n",
      "step 59500, change in cost 0.000194073\n",
      "step 59510, training accuracy 0.96748\n",
      "step 59510, cost 5.26361\n",
      "step 59510, change in cost 0.000195026\n",
      "step 59520, training accuracy 0.96748\n",
      "step 59520, cost 5.26342\n",
      "step 59520, change in cost 0.000192165\n",
      "step 59530, training accuracy 0.96748\n",
      "step 59530, cost 5.26322\n",
      "step 59530, change in cost 0.000193596\n",
      "step 59540, training accuracy 0.96748\n",
      "step 59540, cost 5.26303\n",
      "step 59540, change in cost 0.000194073\n",
      "step 59550, training accuracy 0.96748\n",
      "step 59550, cost 5.26284\n",
      "step 59550, change in cost 0.000191689\n",
      "step 59560, training accuracy 0.96748\n",
      "step 59560, cost 5.26264\n",
      "step 59560, change in cost 0.000194073\n",
      "step 59570, training accuracy 0.96748\n",
      "step 59570, cost 5.26245\n",
      "step 59570, change in cost 0.000192165\n",
      "step 59580, training accuracy 0.96748\n",
      "step 59580, cost 5.26226\n",
      "step 59580, change in cost 0.000193596\n",
      "step 59590, training accuracy 0.96748\n",
      "step 59590, cost 5.26206\n",
      "step 59590, change in cost 0.000193119\n",
      "step 59600, training accuracy 0.96748\n",
      "step 59600, cost 5.26187\n",
      "step 59600, change in cost 0.000191689\n",
      "step 59610, training accuracy 0.96748\n",
      "step 59610, cost 5.26168\n",
      "step 59610, change in cost 0.000193596\n",
      "step 59620, training accuracy 0.96748\n",
      "step 59620, cost 5.26149\n",
      "step 59620, change in cost 0.000191689\n",
      "step 59630, training accuracy 0.96748\n",
      "step 59630, cost 5.2613\n",
      "step 59630, change in cost 0.000191212\n",
      "step 59640, training accuracy 0.96748\n",
      "step 59640, cost 5.2611\n",
      "step 59640, change in cost 0.000193119\n",
      "step 59650, training accuracy 0.96748\n",
      "step 59650, cost 5.26091\n",
      "step 59650, change in cost 0.000192642\n",
      "step 59660, training accuracy 0.96748\n",
      "step 59660, cost 5.26072\n",
      "step 59660, change in cost 0.000191212\n",
      "step 59670, training accuracy 0.96748\n",
      "step 59670, cost 5.26053\n",
      "step 59670, change in cost 0.000191212\n",
      "step 59680, training accuracy 0.96748\n",
      "step 59680, cost 5.26034\n",
      "step 59680, change in cost 0.000192165\n",
      "step 59690, training accuracy 0.96748\n",
      "step 59690, cost 5.26015\n",
      "step 59690, change in cost 0.000191212\n",
      "step 59700, training accuracy 0.96748\n",
      "step 59700, cost 5.25995\n",
      "step 59700, change in cost 0.000191689\n",
      "step 59710, training accuracy 0.96748\n",
      "step 59710, cost 5.25976\n",
      "step 59710, change in cost 0.000190735\n",
      "step 59720, training accuracy 0.96748\n",
      "step 59720, cost 5.25957\n",
      "step 59720, change in cost 0.000190735\n",
      "step 59730, training accuracy 0.96748\n",
      "step 59730, cost 5.25938\n",
      "step 59730, change in cost 0.000191212\n",
      "step 59740, training accuracy 0.96748\n",
      "step 59740, cost 5.25919\n",
      "step 59740, change in cost 0.000190258\n",
      "step 59750, training accuracy 0.96748\n",
      "step 59750, cost 5.259\n",
      "step 59750, change in cost 0.000190258\n",
      "step 59760, training accuracy 0.96748\n",
      "step 59760, cost 5.25881\n",
      "step 59760, change in cost 0.000191212\n",
      "step 59770, training accuracy 0.96748\n",
      "step 59770, cost 5.25862\n",
      "step 59770, change in cost 0.000190258\n",
      "step 59780, training accuracy 0.96748\n",
      "step 59780, cost 5.25843\n",
      "step 59780, change in cost 0.000189304\n",
      "step 59790, training accuracy 0.96748\n",
      "step 59790, cost 5.25824\n",
      "step 59790, change in cost 0.000191689\n",
      "step 59800, training accuracy 0.96748\n",
      "step 59800, cost 5.25805\n",
      "step 59800, change in cost 0.000188828\n",
      "step 59810, training accuracy 0.96748\n",
      "step 59810, cost 5.25786\n",
      "step 59810, change in cost 0.000189781\n",
      "step 59820, training accuracy 0.96748\n",
      "step 59820, cost 5.25767\n",
      "step 59820, change in cost 0.000190258\n",
      "step 59830, training accuracy 0.96748\n",
      "step 59830, cost 5.25748\n",
      "step 59830, change in cost 0.000189304\n",
      "step 59840, training accuracy 0.96748\n",
      "step 59840, cost 5.25729\n",
      "step 59840, change in cost 0.000188828\n",
      "step 59850, training accuracy 0.96748\n",
      "step 59850, cost 5.2571\n",
      "step 59850, change in cost 0.000188828\n",
      "step 59860, training accuracy 0.96748\n",
      "step 59860, cost 5.25691\n",
      "step 59860, change in cost 0.000189304\n",
      "step 59870, training accuracy 0.96748\n",
      "step 59870, cost 5.25672\n",
      "step 59870, change in cost 0.000189304\n",
      "step 59880, training accuracy 0.96748\n",
      "step 59880, cost 5.25653\n",
      "step 59880, change in cost 0.000189781\n",
      "step 59890, training accuracy 0.96748\n",
      "step 59890, cost 5.25634\n",
      "step 59890, change in cost 0.000189781\n",
      "step 59900, training accuracy 0.96748\n",
      "step 59900, cost 5.25616\n",
      "step 59900, change in cost 0.000188351\n",
      "step 59910, training accuracy 0.96748\n",
      "step 59910, cost 5.25597\n",
      "step 59910, change in cost 0.000187397\n",
      "step 59920, training accuracy 0.96748\n",
      "step 59920, cost 5.25578\n",
      "step 59920, change in cost 0.000188828\n",
      "step 59930, training accuracy 0.96748\n",
      "step 59930, cost 5.25559\n",
      "step 59930, change in cost 0.000188351\n",
      "step 59940, training accuracy 0.96748\n",
      "step 59940, cost 5.2554\n",
      "step 59940, change in cost 0.000188351\n",
      "step 59950, training accuracy 0.96748\n",
      "step 59950, cost 5.25521\n",
      "step 59950, change in cost 0.000187874\n",
      "step 59960, training accuracy 0.96748\n",
      "step 59960, cost 5.25503\n",
      "step 59960, change in cost 0.000188351\n",
      "step 59970, training accuracy 0.96748\n",
      "step 59970, cost 5.25484\n",
      "step 59970, change in cost 0.000188828\n",
      "step 59980, training accuracy 0.96748\n",
      "step 59980, cost 5.25465\n",
      "step 59980, change in cost 0.000187397\n",
      "step 59990, training accuracy 0.96748\n",
      "step 59990, cost 5.25446\n",
      "step 59990, change in cost 0.000188351\n",
      "step 60000, training accuracy 0.96748\n",
      "step 60000, cost 5.25427\n",
      "step 60000, change in cost 0.00018692\n",
      "step 60010, training accuracy 0.96748\n",
      "step 60010, cost 5.25409\n",
      "step 60010, change in cost 0.000186443\n",
      "step 60020, training accuracy 0.96748\n",
      "step 60020, cost 5.2539\n",
      "step 60020, change in cost 0.000187874\n",
      "step 60030, training accuracy 0.96748\n",
      "step 60030, cost 5.25371\n",
      "step 60030, change in cost 0.00018692\n",
      "step 60040, training accuracy 0.96748\n",
      "step 60040, cost 5.25353\n",
      "step 60040, change in cost 0.000186443\n",
      "step 60050, training accuracy 0.96748\n",
      "step 60050, cost 5.25334\n",
      "step 60050, change in cost 0.000187397\n",
      "step 60060, training accuracy 0.96748\n",
      "step 60060, cost 5.25315\n",
      "step 60060, change in cost 0.00018549\n",
      "step 60070, training accuracy 0.96748\n",
      "step 60070, cost 5.25297\n",
      "step 60070, change in cost 0.000187397\n",
      "step 60080, training accuracy 0.96748\n",
      "step 60080, cost 5.25278\n",
      "step 60080, change in cost 0.000186443\n",
      "step 60090, training accuracy 0.96748\n",
      "step 60090, cost 5.25259\n",
      "step 60090, change in cost 0.000186443\n",
      "step 60100, training accuracy 0.96748\n",
      "step 60100, cost 5.25241\n",
      "step 60100, change in cost 0.00018692\n",
      "step 60110, training accuracy 0.96748\n",
      "step 60110, cost 5.25222\n",
      "step 60110, change in cost 0.00018549\n",
      "step 60120, training accuracy 0.96748\n",
      "step 60120, cost 5.25204\n",
      "step 60120, change in cost 0.000185966\n",
      "step 60130, training accuracy 0.96748\n",
      "step 60130, cost 5.25185\n",
      "step 60130, change in cost 0.000186443\n",
      "step 60140, training accuracy 0.96748\n",
      "step 60140, cost 5.25166\n",
      "step 60140, change in cost 0.00018549\n",
      "step 60150, training accuracy 0.96748\n",
      "step 60150, cost 5.25148\n",
      "step 60150, change in cost 0.00018692\n",
      "step 60160, training accuracy 0.96748\n",
      "step 60160, cost 5.25129\n",
      "step 60160, change in cost 0.000184536\n",
      "step 60170, training accuracy 0.96748\n",
      "step 60170, cost 5.25111\n",
      "step 60170, change in cost 0.000185966\n",
      "step 60180, training accuracy 0.96748\n",
      "step 60180, cost 5.25092\n",
      "step 60180, change in cost 0.000185966\n",
      "step 60190, training accuracy 0.96748\n",
      "step 60190, cost 5.25074\n",
      "step 60190, change in cost 0.000184536\n",
      "step 60200, training accuracy 0.96748\n",
      "step 60200, cost 5.25055\n",
      "step 60200, change in cost 0.00018549\n",
      "step 60210, training accuracy 0.96748\n",
      "step 60210, cost 5.25036\n",
      "step 60210, change in cost 0.000185966\n",
      "step 60220, training accuracy 0.96748\n",
      "step 60220, cost 5.25018\n",
      "step 60220, change in cost 0.000184059\n",
      "step 60230, training accuracy 0.96748\n",
      "step 60230, cost 5.24999\n",
      "step 60230, change in cost 0.000185966\n",
      "step 60240, training accuracy 0.96748\n",
      "step 60240, cost 5.24981\n",
      "step 60240, change in cost 0.000185013\n",
      "step 60250, training accuracy 0.96748\n",
      "step 60250, cost 5.24963\n",
      "step 60250, change in cost 0.000184059\n",
      "step 60260, training accuracy 0.96748\n",
      "step 60260, cost 5.24944\n",
      "step 60260, change in cost 0.000184536\n",
      "step 60270, training accuracy 0.96748\n",
      "step 60270, cost 5.24926\n",
      "step 60270, change in cost 0.000184536\n",
      "step 60280, training accuracy 0.96748\n",
      "step 60280, cost 5.24907\n",
      "step 60280, change in cost 0.000184536\n",
      "step 60290, training accuracy 0.96748\n",
      "step 60290, cost 5.24889\n",
      "step 60290, change in cost 0.00018549\n",
      "step 60300, training accuracy 0.96748\n",
      "step 60300, cost 5.2487\n",
      "step 60300, change in cost 0.000183582\n",
      "step 60310, training accuracy 0.96748\n",
      "step 60310, cost 5.24852\n",
      "step 60310, change in cost 0.000184536\n",
      "step 60320, training accuracy 0.96748\n",
      "step 60320, cost 5.24833\n",
      "step 60320, change in cost 0.000183105\n",
      "step 60330, training accuracy 0.96748\n",
      "step 60330, cost 5.24815\n",
      "step 60330, change in cost 0.000184059\n",
      "step 60340, training accuracy 0.96748\n",
      "step 60340, cost 5.24797\n",
      "step 60340, change in cost 0.000184059\n",
      "step 60350, training accuracy 0.96748\n",
      "step 60350, cost 5.24778\n",
      "step 60350, change in cost 0.000183105\n",
      "step 60360, training accuracy 0.96748\n",
      "step 60360, cost 5.2476\n",
      "step 60360, change in cost 0.000184059\n",
      "step 60370, training accuracy 0.96748\n",
      "step 60370, cost 5.24742\n",
      "step 60370, change in cost 0.000183105\n",
      "step 60380, training accuracy 0.96748\n",
      "step 60380, cost 5.24723\n",
      "step 60380, change in cost 0.000183105\n",
      "step 60390, training accuracy 0.96748\n",
      "step 60390, cost 5.24705\n",
      "step 60390, change in cost 0.000184059\n",
      "step 60400, training accuracy 0.96748\n",
      "step 60400, cost 5.24687\n",
      "step 60400, change in cost 0.000183105\n",
      "step 60410, training accuracy 0.96748\n",
      "step 60410, cost 5.24668\n",
      "step 60410, change in cost 0.000183105\n",
      "step 60420, training accuracy 0.96748\n",
      "step 60420, cost 5.2465\n",
      "step 60420, change in cost 0.000184059\n",
      "step 60430, training accuracy 0.96748\n",
      "step 60430, cost 5.24632\n",
      "step 60430, change in cost 0.000181675\n",
      "step 60440, training accuracy 0.96748\n",
      "step 60440, cost 5.24613\n",
      "step 60440, change in cost 0.000182629\n",
      "step 60450, training accuracy 0.96748\n",
      "step 60450, cost 5.24595\n",
      "step 60450, change in cost 0.000182629\n",
      "step 60460, training accuracy 0.96748\n",
      "step 60460, cost 5.24577\n",
      "step 60460, change in cost 0.000182629\n",
      "step 60470, training accuracy 0.96748\n",
      "step 60470, cost 5.24559\n",
      "step 60470, change in cost 0.000182152\n",
      "step 60480, training accuracy 0.96748\n",
      "step 60480, cost 5.2454\n",
      "step 60480, change in cost 0.000183582\n",
      "step 60490, training accuracy 0.96748\n",
      "step 60490, cost 5.24522\n",
      "step 60490, change in cost 0.000182152\n",
      "step 60500, training accuracy 0.96748\n",
      "step 60500, cost 5.24504\n",
      "step 60500, change in cost 0.000180721\n",
      "step 60510, training accuracy 0.96748\n",
      "step 60510, cost 5.24486\n",
      "step 60510, change in cost 0.000183105\n",
      "step 60520, training accuracy 0.96748\n",
      "step 60520, cost 5.24468\n",
      "step 60520, change in cost 0.000181198\n",
      "step 60530, training accuracy 0.96748\n",
      "step 60530, cost 5.24449\n",
      "step 60530, change in cost 0.000182152\n",
      "step 60540, training accuracy 0.96748\n",
      "step 60540, cost 5.24431\n",
      "step 60540, change in cost 0.000182152\n",
      "step 60550, training accuracy 0.96748\n",
      "step 60550, cost 5.24413\n",
      "step 60550, change in cost 0.000181198\n",
      "step 60560, training accuracy 0.96748\n",
      "step 60560, cost 5.24395\n",
      "step 60560, change in cost 0.000181198\n",
      "step 60570, training accuracy 0.96748\n",
      "step 60570, cost 5.24377\n",
      "step 60570, change in cost 0.000181198\n",
      "step 60580, training accuracy 0.96748\n",
      "step 60580, cost 5.24359\n",
      "step 60580, change in cost 0.000181198\n",
      "step 60590, training accuracy 0.96748\n",
      "step 60590, cost 5.24341\n",
      "step 60590, change in cost 0.000181198\n",
      "step 60600, training accuracy 0.96748\n",
      "step 60600, cost 5.24322\n",
      "step 60600, change in cost 0.000181675\n",
      "step 60610, training accuracy 0.96748\n",
      "step 60610, cost 5.24305\n",
      "step 60610, change in cost 0.000179291\n",
      "step 60620, training accuracy 0.96748\n",
      "step 60620, cost 5.24286\n",
      "step 60620, change in cost 0.000181675\n",
      "step 60630, training accuracy 0.96748\n",
      "step 60630, cost 5.24268\n",
      "step 60630, change in cost 0.000180244\n",
      "step 60640, training accuracy 0.96748\n",
      "step 60640, cost 5.2425\n",
      "step 60640, change in cost 0.000179768\n",
      "step 60650, training accuracy 0.96748\n",
      "step 60650, cost 5.24232\n",
      "step 60650, change in cost 0.000181675\n",
      "step 60660, training accuracy 0.96748\n",
      "step 60660, cost 5.24214\n",
      "step 60660, change in cost 0.000180244\n",
      "step 60670, training accuracy 0.96748\n",
      "step 60670, cost 5.24196\n",
      "step 60670, change in cost 0.000179291\n",
      "step 60680, training accuracy 0.96748\n",
      "step 60680, cost 5.24178\n",
      "step 60680, change in cost 0.000180721\n",
      "step 60690, training accuracy 0.96748\n",
      "step 60690, cost 5.2416\n",
      "step 60690, change in cost 0.000179768\n",
      "step 60700, training accuracy 0.96748\n",
      "step 60700, cost 5.24142\n",
      "step 60700, change in cost 0.000181198\n",
      "step 60710, training accuracy 0.96748\n",
      "step 60710, cost 5.24124\n",
      "step 60710, change in cost 0.000178337\n",
      "step 60720, training accuracy 0.96748\n",
      "step 60720, cost 5.24106\n",
      "step 60720, change in cost 0.000180244\n",
      "step 60730, training accuracy 0.96748\n",
      "step 60730, cost 5.24088\n",
      "step 60730, change in cost 0.000179291\n",
      "step 60740, training accuracy 0.96748\n",
      "step 60740, cost 5.2407\n",
      "step 60740, change in cost 0.000180721\n",
      "step 60750, training accuracy 0.96748\n",
      "step 60750, cost 5.24052\n",
      "step 60750, change in cost 0.000179768\n",
      "step 60760, training accuracy 0.96748\n",
      "step 60760, cost 5.24035\n",
      "step 60760, change in cost 0.000177383\n",
      "step 60770, training accuracy 0.96748\n",
      "step 60770, cost 5.24016\n",
      "step 60770, change in cost 0.000180244\n",
      "step 60780, training accuracy 0.96748\n",
      "step 60780, cost 5.23999\n",
      "step 60780, change in cost 0.000178814\n",
      "step 60790, training accuracy 0.96748\n",
      "step 60790, cost 5.23981\n",
      "step 60790, change in cost 0.000179768\n",
      "step 60800, training accuracy 0.96748\n",
      "step 60800, cost 5.23963\n",
      "step 60800, change in cost 0.000178337\n",
      "step 60810, training accuracy 0.96748\n",
      "step 60810, cost 5.23945\n",
      "step 60810, change in cost 0.000179291\n",
      "step 60820, training accuracy 0.96748\n",
      "step 60820, cost 5.23927\n",
      "step 60820, change in cost 0.00017786\n",
      "step 60830, training accuracy 0.96748\n",
      "step 60830, cost 5.23909\n",
      "step 60830, change in cost 0.000179768\n",
      "step 60840, training accuracy 0.96748\n",
      "step 60840, cost 5.23891\n",
      "step 60840, change in cost 0.00017786\n",
      "step 60850, training accuracy 0.96748\n",
      "step 60850, cost 5.23873\n",
      "step 60850, change in cost 0.000178814\n",
      "step 60860, training accuracy 0.96748\n",
      "step 60860, cost 5.23856\n",
      "step 60860, change in cost 0.00017786\n",
      "step 60870, training accuracy 0.96748\n",
      "step 60870, cost 5.23838\n",
      "step 60870, change in cost 0.000178814\n",
      "step 60880, training accuracy 0.96748\n",
      "step 60880, cost 5.2382\n",
      "step 60880, change in cost 0.000177383\n",
      "step 60890, training accuracy 0.96748\n",
      "step 60890, cost 5.23802\n",
      "step 60890, change in cost 0.000179291\n",
      "step 60900, training accuracy 0.96748\n",
      "step 60900, cost 5.23784\n",
      "step 60900, change in cost 0.000176907\n",
      "step 60910, training accuracy 0.96748\n",
      "step 60910, cost 5.23767\n",
      "step 60910, change in cost 0.00017786\n",
      "step 60920, training accuracy 0.96748\n",
      "step 60920, cost 5.23749\n",
      "step 60920, change in cost 0.000178337\n",
      "step 60930, training accuracy 0.96748\n",
      "step 60930, cost 5.23731\n",
      "step 60930, change in cost 0.000177383\n",
      "step 60940, training accuracy 0.96748\n",
      "step 60940, cost 5.23713\n",
      "step 60940, change in cost 0.000178337\n",
      "step 60950, training accuracy 0.96748\n",
      "step 60950, cost 5.23696\n",
      "step 60950, change in cost 0.00017643\n",
      "step 60960, training accuracy 0.96748\n",
      "step 60960, cost 5.23678\n",
      "step 60960, change in cost 0.000177383\n",
      "step 60970, training accuracy 0.96748\n",
      "step 60970, cost 5.2366\n",
      "step 60970, change in cost 0.000178814\n",
      "step 60980, training accuracy 0.96748\n",
      "step 60980, cost 5.23642\n",
      "step 60980, change in cost 0.00017643\n",
      "step 60990, training accuracy 0.96748\n",
      "step 60990, cost 5.23624\n",
      "step 60990, change in cost 0.000178337\n",
      "step 61000, training accuracy 0.96748\n",
      "step 61000, cost 5.23607\n",
      "step 61000, change in cost 0.00017643\n",
      "step 61010, training accuracy 0.96748\n",
      "step 61010, cost 5.23589\n",
      "step 61010, change in cost 0.00017786\n",
      "step 61020, training accuracy 0.96748\n",
      "step 61020, cost 5.23571\n",
      "step 61020, change in cost 0.000176907\n",
      "step 61030, training accuracy 0.96748\n",
      "step 61030, cost 5.23554\n",
      "step 61030, change in cost 0.000175476\n",
      "step 61040, training accuracy 0.96748\n",
      "step 61040, cost 5.23536\n",
      "step 61040, change in cost 0.00017643\n",
      "step 61050, training accuracy 0.96748\n",
      "step 61050, cost 5.23519\n",
      "step 61050, change in cost 0.000175953\n",
      "step 61060, training accuracy 0.96748\n",
      "step 61060, cost 5.23501\n",
      "step 61060, change in cost 0.00017643\n",
      "step 61070, training accuracy 0.96748\n",
      "step 61070, cost 5.23483\n",
      "step 61070, change in cost 0.000177383\n",
      "step 61080, training accuracy 0.96748\n",
      "step 61080, cost 5.23466\n",
      "step 61080, change in cost 0.000174522\n",
      "step 61090, training accuracy 0.96748\n",
      "step 61090, cost 5.23448\n",
      "step 61090, change in cost 0.00017643\n",
      "step 61100, training accuracy 0.96748\n",
      "step 61100, cost 5.2343\n",
      "step 61100, change in cost 0.000175953\n",
      "step 61110, training accuracy 0.96748\n",
      "step 61110, cost 5.23413\n",
      "step 61110, change in cost 0.000174999\n",
      "step 61120, training accuracy 0.96748\n",
      "step 61120, cost 5.23395\n",
      "step 61120, change in cost 0.000176907\n",
      "step 61130, training accuracy 0.96748\n",
      "step 61130, cost 5.23378\n",
      "step 61130, change in cost 0.000174999\n",
      "step 61140, training accuracy 0.96748\n",
      "step 61140, cost 5.2336\n",
      "step 61140, change in cost 0.000174522\n",
      "step 61150, training accuracy 0.96748\n",
      "step 61150, cost 5.23343\n",
      "step 61150, change in cost 0.000175476\n",
      "step 61160, training accuracy 0.96748\n",
      "step 61160, cost 5.23325\n",
      "step 61160, change in cost 0.000175476\n",
      "step 61170, training accuracy 0.96748\n",
      "step 61170, cost 5.23308\n",
      "step 61170, change in cost 0.000175953\n",
      "step 61180, training accuracy 0.96748\n",
      "step 61180, cost 5.2329\n",
      "step 61180, change in cost 0.000175953\n",
      "step 61190, training accuracy 0.96748\n",
      "step 61190, cost 5.23273\n",
      "step 61190, change in cost 0.000173569\n",
      "step 61200, training accuracy 0.96748\n",
      "step 61200, cost 5.23255\n",
      "step 61200, change in cost 0.000176907\n",
      "step 61210, training accuracy 0.96748\n",
      "step 61210, cost 5.23238\n",
      "step 61210, change in cost 0.000173569\n",
      "step 61220, training accuracy 0.96748\n",
      "step 61220, cost 5.2322\n",
      "step 61220, change in cost 0.000174999\n",
      "step 61230, training accuracy 0.96748\n",
      "step 61230, cost 5.23203\n",
      "step 61230, change in cost 0.000174999\n",
      "step 61240, training accuracy 0.96748\n",
      "step 61240, cost 5.23185\n",
      "step 61240, change in cost 0.000174046\n",
      "step 61250, training accuracy 0.96748\n",
      "step 61250, cost 5.23168\n",
      "step 61250, change in cost 0.000174522\n",
      "step 61260, training accuracy 0.96748\n",
      "step 61260, cost 5.2315\n",
      "step 61260, change in cost 0.000174522\n",
      "step 61270, training accuracy 0.96748\n",
      "step 61270, cost 5.23133\n",
      "step 61270, change in cost 0.000174046\n",
      "step 61280, training accuracy 0.96748\n",
      "step 61280, cost 5.23116\n",
      "step 61280, change in cost 0.000174046\n",
      "step 61290, training accuracy 0.96748\n",
      "step 61290, cost 5.23098\n",
      "step 61290, change in cost 0.000173569\n",
      "step 61300, training accuracy 0.96748\n",
      "step 61300, cost 5.23081\n",
      "step 61300, change in cost 0.000174522\n",
      "step 61310, training accuracy 0.96748\n",
      "step 61310, cost 5.23063\n",
      "step 61310, change in cost 0.000173569\n",
      "step 61320, training accuracy 0.96748\n",
      "step 61320, cost 5.23046\n",
      "step 61320, change in cost 0.000173569\n",
      "step 61330, training accuracy 0.96748\n",
      "step 61330, cost 5.23029\n",
      "step 61330, change in cost 0.000173092\n",
      "step 61340, training accuracy 0.96748\n",
      "step 61340, cost 5.23011\n",
      "step 61340, change in cost 0.000174046\n",
      "step 61350, training accuracy 0.96748\n",
      "step 61350, cost 5.22994\n",
      "step 61350, change in cost 0.000174046\n",
      "step 61360, training accuracy 0.96748\n",
      "step 61360, cost 5.22976\n",
      "step 61360, change in cost 0.000174046\n",
      "step 61370, training accuracy 0.96748\n",
      "step 61370, cost 5.22959\n",
      "step 61370, change in cost 0.000172615\n",
      "step 61380, training accuracy 0.96748\n",
      "step 61380, cost 5.22942\n",
      "step 61380, change in cost 0.000171661\n",
      "step 61390, training accuracy 0.96748\n",
      "step 61390, cost 5.22925\n",
      "step 61390, change in cost 0.000174046\n",
      "step 61400, training accuracy 0.96748\n",
      "step 61400, cost 5.22907\n",
      "step 61400, change in cost 0.000174046\n",
      "step 61410, training accuracy 0.96748\n",
      "step 61410, cost 5.2289\n",
      "step 61410, change in cost 0.000172138\n",
      "step 61420, training accuracy 0.96748\n",
      "step 61420, cost 5.22873\n",
      "step 61420, change in cost 0.000172615\n",
      "step 61430, training accuracy 0.96748\n",
      "step 61430, cost 5.22855\n",
      "step 61430, change in cost 0.000173092\n",
      "step 61440, training accuracy 0.96748\n",
      "step 61440, cost 5.22838\n",
      "step 61440, change in cost 0.000173092\n",
      "step 61450, training accuracy 0.96748\n",
      "step 61450, cost 5.22821\n",
      "step 61450, change in cost 0.000172138\n",
      "step 61460, training accuracy 0.96748\n",
      "step 61460, cost 5.22804\n",
      "step 61460, change in cost 0.000172615\n",
      "step 61470, training accuracy 0.96748\n",
      "step 61470, cost 5.22787\n",
      "step 61470, change in cost 0.000171661\n",
      "step 61480, training accuracy 0.96748\n",
      "step 61480, cost 5.22769\n",
      "step 61480, change in cost 0.000173092\n",
      "step 61490, training accuracy 0.96748\n",
      "step 61490, cost 5.22752\n",
      "step 61490, change in cost 0.000172138\n",
      "step 61500, training accuracy 0.96748\n",
      "step 61500, cost 5.22735\n",
      "step 61500, change in cost 0.000172615\n",
      "step 61510, training accuracy 0.96748\n",
      "step 61510, cost 5.22717\n",
      "step 61510, change in cost 0.000172615\n",
      "step 61520, training accuracy 0.96748\n",
      "step 61520, cost 5.227\n",
      "step 61520, change in cost 0.000171185\n",
      "step 61530, training accuracy 0.96748\n",
      "step 61530, cost 5.22683\n",
      "step 61530, change in cost 0.000172138\n",
      "step 61540, training accuracy 0.96748\n",
      "step 61540, cost 5.22666\n",
      "step 61540, change in cost 0.000172138\n",
      "step 61550, training accuracy 0.96748\n",
      "step 61550, cost 5.22649\n",
      "step 61550, change in cost 0.000172138\n",
      "step 61560, training accuracy 0.96748\n",
      "step 61560, cost 5.22632\n",
      "step 61560, change in cost 0.000170708\n",
      "step 61570, training accuracy 0.96748\n",
      "step 61570, cost 5.22614\n",
      "step 61570, change in cost 0.000172615\n",
      "step 61580, training accuracy 0.96748\n",
      "step 61580, cost 5.22597\n",
      "step 61580, change in cost 0.000170708\n",
      "step 61590, training accuracy 0.96748\n",
      "step 61590, cost 5.2258\n",
      "step 61590, change in cost 0.000170708\n",
      "step 61600, training accuracy 0.96748\n",
      "step 61600, cost 5.22563\n",
      "step 61600, change in cost 0.000170708\n",
      "step 61610, training accuracy 0.96748\n",
      "step 61610, cost 5.22546\n",
      "step 61610, change in cost 0.000171661\n",
      "step 61620, training accuracy 0.96748\n",
      "step 61620, cost 5.22529\n",
      "step 61620, change in cost 0.000169754\n",
      "step 61630, training accuracy 0.96748\n",
      "step 61630, cost 5.22512\n",
      "step 61630, change in cost 0.000173092\n",
      "step 61640, training accuracy 0.96748\n",
      "step 61640, cost 5.22495\n",
      "step 61640, change in cost 0.000170708\n",
      "step 61650, training accuracy 0.96748\n",
      "step 61650, cost 5.22478\n",
      "step 61650, change in cost 0.000170231\n",
      "step 61660, training accuracy 0.96748\n",
      "step 61660, cost 5.22461\n",
      "step 61660, change in cost 0.000170708\n",
      "step 61670, training accuracy 0.96748\n",
      "step 61670, cost 5.22444\n",
      "step 61670, change in cost 0.000170231\n",
      "step 61680, training accuracy 0.96748\n",
      "step 61680, cost 5.22427\n",
      "step 61680, change in cost 0.000169277\n",
      "step 61690, training accuracy 0.96748\n",
      "step 61690, cost 5.2241\n",
      "step 61690, change in cost 0.000170708\n",
      "step 61700, training accuracy 0.96748\n",
      "step 61700, cost 5.22393\n",
      "step 61700, change in cost 0.000169754\n",
      "step 61710, training accuracy 0.96748\n",
      "step 61710, cost 5.22375\n",
      "step 61710, change in cost 0.000170708\n",
      "step 61720, training accuracy 0.96748\n",
      "step 61720, cost 5.22358\n",
      "step 61720, change in cost 0.000170708\n",
      "step 61730, training accuracy 0.96748\n",
      "step 61730, cost 5.22341\n",
      "step 61730, change in cost 0.000169754\n",
      "step 61740, training accuracy 0.96748\n",
      "step 61740, cost 5.22324\n",
      "step 61740, change in cost 0.000169754\n",
      "step 61750, training accuracy 0.96748\n",
      "step 61750, cost 5.22307\n",
      "step 61750, change in cost 0.000170708\n",
      "step 61760, training accuracy 0.96748\n",
      "step 61760, cost 5.2229\n",
      "step 61760, change in cost 0.000169754\n",
      "step 61770, training accuracy 0.96748\n",
      "step 61770, cost 5.22274\n",
      "step 61770, change in cost 0.0001688\n",
      "step 61780, training accuracy 0.96748\n",
      "step 61780, cost 5.22256\n",
      "step 61780, change in cost 0.000171185\n",
      "step 61790, training accuracy 0.96748\n",
      "step 61790, cost 5.2224\n",
      "step 61790, change in cost 0.000168324\n",
      "step 61800, training accuracy 0.96748\n",
      "step 61800, cost 5.22223\n",
      "step 61800, change in cost 0.000170231\n",
      "step 61810, training accuracy 0.96748\n",
      "step 61810, cost 5.22206\n",
      "step 61810, change in cost 0.000169277\n",
      "step 61820, training accuracy 0.96748\n",
      "step 61820, cost 5.22189\n",
      "step 61820, change in cost 0.000169754\n",
      "step 61830, training accuracy 0.96748\n",
      "step 61830, cost 5.22172\n",
      "step 61830, change in cost 0.000168324\n",
      "step 61840, training accuracy 0.96748\n",
      "step 61840, cost 5.22155\n",
      "step 61840, change in cost 0.000169277\n",
      "step 61850, training accuracy 0.96748\n",
      "step 61850, cost 5.22138\n",
      "step 61850, change in cost 0.000169754\n",
      "step 61860, training accuracy 0.96748\n",
      "step 61860, cost 5.22121\n",
      "step 61860, change in cost 0.000169277\n",
      "step 61870, training accuracy 0.96748\n",
      "step 61870, cost 5.22104\n",
      "step 61870, change in cost 0.0001688\n",
      "step 61880, training accuracy 0.96748\n",
      "step 61880, cost 5.22087\n",
      "step 61880, change in cost 0.000168324\n",
      "step 61890, training accuracy 0.96748\n",
      "step 61890, cost 5.2207\n",
      "step 61890, change in cost 0.000168324\n",
      "step 61900, training accuracy 0.96748\n",
      "step 61900, cost 5.22054\n",
      "step 61900, change in cost 0.000169277\n",
      "step 61910, training accuracy 0.96748\n",
      "step 61910, cost 5.22037\n",
      "step 61910, change in cost 0.000167847\n",
      "step 61920, training accuracy 0.96748\n",
      "step 61920, cost 5.2202\n",
      "step 61920, change in cost 0.000168324\n",
      "step 61930, training accuracy 0.96748\n",
      "step 61930, cost 5.22003\n",
      "step 61930, change in cost 0.000169277\n",
      "step 61940, training accuracy 0.96748\n",
      "step 61940, cost 5.21986\n",
      "step 61940, change in cost 0.000167847\n",
      "step 61950, training accuracy 0.96748\n",
      "step 61950, cost 5.21969\n",
      "step 61950, change in cost 0.0001688\n",
      "step 61960, training accuracy 0.96748\n",
      "step 61960, cost 5.21952\n",
      "step 61960, change in cost 0.000168324\n",
      "step 61970, training accuracy 0.96748\n",
      "step 61970, cost 5.21936\n",
      "step 61970, change in cost 0.000166893\n",
      "step 61980, training accuracy 0.96748\n",
      "step 61980, cost 5.21919\n",
      "step 61980, change in cost 0.000167847\n",
      "step 61990, training accuracy 0.96748\n",
      "step 61990, cost 5.21902\n",
      "step 61990, change in cost 0.00016737\n",
      "step 62000, training accuracy 0.96748\n",
      "step 62000, cost 5.21885\n",
      "step 62000, change in cost 0.000169277\n",
      "step 62010, training accuracy 0.96748\n",
      "step 62010, cost 5.21869\n",
      "step 62010, change in cost 0.00016737\n",
      "step 62020, training accuracy 0.96748\n",
      "step 62020, cost 5.21852\n",
      "step 62020, change in cost 0.000168324\n",
      "step 62030, training accuracy 0.96748\n",
      "step 62030, cost 5.21835\n",
      "step 62030, change in cost 0.000165462\n",
      "step 62040, training accuracy 0.96748\n",
      "step 62040, cost 5.21818\n",
      "step 62040, change in cost 0.000168324\n",
      "step 62050, training accuracy 0.96748\n",
      "step 62050, cost 5.21802\n",
      "step 62050, change in cost 0.000166416\n",
      "step 62060, training accuracy 0.96748\n",
      "step 62060, cost 5.21785\n",
      "step 62060, change in cost 0.00016737\n",
      "step 62070, training accuracy 0.96748\n",
      "step 62070, cost 5.21768\n",
      "step 62070, change in cost 0.000166416\n",
      "step 62080, training accuracy 0.96748\n",
      "step 62080, cost 5.21752\n",
      "step 62080, change in cost 0.000168324\n",
      "step 62090, training accuracy 0.96748\n",
      "step 62090, cost 5.21735\n",
      "step 62090, change in cost 0.000166416\n",
      "step 62100, training accuracy 0.96748\n",
      "step 62100, cost 5.21718\n",
      "step 62100, change in cost 0.000167847\n",
      "step 62110, training accuracy 0.96748\n",
      "step 62110, cost 5.21701\n",
      "step 62110, change in cost 0.000166416\n",
      "step 62120, training accuracy 0.96748\n",
      "step 62120, cost 5.21685\n",
      "step 62120, change in cost 0.00016737\n",
      "step 62130, training accuracy 0.96748\n",
      "step 62130, cost 5.21668\n",
      "step 62130, change in cost 0.000165939\n",
      "step 62140, training accuracy 0.96748\n",
      "step 62140, cost 5.21651\n",
      "step 62140, change in cost 0.000167847\n",
      "step 62150, training accuracy 0.96748\n",
      "step 62150, cost 5.21635\n",
      "step 62150, change in cost 0.000166893\n",
      "step 62160, training accuracy 0.96748\n",
      "step 62160, cost 5.21618\n",
      "step 62160, change in cost 0.000165939\n",
      "step 62170, training accuracy 0.96748\n",
      "step 62170, cost 5.21601\n",
      "step 62170, change in cost 0.000166893\n",
      "step 62180, training accuracy 0.96748\n",
      "step 62180, cost 5.21585\n",
      "step 62180, change in cost 0.000165462\n",
      "step 62190, training accuracy 0.96748\n",
      "step 62190, cost 5.21568\n",
      "step 62190, change in cost 0.000165462\n",
      "step 62200, training accuracy 0.96748\n",
      "step 62200, cost 5.21552\n",
      "step 62200, change in cost 0.000166893\n",
      "step 62210, training accuracy 0.96748\n",
      "step 62210, cost 5.21535\n",
      "step 62210, change in cost 0.000165939\n",
      "step 62220, training accuracy 0.96748\n",
      "step 62220, cost 5.21518\n",
      "step 62220, change in cost 0.000166893\n",
      "step 62230, training accuracy 0.96748\n",
      "step 62230, cost 5.21502\n",
      "step 62230, change in cost 0.000164986\n",
      "step 62240, training accuracy 0.96748\n",
      "step 62240, cost 5.21485\n",
      "step 62240, change in cost 0.000165939\n",
      "step 62250, training accuracy 0.96748\n",
      "step 62250, cost 5.21469\n",
      "step 62250, change in cost 0.000166416\n",
      "step 62260, training accuracy 0.96748\n",
      "step 62260, cost 5.21452\n",
      "step 62260, change in cost 0.000165462\n",
      "step 62270, training accuracy 0.96748\n",
      "step 62270, cost 5.21435\n",
      "step 62270, change in cost 0.000165939\n",
      "step 62280, training accuracy 0.96748\n",
      "step 62280, cost 5.21419\n",
      "step 62280, change in cost 0.000164509\n",
      "step 62290, training accuracy 0.96748\n",
      "step 62290, cost 5.21402\n",
      "step 62290, change in cost 0.000165939\n",
      "step 62300, training accuracy 0.96748\n",
      "step 62300, cost 5.21386\n",
      "step 62300, change in cost 0.000164986\n",
      "step 62310, training accuracy 0.96748\n",
      "step 62310, cost 5.21369\n",
      "step 62310, change in cost 0.00016737\n",
      "step 62320, training accuracy 0.96748\n",
      "step 62320, cost 5.21353\n",
      "step 62320, change in cost 0.000164032\n",
      "step 62330, training accuracy 0.96748\n",
      "step 62330, cost 5.21336\n",
      "step 62330, change in cost 0.000164509\n",
      "step 62340, training accuracy 0.96748\n",
      "step 62340, cost 5.2132\n",
      "step 62340, change in cost 0.000165462\n",
      "step 62350, training accuracy 0.96748\n",
      "step 62350, cost 5.21303\n",
      "step 62350, change in cost 0.000164032\n",
      "step 62360, training accuracy 0.96748\n",
      "step 62360, cost 5.21287\n",
      "step 62360, change in cost 0.000165939\n",
      "step 62370, training accuracy 0.96748\n",
      "step 62370, cost 5.2127\n",
      "step 62370, change in cost 0.000164032\n",
      "step 62380, training accuracy 0.96748\n",
      "step 62380, cost 5.21254\n",
      "step 62380, change in cost 0.000164986\n",
      "step 62390, training accuracy 0.96748\n",
      "step 62390, cost 5.21237\n",
      "step 62390, change in cost 0.000164986\n",
      "step 62400, training accuracy 0.96748\n",
      "step 62400, cost 5.21221\n",
      "step 62400, change in cost 0.000164032\n",
      "step 62410, training accuracy 0.96748\n",
      "step 62410, cost 5.21205\n",
      "step 62410, change in cost 0.000164032\n",
      "step 62420, training accuracy 0.96748\n",
      "step 62420, cost 5.21188\n",
      "step 62420, change in cost 0.000164509\n",
      "step 62430, training accuracy 0.96748\n",
      "step 62430, cost 5.21172\n",
      "step 62430, change in cost 0.000164032\n",
      "step 62440, training accuracy 0.96748\n",
      "step 62440, cost 5.21155\n",
      "step 62440, change in cost 0.000163555\n",
      "step 62450, training accuracy 0.96748\n",
      "step 62450, cost 5.21139\n",
      "step 62450, change in cost 0.000164986\n",
      "step 62460, training accuracy 0.96748\n",
      "step 62460, cost 5.21122\n",
      "step 62460, change in cost 0.000164032\n",
      "step 62470, training accuracy 0.96748\n",
      "step 62470, cost 5.21106\n",
      "step 62470, change in cost 0.000163078\n",
      "step 62480, training accuracy 0.96748\n",
      "step 62480, cost 5.2109\n",
      "step 62480, change in cost 0.000164986\n",
      "step 62490, training accuracy 0.96748\n",
      "step 62490, cost 5.21073\n",
      "step 62490, change in cost 0.000164032\n",
      "step 62500, training accuracy 0.96748\n",
      "step 62500, cost 5.21057\n",
      "step 62500, change in cost 0.000164032\n",
      "step 62510, training accuracy 0.96748\n",
      "step 62510, cost 5.21041\n",
      "step 62510, change in cost 0.000162601\n",
      "step 62520, training accuracy 0.96748\n",
      "step 62520, cost 5.21024\n",
      "step 62520, change in cost 0.000164509\n",
      "step 62530, training accuracy 0.96748\n",
      "step 62530, cost 5.21008\n",
      "step 62530, change in cost 0.000162601\n",
      "step 62540, training accuracy 0.96748\n",
      "step 62540, cost 5.20992\n",
      "step 62540, change in cost 0.000162601\n",
      "step 62550, training accuracy 0.96748\n",
      "step 62550, cost 5.20975\n",
      "step 62550, change in cost 0.000164032\n",
      "step 62560, training accuracy 0.96748\n",
      "step 62560, cost 5.20959\n",
      "step 62560, change in cost 0.000164032\n",
      "step 62570, training accuracy 0.96748\n",
      "step 62570, cost 5.20943\n",
      "step 62570, change in cost 0.000162601\n",
      "step 62580, training accuracy 0.96748\n",
      "step 62580, cost 5.20926\n",
      "step 62580, change in cost 0.000163555\n",
      "step 62590, training accuracy 0.96748\n",
      "step 62590, cost 5.2091\n",
      "step 62590, change in cost 0.000163078\n",
      "step 62600, training accuracy 0.96748\n",
      "step 62600, cost 5.20894\n",
      "step 62600, change in cost 0.000162601\n",
      "step 62610, training accuracy 0.96748\n",
      "step 62610, cost 5.20877\n",
      "step 62610, change in cost 0.000162601\n",
      "step 62620, training accuracy 0.96748\n",
      "step 62620, cost 5.20861\n",
      "step 62620, change in cost 0.000163555\n",
      "step 62630, training accuracy 0.96748\n",
      "step 62630, cost 5.20845\n",
      "step 62630, change in cost 0.000161648\n",
      "step 62640, training accuracy 0.96748\n",
      "step 62640, cost 5.20829\n",
      "step 62640, change in cost 0.000163078\n",
      "step 62650, training accuracy 0.96748\n",
      "step 62650, cost 5.20812\n",
      "step 62650, change in cost 0.000163078\n",
      "step 62660, training accuracy 0.96748\n",
      "step 62660, cost 5.20796\n",
      "step 62660, change in cost 0.000161171\n",
      "step 62670, training accuracy 0.96748\n",
      "step 62670, cost 5.2078\n",
      "step 62670, change in cost 0.000163555\n",
      "step 62680, training accuracy 0.96748\n",
      "step 62680, cost 5.20763\n",
      "step 62680, change in cost 0.000162601\n",
      "step 62690, training accuracy 0.96748\n",
      "step 62690, cost 5.20747\n",
      "step 62690, change in cost 0.000161171\n",
      "step 62700, training accuracy 0.96748\n",
      "step 62700, cost 5.20731\n",
      "step 62700, change in cost 0.000163555\n",
      "step 62710, training accuracy 0.96748\n",
      "step 62710, cost 5.20715\n",
      "step 62710, change in cost 0.000160694\n",
      "step 62720, training accuracy 0.96748\n",
      "step 62720, cost 5.20699\n",
      "step 62720, change in cost 0.000163078\n",
      "step 62730, training accuracy 0.96748\n",
      "step 62730, cost 5.20683\n",
      "step 62730, change in cost 0.000161171\n",
      "step 62740, training accuracy 0.96748\n",
      "step 62740, cost 5.20666\n",
      "step 62740, change in cost 0.000163078\n",
      "step 62750, training accuracy 0.96748\n",
      "step 62750, cost 5.2065\n",
      "step 62750, change in cost 0.000161171\n",
      "step 62760, training accuracy 0.96748\n",
      "step 62760, cost 5.20634\n",
      "step 62760, change in cost 0.000162125\n",
      "step 62770, training accuracy 0.96748\n",
      "step 62770, cost 5.20618\n",
      "step 62770, change in cost 0.000160694\n",
      "step 62780, training accuracy 0.96748\n",
      "step 62780, cost 5.20602\n",
      "step 62780, change in cost 0.000161648\n",
      "step 62790, training accuracy 0.96748\n",
      "step 62790, cost 5.20585\n",
      "step 62790, change in cost 0.000161648\n",
      "step 62800, training accuracy 0.96748\n",
      "step 62800, cost 5.20569\n",
      "step 62800, change in cost 0.000161648\n",
      "step 62810, training accuracy 0.96748\n",
      "step 62810, cost 5.20553\n",
      "step 62810, change in cost 0.000160694\n",
      "step 62820, training accuracy 0.96748\n",
      "step 62820, cost 5.20537\n",
      "step 62820, change in cost 0.000161648\n",
      "step 62830, training accuracy 0.96748\n",
      "step 62830, cost 5.20521\n",
      "step 62830, change in cost 0.000161171\n",
      "step 62840, training accuracy 0.96748\n",
      "step 62840, cost 5.20505\n",
      "step 62840, change in cost 0.000162125\n",
      "step 62850, training accuracy 0.96748\n",
      "step 62850, cost 5.20489\n",
      "step 62850, change in cost 0.000160217\n",
      "step 62860, training accuracy 0.96748\n",
      "step 62860, cost 5.20473\n",
      "step 62860, change in cost 0.000161171\n",
      "step 62870, training accuracy 0.96748\n",
      "step 62870, cost 5.20457\n",
      "step 62870, change in cost 0.000160217\n",
      "step 62880, training accuracy 0.96748\n",
      "step 62880, cost 5.20441\n",
      "step 62880, change in cost 0.000160694\n",
      "step 62890, training accuracy 0.96748\n",
      "step 62890, cost 5.20424\n",
      "step 62890, change in cost 0.000161648\n",
      "step 62900, training accuracy 0.96748\n",
      "step 62900, cost 5.20408\n",
      "step 62900, change in cost 0.000160217\n",
      "step 62910, training accuracy 0.96748\n",
      "step 62910, cost 5.20392\n",
      "step 62910, change in cost 0.000160217\n",
      "step 62920, training accuracy 0.96748\n",
      "step 62920, cost 5.20376\n",
      "step 62920, change in cost 0.000160694\n",
      "step 62930, training accuracy 0.96748\n",
      "step 62930, cost 5.2036\n",
      "step 62930, change in cost 0.000161171\n",
      "step 62940, training accuracy 0.96748\n",
      "step 62940, cost 5.20344\n",
      "step 62940, change in cost 0.00015974\n",
      "step 62950, training accuracy 0.96748\n",
      "step 62950, cost 5.20328\n",
      "step 62950, change in cost 0.000160694\n",
      "step 62960, training accuracy 0.96748\n",
      "step 62960, cost 5.20312\n",
      "step 62960, change in cost 0.00015974\n",
      "step 62970, training accuracy 0.96748\n",
      "step 62970, cost 5.20296\n",
      "step 62970, change in cost 0.000160217\n",
      "step 62980, training accuracy 0.96748\n",
      "step 62980, cost 5.2028\n",
      "step 62980, change in cost 0.000158787\n",
      "step 62990, training accuracy 0.96748\n",
      "step 62990, cost 5.20264\n",
      "step 62990, change in cost 0.000160694\n",
      "step 63000, training accuracy 0.96748\n",
      "step 63000, cost 5.20248\n",
      "step 63000, change in cost 0.000160217\n",
      "step 63010, training accuracy 0.96748\n",
      "step 63010, cost 5.20232\n",
      "step 63010, change in cost 0.00015974\n",
      "step 63020, training accuracy 0.96748\n",
      "step 63020, cost 5.20216\n",
      "step 63020, change in cost 0.00015974\n",
      "step 63030, training accuracy 0.96748\n",
      "step 63030, cost 5.202\n",
      "step 63030, change in cost 0.000160217\n",
      "step 63040, training accuracy 0.96748\n",
      "step 63040, cost 5.20184\n",
      "step 63040, change in cost 0.00015974\n",
      "step 63050, training accuracy 0.96748\n",
      "step 63050, cost 5.20168\n",
      "step 63050, change in cost 0.00015831\n",
      "step 63060, training accuracy 0.96748\n",
      "step 63060, cost 5.20152\n",
      "step 63060, change in cost 0.000160217\n",
      "step 63070, training accuracy 0.96748\n",
      "step 63070, cost 5.20136\n",
      "step 63070, change in cost 0.000159264\n",
      "step 63080, training accuracy 0.96748\n",
      "step 63080, cost 5.2012\n",
      "step 63080, change in cost 0.000160217\n",
      "step 63090, training accuracy 0.96748\n",
      "step 63090, cost 5.20105\n",
      "step 63090, change in cost 0.000158787\n",
      "step 63100, training accuracy 0.96748\n",
      "step 63100, cost 5.20089\n",
      "step 63100, change in cost 0.00015974\n",
      "step 63110, training accuracy 0.96748\n",
      "step 63110, cost 5.20073\n",
      "step 63110, change in cost 0.000158787\n",
      "step 63120, training accuracy 0.96748\n",
      "step 63120, cost 5.20057\n",
      "step 63120, change in cost 0.000160217\n",
      "step 63130, training accuracy 0.96748\n",
      "step 63130, cost 5.20041\n",
      "step 63130, change in cost 0.00015831\n",
      "step 63140, training accuracy 0.96748\n",
      "step 63140, cost 5.20025\n",
      "step 63140, change in cost 0.000159264\n",
      "step 63150, training accuracy 0.96748\n",
      "step 63150, cost 5.20009\n",
      "step 63150, change in cost 0.00015831\n",
      "step 63160, training accuracy 0.96748\n",
      "step 63160, cost 5.19993\n",
      "step 63160, change in cost 0.000159264\n",
      "step 63170, training accuracy 0.96748\n",
      "step 63170, cost 5.19977\n",
      "step 63170, change in cost 0.000159264\n",
      "step 63180, training accuracy 0.96748\n",
      "step 63180, cost 5.19961\n",
      "step 63180, change in cost 0.000159264\n",
      "step 63190, training accuracy 0.96748\n",
      "step 63190, cost 5.19945\n",
      "step 63190, change in cost 0.000158787\n",
      "step 63200, training accuracy 0.96748\n",
      "step 63200, cost 5.1993\n",
      "step 63200, change in cost 0.000158787\n",
      "step 63210, training accuracy 0.96748\n",
      "step 63210, cost 5.19914\n",
      "step 63210, change in cost 0.000157833\n",
      "step 63220, training accuracy 0.96748\n",
      "step 63220, cost 5.19898\n",
      "step 63220, change in cost 0.000157833\n",
      "step 63230, training accuracy 0.96748\n",
      "step 63230, cost 5.19882\n",
      "step 63230, change in cost 0.00015831\n",
      "step 63240, training accuracy 0.96748\n",
      "step 63240, cost 5.19866\n",
      "step 63240, change in cost 0.000159264\n",
      "step 63250, training accuracy 0.96748\n",
      "step 63250, cost 5.1985\n",
      "step 63250, change in cost 0.000157833\n",
      "step 63260, training accuracy 0.96748\n",
      "step 63260, cost 5.19835\n",
      "step 63260, change in cost 0.000157833\n",
      "step 63270, training accuracy 0.96748\n",
      "step 63270, cost 5.19819\n",
      "step 63270, change in cost 0.00015831\n",
      "step 63280, training accuracy 0.96748\n",
      "step 63280, cost 5.19803\n",
      "step 63280, change in cost 0.000157833\n",
      "step 63290, training accuracy 0.96748\n",
      "step 63290, cost 5.19787\n",
      "step 63290, change in cost 0.000157833\n",
      "step 63300, training accuracy 0.96748\n",
      "step 63300, cost 5.19771\n",
      "step 63300, change in cost 0.000157833\n",
      "step 63310, training accuracy 0.96748\n",
      "step 63310, cost 5.19756\n",
      "step 63310, change in cost 0.000157833\n",
      "step 63320, training accuracy 0.96748\n",
      "step 63320, cost 5.1974\n",
      "step 63320, change in cost 0.000157356\n",
      "step 63330, training accuracy 0.96748\n",
      "step 63330, cost 5.19724\n",
      "step 63330, change in cost 0.000157833\n",
      "step 63340, training accuracy 0.96748\n",
      "step 63340, cost 5.19708\n",
      "step 63340, change in cost 0.000158787\n",
      "step 63350, training accuracy 0.96748\n",
      "step 63350, cost 5.19693\n",
      "step 63350, change in cost 0.000155926\n",
      "step 63360, training accuracy 0.96748\n",
      "step 63360, cost 5.19677\n",
      "step 63360, change in cost 0.000157833\n",
      "step 63370, training accuracy 0.96748\n",
      "step 63370, cost 5.19661\n",
      "step 63370, change in cost 0.00015831\n",
      "step 63380, training accuracy 0.96748\n",
      "step 63380, cost 5.19646\n",
      "step 63380, change in cost 0.000155449\n",
      "step 63390, training accuracy 0.96748\n",
      "step 63390, cost 5.1963\n",
      "step 63390, change in cost 0.00015831\n",
      "step 63400, training accuracy 0.96748\n",
      "step 63400, cost 5.19614\n",
      "step 63400, change in cost 0.000156403\n",
      "step 63410, training accuracy 0.96748\n",
      "step 63410, cost 5.19598\n",
      "step 63410, change in cost 0.000157833\n",
      "step 63420, training accuracy 0.96748\n",
      "step 63420, cost 5.19583\n",
      "step 63420, change in cost 0.000156879\n",
      "step 63430, training accuracy 0.96748\n",
      "step 63430, cost 5.19567\n",
      "step 63430, change in cost 0.000156879\n",
      "step 63440, training accuracy 0.96748\n",
      "step 63440, cost 5.19551\n",
      "step 63440, change in cost 0.000156879\n",
      "step 63450, training accuracy 0.96748\n",
      "step 63450, cost 5.19536\n",
      "step 63450, change in cost 0.000156403\n",
      "step 63460, training accuracy 0.96748\n",
      "step 63460, cost 5.1952\n",
      "step 63460, change in cost 0.000155926\n",
      "step 63470, training accuracy 0.96748\n",
      "step 63470, cost 5.19504\n",
      "step 63470, change in cost 0.00015831\n",
      "step 63480, training accuracy 0.96748\n",
      "step 63480, cost 5.19488\n",
      "step 63480, change in cost 0.000156879\n",
      "step 63490, training accuracy 0.96748\n",
      "step 63490, cost 5.19473\n",
      "step 63490, change in cost 0.000155449\n",
      "step 63500, training accuracy 0.96748\n",
      "step 63500, cost 5.19457\n",
      "step 63500, change in cost 0.000156403\n",
      "step 63510, training accuracy 0.96748\n",
      "step 63510, cost 5.19442\n",
      "step 63510, change in cost 0.000156403\n",
      "step 63520, training accuracy 0.96748\n",
      "step 63520, cost 5.19426\n",
      "step 63520, change in cost 0.000156403\n",
      "step 63530, training accuracy 0.96748\n",
      "step 63530, cost 5.1941\n",
      "step 63530, change in cost 0.000156879\n",
      "step 63540, training accuracy 0.96748\n",
      "step 63540, cost 5.19395\n",
      "step 63540, change in cost 0.000155926\n",
      "step 63550, training accuracy 0.96748\n",
      "step 63550, cost 5.19379\n",
      "step 63550, change in cost 0.000156403\n",
      "step 63560, training accuracy 0.96748\n",
      "step 63560, cost 5.19363\n",
      "step 63560, change in cost 0.000156403\n",
      "step 63570, training accuracy 0.96748\n",
      "step 63570, cost 5.19348\n",
      "step 63570, change in cost 0.000156879\n",
      "step 63580, training accuracy 0.96748\n",
      "step 63580, cost 5.19332\n",
      "step 63580, change in cost 0.000155926\n",
      "step 63590, training accuracy 0.96748\n",
      "step 63590, cost 5.19317\n",
      "step 63590, change in cost 0.000155449\n",
      "step 63600, training accuracy 0.96748\n",
      "step 63600, cost 5.19301\n",
      "step 63600, change in cost 0.000156403\n",
      "step 63610, training accuracy 0.96748\n",
      "step 63610, cost 5.19285\n",
      "step 63610, change in cost 0.000155449\n",
      "step 63620, training accuracy 0.96748\n",
      "step 63620, cost 5.1927\n",
      "step 63620, change in cost 0.000154972\n",
      "step 63630, training accuracy 0.96748\n",
      "step 63630, cost 5.19254\n",
      "step 63630, change in cost 0.000155449\n",
      "step 63640, training accuracy 0.96748\n",
      "step 63640, cost 5.19239\n",
      "step 63640, change in cost 0.000155926\n",
      "step 63650, training accuracy 0.96748\n",
      "step 63650, cost 5.19223\n",
      "step 63650, change in cost 0.000154972\n",
      "step 63660, training accuracy 0.96748\n",
      "step 63660, cost 5.19208\n",
      "step 63660, change in cost 0.000156879\n",
      "step 63670, training accuracy 0.96748\n",
      "step 63670, cost 5.19192\n",
      "step 63670, change in cost 0.000155449\n",
      "step 63680, training accuracy 0.96748\n",
      "step 63680, cost 5.19176\n",
      "step 63680, change in cost 0.000155449\n",
      "step 63690, training accuracy 0.96748\n",
      "step 63690, cost 5.19161\n",
      "step 63690, change in cost 0.000154972\n",
      "step 63700, training accuracy 0.96748\n",
      "step 63700, cost 5.19145\n",
      "step 63700, change in cost 0.000154972\n",
      "step 63710, training accuracy 0.96748\n",
      "step 63710, cost 5.1913\n",
      "step 63710, change in cost 0.000154495\n",
      "step 63720, training accuracy 0.96748\n",
      "step 63720, cost 5.19114\n",
      "step 63720, change in cost 0.000155449\n",
      "step 63730, training accuracy 0.96748\n",
      "step 63730, cost 5.19099\n",
      "step 63730, change in cost 0.000154495\n",
      "step 63740, training accuracy 0.96748\n",
      "step 63740, cost 5.19083\n",
      "step 63740, change in cost 0.000155926\n",
      "step 63750, training accuracy 0.96748\n",
      "step 63750, cost 5.19068\n",
      "step 63750, change in cost 0.000154018\n",
      "step 63760, training accuracy 0.96748\n",
      "step 63760, cost 5.19053\n",
      "step 63760, change in cost 0.000154972\n",
      "step 63770, training accuracy 0.96748\n",
      "step 63770, cost 5.19037\n",
      "step 63770, change in cost 0.000154495\n",
      "step 63780, training accuracy 0.96748\n",
      "step 63780, cost 5.19022\n",
      "step 63780, change in cost 0.000153542\n",
      "step 63790, training accuracy 0.96748\n",
      "step 63790, cost 5.19006\n",
      "step 63790, change in cost 0.000155449\n",
      "step 63800, training accuracy 0.96748\n",
      "step 63800, cost 5.18991\n",
      "step 63800, change in cost 0.000154018\n",
      "step 63810, training accuracy 0.96748\n",
      "step 63810, cost 5.18975\n",
      "step 63810, change in cost 0.000155449\n",
      "step 63820, training accuracy 0.96748\n",
      "step 63820, cost 5.1896\n",
      "step 63820, change in cost 0.000154495\n",
      "step 63830, training accuracy 0.96748\n",
      "step 63830, cost 5.18944\n",
      "step 63830, change in cost 0.000154495\n",
      "step 63840, training accuracy 0.96748\n",
      "step 63840, cost 5.18929\n",
      "step 63840, change in cost 0.000153542\n",
      "step 63850, training accuracy 0.96748\n",
      "step 63850, cost 5.18914\n",
      "step 63850, change in cost 0.000154495\n",
      "step 63860, training accuracy 0.96748\n",
      "step 63860, cost 5.18898\n",
      "step 63860, change in cost 0.000154018\n",
      "step 63870, training accuracy 0.96748\n",
      "step 63870, cost 5.18883\n",
      "step 63870, change in cost 0.000154972\n",
      "step 63880, training accuracy 0.96748\n",
      "step 63880, cost 5.18867\n",
      "step 63880, change in cost 0.000153542\n",
      "step 63890, training accuracy 0.96748\n",
      "step 63890, cost 5.18852\n",
      "step 63890, change in cost 0.000154018\n",
      "step 63900, training accuracy 0.96748\n",
      "step 63900, cost 5.18836\n",
      "step 63900, change in cost 0.000154018\n",
      "step 63910, training accuracy 0.96748\n",
      "step 63910, cost 5.18821\n",
      "step 63910, change in cost 0.000154018\n",
      "step 63920, training accuracy 0.96748\n",
      "step 63920, cost 5.18806\n",
      "step 63920, change in cost 0.000154018\n",
      "step 63930, training accuracy 0.96748\n",
      "step 63930, cost 5.1879\n",
      "step 63930, change in cost 0.000153542\n",
      "step 63940, training accuracy 0.96748\n",
      "step 63940, cost 5.18775\n",
      "step 63940, change in cost 0.000153065\n",
      "step 63950, training accuracy 0.96748\n",
      "step 63950, cost 5.1876\n",
      "step 63950, change in cost 0.000153065\n",
      "step 63960, training accuracy 0.96748\n",
      "step 63960, cost 5.18744\n",
      "step 63960, change in cost 0.000154018\n",
      "step 63970, training accuracy 0.96748\n",
      "step 63970, cost 5.18729\n",
      "step 63970, change in cost 0.000153542\n",
      "step 63980, training accuracy 0.96748\n",
      "step 63980, cost 5.18714\n",
      "step 63980, change in cost 0.000153065\n",
      "step 63990, training accuracy 0.96748\n",
      "step 63990, cost 5.18698\n",
      "step 63990, change in cost 0.000152588\n",
      "step 64000, training accuracy 0.96748\n",
      "step 64000, cost 5.18683\n",
      "step 64000, change in cost 0.000153065\n",
      "step 64010, training accuracy 0.96748\n",
      "step 64010, cost 5.18668\n",
      "step 64010, change in cost 0.000154018\n",
      "step 64020, training accuracy 0.96748\n",
      "step 64020, cost 5.18652\n",
      "step 64020, change in cost 0.000152588\n",
      "step 64030, training accuracy 0.96748\n",
      "step 64030, cost 5.18637\n",
      "step 64030, change in cost 0.000152588\n",
      "step 64040, training accuracy 0.96748\n",
      "step 64040, cost 5.18622\n",
      "step 64040, change in cost 0.000154495\n",
      "step 64050, training accuracy 0.96748\n",
      "step 64050, cost 5.18607\n",
      "step 64050, change in cost 0.000152111\n",
      "step 64060, training accuracy 0.96748\n",
      "step 64060, cost 5.18591\n",
      "step 64060, change in cost 0.000154018\n",
      "step 64070, training accuracy 0.96748\n",
      "step 64070, cost 5.18576\n",
      "step 64070, change in cost 0.000151634\n",
      "step 64080, training accuracy 0.96748\n",
      "step 64080, cost 5.18561\n",
      "step 64080, change in cost 0.000153542\n",
      "step 64090, training accuracy 0.96748\n",
      "step 64090, cost 5.18545\n",
      "step 64090, change in cost 0.000152588\n",
      "step 64100, training accuracy 0.96748\n",
      "step 64100, cost 5.1853\n",
      "step 64100, change in cost 0.000152588\n",
      "step 64110, training accuracy 0.96748\n",
      "step 64110, cost 5.18515\n",
      "step 64110, change in cost 0.000152588\n",
      "step 64120, training accuracy 0.96748\n",
      "step 64120, cost 5.185\n",
      "step 64120, change in cost 0.000153065\n",
      "step 64130, training accuracy 0.96748\n",
      "step 64130, cost 5.18484\n",
      "step 64130, change in cost 0.000151157\n",
      "step 64140, training accuracy 0.96748\n",
      "step 64140, cost 5.18469\n",
      "step 64140, change in cost 0.000153542\n",
      "step 64150, training accuracy 0.96748\n",
      "step 64150, cost 5.18454\n",
      "step 64150, change in cost 0.000151157\n",
      "step 64160, training accuracy 0.96748\n",
      "step 64160, cost 5.18439\n",
      "step 64160, change in cost 0.000153065\n",
      "step 64170, training accuracy 0.96748\n",
      "step 64170, cost 5.18423\n",
      "step 64170, change in cost 0.000151634\n",
      "step 64180, training accuracy 0.96748\n",
      "step 64180, cost 5.18408\n",
      "step 64180, change in cost 0.000152111\n",
      "step 64190, training accuracy 0.96748\n",
      "step 64190, cost 5.18393\n",
      "step 64190, change in cost 0.000153065\n",
      "step 64200, training accuracy 0.96748\n",
      "step 64200, cost 5.18378\n",
      "step 64200, change in cost 0.000150681\n",
      "step 64210, training accuracy 0.96748\n",
      "step 64210, cost 5.18363\n",
      "step 64210, change in cost 0.000153065\n",
      "step 64220, training accuracy 0.96748\n",
      "step 64220, cost 5.18347\n",
      "step 64220, change in cost 0.000151634\n",
      "step 64230, training accuracy 0.96748\n",
      "step 64230, cost 5.18332\n",
      "step 64230, change in cost 0.000152588\n",
      "step 64240, training accuracy 0.96748\n",
      "step 64240, cost 5.18317\n",
      "step 64240, change in cost 0.000151634\n",
      "step 64250, training accuracy 0.96748\n",
      "step 64250, cost 5.18302\n",
      "step 64250, change in cost 0.000150681\n",
      "step 64260, training accuracy 0.96748\n",
      "step 64260, cost 5.18287\n",
      "step 64260, change in cost 0.000152111\n",
      "step 64270, training accuracy 0.96748\n",
      "step 64270, cost 5.18272\n",
      "step 64270, change in cost 0.000151157\n",
      "step 64280, training accuracy 0.96748\n",
      "step 64280, cost 5.18256\n",
      "step 64280, change in cost 0.000152111\n",
      "step 64290, training accuracy 0.96748\n",
      "step 64290, cost 5.18241\n",
      "step 64290, change in cost 0.000151634\n",
      "step 64300, training accuracy 0.96748\n",
      "step 64300, cost 5.18226\n",
      "step 64300, change in cost 0.000151634\n",
      "step 64310, training accuracy 0.96748\n",
      "step 64310, cost 5.18211\n",
      "step 64310, change in cost 0.000151634\n",
      "step 64320, training accuracy 0.96748\n",
      "step 64320, cost 5.18196\n",
      "step 64320, change in cost 0.000150681\n",
      "step 64330, training accuracy 0.96748\n",
      "step 64330, cost 5.18181\n",
      "step 64330, change in cost 0.000150681\n",
      "step 64340, training accuracy 0.96748\n",
      "step 64340, cost 5.18166\n",
      "step 64340, change in cost 0.000151634\n",
      "step 64350, training accuracy 0.96748\n",
      "step 64350, cost 5.18151\n",
      "step 64350, change in cost 0.000150681\n",
      "step 64360, training accuracy 0.96748\n",
      "step 64360, cost 5.18135\n",
      "step 64360, change in cost 0.000150681\n",
      "step 64370, training accuracy 0.96748\n",
      "step 64370, cost 5.1812\n",
      "step 64370, change in cost 0.000150681\n",
      "step 64380, training accuracy 0.96748\n",
      "step 64380, cost 5.18105\n",
      "step 64380, change in cost 0.000150681\n",
      "step 64390, training accuracy 0.96748\n",
      "step 64390, cost 5.1809\n",
      "step 64390, change in cost 0.000151634\n",
      "step 64400, training accuracy 0.96748\n",
      "step 64400, cost 5.18075\n",
      "step 64400, change in cost 0.000151157\n",
      "step 64410, training accuracy 0.96748\n",
      "step 64410, cost 5.1806\n",
      "step 64410, change in cost 0.000150204\n",
      "step 64420, training accuracy 0.96748\n",
      "step 64420, cost 5.18045\n",
      "step 64420, change in cost 0.000150681\n",
      "step 64430, training accuracy 0.96748\n",
      "step 64430, cost 5.1803\n",
      "step 64430, change in cost 0.000150204\n",
      "step 64440, training accuracy 0.96748\n",
      "step 64440, cost 5.18015\n",
      "step 64440, change in cost 0.000151157\n",
      "step 64450, training accuracy 0.96748\n",
      "step 64450, cost 5.18\n",
      "step 64450, change in cost 0.000149727\n",
      "step 64460, training accuracy 0.96748\n",
      "step 64460, cost 5.17985\n",
      "step 64460, change in cost 0.000150681\n",
      "step 64470, training accuracy 0.96748\n",
      "step 64470, cost 5.1797\n",
      "step 64470, change in cost 0.000150681\n",
      "step 64480, training accuracy 0.96748\n",
      "step 64480, cost 5.17955\n",
      "step 64480, change in cost 0.000150681\n",
      "step 64490, training accuracy 0.96748\n",
      "step 64490, cost 5.1794\n",
      "step 64490, change in cost 0.000150681\n",
      "step 64500, training accuracy 0.96748\n",
      "step 64500, cost 5.17925\n",
      "step 64500, change in cost 0.000149727\n",
      "step 64510, training accuracy 0.96748\n",
      "step 64510, cost 5.1791\n",
      "step 64510, change in cost 0.000148773\n",
      "step 64520, training accuracy 0.96748\n",
      "step 64520, cost 5.17895\n",
      "step 64520, change in cost 0.000150204\n",
      "step 64530, training accuracy 0.96748\n",
      "step 64530, cost 5.1788\n",
      "step 64530, change in cost 0.000149727\n",
      "step 64540, training accuracy 0.96748\n",
      "step 64540, cost 5.17865\n",
      "step 64540, change in cost 0.000150681\n",
      "step 64550, training accuracy 0.96748\n",
      "step 64550, cost 5.1785\n",
      "step 64550, change in cost 0.000150204\n",
      "step 64560, training accuracy 0.96748\n",
      "step 64560, cost 5.17835\n",
      "step 64560, change in cost 0.00014925\n",
      "step 64570, training accuracy 0.96748\n",
      "step 64570, cost 5.1782\n",
      "step 64570, change in cost 0.000150204\n",
      "step 64580, training accuracy 0.96748\n",
      "step 64580, cost 5.17805\n",
      "step 64580, change in cost 0.000149727\n",
      "step 64590, training accuracy 0.96748\n",
      "step 64590, cost 5.1779\n",
      "step 64590, change in cost 0.000148773\n",
      "step 64600, training accuracy 0.96748\n",
      "step 64600, cost 5.17775\n",
      "step 64600, change in cost 0.000149727\n",
      "step 64610, training accuracy 0.96748\n",
      "step 64610, cost 5.1776\n",
      "step 64610, change in cost 0.000150204\n",
      "step 64620, training accuracy 0.96748\n",
      "step 64620, cost 5.17745\n",
      "step 64620, change in cost 0.000148296\n",
      "step 64630, training accuracy 0.96748\n",
      "step 64630, cost 5.1773\n",
      "step 64630, change in cost 0.000149727\n",
      "step 64640, training accuracy 0.96748\n",
      "step 64640, cost 5.17715\n",
      "step 64640, change in cost 0.000150681\n",
      "step 64650, training accuracy 0.96748\n",
      "step 64650, cost 5.177\n",
      "step 64650, change in cost 0.00014782\n",
      "step 64660, training accuracy 0.96748\n",
      "step 64660, cost 5.17685\n",
      "step 64660, change in cost 0.000149727\n",
      "step 64670, training accuracy 0.96748\n",
      "step 64670, cost 5.1767\n",
      "step 64670, change in cost 0.00014925\n",
      "step 64680, training accuracy 0.96748\n",
      "step 64680, cost 5.17655\n",
      "step 64680, change in cost 0.00014925\n",
      "step 64690, training accuracy 0.96748\n",
      "step 64690, cost 5.1764\n",
      "step 64690, change in cost 0.000148773\n",
      "step 64700, training accuracy 0.96748\n",
      "step 64700, cost 5.17626\n",
      "step 64700, change in cost 0.000148773\n",
      "step 64710, training accuracy 0.96748\n",
      "step 64710, cost 5.17611\n",
      "step 64710, change in cost 0.00014925\n",
      "step 64720, training accuracy 0.96748\n",
      "step 64720, cost 5.17596\n",
      "step 64720, change in cost 0.000148296\n",
      "step 64730, training accuracy 0.96748\n",
      "step 64730, cost 5.17581\n",
      "step 64730, change in cost 0.00014925\n",
      "step 64740, training accuracy 0.96748\n",
      "step 64740, cost 5.17566\n",
      "step 64740, change in cost 0.00014925\n",
      "step 64750, training accuracy 0.96748\n",
      "step 64750, cost 5.17551\n",
      "step 64750, change in cost 0.000148296\n",
      "step 64760, training accuracy 0.96748\n",
      "step 64760, cost 5.17536\n",
      "step 64760, change in cost 0.000149727\n",
      "step 64770, training accuracy 0.96748\n",
      "step 64770, cost 5.17522\n",
      "step 64770, change in cost 0.000146866\n",
      "step 64780, training accuracy 0.96748\n",
      "step 64780, cost 5.17507\n",
      "step 64780, change in cost 0.00014925\n",
      "step 64790, training accuracy 0.96748\n",
      "step 64790, cost 5.17492\n",
      "step 64790, change in cost 0.000148296\n",
      "step 64800, training accuracy 0.96748\n",
      "step 64800, cost 5.17477\n",
      "step 64800, change in cost 0.000148773\n",
      "step 64810, training accuracy 0.96748\n",
      "step 64810, cost 5.17462\n",
      "step 64810, change in cost 0.00014782\n",
      "step 64820, training accuracy 0.96748\n",
      "step 64820, cost 5.17447\n",
      "step 64820, change in cost 0.00014782\n",
      "step 64830, training accuracy 0.96748\n",
      "step 64830, cost 5.17432\n",
      "step 64830, change in cost 0.000148296\n",
      "step 64840, training accuracy 0.96748\n",
      "step 64840, cost 5.17418\n",
      "step 64840, change in cost 0.000148773\n",
      "step 64850, training accuracy 0.96748\n",
      "step 64850, cost 5.17403\n",
      "step 64850, change in cost 0.00014782\n",
      "step 64860, training accuracy 0.96748\n",
      "step 64860, cost 5.17388\n",
      "step 64860, change in cost 0.000148296\n",
      "step 64870, training accuracy 0.96748\n",
      "step 64870, cost 5.17373\n",
      "step 64870, change in cost 0.000147343\n",
      "step 64880, training accuracy 0.96748\n",
      "step 64880, cost 5.17358\n",
      "step 64880, change in cost 0.000148296\n",
      "step 64890, training accuracy 0.96748\n",
      "step 64890, cost 5.17344\n",
      "step 64890, change in cost 0.000147343\n",
      "step 64900, training accuracy 0.96748\n",
      "step 64900, cost 5.17329\n",
      "step 64900, change in cost 0.000147343\n",
      "step 64910, training accuracy 0.96748\n",
      "step 64910, cost 5.17314\n",
      "step 64910, change in cost 0.00014782\n",
      "step 64920, training accuracy 0.96748\n",
      "step 64920, cost 5.17299\n",
      "step 64920, change in cost 0.00014782\n",
      "step 64930, training accuracy 0.96748\n",
      "step 64930, cost 5.17285\n",
      "step 64930, change in cost 0.000147343\n",
      "step 64940, training accuracy 0.96748\n",
      "step 64940, cost 5.1727\n",
      "step 64940, change in cost 0.00014782\n",
      "step 64950, training accuracy 0.96748\n",
      "step 64950, cost 5.17255\n",
      "step 64950, change in cost 0.00014782\n",
      "step 64960, training accuracy 0.96748\n",
      "step 64960, cost 5.1724\n",
      "step 64960, change in cost 0.000146866\n",
      "step 64970, training accuracy 0.96748\n",
      "step 64970, cost 5.17226\n",
      "step 64970, change in cost 0.000147343\n",
      "step 64980, training accuracy 0.96748\n",
      "step 64980, cost 5.17211\n",
      "step 64980, change in cost 0.000148296\n",
      "step 64990, training accuracy 0.96748\n",
      "step 64990, cost 5.17196\n",
      "step 64990, change in cost 0.000145435\n",
      "step 65000, training accuracy 0.96748\n",
      "step 65000, cost 5.17182\n",
      "step 65000, change in cost 0.000146389\n",
      "step 65010, training accuracy 0.96748\n",
      "step 65010, cost 5.17167\n",
      "step 65010, change in cost 0.00014782\n",
      "step 65020, training accuracy 0.96748\n",
      "step 65020, cost 5.17152\n",
      "step 65020, change in cost 0.000146866\n",
      "step 65030, training accuracy 0.96748\n",
      "step 65030, cost 5.17138\n",
      "step 65030, change in cost 0.000145912\n",
      "step 65040, training accuracy 0.96748\n",
      "step 65040, cost 5.17123\n",
      "step 65040, change in cost 0.000148296\n",
      "step 65050, training accuracy 0.96748\n",
      "step 65050, cost 5.17108\n",
      "step 65050, change in cost 0.000145435\n",
      "step 65060, training accuracy 0.96748\n",
      "step 65060, cost 5.17093\n",
      "step 65060, change in cost 0.00014782\n",
      "step 65070, training accuracy 0.96748\n",
      "step 65070, cost 5.17079\n",
      "step 65070, change in cost 0.000145912\n",
      "step 65080, training accuracy 0.96748\n",
      "step 65080, cost 5.17064\n",
      "step 65080, change in cost 0.000146866\n",
      "step 65090, training accuracy 0.96748\n",
      "step 65090, cost 5.17049\n",
      "step 65090, change in cost 0.000147343\n",
      "step 65100, training accuracy 0.96748\n",
      "step 65100, cost 5.17035\n",
      "step 65100, change in cost 0.000146389\n",
      "step 65110, training accuracy 0.96748\n",
      "step 65110, cost 5.1702\n",
      "step 65110, change in cost 0.000145912\n",
      "step 65120, training accuracy 0.96748\n",
      "step 65120, cost 5.17006\n",
      "step 65120, change in cost 0.000146866\n",
      "step 65130, training accuracy 0.96748\n",
      "step 65130, cost 5.16991\n",
      "step 65130, change in cost 0.000146389\n",
      "step 65140, training accuracy 0.96748\n",
      "step 65140, cost 5.16976\n",
      "step 65140, change in cost 0.000145912\n",
      "step 65150, training accuracy 0.96748\n",
      "step 65150, cost 5.16962\n",
      "step 65150, change in cost 0.000146389\n",
      "step 65160, training accuracy 0.96748\n",
      "step 65160, cost 5.16947\n",
      "step 65160, change in cost 0.000145912\n",
      "step 65170, training accuracy 0.96748\n",
      "step 65170, cost 5.16932\n",
      "step 65170, change in cost 0.000146866\n",
      "step 65180, training accuracy 0.96748\n",
      "step 65180, cost 5.16918\n",
      "step 65180, change in cost 0.000145912\n",
      "step 65190, training accuracy 0.96748\n",
      "step 65190, cost 5.16903\n",
      "step 65190, change in cost 0.000145435\n",
      "step 65200, training accuracy 0.96748\n",
      "step 65200, cost 5.16889\n",
      "step 65200, change in cost 0.000145912\n",
      "step 65210, training accuracy 0.96748\n",
      "step 65210, cost 5.16874\n",
      "step 65210, change in cost 0.000147343\n",
      "step 65220, training accuracy 0.96748\n",
      "step 65220, cost 5.16859\n",
      "step 65220, change in cost 0.000144958\n",
      "step 65230, training accuracy 0.96748\n",
      "step 65230, cost 5.16845\n",
      "step 65230, change in cost 0.000145912\n",
      "step 65240, training accuracy 0.96748\n",
      "step 65240, cost 5.1683\n",
      "step 65240, change in cost 0.000146389\n",
      "step 65250, training accuracy 0.96748\n",
      "step 65250, cost 5.16816\n",
      "step 65250, change in cost 0.000145435\n",
      "step 65260, training accuracy 0.96748\n",
      "step 65260, cost 5.16801\n",
      "step 65260, change in cost 0.000145435\n",
      "step 65270, training accuracy 0.96748\n",
      "step 65270, cost 5.16787\n",
      "step 65270, change in cost 0.000144958\n",
      "step 65280, training accuracy 0.96748\n",
      "step 65280, cost 5.16772\n",
      "step 65280, change in cost 0.000146389\n",
      "step 65290, training accuracy 0.96748\n",
      "step 65290, cost 5.16757\n",
      "step 65290, change in cost 0.000145435\n",
      "step 65300, training accuracy 0.96748\n",
      "step 65300, cost 5.16743\n",
      "step 65300, change in cost 0.000144958\n",
      "step 65310, training accuracy 0.96748\n",
      "step 65310, cost 5.16728\n",
      "step 65310, change in cost 0.000146866\n",
      "step 65320, training accuracy 0.96748\n",
      "step 65320, cost 5.16714\n",
      "step 65320, change in cost 0.000144958\n",
      "step 65330, training accuracy 0.96748\n",
      "step 65330, cost 5.16699\n",
      "step 65330, change in cost 0.000145435\n",
      "step 65340, training accuracy 0.96748\n",
      "step 65340, cost 5.16685\n",
      "step 65340, change in cost 0.000145912\n",
      "step 65350, training accuracy 0.96748\n",
      "step 65350, cost 5.1667\n",
      "step 65350, change in cost 0.000144005\n",
      "step 65360, training accuracy 0.96748\n",
      "step 65360, cost 5.16656\n",
      "step 65360, change in cost 0.000144958\n",
      "step 65370, training accuracy 0.96748\n",
      "step 65370, cost 5.16641\n",
      "step 65370, change in cost 0.000146866\n",
      "step 65380, training accuracy 0.96748\n",
      "step 65380, cost 5.16627\n",
      "step 65380, change in cost 0.000144958\n",
      "step 65390, training accuracy 0.96748\n",
      "step 65390, cost 5.16612\n",
      "step 65390, change in cost 0.000144005\n",
      "step 65400, training accuracy 0.96748\n",
      "step 65400, cost 5.16598\n",
      "step 65400, change in cost 0.000144958\n",
      "step 65410, training accuracy 0.96748\n",
      "step 65410, cost 5.16583\n",
      "step 65410, change in cost 0.000144005\n",
      "step 65420, training accuracy 0.96748\n",
      "step 65420, cost 5.16569\n",
      "step 65420, change in cost 0.000145435\n",
      "step 65430, training accuracy 0.96748\n",
      "step 65430, cost 5.16554\n",
      "step 65430, change in cost 0.000144482\n",
      "step 65440, training accuracy 0.96748\n",
      "step 65440, cost 5.1654\n",
      "step 65440, change in cost 0.000144958\n",
      "step 65450, training accuracy 0.96748\n",
      "step 65450, cost 5.16525\n",
      "step 65450, change in cost 0.000144482\n",
      "step 65460, training accuracy 0.96748\n",
      "step 65460, cost 5.16511\n",
      "step 65460, change in cost 0.000143528\n",
      "step 65470, training accuracy 0.96748\n",
      "step 65470, cost 5.16496\n",
      "step 65470, change in cost 0.000144958\n",
      "step 65480, training accuracy 0.96748\n",
      "step 65480, cost 5.16482\n",
      "step 65480, change in cost 0.000144958\n",
      "step 65490, training accuracy 0.96748\n",
      "step 65490, cost 5.16467\n",
      "step 65490, change in cost 0.000144958\n",
      "step 65500, training accuracy 0.96748\n",
      "step 65500, cost 5.16453\n",
      "step 65500, change in cost 0.000142574\n",
      "step 65510, training accuracy 0.96748\n",
      "step 65510, cost 5.16439\n",
      "step 65510, change in cost 0.000144958\n",
      "step 65520, training accuracy 0.96748\n",
      "step 65520, cost 5.16424\n",
      "step 65520, change in cost 0.000145435\n",
      "step 65530, training accuracy 0.96748\n",
      "step 65530, cost 5.1641\n",
      "step 65530, change in cost 0.000144005\n",
      "step 65540, training accuracy 0.96748\n",
      "step 65540, cost 5.16395\n",
      "step 65540, change in cost 0.000144482\n",
      "step 65550, training accuracy 0.96748\n",
      "step 65550, cost 5.16381\n",
      "step 65550, change in cost 0.000143528\n",
      "step 65560, training accuracy 0.96748\n",
      "step 65560, cost 5.16367\n",
      "step 65560, change in cost 0.000144005\n",
      "step 65570, training accuracy 0.96748\n",
      "step 65570, cost 5.16352\n",
      "step 65570, change in cost 0.000144005\n",
      "step 65580, training accuracy 0.96748\n",
      "step 65580, cost 5.16338\n",
      "step 65580, change in cost 0.000144958\n",
      "step 65590, training accuracy 0.96748\n",
      "step 65590, cost 5.16323\n",
      "step 65590, change in cost 0.000143528\n",
      "step 65600, training accuracy 0.96748\n",
      "step 65600, cost 5.16309\n",
      "step 65600, change in cost 0.000142574\n",
      "step 65610, training accuracy 0.96748\n",
      "step 65610, cost 5.16295\n",
      "step 65610, change in cost 0.000144482\n",
      "step 65620, training accuracy 0.96748\n",
      "step 65620, cost 5.1628\n",
      "step 65620, change in cost 0.000143528\n",
      "step 65630, training accuracy 0.96748\n",
      "step 65630, cost 5.16266\n",
      "step 65630, change in cost 0.000144005\n",
      "step 65640, training accuracy 0.96748\n",
      "step 65640, cost 5.16251\n",
      "step 65640, change in cost 0.000144005\n",
      "step 65650, training accuracy 0.96748\n",
      "step 65650, cost 5.16237\n",
      "step 65650, change in cost 0.000143051\n",
      "step 65660, training accuracy 0.96748\n",
      "step 65660, cost 5.16223\n",
      "step 65660, change in cost 0.000144005\n",
      "step 65670, training accuracy 0.96748\n",
      "step 65670, cost 5.16208\n",
      "step 65670, change in cost 0.000143528\n",
      "step 65680, training accuracy 0.96748\n",
      "step 65680, cost 5.16194\n",
      "step 65680, change in cost 0.000143051\n",
      "step 65690, training accuracy 0.96748\n",
      "step 65690, cost 5.1618\n",
      "step 65690, change in cost 0.000143528\n",
      "step 65700, training accuracy 0.96748\n",
      "step 65700, cost 5.16165\n",
      "step 65700, change in cost 0.000143051\n",
      "step 65710, training accuracy 0.96748\n",
      "step 65710, cost 5.16151\n",
      "step 65710, change in cost 0.000142574\n",
      "step 65720, training accuracy 0.96748\n",
      "step 65720, cost 5.16137\n",
      "step 65720, change in cost 0.000143528\n",
      "step 65730, training accuracy 0.96748\n",
      "step 65730, cost 5.16122\n",
      "step 65730, change in cost 0.000143528\n",
      "step 65740, training accuracy 0.96748\n",
      "step 65740, cost 5.16108\n",
      "step 65740, change in cost 0.000142574\n",
      "step 65750, training accuracy 0.96748\n",
      "step 65750, cost 5.16094\n",
      "step 65750, change in cost 0.000144005\n",
      "step 65760, training accuracy 0.96748\n",
      "step 65760, cost 5.1608\n",
      "step 65760, change in cost 0.000142574\n",
      "step 65770, training accuracy 0.96748\n",
      "step 65770, cost 5.16065\n",
      "step 65770, change in cost 0.000143528\n",
      "step 65780, training accuracy 0.96748\n",
      "step 65780, cost 5.16051\n",
      "step 65780, change in cost 0.000142574\n",
      "step 65790, training accuracy 0.96748\n",
      "step 65790, cost 5.16037\n",
      "step 65790, change in cost 0.000143528\n",
      "step 65800, training accuracy 0.96748\n",
      "step 65800, cost 5.16022\n",
      "step 65800, change in cost 0.000142097\n",
      "step 65810, training accuracy 0.96748\n",
      "step 65810, cost 5.16008\n",
      "step 65810, change in cost 0.000142097\n",
      "step 65820, training accuracy 0.96748\n",
      "step 65820, cost 5.15994\n",
      "step 65820, change in cost 0.000142574\n",
      "step 65830, training accuracy 0.96748\n",
      "step 65830, cost 5.1598\n",
      "step 65830, change in cost 0.000142574\n",
      "step 65840, training accuracy 0.96748\n",
      "step 65840, cost 5.15965\n",
      "step 65840, change in cost 0.000142097\n",
      "step 65850, training accuracy 0.96748\n",
      "step 65850, cost 5.15951\n",
      "step 65850, change in cost 0.000142574\n",
      "step 65860, training accuracy 0.96748\n",
      "step 65860, cost 5.15937\n",
      "step 65860, change in cost 0.000142574\n",
      "step 65870, training accuracy 0.96748\n",
      "step 65870, cost 5.15923\n",
      "step 65870, change in cost 0.000142574\n",
      "step 65880, training accuracy 0.96748\n",
      "step 65880, cost 5.15908\n",
      "step 65880, change in cost 0.000142574\n",
      "step 65890, training accuracy 0.96748\n",
      "step 65890, cost 5.15894\n",
      "step 65890, change in cost 0.000142097\n",
      "step 65900, training accuracy 0.96748\n",
      "step 65900, cost 5.1588\n",
      "step 65900, change in cost 0.000142574\n",
      "step 65910, training accuracy 0.96748\n",
      "step 65910, cost 5.15866\n",
      "step 65910, change in cost 0.000141144\n",
      "step 65920, training accuracy 0.96748\n",
      "step 65920, cost 5.15852\n",
      "step 65920, change in cost 0.000143051\n",
      "step 65930, training accuracy 0.96748\n",
      "step 65930, cost 5.15837\n",
      "step 65930, change in cost 0.000141621\n",
      "step 65940, training accuracy 0.96748\n",
      "step 65940, cost 5.15823\n",
      "step 65940, change in cost 0.000141144\n",
      "step 65950, training accuracy 0.96748\n",
      "step 65950, cost 5.15809\n",
      "step 65950, change in cost 0.000142097\n",
      "step 65960, training accuracy 0.96748\n",
      "step 65960, cost 5.15795\n",
      "step 65960, change in cost 0.000142097\n",
      "step 65970, training accuracy 0.96748\n",
      "step 65970, cost 5.15781\n",
      "step 65970, change in cost 0.000141621\n",
      "step 65980, training accuracy 0.96748\n",
      "step 65980, cost 5.15767\n",
      "step 65980, change in cost 0.000141621\n",
      "step 65990, training accuracy 0.96748\n",
      "step 65990, cost 5.15752\n",
      "step 65990, change in cost 0.000142574\n",
      "step 66000, training accuracy 0.96748\n",
      "step 66000, cost 5.15738\n",
      "step 66000, change in cost 0.000140667\n",
      "step 66010, training accuracy 0.96748\n",
      "step 66010, cost 5.15724\n",
      "step 66010, change in cost 0.000142097\n",
      "step 66020, training accuracy 0.96748\n",
      "step 66020, cost 5.1571\n",
      "step 66020, change in cost 0.000142097\n",
      "step 66030, training accuracy 0.96748\n",
      "step 66030, cost 5.15696\n",
      "step 66030, change in cost 0.000141144\n",
      "step 66040, training accuracy 0.96748\n",
      "step 66040, cost 5.15682\n",
      "step 66040, change in cost 0.000141144\n",
      "step 66050, training accuracy 0.96748\n",
      "step 66050, cost 5.15667\n",
      "step 66050, change in cost 0.000142097\n",
      "step 66060, training accuracy 0.96748\n",
      "step 66060, cost 5.15653\n",
      "step 66060, change in cost 0.000141144\n",
      "step 66070, training accuracy 0.96748\n",
      "step 66070, cost 5.15639\n",
      "step 66070, change in cost 0.00014019\n",
      "step 66080, training accuracy 0.96748\n",
      "step 66080, cost 5.15625\n",
      "step 66080, change in cost 0.000142097\n",
      "step 66090, training accuracy 0.96748\n",
      "step 66090, cost 5.15611\n",
      "step 66090, change in cost 0.000141621\n",
      "step 66100, training accuracy 0.96748\n",
      "step 66100, cost 5.15597\n",
      "step 66100, change in cost 0.000140667\n",
      "step 66110, training accuracy 0.96748\n",
      "step 66110, cost 5.15583\n",
      "step 66110, change in cost 0.000141144\n",
      "step 66120, training accuracy 0.96748\n",
      "step 66120, cost 5.15569\n",
      "step 66120, change in cost 0.000141144\n",
      "step 66130, training accuracy 0.96748\n",
      "step 66130, cost 5.15554\n",
      "step 66130, change in cost 0.000141144\n",
      "step 66140, training accuracy 0.96748\n",
      "step 66140, cost 5.1554\n",
      "step 66140, change in cost 0.000142574\n",
      "step 66150, training accuracy 0.96748\n",
      "step 66150, cost 5.15526\n",
      "step 66150, change in cost 0.000140667\n",
      "step 66160, training accuracy 0.96748\n",
      "step 66160, cost 5.15512\n",
      "step 66160, change in cost 0.000139236\n",
      "step 66170, training accuracy 0.96748\n",
      "step 66170, cost 5.15498\n",
      "step 66170, change in cost 0.000141621\n",
      "step 66180, training accuracy 0.96748\n",
      "step 66180, cost 5.15484\n",
      "step 66180, change in cost 0.000139713\n",
      "step 66190, training accuracy 0.96748\n",
      "step 66190, cost 5.1547\n",
      "step 66190, change in cost 0.000141144\n",
      "step 66200, training accuracy 0.96748\n",
      "step 66200, cost 5.15456\n",
      "step 66200, change in cost 0.000141144\n",
      "step 66210, training accuracy 0.96748\n",
      "step 66210, cost 5.15442\n",
      "step 66210, change in cost 0.000141144\n",
      "step 66220, training accuracy 0.96748\n",
      "step 66220, cost 5.15428\n",
      "step 66220, change in cost 0.000139713\n",
      "step 66230, training accuracy 0.96748\n",
      "step 66230, cost 5.15414\n",
      "step 66230, change in cost 0.000141144\n",
      "step 66240, training accuracy 0.96748\n",
      "step 66240, cost 5.154\n",
      "step 66240, change in cost 0.00014019\n",
      "step 66250, training accuracy 0.96748\n",
      "step 66250, cost 5.15386\n",
      "step 66250, change in cost 0.00014019\n",
      "step 66260, training accuracy 0.96748\n",
      "step 66260, cost 5.15372\n",
      "step 66260, change in cost 0.000139236\n",
      "step 66270, training accuracy 0.96748\n",
      "step 66270, cost 5.15357\n",
      "step 66270, change in cost 0.000141621\n",
      "step 66280, training accuracy 0.96748\n",
      "step 66280, cost 5.15343\n",
      "step 66280, change in cost 0.00014019\n",
      "step 66290, training accuracy 0.96748\n",
      "step 66290, cost 5.15329\n",
      "step 66290, change in cost 0.00014019\n",
      "step 66300, training accuracy 0.96748\n",
      "step 66300, cost 5.15316\n",
      "step 66300, change in cost 0.000139236\n",
      "step 66310, training accuracy 0.96748\n",
      "step 66310, cost 5.15302\n",
      "step 66310, change in cost 0.00014019\n",
      "step 66320, training accuracy 0.96748\n",
      "step 66320, cost 5.15288\n",
      "step 66320, change in cost 0.000139713\n",
      "step 66330, training accuracy 0.96748\n",
      "step 66330, cost 5.15273\n",
      "step 66330, change in cost 0.000140667\n",
      "step 66340, training accuracy 0.96748\n",
      "step 66340, cost 5.15259\n",
      "step 66340, change in cost 0.00014019\n",
      "step 66350, training accuracy 0.96748\n",
      "step 66350, cost 5.15245\n",
      "step 66350, change in cost 0.000139713\n",
      "step 66360, training accuracy 0.96748\n",
      "step 66360, cost 5.15232\n",
      "step 66360, change in cost 0.00013876\n",
      "step 66370, training accuracy 0.96748\n",
      "step 66370, cost 5.15218\n",
      "step 66370, change in cost 0.000139236\n",
      "step 66380, training accuracy 0.96748\n",
      "step 66380, cost 5.15204\n",
      "step 66380, change in cost 0.00014019\n",
      "step 66390, training accuracy 0.96748\n",
      "step 66390, cost 5.1519\n",
      "step 66390, change in cost 0.000139236\n",
      "step 66400, training accuracy 0.96748\n",
      "step 66400, cost 5.15176\n",
      "step 66400, change in cost 0.00014019\n",
      "step 66410, training accuracy 0.96748\n",
      "step 66410, cost 5.15162\n",
      "step 66410, change in cost 0.000138283\n",
      "step 66420, training accuracy 0.96748\n",
      "step 66420, cost 5.15148\n",
      "step 66420, change in cost 0.000141144\n",
      "step 66430, training accuracy 0.96748\n",
      "step 66430, cost 5.15134\n",
      "step 66430, change in cost 0.000138283\n",
      "step 66440, training accuracy 0.96748\n",
      "step 66440, cost 5.1512\n",
      "step 66440, change in cost 0.000139236\n",
      "step 66450, training accuracy 0.96748\n",
      "step 66450, cost 5.15106\n",
      "step 66450, change in cost 0.000139236\n",
      "step 66460, training accuracy 0.96748\n",
      "step 66460, cost 5.15092\n",
      "step 66460, change in cost 0.00013876\n",
      "step 66470, training accuracy 0.96748\n",
      "step 66470, cost 5.15078\n",
      "step 66470, change in cost 0.00014019\n",
      "step 66480, training accuracy 0.96748\n",
      "step 66480, cost 5.15064\n",
      "step 66480, change in cost 0.00013876\n",
      "step 66490, training accuracy 0.96748\n",
      "step 66490, cost 5.1505\n",
      "step 66490, change in cost 0.00013876\n",
      "step 66500, training accuracy 0.96748\n",
      "step 66500, cost 5.15037\n",
      "step 66500, change in cost 0.00013876\n",
      "step 66510, training accuracy 0.96748\n",
      "step 66510, cost 5.15023\n",
      "step 66510, change in cost 0.000139236\n",
      "step 66520, training accuracy 0.96748\n",
      "step 66520, cost 5.15009\n",
      "step 66520, change in cost 0.000139236\n",
      "step 66530, training accuracy 0.96748\n",
      "step 66530, cost 5.14995\n",
      "step 66530, change in cost 0.000137806\n",
      "step 66540, training accuracy 0.96748\n",
      "step 66540, cost 5.14981\n",
      "step 66540, change in cost 0.000139236\n",
      "step 66550, training accuracy 0.96748\n",
      "step 66550, cost 5.14967\n",
      "step 66550, change in cost 0.00013876\n",
      "step 66560, training accuracy 0.96748\n",
      "step 66560, cost 5.14953\n",
      "step 66560, change in cost 0.000138283\n",
      "step 66570, training accuracy 0.96748\n",
      "step 66570, cost 5.14939\n",
      "step 66570, change in cost 0.000138283\n",
      "step 66580, training accuracy 0.96748\n",
      "step 66580, cost 5.14926\n",
      "step 66580, change in cost 0.00013876\n",
      "step 66590, training accuracy 0.96748\n",
      "step 66590, cost 5.14912\n",
      "step 66590, change in cost 0.000139713\n",
      "step 66600, training accuracy 0.96748\n",
      "step 66600, cost 5.14898\n",
      "step 66600, change in cost 0.000138283\n",
      "step 66610, training accuracy 0.96748\n",
      "step 66610, cost 5.14884\n",
      "step 66610, change in cost 0.000138283\n",
      "step 66620, training accuracy 0.96748\n",
      "step 66620, cost 5.1487\n",
      "step 66620, change in cost 0.000138283\n",
      "step 66630, training accuracy 0.96748\n",
      "step 66630, cost 5.14856\n",
      "step 66630, change in cost 0.000138283\n",
      "step 66640, training accuracy 0.96748\n",
      "step 66640, cost 5.14842\n",
      "step 66640, change in cost 0.000139713\n",
      "step 66650, training accuracy 0.96748\n",
      "step 66650, cost 5.14829\n",
      "step 66650, change in cost 0.000136852\n",
      "step 66660, training accuracy 0.96748\n",
      "step 66660, cost 5.14815\n",
      "step 66660, change in cost 0.00013876\n",
      "step 66670, training accuracy 0.96748\n",
      "step 66670, cost 5.14801\n",
      "step 66670, change in cost 0.000138283\n",
      "step 66680, training accuracy 0.96748\n",
      "step 66680, cost 5.14787\n",
      "step 66680, change in cost 0.000136852\n",
      "step 66690, training accuracy 0.96748\n",
      "step 66690, cost 5.14773\n",
      "step 66690, change in cost 0.000139236\n",
      "step 66700, training accuracy 0.96748\n",
      "step 66700, cost 5.1476\n",
      "step 66700, change in cost 0.000137806\n",
      "step 66710, training accuracy 0.96748\n",
      "step 66710, cost 5.14746\n",
      "step 66710, change in cost 0.000139713\n",
      "step 66720, training accuracy 0.96748\n",
      "step 66720, cost 5.14732\n",
      "step 66720, change in cost 0.000136852\n",
      "step 66730, training accuracy 0.96748\n",
      "step 66730, cost 5.14718\n",
      "step 66730, change in cost 0.000137329\n",
      "step 66740, training accuracy 0.96748\n",
      "step 66740, cost 5.14704\n",
      "step 66740, change in cost 0.000138283\n",
      "step 66750, training accuracy 0.96748\n",
      "step 66750, cost 5.1469\n",
      "step 66750, change in cost 0.00013876\n",
      "step 66760, training accuracy 0.96748\n",
      "step 66760, cost 5.14677\n",
      "step 66760, change in cost 0.000137329\n",
      "step 66770, training accuracy 0.96748\n",
      "step 66770, cost 5.14663\n",
      "step 66770, change in cost 0.000138283\n",
      "step 66780, training accuracy 0.96748\n",
      "step 66780, cost 5.14649\n",
      "step 66780, change in cost 0.000137329\n",
      "step 66790, training accuracy 0.96748\n",
      "step 66790, cost 5.14635\n",
      "step 66790, change in cost 0.000137806\n",
      "step 66800, training accuracy 0.96748\n",
      "step 66800, cost 5.14622\n",
      "step 66800, change in cost 0.000137806\n",
      "step 66810, training accuracy 0.96748\n",
      "step 66810, cost 5.14608\n",
      "step 66810, change in cost 0.000137329\n",
      "step 66820, training accuracy 0.96748\n",
      "step 66820, cost 5.14594\n",
      "step 66820, change in cost 0.000136852\n",
      "step 66830, training accuracy 0.96748\n",
      "step 66830, cost 5.1458\n",
      "step 66830, change in cost 0.000137329\n",
      "step 66840, training accuracy 0.96748\n",
      "step 66840, cost 5.14567\n",
      "step 66840, change in cost 0.000137806\n",
      "step 66850, training accuracy 0.96748\n",
      "step 66850, cost 5.14553\n",
      "step 66850, change in cost 0.000136852\n",
      "step 66860, training accuracy 0.96748\n",
      "step 66860, cost 5.14539\n",
      "step 66860, change in cost 0.000136375\n",
      "step 66870, training accuracy 0.96748\n",
      "step 66870, cost 5.14526\n",
      "step 66870, change in cost 0.000137806\n",
      "step 66880, training accuracy 0.96748\n",
      "step 66880, cost 5.14512\n",
      "step 66880, change in cost 0.000137329\n",
      "step 66890, training accuracy 0.96748\n",
      "step 66890, cost 5.14498\n",
      "step 66890, change in cost 0.000137806\n",
      "step 66900, training accuracy 0.96748\n",
      "step 66900, cost 5.14484\n",
      "step 66900, change in cost 0.000136375\n",
      "step 66910, training accuracy 0.96748\n",
      "step 66910, cost 5.14471\n",
      "step 66910, change in cost 0.000136852\n",
      "step 66920, training accuracy 0.96748\n",
      "step 66920, cost 5.14457\n",
      "step 66920, change in cost 0.000138283\n",
      "step 66930, training accuracy 0.96748\n",
      "step 66930, cost 5.14443\n",
      "step 66930, change in cost 0.000136375\n",
      "step 66940, training accuracy 0.96748\n",
      "step 66940, cost 5.1443\n",
      "step 66940, change in cost 0.000137329\n",
      "step 66950, training accuracy 0.96748\n",
      "step 66950, cost 5.14416\n",
      "step 66950, change in cost 0.000137329\n",
      "step 66960, training accuracy 0.96748\n",
      "step 66960, cost 5.14402\n",
      "step 66960, change in cost 0.000137329\n",
      "step 66970, training accuracy 0.96748\n",
      "step 66970, cost 5.14389\n",
      "step 66970, change in cost 0.000135422\n",
      "step 66980, training accuracy 0.96748\n",
      "step 66980, cost 5.14375\n",
      "step 66980, change in cost 0.000138283\n",
      "step 66990, training accuracy 0.96748\n",
      "step 66990, cost 5.14361\n",
      "step 66990, change in cost 0.000136375\n",
      "step 67000, training accuracy 0.96748\n",
      "step 67000, cost 5.14347\n",
      "step 67000, change in cost 0.000136375\n",
      "step 67010, training accuracy 0.96748\n",
      "step 67010, cost 5.14334\n",
      "step 67010, change in cost 0.000135899\n",
      "step 67020, training accuracy 0.96748\n",
      "step 67020, cost 5.1432\n",
      "step 67020, change in cost 0.000136852\n",
      "step 67030, training accuracy 0.96748\n",
      "step 67030, cost 5.14307\n",
      "step 67030, change in cost 0.000136375\n",
      "step 67040, training accuracy 0.96748\n",
      "step 67040, cost 5.14293\n",
      "step 67040, change in cost 0.000136375\n",
      "step 67050, training accuracy 0.96748\n",
      "step 67050, cost 5.14279\n",
      "step 67050, change in cost 0.000135899\n",
      "step 67060, training accuracy 0.96748\n",
      "step 67060, cost 5.14266\n",
      "step 67060, change in cost 0.000136852\n",
      "step 67070, training accuracy 0.96748\n",
      "step 67070, cost 5.14252\n",
      "step 67070, change in cost 0.000137806\n",
      "step 67080, training accuracy 0.96748\n",
      "step 67080, cost 5.14238\n",
      "step 67080, change in cost 0.000134945\n",
      "step 67090, training accuracy 0.96748\n",
      "step 67090, cost 5.14225\n",
      "step 67090, change in cost 0.000136375\n",
      "step 67100, training accuracy 0.96748\n",
      "step 67100, cost 5.14211\n",
      "step 67100, change in cost 0.000137329\n",
      "step 67110, training accuracy 0.96748\n",
      "step 67110, cost 5.14197\n",
      "step 67110, change in cost 0.000135899\n",
      "step 67120, training accuracy 0.96748\n",
      "step 67120, cost 5.14184\n",
      "step 67120, change in cost 0.000135899\n",
      "step 67130, training accuracy 0.96748\n",
      "step 67130, cost 5.1417\n",
      "step 67130, change in cost 0.000135899\n",
      "step 67140, training accuracy 0.96748\n",
      "step 67140, cost 5.14157\n",
      "step 67140, change in cost 0.000134945\n",
      "step 67150, training accuracy 0.96748\n",
      "step 67150, cost 5.14143\n",
      "step 67150, change in cost 0.000137806\n",
      "step 67160, training accuracy 0.96748\n",
      "step 67160, cost 5.14129\n",
      "step 67160, change in cost 0.000134945\n",
      "step 67170, training accuracy 0.96748\n",
      "step 67170, cost 5.14116\n",
      "step 67170, change in cost 0.000136375\n",
      "step 67180, training accuracy 0.96748\n",
      "step 67180, cost 5.14102\n",
      "step 67180, change in cost 0.000135422\n",
      "step 67190, training accuracy 0.96748\n",
      "step 67190, cost 5.14089\n",
      "step 67190, change in cost 0.000137329\n",
      "step 67200, training accuracy 0.96748\n",
      "step 67200, cost 5.14075\n",
      "step 67200, change in cost 0.000134468\n",
      "step 67210, training accuracy 0.96748\n",
      "step 67210, cost 5.14061\n",
      "step 67210, change in cost 0.000136375\n",
      "step 67220, training accuracy 0.96748\n",
      "step 67220, cost 5.14048\n",
      "step 67220, change in cost 0.000136375\n",
      "step 67230, training accuracy 0.96748\n",
      "step 67230, cost 5.14034\n",
      "step 67230, change in cost 0.000135899\n",
      "step 67240, training accuracy 0.96748\n",
      "step 67240, cost 5.14021\n",
      "step 67240, change in cost 0.000135899\n",
      "step 67250, training accuracy 0.96748\n",
      "step 67250, cost 5.14007\n",
      "step 67250, change in cost 0.000134945\n",
      "step 67260, training accuracy 0.96748\n",
      "step 67260, cost 5.13994\n",
      "step 67260, change in cost 0.000135899\n",
      "step 67270, training accuracy 0.96748\n",
      "step 67270, cost 5.1398\n",
      "step 67270, change in cost 0.000134468\n",
      "step 67280, training accuracy 0.96748\n",
      "step 67280, cost 5.13966\n",
      "step 67280, change in cost 0.000136375\n",
      "step 67290, training accuracy 0.96748\n",
      "step 67290, cost 5.13953\n",
      "step 67290, change in cost 0.000134945\n",
      "step 67300, training accuracy 0.96748\n",
      "step 67300, cost 5.13939\n",
      "step 67300, change in cost 0.000135899\n",
      "step 67310, training accuracy 0.96748\n",
      "step 67310, cost 5.13926\n",
      "step 67310, change in cost 0.000133991\n",
      "step 67320, training accuracy 0.96748\n",
      "step 67320, cost 5.13912\n",
      "step 67320, change in cost 0.000135422\n",
      "step 67330, training accuracy 0.96748\n",
      "step 67330, cost 5.13899\n",
      "step 67330, change in cost 0.000135422\n",
      "step 67340, training accuracy 0.96748\n",
      "step 67340, cost 5.13885\n",
      "step 67340, change in cost 0.000135899\n",
      "step 67350, training accuracy 0.96748\n",
      "step 67350, cost 5.13872\n",
      "step 67350, change in cost 0.000133991\n",
      "step 67360, training accuracy 0.96748\n",
      "step 67360, cost 5.13858\n",
      "step 67360, change in cost 0.000135899\n",
      "step 67370, training accuracy 0.96748\n",
      "step 67370, cost 5.13845\n",
      "step 67370, change in cost 0.000133991\n",
      "step 67380, training accuracy 0.96748\n",
      "step 67380, cost 5.13831\n",
      "step 67380, change in cost 0.000135422\n",
      "step 67390, training accuracy 0.96748\n",
      "step 67390, cost 5.13818\n",
      "step 67390, change in cost 0.000133991\n",
      "step 67400, training accuracy 0.96748\n",
      "step 67400, cost 5.13804\n",
      "step 67400, change in cost 0.000134945\n",
      "step 67410, training accuracy 0.96748\n",
      "step 67410, cost 5.13791\n",
      "step 67410, change in cost 0.000134468\n",
      "step 67420, training accuracy 0.96748\n",
      "step 67420, cost 5.13778\n",
      "step 67420, change in cost 0.000134945\n",
      "step 67430, training accuracy 0.96748\n",
      "step 67430, cost 5.13764\n",
      "step 67430, change in cost 0.000135422\n",
      "step 67440, training accuracy 0.96748\n",
      "step 67440, cost 5.1375\n",
      "step 67440, change in cost 0.000135422\n",
      "step 67450, training accuracy 0.96748\n",
      "step 67450, cost 5.13737\n",
      "step 67450, change in cost 0.000133514\n",
      "step 67460, training accuracy 0.96748\n",
      "step 67460, cost 5.13724\n",
      "step 67460, change in cost 0.000134468\n",
      "step 67470, training accuracy 0.96748\n",
      "step 67470, cost 5.1371\n",
      "step 67470, change in cost 0.000134468\n",
      "step 67480, training accuracy 0.96748\n",
      "step 67480, cost 5.13697\n",
      "step 67480, change in cost 0.000134468\n",
      "step 67490, training accuracy 0.96748\n",
      "step 67490, cost 5.13683\n",
      "step 67490, change in cost 0.000134468\n",
      "step 67500, training accuracy 0.96748\n",
      "step 67500, cost 5.1367\n",
      "step 67500, change in cost 0.000134945\n",
      "step 67510, training accuracy 0.96748\n",
      "step 67510, cost 5.13656\n",
      "step 67510, change in cost 0.000134468\n",
      "step 67520, training accuracy 0.96748\n",
      "step 67520, cost 5.13643\n",
      "step 67520, change in cost 0.000133991\n",
      "step 67530, training accuracy 0.96748\n",
      "step 67530, cost 5.1363\n",
      "step 67530, change in cost 0.000134468\n",
      "step 67540, training accuracy 0.96748\n",
      "step 67540, cost 5.13616\n",
      "step 67540, change in cost 0.000134468\n",
      "step 67550, training accuracy 0.96748\n",
      "step 67550, cost 5.13603\n",
      "step 67550, change in cost 0.000133991\n",
      "step 67560, training accuracy 0.96748\n",
      "step 67560, cost 5.13589\n",
      "step 67560, change in cost 0.000133038\n",
      "step 67570, training accuracy 0.96748\n",
      "step 67570, cost 5.13576\n",
      "step 67570, change in cost 0.000135422\n",
      "step 67580, training accuracy 0.96748\n",
      "step 67580, cost 5.13562\n",
      "step 67580, change in cost 0.000134468\n",
      "step 67590, training accuracy 0.96748\n",
      "step 67590, cost 5.13549\n",
      "step 67590, change in cost 0.000132561\n",
      "step 67600, training accuracy 0.96748\n",
      "step 67600, cost 5.13536\n",
      "step 67600, change in cost 0.000134468\n",
      "step 67610, training accuracy 0.96748\n",
      "step 67610, cost 5.13522\n",
      "step 67610, change in cost 0.000133514\n",
      "step 67620, training accuracy 0.96748\n",
      "step 67620, cost 5.13509\n",
      "step 67620, change in cost 0.000134468\n",
      "step 67630, training accuracy 0.96748\n",
      "step 67630, cost 5.13495\n",
      "step 67630, change in cost 0.000134468\n",
      "step 67640, training accuracy 0.96748\n",
      "step 67640, cost 5.13482\n",
      "step 67640, change in cost 0.000133038\n",
      "step 67650, training accuracy 0.96748\n",
      "step 67650, cost 5.13469\n",
      "step 67650, change in cost 0.000133991\n",
      "step 67660, training accuracy 0.96748\n",
      "step 67660, cost 5.13455\n",
      "step 67660, change in cost 0.000133514\n",
      "step 67670, training accuracy 0.96748\n",
      "step 67670, cost 5.13442\n",
      "step 67670, change in cost 0.000134468\n",
      "step 67680, training accuracy 0.96748\n",
      "step 67680, cost 5.13429\n",
      "step 67680, change in cost 0.000133514\n",
      "step 67690, training accuracy 0.96748\n",
      "step 67690, cost 5.13415\n",
      "step 67690, change in cost 0.000134468\n",
      "step 67700, training accuracy 0.96748\n",
      "step 67700, cost 5.13402\n",
      "step 67700, change in cost 0.000132084\n",
      "step 67710, training accuracy 0.96748\n",
      "step 67710, cost 5.13388\n",
      "step 67710, change in cost 0.000134468\n",
      "step 67720, training accuracy 0.96748\n",
      "step 67720, cost 5.13375\n",
      "step 67720, change in cost 0.000132561\n",
      "step 67730, training accuracy 0.96748\n",
      "step 67730, cost 5.13362\n",
      "step 67730, change in cost 0.000133991\n",
      "step 67740, training accuracy 0.96748\n",
      "step 67740, cost 5.13348\n",
      "step 67740, change in cost 0.000133514\n",
      "step 67750, training accuracy 0.96748\n",
      "step 67750, cost 5.13335\n",
      "step 67750, change in cost 0.000132561\n",
      "step 67760, training accuracy 0.96748\n",
      "step 67760, cost 5.13322\n",
      "step 67760, change in cost 0.000132561\n",
      "step 67770, training accuracy 0.96748\n",
      "step 67770, cost 5.13309\n",
      "step 67770, change in cost 0.000133514\n",
      "step 67780, training accuracy 0.96748\n",
      "step 67780, cost 5.13295\n",
      "step 67780, change in cost 0.000133038\n",
      "step 67790, training accuracy 0.96748\n",
      "step 67790, cost 5.13282\n",
      "step 67790, change in cost 0.000133514\n",
      "step 67800, training accuracy 0.96748\n",
      "step 67800, cost 5.13269\n",
      "step 67800, change in cost 0.000132561\n",
      "step 67810, training accuracy 0.96748\n",
      "step 67810, cost 5.13255\n",
      "step 67810, change in cost 0.000132561\n",
      "step 67820, training accuracy 0.96748\n",
      "step 67820, cost 5.13242\n",
      "step 67820, change in cost 0.000133038\n",
      "step 67830, training accuracy 0.96748\n",
      "step 67830, cost 5.13229\n",
      "step 67830, change in cost 0.000133514\n",
      "step 67840, training accuracy 0.96748\n",
      "step 67840, cost 5.13216\n",
      "step 67840, change in cost 0.000132561\n",
      "step 67850, training accuracy 0.96748\n",
      "step 67850, cost 5.13202\n",
      "step 67850, change in cost 0.000133514\n",
      "step 67860, training accuracy 0.96748\n",
      "step 67860, cost 5.13189\n",
      "step 67860, change in cost 0.000133038\n",
      "step 67870, training accuracy 0.96748\n",
      "step 67870, cost 5.13176\n",
      "step 67870, change in cost 0.000133038\n",
      "step 67880, training accuracy 0.96748\n",
      "step 67880, cost 5.13162\n",
      "step 67880, change in cost 0.000131607\n",
      "step 67890, training accuracy 0.96748\n",
      "step 67890, cost 5.13149\n",
      "step 67890, change in cost 0.000133038\n",
      "step 67900, training accuracy 0.96748\n",
      "step 67900, cost 5.13136\n",
      "step 67900, change in cost 0.000133038\n",
      "step 67910, training accuracy 0.96748\n",
      "step 67910, cost 5.13123\n",
      "step 67910, change in cost 0.000132084\n",
      "step 67920, training accuracy 0.96748\n",
      "step 67920, cost 5.13109\n",
      "step 67920, change in cost 0.000131607\n",
      "step 67930, training accuracy 0.96748\n",
      "step 67930, cost 5.13096\n",
      "step 67930, change in cost 0.000132084\n",
      "step 67940, training accuracy 0.96748\n",
      "step 67940, cost 5.13083\n",
      "step 67940, change in cost 0.000132561\n",
      "step 67950, training accuracy 0.96748\n",
      "step 67950, cost 5.1307\n",
      "step 67950, change in cost 0.000132084\n",
      "step 67960, training accuracy 0.96748\n",
      "step 67960, cost 5.13057\n",
      "step 67960, change in cost 0.000132084\n",
      "step 67970, training accuracy 0.96748\n",
      "step 67970, cost 5.13043\n",
      "step 67970, change in cost 0.000132561\n",
      "step 67980, training accuracy 0.96748\n",
      "step 67980, cost 5.1303\n",
      "step 67980, change in cost 0.000132561\n",
      "step 67990, training accuracy 0.96748\n",
      "step 67990, cost 5.13017\n",
      "step 67990, change in cost 0.000133038\n",
      "step 68000, training accuracy 0.96748\n",
      "step 68000, cost 5.13004\n",
      "step 68000, change in cost 0.000131607\n",
      "step 68010, training accuracy 0.96748\n",
      "step 68010, cost 5.1299\n",
      "step 68010, change in cost 0.000132084\n",
      "step 68020, training accuracy 0.96748\n",
      "step 68020, cost 5.12977\n",
      "step 68020, change in cost 0.000131607\n",
      "step 68030, training accuracy 0.96748\n",
      "step 68030, cost 5.12964\n",
      "step 68030, change in cost 0.000131607\n",
      "step 68040, training accuracy 0.96748\n",
      "step 68040, cost 5.12951\n",
      "step 68040, change in cost 0.000131607\n",
      "step 68050, training accuracy 0.96748\n",
      "step 68050, cost 5.12938\n",
      "step 68050, change in cost 0.000131607\n",
      "step 68060, training accuracy 0.96748\n",
      "step 68060, cost 5.12925\n",
      "step 68060, change in cost 0.000131607\n",
      "step 68070, training accuracy 0.96748\n",
      "step 68070, cost 5.12911\n",
      "step 68070, change in cost 0.000132561\n",
      "step 68080, training accuracy 0.96748\n",
      "step 68080, cost 5.12898\n",
      "step 68080, change in cost 0.000131607\n",
      "step 68090, training accuracy 0.96748\n",
      "step 68090, cost 5.12885\n",
      "step 68090, change in cost 0.000132084\n",
      "step 68100, training accuracy 0.96748\n",
      "step 68100, cost 5.12872\n",
      "step 68100, change in cost 0.000131607\n",
      "step 68110, training accuracy 0.96748\n",
      "step 68110, cost 5.12859\n",
      "step 68110, change in cost 0.000132084\n",
      "step 68120, training accuracy 0.96748\n",
      "step 68120, cost 5.12845\n",
      "step 68120, change in cost 0.000132084\n",
      "step 68130, training accuracy 0.96748\n",
      "step 68130, cost 5.12832\n",
      "step 68130, change in cost 0.000131607\n",
      "step 68140, training accuracy 0.96748\n",
      "step 68140, cost 5.12819\n",
      "step 68140, change in cost 0.000132084\n",
      "step 68150, training accuracy 0.96748\n",
      "step 68150, cost 5.12806\n",
      "step 68150, change in cost 0.000130653\n",
      "step 68160, training accuracy 0.96748\n",
      "step 68160, cost 5.12793\n",
      "step 68160, change in cost 0.00013113\n",
      "step 68170, training accuracy 0.96748\n",
      "step 68170, cost 5.1278\n",
      "step 68170, change in cost 0.000132084\n",
      "step 68180, training accuracy 0.96748\n",
      "step 68180, cost 5.12766\n",
      "step 68180, change in cost 0.000131607\n",
      "step 68190, training accuracy 0.96748\n",
      "step 68190, cost 5.12753\n",
      "step 68190, change in cost 0.000131607\n",
      "step 68200, training accuracy 0.96748\n",
      "step 68200, cost 5.1274\n",
      "step 68200, change in cost 0.000131607\n",
      "step 68210, training accuracy 0.96748\n",
      "step 68210, cost 5.12727\n",
      "step 68210, change in cost 0.000131607\n",
      "step 68220, training accuracy 0.96748\n",
      "step 68220, cost 5.12714\n",
      "step 68220, change in cost 0.0001297\n",
      "step 68230, training accuracy 0.96748\n",
      "step 68230, cost 5.12701\n",
      "step 68230, change in cost 0.000131607\n",
      "step 68240, training accuracy 0.96748\n",
      "step 68240, cost 5.12688\n",
      "step 68240, change in cost 0.000130177\n",
      "step 68250, training accuracy 0.96748\n",
      "step 68250, cost 5.12675\n",
      "step 68250, change in cost 0.000132084\n",
      "step 68260, training accuracy 0.96748\n",
      "step 68260, cost 5.12662\n",
      "step 68260, change in cost 0.000130653\n",
      "step 68270, training accuracy 0.96748\n",
      "step 68270, cost 5.12648\n",
      "step 68270, change in cost 0.000131607\n",
      "step 68280, training accuracy 0.96748\n",
      "step 68280, cost 5.12635\n",
      "step 68280, change in cost 0.000131607\n",
      "step 68290, training accuracy 0.96748\n",
      "step 68290, cost 5.12622\n",
      "step 68290, change in cost 0.000130653\n",
      "step 68300, training accuracy 0.96748\n",
      "step 68300, cost 5.12609\n",
      "step 68300, change in cost 0.000130653\n",
      "step 68310, training accuracy 0.96748\n",
      "step 68310, cost 5.12596\n",
      "step 68310, change in cost 0.00013113\n",
      "step 68320, training accuracy 0.96748\n",
      "step 68320, cost 5.12583\n",
      "step 68320, change in cost 0.000130177\n",
      "step 68330, training accuracy 0.96748\n",
      "step 68330, cost 5.1257\n",
      "step 68330, change in cost 0.000131607\n",
      "step 68340, training accuracy 0.96748\n",
      "step 68340, cost 5.12557\n",
      "step 68340, change in cost 0.0001297\n",
      "step 68350, training accuracy 0.96748\n",
      "step 68350, cost 5.12544\n",
      "step 68350, change in cost 0.000130653\n",
      "step 68360, training accuracy 0.96748\n",
      "step 68360, cost 5.12531\n",
      "step 68360, change in cost 0.000130653\n",
      "step 68370, training accuracy 0.96748\n",
      "step 68370, cost 5.12518\n",
      "step 68370, change in cost 0.000131607\n",
      "step 68380, training accuracy 0.96748\n",
      "step 68380, cost 5.12505\n",
      "step 68380, change in cost 0.0001297\n",
      "step 68390, training accuracy 0.96748\n",
      "step 68390, cost 5.12492\n",
      "step 68390, change in cost 0.000130653\n",
      "step 68400, training accuracy 0.96748\n",
      "step 68400, cost 5.12478\n",
      "step 68400, change in cost 0.00013113\n",
      "step 68410, training accuracy 0.96748\n",
      "step 68410, cost 5.12465\n",
      "step 68410, change in cost 0.000130177\n",
      "step 68420, training accuracy 0.96748\n",
      "step 68420, cost 5.12452\n",
      "step 68420, change in cost 0.000130177\n",
      "step 68430, training accuracy 0.96748\n",
      "step 68430, cost 5.12439\n",
      "step 68430, change in cost 0.00013113\n",
      "step 68440, training accuracy 0.96748\n",
      "step 68440, cost 5.12426\n",
      "step 68440, change in cost 0.000130177\n",
      "step 68450, training accuracy 0.96748\n",
      "step 68450, cost 5.12413\n",
      "step 68450, change in cost 0.00013113\n",
      "step 68460, training accuracy 0.96748\n",
      "step 68460, cost 5.124\n",
      "step 68460, change in cost 0.000129223\n",
      "step 68470, training accuracy 0.96748\n",
      "step 68470, cost 5.12387\n",
      "step 68470, change in cost 0.000130653\n",
      "step 68480, training accuracy 0.96748\n",
      "step 68480, cost 5.12374\n",
      "step 68480, change in cost 0.0001297\n",
      "step 68490, training accuracy 0.96748\n",
      "step 68490, cost 5.12361\n",
      "step 68490, change in cost 0.000130653\n",
      "step 68500, training accuracy 0.96748\n",
      "step 68500, cost 5.12348\n",
      "step 68500, change in cost 0.000129223\n",
      "step 68510, training accuracy 0.96748\n",
      "step 68510, cost 5.12335\n",
      "step 68510, change in cost 0.000130653\n",
      "step 68520, training accuracy 0.96748\n",
      "step 68520, cost 5.12322\n",
      "step 68520, change in cost 0.000130653\n",
      "step 68530, training accuracy 0.96748\n",
      "step 68530, cost 5.12309\n",
      "step 68530, change in cost 0.0001297\n",
      "step 68540, training accuracy 0.96748\n",
      "step 68540, cost 5.12296\n",
      "step 68540, change in cost 0.000130177\n",
      "step 68550, training accuracy 0.96748\n",
      "step 68550, cost 5.12283\n",
      "step 68550, change in cost 0.000129223\n",
      "step 68560, training accuracy 0.96748\n",
      "step 68560, cost 5.1227\n",
      "step 68560, change in cost 0.0001297\n",
      "step 68570, training accuracy 0.96748\n",
      "step 68570, cost 5.12257\n",
      "step 68570, change in cost 0.000130177\n",
      "step 68580, training accuracy 0.96748\n",
      "step 68580, cost 5.12244\n",
      "step 68580, change in cost 0.000129223\n",
      "step 68590, training accuracy 0.96748\n",
      "step 68590, cost 5.12231\n",
      "step 68590, change in cost 0.000130653\n",
      "step 68600, training accuracy 0.96748\n",
      "step 68600, cost 5.12218\n",
      "step 68600, change in cost 0.000128746\n",
      "step 68610, training accuracy 0.96748\n",
      "step 68610, cost 5.12205\n",
      "step 68610, change in cost 0.000130653\n",
      "step 68620, training accuracy 0.96748\n",
      "step 68620, cost 5.12192\n",
      "step 68620, change in cost 0.0001297\n",
      "step 68630, training accuracy 0.96748\n",
      "step 68630, cost 5.12179\n",
      "step 68630, change in cost 0.000129223\n",
      "step 68640, training accuracy 0.96748\n",
      "step 68640, cost 5.12166\n",
      "step 68640, change in cost 0.000130177\n",
      "step 68650, training accuracy 0.96748\n",
      "step 68650, cost 5.12153\n",
      "step 68650, change in cost 0.000128746\n",
      "step 68660, training accuracy 0.96748\n",
      "step 68660, cost 5.12141\n",
      "step 68660, change in cost 0.000127792\n",
      "step 68670, training accuracy 0.96748\n",
      "step 68670, cost 5.12128\n",
      "step 68670, change in cost 0.000130653\n",
      "step 68680, training accuracy 0.96748\n",
      "step 68680, cost 5.12115\n",
      "step 68680, change in cost 0.000128746\n",
      "step 68690, training accuracy 0.96748\n",
      "step 68690, cost 5.12102\n",
      "step 68690, change in cost 0.0001297\n",
      "step 68700, training accuracy 0.96748\n",
      "step 68700, cost 5.12089\n",
      "step 68700, change in cost 0.0001297\n",
      "step 68710, training accuracy 0.96748\n",
      "step 68710, cost 5.12076\n",
      "step 68710, change in cost 0.000129223\n",
      "step 68720, training accuracy 0.96748\n",
      "step 68720, cost 5.12063\n",
      "step 68720, change in cost 0.000129223\n",
      "step 68730, training accuracy 0.96748\n",
      "step 68730, cost 5.1205\n",
      "step 68730, change in cost 0.000128269\n",
      "step 68740, training accuracy 0.96748\n",
      "step 68740, cost 5.12037\n",
      "step 68740, change in cost 0.00013113\n",
      "step 68750, training accuracy 0.96748\n",
      "step 68750, cost 5.12024\n",
      "step 68750, change in cost 0.000128746\n",
      "step 68760, training accuracy 0.96748\n",
      "step 68760, cost 5.12011\n",
      "step 68760, change in cost 0.0001297\n",
      "step 68770, training accuracy 0.96748\n",
      "step 68770, cost 5.11998\n",
      "step 68770, change in cost 0.000128746\n",
      "step 68780, training accuracy 0.96748\n",
      "step 68780, cost 5.11985\n",
      "step 68780, change in cost 0.000127792\n",
      "step 68790, training accuracy 0.96748\n",
      "step 68790, cost 5.11973\n",
      "step 68790, change in cost 0.0001297\n",
      "step 68800, training accuracy 0.96748\n",
      "step 68800, cost 5.1196\n",
      "step 68800, change in cost 0.000127792\n",
      "step 68810, training accuracy 0.96748\n",
      "step 68810, cost 5.11947\n",
      "step 68810, change in cost 0.0001297\n",
      "step 68820, training accuracy 0.96748\n",
      "step 68820, cost 5.11934\n",
      "step 68820, change in cost 0.000128746\n",
      "step 68830, training accuracy 0.96748\n",
      "step 68830, cost 5.11921\n",
      "step 68830, change in cost 0.000127792\n",
      "step 68840, training accuracy 0.96748\n",
      "step 68840, cost 5.11908\n",
      "step 68840, change in cost 0.000127792\n",
      "step 68850, training accuracy 0.96748\n",
      "step 68850, cost 5.11895\n",
      "step 68850, change in cost 0.0001297\n",
      "step 68860, training accuracy 0.96748\n",
      "step 68860, cost 5.11882\n",
      "step 68860, change in cost 0.0001297\n",
      "step 68870, training accuracy 0.96748\n",
      "step 68870, cost 5.1187\n",
      "step 68870, change in cost 0.000126839\n",
      "step 68880, training accuracy 0.96748\n",
      "step 68880, cost 5.11857\n",
      "step 68880, change in cost 0.000129223\n",
      "step 68890, training accuracy 0.96748\n",
      "step 68890, cost 5.11844\n",
      "step 68890, change in cost 0.000128269\n",
      "step 68900, training accuracy 0.96748\n",
      "step 68900, cost 5.11831\n",
      "step 68900, change in cost 0.0001297\n",
      "step 68910, training accuracy 0.96748\n",
      "step 68910, cost 5.11818\n",
      "step 68910, change in cost 0.000127316\n",
      "step 68920, training accuracy 0.96748\n",
      "step 68920, cost 5.11805\n",
      "step 68920, change in cost 0.000128746\n",
      "step 68930, training accuracy 0.96748\n",
      "step 68930, cost 5.11793\n",
      "step 68930, change in cost 0.000127792\n",
      "step 68940, training accuracy 0.96748\n",
      "step 68940, cost 5.1178\n",
      "step 68940, change in cost 0.000128269\n",
      "step 68950, training accuracy 0.96748\n",
      "step 68950, cost 5.11767\n",
      "step 68950, change in cost 0.000128746\n",
      "step 68960, training accuracy 0.96748\n",
      "step 68960, cost 5.11754\n",
      "step 68960, change in cost 0.000127792\n",
      "step 68970, training accuracy 0.96748\n",
      "step 68970, cost 5.11741\n",
      "step 68970, change in cost 0.000126839\n",
      "step 68980, training accuracy 0.96748\n",
      "step 68980, cost 5.11728\n",
      "step 68980, change in cost 0.0001297\n",
      "step 68990, training accuracy 0.96748\n",
      "step 68990, cost 5.11716\n",
      "step 68990, change in cost 0.000127316\n",
      "step 69000, training accuracy 0.96748\n",
      "step 69000, cost 5.11703\n",
      "step 69000, change in cost 0.000128269\n",
      "step 69010, training accuracy 0.96748\n",
      "step 69010, cost 5.1169\n",
      "step 69010, change in cost 0.000128269\n",
      "step 69020, training accuracy 0.96748\n",
      "step 69020, cost 5.11677\n",
      "step 69020, change in cost 0.000127792\n",
      "step 69030, training accuracy 0.96748\n",
      "step 69030, cost 5.11664\n",
      "step 69030, change in cost 0.000128269\n",
      "step 69040, training accuracy 0.96748\n",
      "step 69040, cost 5.11652\n",
      "step 69040, change in cost 0.000126839\n",
      "step 69050, training accuracy 0.96748\n",
      "step 69050, cost 5.11639\n",
      "step 69050, change in cost 0.000127792\n",
      "step 69060, training accuracy 0.96748\n",
      "step 69060, cost 5.11626\n",
      "step 69060, change in cost 0.000128269\n",
      "step 69070, training accuracy 0.96748\n",
      "step 69070, cost 5.11613\n",
      "step 69070, change in cost 0.000127316\n",
      "step 69080, training accuracy 0.96748\n",
      "step 69080, cost 5.11601\n",
      "step 69080, change in cost 0.000128746\n",
      "step 69090, training accuracy 0.96748\n",
      "step 69090, cost 5.11588\n",
      "step 69090, change in cost 0.000126839\n",
      "step 69100, training accuracy 0.96748\n",
      "step 69100, cost 5.11575\n",
      "step 69100, change in cost 0.000127792\n",
      "step 69110, training accuracy 0.96748\n",
      "step 69110, cost 5.11562\n",
      "step 69110, change in cost 0.000126839\n",
      "step 69120, training accuracy 0.96748\n",
      "step 69120, cost 5.1155\n",
      "step 69120, change in cost 0.000128269\n",
      "step 69130, training accuracy 0.96748\n",
      "step 69130, cost 5.11537\n",
      "step 69130, change in cost 0.000127316\n",
      "step 69140, training accuracy 0.96748\n",
      "step 69140, cost 5.11524\n",
      "step 69140, change in cost 0.000128746\n",
      "step 69150, training accuracy 0.96748\n",
      "step 69150, cost 5.11511\n",
      "step 69150, change in cost 0.000126839\n",
      "step 69160, training accuracy 0.96748\n",
      "step 69160, cost 5.11499\n",
      "step 69160, change in cost 0.000126839\n",
      "step 69170, training accuracy 0.96748\n",
      "step 69170, cost 5.11486\n",
      "step 69170, change in cost 0.000126839\n",
      "step 69180, training accuracy 0.96748\n",
      "step 69180, cost 5.11473\n",
      "step 69180, change in cost 0.000127316\n",
      "step 69190, training accuracy 0.96748\n",
      "step 69190, cost 5.1146\n",
      "step 69190, change in cost 0.000127316\n",
      "step 69200, training accuracy 0.96748\n",
      "step 69200, cost 5.11448\n",
      "step 69200, change in cost 0.000126839\n",
      "step 69210, training accuracy 0.96748\n",
      "step 69210, cost 5.11435\n",
      "step 69210, change in cost 0.000127792\n",
      "step 69220, training accuracy 0.96748\n",
      "step 69220, cost 5.11422\n",
      "step 69220, change in cost 0.000126839\n",
      "step 69230, training accuracy 0.96748\n",
      "step 69230, cost 5.1141\n",
      "step 69230, change in cost 0.000127792\n",
      "step 69240, training accuracy 0.96748\n",
      "step 69240, cost 5.11397\n",
      "step 69240, change in cost 0.000126839\n",
      "step 69250, training accuracy 0.96748\n",
      "step 69250, cost 5.11384\n",
      "step 69250, change in cost 0.000126362\n",
      "step 69260, training accuracy 0.96748\n",
      "step 69260, cost 5.11371\n",
      "step 69260, change in cost 0.000128269\n",
      "step 69270, training accuracy 0.96748\n",
      "step 69270, cost 5.11359\n",
      "step 69270, change in cost 0.000126362\n",
      "step 69280, training accuracy 0.96748\n",
      "step 69280, cost 5.11346\n",
      "step 69280, change in cost 0.000126839\n",
      "step 69290, training accuracy 0.96748\n",
      "step 69290, cost 5.11333\n",
      "step 69290, change in cost 0.000127316\n",
      "step 69300, training accuracy 0.96748\n",
      "step 69300, cost 5.11321\n",
      "step 69300, change in cost 0.000125885\n",
      "step 69310, training accuracy 0.96748\n",
      "step 69310, cost 5.11308\n",
      "step 69310, change in cost 0.000126839\n",
      "step 69320, training accuracy 0.96748\n",
      "step 69320, cost 5.11295\n",
      "step 69320, change in cost 0.000126362\n",
      "step 69330, training accuracy 0.96748\n",
      "step 69330, cost 5.11283\n",
      "step 69330, change in cost 0.000126839\n",
      "step 69340, training accuracy 0.96748\n",
      "step 69340, cost 5.1127\n",
      "step 69340, change in cost 0.000126839\n",
      "step 69350, training accuracy 0.96748\n",
      "step 69350, cost 5.11257\n",
      "step 69350, change in cost 0.000127316\n",
      "step 69360, training accuracy 0.96748\n",
      "step 69360, cost 5.11245\n",
      "step 69360, change in cost 0.000125885\n",
      "step 69370, training accuracy 0.96748\n",
      "step 69370, cost 5.11232\n",
      "step 69370, change in cost 0.000127316\n",
      "step 69380, training accuracy 0.96748\n",
      "step 69380, cost 5.1122\n",
      "step 69380, change in cost 0.000125408\n",
      "step 69390, training accuracy 0.96748\n",
      "step 69390, cost 5.11207\n",
      "step 69390, change in cost 0.000126362\n",
      "step 69400, training accuracy 0.96748\n",
      "step 69400, cost 5.11194\n",
      "step 69400, change in cost 0.000126839\n",
      "step 69410, training accuracy 0.96748\n",
      "step 69410, cost 5.11182\n",
      "step 69410, change in cost 0.000125408\n",
      "step 69420, training accuracy 0.96748\n",
      "step 69420, cost 5.11169\n",
      "step 69420, change in cost 0.000126839\n",
      "step 69430, training accuracy 0.96748\n",
      "step 69430, cost 5.11156\n",
      "step 69430, change in cost 0.000125408\n",
      "step 69440, training accuracy 0.96748\n",
      "step 69440, cost 5.11144\n",
      "step 69440, change in cost 0.000126362\n",
      "step 69450, training accuracy 0.96748\n",
      "step 69450, cost 5.11131\n",
      "step 69450, change in cost 0.000126362\n",
      "step 69460, training accuracy 0.96748\n",
      "step 69460, cost 5.11119\n",
      "step 69460, change in cost 0.000126362\n",
      "step 69470, training accuracy 0.96748\n",
      "step 69470, cost 5.11106\n",
      "step 69470, change in cost 0.000126362\n",
      "step 69480, training accuracy 0.96748\n",
      "step 69480, cost 5.11093\n",
      "step 69480, change in cost 0.000125408\n",
      "step 69490, training accuracy 0.96748\n",
      "step 69490, cost 5.11081\n",
      "step 69490, change in cost 0.000126839\n",
      "step 69500, training accuracy 0.96748\n",
      "step 69500, cost 5.11068\n",
      "step 69500, change in cost 0.000125885\n",
      "step 69510, training accuracy 0.96748\n",
      "step 69510, cost 5.11055\n",
      "step 69510, change in cost 0.000125885\n",
      "step 69520, training accuracy 0.96748\n",
      "step 69520, cost 5.11043\n",
      "step 69520, change in cost 0.000125885\n",
      "step 69530, training accuracy 0.96748\n",
      "step 69530, cost 5.1103\n",
      "step 69530, change in cost 0.000124931\n",
      "step 69540, training accuracy 0.96748\n",
      "step 69540, cost 5.11018\n",
      "step 69540, change in cost 0.000126839\n",
      "step 69550, training accuracy 0.96748\n",
      "step 69550, cost 5.11005\n",
      "step 69550, change in cost 0.000125885\n",
      "step 69560, training accuracy 0.96748\n",
      "step 69560, cost 5.10993\n",
      "step 69560, change in cost 0.000125885\n",
      "step 69570, training accuracy 0.96748\n",
      "step 69570, cost 5.1098\n",
      "step 69570, change in cost 0.000125885\n",
      "step 69580, training accuracy 0.96748\n",
      "step 69580, cost 5.10967\n",
      "step 69580, change in cost 0.000125885\n",
      "step 69590, training accuracy 0.96748\n",
      "step 69590, cost 5.10955\n",
      "step 69590, change in cost 0.000124931\n",
      "step 69600, training accuracy 0.96748\n",
      "step 69600, cost 5.10942\n",
      "step 69600, change in cost 0.000125885\n",
      "step 69610, training accuracy 0.96748\n",
      "step 69610, cost 5.1093\n",
      "step 69610, change in cost 0.000125408\n",
      "step 69620, training accuracy 0.96748\n",
      "step 69620, cost 5.10917\n",
      "step 69620, change in cost 0.000126362\n",
      "step 69630, training accuracy 0.96748\n",
      "step 69630, cost 5.10905\n",
      "step 69630, change in cost 0.000125885\n",
      "step 69640, training accuracy 0.96748\n",
      "step 69640, cost 5.10892\n",
      "step 69640, change in cost 0.000124931\n",
      "step 69650, training accuracy 0.96748\n",
      "step 69650, cost 5.1088\n",
      "step 69650, change in cost 0.000124931\n",
      "step 69660, training accuracy 0.96748\n",
      "step 69660, cost 5.10867\n",
      "step 69660, change in cost 0.000124931\n",
      "step 69670, training accuracy 0.96748\n",
      "step 69670, cost 5.10854\n",
      "step 69670, change in cost 0.000126362\n",
      "step 69680, training accuracy 0.96748\n",
      "step 69680, cost 5.10842\n",
      "step 69680, change in cost 0.000124454\n",
      "step 69690, training accuracy 0.96748\n",
      "step 69690, cost 5.10829\n",
      "step 69690, change in cost 0.000124931\n",
      "step 69700, training accuracy 0.96748\n",
      "step 69700, cost 5.10817\n",
      "step 69700, change in cost 0.000125885\n",
      "step 69710, training accuracy 0.96748\n",
      "step 69710, cost 5.10804\n",
      "step 69710, change in cost 0.000125408\n",
      "step 69720, training accuracy 0.96748\n",
      "step 69720, cost 5.10792\n",
      "step 69720, change in cost 0.000124454\n",
      "step 69730, training accuracy 0.96748\n",
      "step 69730, cost 5.10779\n",
      "step 69730, change in cost 0.000124931\n",
      "step 69740, training accuracy 0.96748\n",
      "step 69740, cost 5.10767\n",
      "step 69740, change in cost 0.000124931\n",
      "step 69750, training accuracy 0.96748\n",
      "step 69750, cost 5.10754\n",
      "step 69750, change in cost 0.000124931\n",
      "step 69760, training accuracy 0.96748\n",
      "step 69760, cost 5.10742\n",
      "step 69760, change in cost 0.000124931\n",
      "step 69770, training accuracy 0.96748\n",
      "step 69770, cost 5.10729\n",
      "step 69770, change in cost 0.000124454\n",
      "step 69780, training accuracy 0.96748\n",
      "step 69780, cost 5.10717\n",
      "step 69780, change in cost 0.000126362\n",
      "step 69790, training accuracy 0.96748\n",
      "step 69790, cost 5.10704\n",
      "step 69790, change in cost 0.000123978\n",
      "step 69800, training accuracy 0.96748\n",
      "step 69800, cost 5.10692\n",
      "step 69800, change in cost 0.000124931\n",
      "step 69810, training accuracy 0.96748\n",
      "step 69810, cost 5.1068\n",
      "step 69810, change in cost 0.000123024\n",
      "step 69820, training accuracy 0.96748\n",
      "step 69820, cost 5.10667\n",
      "step 69820, change in cost 0.000125885\n",
      "step 69830, training accuracy 0.96748\n",
      "step 69830, cost 5.10655\n",
      "step 69830, change in cost 0.000123978\n",
      "step 69840, training accuracy 0.96748\n",
      "step 69840, cost 5.10642\n",
      "step 69840, change in cost 0.000124931\n",
      "step 69850, training accuracy 0.96748\n",
      "step 69850, cost 5.1063\n",
      "step 69850, change in cost 0.000124931\n",
      "step 69860, training accuracy 0.96748\n",
      "step 69860, cost 5.10617\n",
      "step 69860, change in cost 0.000124931\n",
      "step 69870, training accuracy 0.96748\n",
      "step 69870, cost 5.10605\n",
      "step 69870, change in cost 0.000123978\n",
      "step 69880, training accuracy 0.96748\n",
      "step 69880, cost 5.10592\n",
      "step 69880, change in cost 0.000123978\n",
      "step 69890, training accuracy 0.96748\n",
      "step 69890, cost 5.1058\n",
      "step 69890, change in cost 0.000123978\n",
      "step 69900, training accuracy 0.96748\n",
      "step 69900, cost 5.10567\n",
      "step 69900, change in cost 0.000125885\n",
      "step 69910, training accuracy 0.96748\n",
      "step 69910, cost 5.10555\n",
      "step 69910, change in cost 0.000123978\n",
      "step 69920, training accuracy 0.96748\n",
      "step 69920, cost 5.10543\n",
      "step 69920, change in cost 0.000123501\n",
      "step 69930, training accuracy 0.96748\n",
      "step 69930, cost 5.1053\n",
      "step 69930, change in cost 0.000125408\n",
      "step 69940, training accuracy 0.96748\n",
      "step 69940, cost 5.10518\n",
      "step 69940, change in cost 0.000123978\n",
      "step 69950, training accuracy 0.96748\n",
      "step 69950, cost 5.10505\n",
      "step 69950, change in cost 0.000124931\n",
      "step 69960, training accuracy 0.96748\n",
      "step 69960, cost 5.10493\n",
      "step 69960, change in cost 0.000123978\n",
      "step 69970, training accuracy 0.96748\n",
      "step 69970, cost 5.1048\n",
      "step 69970, change in cost 0.000123978\n",
      "step 69980, training accuracy 0.96748\n",
      "step 69980, cost 5.10468\n",
      "step 69980, change in cost 0.000123978\n",
      "step 69990, training accuracy 0.96748\n",
      "step 69990, cost 5.10456\n",
      "step 69990, change in cost 0.000123978\n",
      "step 70000, training accuracy 0.96748\n",
      "step 70000, cost 5.10443\n",
      "step 70000, change in cost 0.000123978\n",
      "step 70010, training accuracy 0.96748\n",
      "step 70010, cost 5.10431\n",
      "step 70010, change in cost 0.000124454\n",
      "step 70020, training accuracy 0.96748\n",
      "step 70020, cost 5.10418\n",
      "step 70020, change in cost 0.000124454\n",
      "step 70030, training accuracy 0.96748\n",
      "step 70030, cost 5.10406\n",
      "step 70030, change in cost 0.000123501\n",
      "step 70040, training accuracy 0.96748\n",
      "step 70040, cost 5.10394\n",
      "step 70040, change in cost 0.000123978\n",
      "step 70050, training accuracy 0.96748\n",
      "step 70050, cost 5.10381\n",
      "step 70050, change in cost 0.000123501\n",
      "step 70060, training accuracy 0.96748\n",
      "step 70060, cost 5.10369\n",
      "step 70060, change in cost 0.000123978\n",
      "step 70070, training accuracy 0.96748\n",
      "step 70070, cost 5.10356\n",
      "step 70070, change in cost 0.000123978\n",
      "step 70080, training accuracy 0.96748\n",
      "step 70080, cost 5.10344\n",
      "step 70080, change in cost 0.000123501\n",
      "step 70090, training accuracy 0.96748\n",
      "step 70090, cost 5.10332\n",
      "step 70090, change in cost 0.000123978\n",
      "step 70100, training accuracy 0.96748\n",
      "step 70100, cost 5.10319\n",
      "step 70100, change in cost 0.000123501\n",
      "step 70110, training accuracy 0.96748\n",
      "step 70110, cost 5.10307\n",
      "step 70110, change in cost 0.000123978\n",
      "step 70120, training accuracy 0.96748\n",
      "step 70120, cost 5.10295\n",
      "step 70120, change in cost 0.000123024\n",
      "step 70130, training accuracy 0.96748\n",
      "step 70130, cost 5.10282\n",
      "step 70130, change in cost 0.000123978\n",
      "step 70140, training accuracy 0.96748\n",
      "step 70140, cost 5.1027\n",
      "step 70140, change in cost 0.000123501\n",
      "step 70150, training accuracy 0.96748\n",
      "step 70150, cost 5.10258\n",
      "step 70150, change in cost 0.000123501\n",
      "step 70160, training accuracy 0.96748\n",
      "step 70160, cost 5.10245\n",
      "step 70160, change in cost 0.000123978\n",
      "step 70170, training accuracy 0.96748\n",
      "step 70170, cost 5.10233\n",
      "step 70170, change in cost 0.000123024\n",
      "step 70180, training accuracy 0.96748\n",
      "step 70180, cost 5.10221\n",
      "step 70180, change in cost 0.000123024\n",
      "step 70190, training accuracy 0.96748\n",
      "step 70190, cost 5.10208\n",
      "step 70190, change in cost 0.000123501\n",
      "step 70200, training accuracy 0.96748\n",
      "step 70200, cost 5.10196\n",
      "step 70200, change in cost 0.000123024\n",
      "step 70210, training accuracy 0.96748\n",
      "step 70210, cost 5.10183\n",
      "step 70210, change in cost 0.000124454\n",
      "step 70220, training accuracy 0.96748\n",
      "step 70220, cost 5.10171\n",
      "step 70220, change in cost 0.000123024\n",
      "step 70230, training accuracy 0.96748\n",
      "step 70230, cost 5.10159\n",
      "step 70230, change in cost 0.000123024\n",
      "step 70240, training accuracy 0.96748\n",
      "step 70240, cost 5.10147\n",
      "step 70240, change in cost 0.000122547\n",
      "step 70250, training accuracy 0.96748\n",
      "step 70250, cost 5.10134\n",
      "step 70250, change in cost 0.000122547\n",
      "step 70260, training accuracy 0.96748\n",
      "step 70260, cost 5.10122\n",
      "step 70260, change in cost 0.000123024\n",
      "step 70270, training accuracy 0.96748\n",
      "step 70270, cost 5.1011\n",
      "step 70270, change in cost 0.000123501\n",
      "step 70280, training accuracy 0.96748\n",
      "step 70280, cost 5.10097\n",
      "step 70280, change in cost 0.000123501\n",
      "step 70290, training accuracy 0.96748\n",
      "step 70290, cost 5.10085\n",
      "step 70290, change in cost 0.000122547\n",
      "step 70300, training accuracy 0.96748\n",
      "step 70300, cost 5.10073\n",
      "step 70300, change in cost 0.000123978\n",
      "step 70310, training accuracy 0.96748\n",
      "step 70310, cost 5.1006\n",
      "step 70310, change in cost 0.000123024\n",
      "step 70320, training accuracy 0.96748\n",
      "step 70320, cost 5.10048\n",
      "step 70320, change in cost 0.000123501\n",
      "step 70330, training accuracy 0.96748\n",
      "step 70330, cost 5.10036\n",
      "step 70330, change in cost 0.000121593\n",
      "step 70340, training accuracy 0.96748\n",
      "step 70340, cost 5.10024\n",
      "step 70340, change in cost 0.000122547\n",
      "step 70350, training accuracy 0.96748\n",
      "step 70350, cost 5.10011\n",
      "step 70350, change in cost 0.000123024\n",
      "step 70360, training accuracy 0.96748\n",
      "step 70360, cost 5.09999\n",
      "step 70360, change in cost 0.000123978\n",
      "step 70370, training accuracy 0.96748\n",
      "step 70370, cost 5.09987\n",
      "step 70370, change in cost 0.00012207\n",
      "step 70380, training accuracy 0.96748\n",
      "step 70380, cost 5.09974\n",
      "step 70380, change in cost 0.000123024\n",
      "step 70390, training accuracy 0.96748\n",
      "step 70390, cost 5.09962\n",
      "step 70390, change in cost 0.000123024\n",
      "step 70400, training accuracy 0.96748\n",
      "step 70400, cost 5.0995\n",
      "step 70400, change in cost 0.000122547\n",
      "step 70410, training accuracy 0.96748\n",
      "step 70410, cost 5.09938\n",
      "step 70410, change in cost 0.000122547\n",
      "step 70420, training accuracy 0.96748\n",
      "step 70420, cost 5.09925\n",
      "step 70420, change in cost 0.000123024\n",
      "step 70430, training accuracy 0.96748\n",
      "step 70430, cost 5.09913\n",
      "step 70430, change in cost 0.000123024\n",
      "step 70440, training accuracy 0.96748\n",
      "step 70440, cost 5.09901\n",
      "step 70440, change in cost 0.000121117\n",
      "step 70450, training accuracy 0.96748\n",
      "step 70450, cost 5.09889\n",
      "step 70450, change in cost 0.000123024\n",
      "step 70460, training accuracy 0.96748\n",
      "step 70460, cost 5.09876\n",
      "step 70460, change in cost 0.00012207\n",
      "step 70470, training accuracy 0.96748\n",
      "step 70470, cost 5.09864\n",
      "step 70470, change in cost 0.000122547\n",
      "step 70480, training accuracy 0.96748\n",
      "step 70480, cost 5.09852\n",
      "step 70480, change in cost 0.000123024\n",
      "step 70490, training accuracy 0.96748\n",
      "step 70490, cost 5.0984\n",
      "step 70490, change in cost 0.000121593\n",
      "step 70500, training accuracy 0.96748\n",
      "step 70500, cost 5.09827\n",
      "step 70500, change in cost 0.000122547\n",
      "step 70510, training accuracy 0.96748\n",
      "step 70510, cost 5.09815\n",
      "step 70510, change in cost 0.00012207\n",
      "step 70520, training accuracy 0.96748\n",
      "step 70520, cost 5.09803\n",
      "step 70520, change in cost 0.000122547\n",
      "step 70530, training accuracy 0.96748\n",
      "step 70530, cost 5.09791\n",
      "step 70530, change in cost 0.000123978\n",
      "step 70540, training accuracy 0.96748\n",
      "step 70540, cost 5.09778\n",
      "step 70540, change in cost 0.00012064\n",
      "step 70550, training accuracy 0.96748\n",
      "step 70550, cost 5.09766\n",
      "step 70550, change in cost 0.00012207\n",
      "step 70560, training accuracy 0.96748\n",
      "step 70560, cost 5.09754\n",
      "step 70560, change in cost 0.000123024\n",
      "step 70570, training accuracy 0.96748\n",
      "step 70570, cost 5.09742\n",
      "step 70570, change in cost 0.00012064\n",
      "step 70580, training accuracy 0.96748\n",
      "step 70580, cost 5.0973\n",
      "step 70580, change in cost 0.000123024\n",
      "step 70590, training accuracy 0.96748\n",
      "step 70590, cost 5.09717\n",
      "step 70590, change in cost 0.00012207\n",
      "step 70600, training accuracy 0.96748\n",
      "step 70600, cost 5.09705\n",
      "step 70600, change in cost 0.000121117\n",
      "step 70610, training accuracy 0.96748\n",
      "step 70610, cost 5.09693\n",
      "step 70610, change in cost 0.000123024\n",
      "step 70620, training accuracy 0.96748\n",
      "step 70620, cost 5.09681\n",
      "step 70620, change in cost 0.000121117\n",
      "step 70630, training accuracy 0.96748\n",
      "step 70630, cost 5.09669\n",
      "step 70630, change in cost 0.000121117\n",
      "step 70640, training accuracy 0.96748\n",
      "step 70640, cost 5.09657\n",
      "step 70640, change in cost 0.000121593\n",
      "step 70650, training accuracy 0.96748\n",
      "step 70650, cost 5.09644\n",
      "step 70650, change in cost 0.000121593\n",
      "step 70660, training accuracy 0.96748\n",
      "step 70660, cost 5.09632\n",
      "step 70660, change in cost 0.000123024\n",
      "step 70670, training accuracy 0.96748\n",
      "step 70670, cost 5.0962\n",
      "step 70670, change in cost 0.000121117\n",
      "step 70680, training accuracy 0.96748\n",
      "step 70680, cost 5.09608\n",
      "step 70680, change in cost 0.000121593\n",
      "step 70690, training accuracy 0.96748\n",
      "step 70690, cost 5.09596\n",
      "step 70690, change in cost 0.00012064\n",
      "step 70700, training accuracy 0.96748\n",
      "step 70700, cost 5.09584\n",
      "step 70700, change in cost 0.00012207\n",
      "step 70710, training accuracy 0.96748\n",
      "step 70710, cost 5.09571\n",
      "step 70710, change in cost 0.000121117\n",
      "step 70720, training accuracy 0.96748\n",
      "step 70720, cost 5.09559\n",
      "step 70720, change in cost 0.000121117\n",
      "step 70730, training accuracy 0.96748\n",
      "step 70730, cost 5.09547\n",
      "step 70730, change in cost 0.00012207\n",
      "step 70740, training accuracy 0.96748\n",
      "step 70740, cost 5.09535\n",
      "step 70740, change in cost 0.000121117\n",
      "step 70750, training accuracy 0.96748\n",
      "step 70750, cost 5.09523\n",
      "step 70750, change in cost 0.000121117\n",
      "step 70760, training accuracy 0.96748\n",
      "step 70760, cost 5.09511\n",
      "step 70760, change in cost 0.000121117\n",
      "step 70770, training accuracy 0.96748\n",
      "step 70770, cost 5.09499\n",
      "step 70770, change in cost 0.000121117\n",
      "step 70780, training accuracy 0.96748\n",
      "step 70780, cost 5.09486\n",
      "step 70780, change in cost 0.00012207\n",
      "step 70790, training accuracy 0.96748\n",
      "step 70790, cost 5.09474\n",
      "step 70790, change in cost 0.000121117\n",
      "step 70800, training accuracy 0.96748\n",
      "step 70800, cost 5.09462\n",
      "step 70800, change in cost 0.00012064\n",
      "step 70810, training accuracy 0.96748\n",
      "step 70810, cost 5.0945\n",
      "step 70810, change in cost 0.00012064\n",
      "step 70820, training accuracy 0.96748\n",
      "step 70820, cost 5.09438\n",
      "step 70820, change in cost 0.00012207\n",
      "step 70830, training accuracy 0.96748\n",
      "step 70830, cost 5.09426\n",
      "step 70830, change in cost 0.00012064\n",
      "step 70840, training accuracy 0.96748\n",
      "step 70840, cost 5.09414\n",
      "step 70840, change in cost 0.000121117\n",
      "step 70850, training accuracy 0.96748\n",
      "step 70850, cost 5.09402\n",
      "step 70850, change in cost 0.000121117\n",
      "step 70860, training accuracy 0.96748\n",
      "step 70860, cost 5.0939\n",
      "step 70860, change in cost 0.000120163\n",
      "step 70870, training accuracy 0.96748\n",
      "step 70870, cost 5.09378\n",
      "step 70870, change in cost 0.000121117\n",
      "step 70880, training accuracy 0.96748\n",
      "step 70880, cost 5.09366\n",
      "step 70880, change in cost 0.00012064\n",
      "step 70890, training accuracy 0.96748\n",
      "step 70890, cost 5.09353\n",
      "step 70890, change in cost 0.000121117\n",
      "step 70900, training accuracy 0.96748\n",
      "step 70900, cost 5.09341\n",
      "step 70900, change in cost 0.000121117\n",
      "step 70910, training accuracy 0.96748\n",
      "step 70910, cost 5.09329\n",
      "step 70910, change in cost 0.00012064\n",
      "step 70920, training accuracy 0.96748\n",
      "step 70920, cost 5.09317\n",
      "step 70920, change in cost 0.000120163\n",
      "step 70930, training accuracy 0.96748\n",
      "step 70930, cost 5.09305\n",
      "step 70930, change in cost 0.00012064\n",
      "step 70940, training accuracy 0.96748\n",
      "step 70940, cost 5.09293\n",
      "step 70940, change in cost 0.000120163\n",
      "step 70950, training accuracy 0.96748\n",
      "step 70950, cost 5.09281\n",
      "step 70950, change in cost 0.000120163\n",
      "step 70960, training accuracy 0.96748\n",
      "step 70960, cost 5.09269\n",
      "step 70960, change in cost 0.000120163\n",
      "step 70970, training accuracy 0.96748\n",
      "step 70970, cost 5.09257\n",
      "step 70970, change in cost 0.000121117\n",
      "step 70980, training accuracy 0.96748\n",
      "step 70980, cost 5.09245\n",
      "step 70980, change in cost 0.000120163\n",
      "step 70990, training accuracy 0.96748\n",
      "step 70990, cost 5.09233\n",
      "step 70990, change in cost 0.000121117\n",
      "step 71000, training accuracy 0.96748\n",
      "step 71000, cost 5.09221\n",
      "step 71000, change in cost 0.000119686\n",
      "step 71010, training accuracy 0.96748\n",
      "step 71010, cost 5.09209\n",
      "step 71010, change in cost 0.000120163\n",
      "step 71020, training accuracy 0.96748\n",
      "step 71020, cost 5.09197\n",
      "step 71020, change in cost 0.00012064\n",
      "step 71030, training accuracy 0.96748\n",
      "step 71030, cost 5.09185\n",
      "step 71030, change in cost 0.000120163\n",
      "step 71040, training accuracy 0.96748\n",
      "step 71040, cost 5.09173\n",
      "step 71040, change in cost 0.000120163\n",
      "step 71050, training accuracy 0.96748\n",
      "step 71050, cost 5.09161\n",
      "step 71050, change in cost 0.000120163\n",
      "step 71060, training accuracy 0.96748\n",
      "step 71060, cost 5.09149\n",
      "step 71060, change in cost 0.000120163\n",
      "step 71070, training accuracy 0.96748\n",
      "step 71070, cost 5.09137\n",
      "step 71070, change in cost 0.000120163\n",
      "step 71080, training accuracy 0.96748\n",
      "step 71080, cost 5.09125\n",
      "step 71080, change in cost 0.000119686\n",
      "step 71090, training accuracy 0.96748\n",
      "step 71090, cost 5.09113\n",
      "step 71090, change in cost 0.000120163\n",
      "step 71100, training accuracy 0.96748\n",
      "step 71100, cost 5.09101\n",
      "step 71100, change in cost 0.000119686\n",
      "step 71110, training accuracy 0.96748\n",
      "step 71110, cost 5.09089\n",
      "step 71110, change in cost 0.000121117\n",
      "step 71120, training accuracy 0.96748\n",
      "step 71120, cost 5.09077\n",
      "step 71120, change in cost 0.000120163\n",
      "step 71130, training accuracy 0.96748\n",
      "step 71130, cost 5.09065\n",
      "step 71130, change in cost 0.000118732\n",
      "step 71140, training accuracy 0.96748\n",
      "step 71140, cost 5.09053\n",
      "step 71140, change in cost 0.00012064\n",
      "step 71150, training accuracy 0.96748\n",
      "step 71150, cost 5.09041\n",
      "step 71150, change in cost 0.000119209\n",
      "step 71160, training accuracy 0.96748\n",
      "step 71160, cost 5.09029\n",
      "step 71160, change in cost 0.000120163\n",
      "step 71170, training accuracy 0.96748\n",
      "step 71170, cost 5.09017\n",
      "step 71170, change in cost 0.000120163\n",
      "step 71180, training accuracy 0.96748\n",
      "step 71180, cost 5.09005\n",
      "step 71180, change in cost 0.000119209\n",
      "step 71190, training accuracy 0.96748\n",
      "step 71190, cost 5.08993\n",
      "step 71190, change in cost 0.000120163\n",
      "step 71200, training accuracy 0.96748\n",
      "step 71200, cost 5.08981\n",
      "step 71200, change in cost 0.000119209\n",
      "step 71210, training accuracy 0.96748\n",
      "step 71210, cost 5.08969\n",
      "step 71210, change in cost 0.000118256\n",
      "step 71220, training accuracy 0.96748\n",
      "step 71220, cost 5.08957\n",
      "step 71220, change in cost 0.000120163\n",
      "step 71230, training accuracy 0.96748\n",
      "step 71230, cost 5.08945\n",
      "step 71230, change in cost 0.000120163\n",
      "step 71240, training accuracy 0.96748\n",
      "step 71240, cost 5.08933\n",
      "step 71240, change in cost 0.000119209\n",
      "step 71250, training accuracy 0.96748\n",
      "step 71250, cost 5.08921\n",
      "step 71250, change in cost 0.000118732\n",
      "step 71260, training accuracy 0.96748\n",
      "step 71260, cost 5.08909\n",
      "step 71260, change in cost 0.000120163\n",
      "step 71270, training accuracy 0.96748\n",
      "step 71270, cost 5.08897\n",
      "step 71270, change in cost 0.000119209\n",
      "step 71280, training accuracy 0.96748\n",
      "step 71280, cost 5.08885\n",
      "step 71280, change in cost 0.000119209\n",
      "step 71290, training accuracy 0.96748\n",
      "step 71290, cost 5.08874\n",
      "step 71290, change in cost 0.000118256\n",
      "step 71300, training accuracy 0.96748\n",
      "step 71300, cost 5.08862\n",
      "step 71300, change in cost 0.000119686\n",
      "step 71310, training accuracy 0.96748\n",
      "step 71310, cost 5.0885\n",
      "step 71310, change in cost 0.00012064\n",
      "step 71320, training accuracy 0.96748\n",
      "step 71320, cost 5.08838\n",
      "step 71320, change in cost 0.000119686\n",
      "step 71330, training accuracy 0.96748\n",
      "step 71330, cost 5.08826\n",
      "step 71330, change in cost 0.000118256\n",
      "step 71340, training accuracy 0.96748\n",
      "step 71340, cost 5.08814\n",
      "step 71340, change in cost 0.000119209\n",
      "step 71350, training accuracy 0.96748\n",
      "step 71350, cost 5.08802\n",
      "step 71350, change in cost 0.000119209\n",
      "step 71360, training accuracy 0.96748\n",
      "step 71360, cost 5.0879\n",
      "step 71360, change in cost 0.000120163\n",
      "step 71370, training accuracy 0.96748\n",
      "step 71370, cost 5.08778\n",
      "step 71370, change in cost 0.000118256\n",
      "step 71380, training accuracy 0.96748\n",
      "step 71380, cost 5.08766\n",
      "step 71380, change in cost 0.000119209\n",
      "step 71390, training accuracy 0.96748\n",
      "step 71390, cost 5.08754\n",
      "step 71390, change in cost 0.000118732\n",
      "step 71400, training accuracy 0.96748\n",
      "step 71400, cost 5.08742\n",
      "step 71400, change in cost 0.000119209\n",
      "step 71410, training accuracy 0.96748\n",
      "step 71410, cost 5.0873\n",
      "step 71410, change in cost 0.000119209\n",
      "step 71420, training accuracy 0.96748\n",
      "step 71420, cost 5.08719\n",
      "step 71420, change in cost 0.000119209\n",
      "step 71430, training accuracy 0.96748\n",
      "step 71430, cost 5.08707\n",
      "step 71430, change in cost 0.000119686\n",
      "step 71440, training accuracy 0.96748\n",
      "step 71440, cost 5.08695\n",
      "step 71440, change in cost 0.000117779\n",
      "step 71450, training accuracy 0.96748\n",
      "step 71450, cost 5.08683\n",
      "step 71450, change in cost 0.000118732\n",
      "step 71460, training accuracy 0.96748\n",
      "step 71460, cost 5.08671\n",
      "step 71460, change in cost 0.000119209\n",
      "step 71470, training accuracy 0.96748\n",
      "step 71470, cost 5.08659\n",
      "step 71470, change in cost 0.000117779\n",
      "step 71480, training accuracy 0.96748\n",
      "step 71480, cost 5.08647\n",
      "step 71480, change in cost 0.000119686\n",
      "step 71490, training accuracy 0.96748\n",
      "step 71490, cost 5.08635\n",
      "step 71490, change in cost 0.000117779\n",
      "step 71500, training accuracy 0.96748\n",
      "step 71500, cost 5.08624\n",
      "step 71500, change in cost 0.000117779\n",
      "step 71510, training accuracy 0.96748\n",
      "step 71510, cost 5.08612\n",
      "step 71510, change in cost 0.00012064\n",
      "step 71520, training accuracy 0.96748\n",
      "step 71520, cost 5.086\n",
      "step 71520, change in cost 0.000118256\n",
      "step 71530, training accuracy 0.96748\n",
      "step 71530, cost 5.08588\n",
      "step 71530, change in cost 0.000118732\n",
      "step 71540, training accuracy 0.96748\n",
      "step 71540, cost 5.08576\n",
      "step 71540, change in cost 0.000118256\n",
      "step 71550, training accuracy 0.96748\n",
      "step 71550, cost 5.08564\n",
      "step 71550, change in cost 0.000118256\n",
      "step 71560, training accuracy 0.96748\n",
      "step 71560, cost 5.08552\n",
      "step 71560, change in cost 0.000118256\n",
      "step 71570, training accuracy 0.96748\n",
      "step 71570, cost 5.08541\n",
      "step 71570, change in cost 0.000118256\n",
      "step 71580, training accuracy 0.96748\n",
      "step 71580, cost 5.08529\n",
      "step 71580, change in cost 0.000120163\n",
      "step 71590, training accuracy 0.96748\n",
      "step 71590, cost 5.08517\n",
      "step 71590, change in cost 0.000116825\n",
      "step 71600, training accuracy 0.96748\n",
      "step 71600, cost 5.08505\n",
      "step 71600, change in cost 0.000118256\n",
      "step 71610, training accuracy 0.96748\n",
      "step 71610, cost 5.08493\n",
      "step 71610, change in cost 0.000119209\n",
      "step 71620, training accuracy 0.96748\n",
      "step 71620, cost 5.08481\n",
      "step 71620, change in cost 0.000117779\n",
      "step 71630, training accuracy 0.96748\n",
      "step 71630, cost 5.0847\n",
      "step 71630, change in cost 0.000117302\n",
      "step 71640, training accuracy 0.96748\n",
      "step 71640, cost 5.08458\n",
      "step 71640, change in cost 0.000119209\n",
      "step 71650, training accuracy 0.96748\n",
      "step 71650, cost 5.08446\n",
      "step 71650, change in cost 0.000118256\n",
      "step 71660, training accuracy 0.96748\n",
      "step 71660, cost 5.08434\n",
      "step 71660, change in cost 0.000116825\n",
      "step 71670, training accuracy 0.96748\n",
      "step 71670, cost 5.08422\n",
      "step 71670, change in cost 0.000118732\n",
      "step 71680, training accuracy 0.96748\n",
      "step 71680, cost 5.08411\n",
      "step 71680, change in cost 0.000118256\n",
      "step 71690, training accuracy 0.96748\n",
      "step 71690, cost 5.08399\n",
      "step 71690, change in cost 0.000116348\n",
      "step 71700, training accuracy 0.96748\n",
      "step 71700, cost 5.08387\n",
      "step 71700, change in cost 0.000118256\n",
      "step 71710, training accuracy 0.96748\n",
      "step 71710, cost 5.08375\n",
      "step 71710, change in cost 0.000118256\n",
      "step 71720, training accuracy 0.96748\n",
      "step 71720, cost 5.08363\n",
      "step 71720, change in cost 0.000118256\n",
      "step 71730, training accuracy 0.96748\n",
      "step 71730, cost 5.08352\n",
      "step 71730, change in cost 0.000117302\n",
      "step 71740, training accuracy 0.96748\n",
      "step 71740, cost 5.0834\n",
      "step 71740, change in cost 0.000119209\n",
      "step 71750, training accuracy 0.96748\n",
      "step 71750, cost 5.08328\n",
      "step 71750, change in cost 0.000117302\n",
      "step 71760, training accuracy 0.96748\n",
      "step 71760, cost 5.08316\n",
      "step 71760, change in cost 0.000117302\n",
      "step 71770, training accuracy 0.96748\n",
      "step 71770, cost 5.08305\n",
      "step 71770, change in cost 0.000117302\n",
      "step 71780, training accuracy 0.96748\n",
      "step 71780, cost 5.08293\n",
      "step 71780, change in cost 0.000118256\n",
      "step 71790, training accuracy 0.96748\n",
      "step 71790, cost 5.08281\n",
      "step 71790, change in cost 0.000117779\n",
      "step 71800, training accuracy 0.96748\n",
      "step 71800, cost 5.08269\n",
      "step 71800, change in cost 0.000117779\n",
      "step 71810, training accuracy 0.96748\n",
      "step 71810, cost 5.08257\n",
      "step 71810, change in cost 0.000117302\n",
      "step 71820, training accuracy 0.96748\n",
      "step 71820, cost 5.08246\n",
      "step 71820, change in cost 0.000118256\n",
      "step 71830, training accuracy 0.96748\n",
      "step 71830, cost 5.08234\n",
      "step 71830, change in cost 0.000117302\n",
      "step 71840, training accuracy 0.96748\n",
      "step 71840, cost 5.08222\n",
      "step 71840, change in cost 0.000118256\n",
      "step 71850, training accuracy 0.96748\n",
      "step 71850, cost 5.0821\n",
      "step 71850, change in cost 0.000117302\n",
      "step 71860, training accuracy 0.96748\n",
      "step 71860, cost 5.08199\n",
      "step 71860, change in cost 0.000117302\n",
      "step 71870, training accuracy 0.96748\n",
      "step 71870, cost 5.08187\n",
      "step 71870, change in cost 0.000117779\n",
      "step 71880, training accuracy 0.96748\n",
      "step 71880, cost 5.08175\n",
      "step 71880, change in cost 0.000116825\n",
      "step 71890, training accuracy 0.96748\n",
      "step 71890, cost 5.08163\n",
      "step 71890, change in cost 0.000118256\n",
      "step 71900, training accuracy 0.96748\n",
      "step 71900, cost 5.08152\n",
      "step 71900, change in cost 0.000117302\n",
      "step 71910, training accuracy 0.96748\n",
      "step 71910, cost 5.0814\n",
      "step 71910, change in cost 0.000116348\n",
      "step 71920, training accuracy 0.96748\n",
      "step 71920, cost 5.08128\n",
      "step 71920, change in cost 0.000118256\n",
      "step 71930, training accuracy 0.96748\n",
      "step 71930, cost 5.08116\n",
      "step 71930, change in cost 0.000116825\n",
      "step 71940, training accuracy 0.96748\n",
      "step 71940, cost 5.08105\n",
      "step 71940, change in cost 0.000117302\n",
      "step 71950, training accuracy 0.96748\n",
      "step 71950, cost 5.08093\n",
      "step 71950, change in cost 0.000117302\n",
      "step 71960, training accuracy 0.96748\n",
      "step 71960, cost 5.08081\n",
      "step 71960, change in cost 0.000117302\n",
      "step 71970, training accuracy 0.96748\n",
      "step 71970, cost 5.0807\n",
      "step 71970, change in cost 0.000117779\n",
      "step 71980, training accuracy 0.96748\n",
      "step 71980, cost 5.08058\n",
      "step 71980, change in cost 0.000117302\n",
      "step 71990, training accuracy 0.96748\n",
      "step 71990, cost 5.08046\n",
      "step 71990, change in cost 0.000117302\n",
      "step 72000, training accuracy 0.96748\n",
      "step 72000, cost 5.08034\n",
      "step 72000, change in cost 0.000116825\n",
      "step 72010, training accuracy 0.96748\n",
      "step 72010, cost 5.08023\n",
      "step 72010, change in cost 0.000116825\n",
      "step 72020, training accuracy 0.96748\n",
      "step 72020, cost 5.08011\n",
      "step 72020, change in cost 0.000117302\n",
      "step 72030, training accuracy 0.96748\n",
      "step 72030, cost 5.07999\n",
      "step 72030, change in cost 0.000116825\n",
      "step 72040, training accuracy 0.96748\n",
      "step 72040, cost 5.07988\n",
      "step 72040, change in cost 0.000116825\n",
      "step 72050, training accuracy 0.96748\n",
      "step 72050, cost 5.07976\n",
      "step 72050, change in cost 0.000116825\n",
      "step 72060, training accuracy 0.96748\n",
      "step 72060, cost 5.07964\n",
      "step 72060, change in cost 0.000116825\n",
      "step 72070, training accuracy 0.96748\n",
      "step 72070, cost 5.07953\n",
      "step 72070, change in cost 0.000116825\n",
      "step 72080, training accuracy 0.96748\n",
      "step 72080, cost 5.07941\n",
      "step 72080, change in cost 0.000116825\n",
      "step 72090, training accuracy 0.96748\n",
      "step 72090, cost 5.07929\n",
      "step 72090, change in cost 0.000116348\n",
      "step 72100, training accuracy 0.96748\n",
      "step 72100, cost 5.07918\n",
      "step 72100, change in cost 0.000116348\n",
      "step 72110, training accuracy 0.96748\n",
      "step 72110, cost 5.07906\n",
      "step 72110, change in cost 0.000117779\n",
      "step 72120, training accuracy 0.96748\n",
      "step 72120, cost 5.07894\n",
      "step 72120, change in cost 0.000116825\n",
      "step 72130, training accuracy 0.96748\n",
      "step 72130, cost 5.07882\n",
      "step 72130, change in cost 0.000116348\n",
      "step 72140, training accuracy 0.96748\n",
      "step 72140, cost 5.07871\n",
      "step 72140, change in cost 0.000117302\n",
      "step 72150, training accuracy 0.96748\n",
      "step 72150, cost 5.07859\n",
      "step 72150, change in cost 0.000116348\n",
      "step 72160, training accuracy 0.96748\n",
      "step 72160, cost 5.07847\n",
      "step 72160, change in cost 0.000116348\n",
      "step 72170, training accuracy 0.96748\n",
      "step 72170, cost 5.07836\n",
      "step 72170, change in cost 0.000116348\n",
      "step 72180, training accuracy 0.96748\n",
      "step 72180, cost 5.07824\n",
      "step 72180, change in cost 0.000116348\n",
      "step 72190, training accuracy 0.96748\n",
      "step 72190, cost 5.07813\n",
      "step 72190, change in cost 0.000116348\n",
      "step 72200, training accuracy 0.96748\n",
      "step 72200, cost 5.07801\n",
      "step 72200, change in cost 0.000116348\n",
      "step 72210, training accuracy 0.96748\n",
      "step 72210, cost 5.07789\n",
      "step 72210, change in cost 0.000116825\n",
      "step 72220, training accuracy 0.96748\n",
      "step 72220, cost 5.07778\n",
      "step 72220, change in cost 0.000115871\n",
      "step 72230, training accuracy 0.96748\n",
      "step 72230, cost 5.07766\n",
      "step 72230, change in cost 0.000117302\n",
      "step 72240, training accuracy 0.96748\n",
      "step 72240, cost 5.07754\n",
      "step 72240, change in cost 0.000115871\n",
      "step 72250, training accuracy 0.96748\n",
      "step 72250, cost 5.07743\n",
      "step 72250, change in cost 0.000115871\n",
      "step 72260, training accuracy 0.96748\n",
      "step 72260, cost 5.07731\n",
      "step 72260, change in cost 0.000116348\n",
      "step 72270, training accuracy 0.96748\n",
      "step 72270, cost 5.07719\n",
      "step 72270, change in cost 0.000117302\n",
      "step 72280, training accuracy 0.96748\n",
      "step 72280, cost 5.07708\n",
      "step 72280, change in cost 0.000115395\n",
      "step 72290, training accuracy 0.96748\n",
      "step 72290, cost 5.07696\n",
      "step 72290, change in cost 0.000116348\n",
      "step 72300, training accuracy 0.96748\n",
      "step 72300, cost 5.07685\n",
      "step 72300, change in cost 0.000115871\n",
      "step 72310, training accuracy 0.96748\n",
      "step 72310, cost 5.07673\n",
      "step 72310, change in cost 0.000115871\n",
      "step 72320, training accuracy 0.96748\n",
      "step 72320, cost 5.07661\n",
      "step 72320, change in cost 0.000116348\n",
      "step 72330, training accuracy 0.96748\n",
      "step 72330, cost 5.0765\n",
      "step 72330, change in cost 0.000115871\n",
      "step 72340, training accuracy 0.96748\n",
      "step 72340, cost 5.07638\n",
      "step 72340, change in cost 0.000115871\n",
      "step 72350, training accuracy 0.96748\n",
      "step 72350, cost 5.07627\n",
      "step 72350, change in cost 0.000115395\n",
      "step 72360, training accuracy 0.96748\n",
      "step 72360, cost 5.07615\n",
      "step 72360, change in cost 0.000115395\n",
      "step 72370, training accuracy 0.96748\n",
      "step 72370, cost 5.07604\n",
      "step 72370, change in cost 0.000116825\n",
      "step 72380, training accuracy 0.96748\n",
      "step 72380, cost 5.07592\n",
      "step 72380, change in cost 0.000116825\n",
      "step 72390, training accuracy 0.96748\n",
      "step 72390, cost 5.0758\n",
      "step 72390, change in cost 0.000115395\n",
      "step 72400, training accuracy 0.96748\n",
      "step 72400, cost 5.07569\n",
      "step 72400, change in cost 0.000116348\n",
      "step 72410, training accuracy 0.96748\n",
      "step 72410, cost 5.07557\n",
      "step 72410, change in cost 0.000114918\n",
      "step 72420, training accuracy 0.96748\n",
      "step 72420, cost 5.07546\n",
      "step 72420, change in cost 0.000115871\n",
      "step 72430, training accuracy 0.96748\n",
      "step 72430, cost 5.07534\n",
      "step 72430, change in cost 0.000116348\n",
      "step 72440, training accuracy 0.96748\n",
      "step 72440, cost 5.07522\n",
      "step 72440, change in cost 0.000114918\n",
      "step 72450, training accuracy 0.96748\n",
      "step 72450, cost 5.07511\n",
      "step 72450, change in cost 0.000115871\n",
      "step 72460, training accuracy 0.96748\n",
      "step 72460, cost 5.07499\n",
      "step 72460, change in cost 0.000114918\n",
      "step 72470, training accuracy 0.96748\n",
      "step 72470, cost 5.07488\n",
      "step 72470, change in cost 0.000114441\n",
      "step 72480, training accuracy 0.96748\n",
      "step 72480, cost 5.07476\n",
      "step 72480, change in cost 0.000116825\n",
      "step 72490, training accuracy 0.96748\n",
      "step 72490, cost 5.07465\n",
      "step 72490, change in cost 0.000115395\n",
      "step 72500, training accuracy 0.96748\n",
      "step 72500, cost 5.07453\n",
      "step 72500, change in cost 0.000115395\n",
      "step 72510, training accuracy 0.96748\n",
      "step 72510, cost 5.07442\n",
      "step 72510, change in cost 0.000115395\n",
      "step 72520, training accuracy 0.96748\n",
      "step 72520, cost 5.0743\n",
      "step 72520, change in cost 0.000115871\n",
      "step 72530, training accuracy 0.96748\n",
      "step 72530, cost 5.07419\n",
      "step 72530, change in cost 0.000114918\n",
      "step 72540, training accuracy 0.96748\n",
      "step 72540, cost 5.07407\n",
      "step 72540, change in cost 0.000115395\n",
      "step 72550, training accuracy 0.96748\n",
      "step 72550, cost 5.07396\n",
      "step 72550, change in cost 0.000114441\n",
      "step 72560, training accuracy 0.96748\n",
      "step 72560, cost 5.07384\n",
      "step 72560, change in cost 0.000115395\n",
      "step 72570, training accuracy 0.96748\n",
      "step 72570, cost 5.07373\n",
      "step 72570, change in cost 0.000114918\n",
      "step 72580, training accuracy 0.96748\n",
      "step 72580, cost 5.07361\n",
      "step 72580, change in cost 0.000116348\n",
      "step 72590, training accuracy 0.96748\n",
      "step 72590, cost 5.07349\n",
      "step 72590, change in cost 0.000113964\n",
      "step 72600, training accuracy 0.96748\n",
      "step 72600, cost 5.07338\n",
      "step 72600, change in cost 0.000115395\n",
      "step 72610, training accuracy 0.96748\n",
      "step 72610, cost 5.07326\n",
      "step 72610, change in cost 0.000115395\n",
      "step 72620, training accuracy 0.96748\n",
      "step 72620, cost 5.07315\n",
      "step 72620, change in cost 0.000114918\n",
      "step 72630, training accuracy 0.96748\n",
      "step 72630, cost 5.07303\n",
      "step 72630, change in cost 0.000114918\n",
      "step 72640, training accuracy 0.96748\n",
      "step 72640, cost 5.07292\n",
      "step 72640, change in cost 0.000114441\n",
      "step 72650, training accuracy 0.96748\n",
      "step 72650, cost 5.07281\n",
      "step 72650, change in cost 0.000114441\n",
      "step 72660, training accuracy 0.96748\n",
      "step 72660, cost 5.07269\n",
      "step 72660, change in cost 0.000115395\n",
      "step 72670, training accuracy 0.96748\n",
      "step 72670, cost 5.07257\n",
      "step 72670, change in cost 0.000115395\n",
      "step 72680, training accuracy 0.96748\n",
      "step 72680, cost 5.07246\n",
      "step 72680, change in cost 0.000114918\n",
      "step 72690, training accuracy 0.96748\n",
      "step 72690, cost 5.07235\n",
      "step 72690, change in cost 0.000113964\n",
      "step 72700, training accuracy 0.96748\n",
      "step 72700, cost 5.07223\n",
      "step 72700, change in cost 0.000114441\n",
      "step 72710, training accuracy 0.96748\n",
      "step 72710, cost 5.07212\n",
      "step 72710, change in cost 0.000114918\n",
      "step 72720, training accuracy 0.96748\n",
      "step 72720, cost 5.072\n",
      "step 72720, change in cost 0.000114918\n",
      "step 72730, training accuracy 0.96748\n",
      "step 72730, cost 5.07189\n",
      "step 72730, change in cost 0.000114918\n",
      "step 72740, training accuracy 0.96748\n",
      "step 72740, cost 5.07177\n",
      "step 72740, change in cost 0.000114441\n",
      "step 72750, training accuracy 0.96748\n",
      "step 72750, cost 5.07166\n",
      "step 72750, change in cost 0.000114441\n",
      "step 72760, training accuracy 0.96748\n",
      "step 72760, cost 5.07154\n",
      "step 72760, change in cost 0.000114918\n",
      "step 72770, training accuracy 0.96748\n",
      "step 72770, cost 5.07143\n",
      "step 72770, change in cost 0.000113964\n",
      "step 72780, training accuracy 0.96748\n",
      "step 72780, cost 5.07131\n",
      "step 72780, change in cost 0.000114918\n",
      "step 72790, training accuracy 0.96748\n",
      "step 72790, cost 5.0712\n",
      "step 72790, change in cost 0.000114918\n",
      "step 72800, training accuracy 0.96748\n",
      "step 72800, cost 5.07108\n",
      "step 72800, change in cost 0.000113964\n",
      "step 72810, training accuracy 0.96748\n",
      "step 72810, cost 5.07097\n",
      "step 72810, change in cost 0.000114441\n",
      "step 72820, training accuracy 0.96748\n",
      "step 72820, cost 5.07086\n",
      "step 72820, change in cost 0.000114918\n",
      "step 72830, training accuracy 0.96748\n",
      "step 72830, cost 5.07074\n",
      "step 72830, change in cost 0.000113964\n",
      "step 72840, training accuracy 0.96748\n",
      "step 72840, cost 5.07063\n",
      "step 72840, change in cost 0.000114918\n",
      "step 72850, training accuracy 0.96748\n",
      "step 72850, cost 5.07051\n",
      "step 72850, change in cost 0.000114918\n",
      "step 72860, training accuracy 0.96748\n",
      "step 72860, cost 5.0704\n",
      "step 72860, change in cost 0.000113487\n",
      "step 72870, training accuracy 0.96748\n",
      "step 72870, cost 5.07028\n",
      "step 72870, change in cost 0.000114441\n",
      "step 72880, training accuracy 0.96748\n",
      "step 72880, cost 5.07017\n",
      "step 72880, change in cost 0.000114441\n",
      "step 72890, training accuracy 0.96748\n",
      "step 72890, cost 5.07005\n",
      "step 72890, change in cost 0.000114918\n",
      "step 72900, training accuracy 0.96748\n",
      "step 72900, cost 5.06994\n",
      "step 72900, change in cost 0.00011301\n",
      "step 72910, training accuracy 0.96748\n",
      "step 72910, cost 5.06983\n",
      "step 72910, change in cost 0.000115395\n",
      "step 72920, training accuracy 0.96748\n",
      "step 72920, cost 5.06971\n",
      "step 72920, change in cost 0.000114441\n",
      "step 72930, training accuracy 0.96748\n",
      "step 72930, cost 5.0696\n",
      "step 72930, change in cost 0.00011301\n",
      "step 72940, training accuracy 0.96748\n",
      "step 72940, cost 5.06949\n",
      "step 72940, change in cost 0.000113487\n",
      "step 72950, training accuracy 0.96748\n",
      "step 72950, cost 5.06937\n",
      "step 72950, change in cost 0.000115395\n",
      "step 72960, training accuracy 0.96748\n",
      "step 72960, cost 5.06926\n",
      "step 72960, change in cost 0.00011301\n",
      "step 72970, training accuracy 0.96748\n",
      "step 72970, cost 5.06914\n",
      "step 72970, change in cost 0.000114441\n",
      "step 72980, training accuracy 0.96748\n",
      "step 72980, cost 5.06903\n",
      "step 72980, change in cost 0.000114441\n",
      "step 72990, training accuracy 0.96748\n",
      "step 72990, cost 5.06891\n",
      "step 72990, change in cost 0.000114441\n",
      "step 73000, training accuracy 0.96748\n",
      "step 73000, cost 5.0688\n",
      "step 73000, change in cost 0.000113964\n",
      "step 73010, training accuracy 0.96748\n",
      "step 73010, cost 5.06869\n",
      "step 73010, change in cost 0.00011301\n",
      "step 73020, training accuracy 0.96748\n",
      "step 73020, cost 5.06857\n",
      "step 73020, change in cost 0.000114441\n",
      "step 73030, training accuracy 0.96748\n",
      "step 73030, cost 5.06846\n",
      "step 73030, change in cost 0.000113487\n",
      "step 73040, training accuracy 0.96748\n",
      "step 73040, cost 5.06835\n",
      "step 73040, change in cost 0.000113487\n",
      "step 73050, training accuracy 0.96748\n",
      "step 73050, cost 5.06823\n",
      "step 73050, change in cost 0.000113487\n",
      "step 73060, training accuracy 0.96748\n",
      "step 73060, cost 5.06812\n",
      "step 73060, change in cost 0.000113487\n",
      "step 73070, training accuracy 0.96748\n",
      "step 73070, cost 5.068\n",
      "step 73070, change in cost 0.000113487\n",
      "step 73080, training accuracy 0.96748\n",
      "step 73080, cost 5.06789\n",
      "step 73080, change in cost 0.00011301\n",
      "step 73090, training accuracy 0.96748\n",
      "step 73090, cost 5.06778\n",
      "step 73090, change in cost 0.000113964\n",
      "step 73100, training accuracy 0.96748\n",
      "step 73100, cost 5.06766\n",
      "step 73100, change in cost 0.00011301\n",
      "step 73110, training accuracy 0.96748\n",
      "step 73110, cost 5.06755\n",
      "step 73110, change in cost 0.000112534\n",
      "step 73120, training accuracy 0.96748\n",
      "step 73120, cost 5.06744\n",
      "step 73120, change in cost 0.000114441\n",
      "step 73130, training accuracy 0.96748\n",
      "step 73130, cost 5.06732\n",
      "step 73130, change in cost 0.000113964\n",
      "step 73140, training accuracy 0.96748\n",
      "step 73140, cost 5.06721\n",
      "step 73140, change in cost 0.000113487\n",
      "step 73150, training accuracy 0.96748\n",
      "step 73150, cost 5.0671\n",
      "step 73150, change in cost 0.000113487\n",
      "step 73160, training accuracy 0.96748\n",
      "step 73160, cost 5.06698\n",
      "step 73160, change in cost 0.000113487\n",
      "step 73170, training accuracy 0.96748\n",
      "step 73170, cost 5.06687\n",
      "step 73170, change in cost 0.00011301\n",
      "step 73180, training accuracy 0.96748\n",
      "step 73180, cost 5.06676\n",
      "step 73180, change in cost 0.000113964\n",
      "step 73190, training accuracy 0.96748\n",
      "step 73190, cost 5.06664\n",
      "step 73190, change in cost 0.00011301\n",
      "step 73200, training accuracy 0.96748\n",
      "step 73200, cost 5.06653\n",
      "step 73200, change in cost 0.000113487\n",
      "step 73210, training accuracy 0.96748\n",
      "step 73210, cost 5.06642\n",
      "step 73210, change in cost 0.00011301\n",
      "step 73220, training accuracy 0.96748\n",
      "step 73220, cost 5.0663\n",
      "step 73220, change in cost 0.000112057\n",
      "step 73230, training accuracy 0.96748\n",
      "step 73230, cost 5.06619\n",
      "step 73230, change in cost 0.00011301\n",
      "step 73240, training accuracy 0.96748\n",
      "step 73240, cost 5.06608\n",
      "step 73240, change in cost 0.000113487\n",
      "step 73250, training accuracy 0.96748\n",
      "step 73250, cost 5.06597\n",
      "step 73250, change in cost 0.000112534\n",
      "step 73260, training accuracy 0.96748\n",
      "step 73260, cost 5.06585\n",
      "step 73260, change in cost 0.000113487\n",
      "step 73270, training accuracy 0.96748\n",
      "step 73270, cost 5.06574\n",
      "step 73270, change in cost 0.000112534\n",
      "step 73280, training accuracy 0.96748\n",
      "step 73280, cost 5.06563\n",
      "step 73280, change in cost 0.000112057\n",
      "step 73290, training accuracy 0.96748\n",
      "step 73290, cost 5.06551\n",
      "step 73290, change in cost 0.000114918\n",
      "step 73300, training accuracy 0.96748\n",
      "step 73300, cost 5.0654\n",
      "step 73300, change in cost 0.000112534\n",
      "step 73310, training accuracy 0.96748\n",
      "step 73310, cost 5.06529\n",
      "step 73310, change in cost 0.000113487\n",
      "step 73320, training accuracy 0.96748\n",
      "step 73320, cost 5.06517\n",
      "step 73320, change in cost 0.000112534\n",
      "step 73330, training accuracy 0.96748\n",
      "step 73330, cost 5.06506\n",
      "step 73330, change in cost 0.000113487\n",
      "step 73340, training accuracy 0.96748\n",
      "step 73340, cost 5.06495\n",
      "step 73340, change in cost 0.000112534\n",
      "step 73350, training accuracy 0.96748\n",
      "step 73350, cost 5.06484\n",
      "step 73350, change in cost 0.000112534\n",
      "step 73360, training accuracy 0.96748\n",
      "step 73360, cost 5.06472\n",
      "step 73360, change in cost 0.000112057\n",
      "step 73370, training accuracy 0.96748\n",
      "step 73370, cost 5.06461\n",
      "step 73370, change in cost 0.000113487\n",
      "step 73380, training accuracy 0.96748\n",
      "step 73380, cost 5.0645\n",
      "step 73380, change in cost 0.00011301\n",
      "step 73390, training accuracy 0.96748\n",
      "step 73390, cost 5.06438\n",
      "step 73390, change in cost 0.00011301\n",
      "step 73400, training accuracy 0.96748\n",
      "step 73400, cost 5.06427\n",
      "step 73400, change in cost 0.000112534\n",
      "step 73410, training accuracy 0.96748\n",
      "step 73410, cost 5.06416\n",
      "step 73410, change in cost 0.000112057\n",
      "step 73420, training accuracy 0.96748\n",
      "step 73420, cost 5.06405\n",
      "step 73420, change in cost 0.000112057\n",
      "step 73430, training accuracy 0.96748\n",
      "step 73430, cost 5.06393\n",
      "step 73430, change in cost 0.00011301\n",
      "step 73440, training accuracy 0.96748\n",
      "step 73440, cost 5.06382\n",
      "step 73440, change in cost 0.000112534\n",
      "step 73450, training accuracy 0.96748\n",
      "step 73450, cost 5.06371\n",
      "step 73450, change in cost 0.000112534\n",
      "step 73460, training accuracy 0.96748\n",
      "step 73460, cost 5.0636\n",
      "step 73460, change in cost 0.000112057\n",
      "step 73470, training accuracy 0.96748\n",
      "step 73470, cost 5.06348\n",
      "step 73470, change in cost 0.00011301\n",
      "step 73480, training accuracy 0.96748\n",
      "step 73480, cost 5.06337\n",
      "step 73480, change in cost 0.000112534\n",
      "step 73490, training accuracy 0.96748\n",
      "step 73490, cost 5.06326\n",
      "step 73490, change in cost 0.000112534\n",
      "step 73500, training accuracy 0.96748\n",
      "step 73500, cost 5.06315\n",
      "step 73500, change in cost 0.000112534\n",
      "step 73510, training accuracy 0.96748\n",
      "step 73510, cost 5.06303\n",
      "step 73510, change in cost 0.000112534\n",
      "step 73520, training accuracy 0.96748\n",
      "step 73520, cost 5.06292\n",
      "step 73520, change in cost 0.00011158\n",
      "step 73530, training accuracy 0.96748\n",
      "step 73530, cost 5.06281\n",
      "step 73530, change in cost 0.00011158\n",
      "step 73540, training accuracy 0.96748\n",
      "step 73540, cost 5.0627\n",
      "step 73540, change in cost 0.000112057\n",
      "step 73550, training accuracy 0.96748\n",
      "step 73550, cost 5.06259\n",
      "step 73550, change in cost 0.00011301\n",
      "step 73560, training accuracy 0.96748\n",
      "step 73560, cost 5.06247\n",
      "step 73560, change in cost 0.00011158\n",
      "step 73570, training accuracy 0.96748\n",
      "step 73570, cost 5.06236\n",
      "step 73570, change in cost 0.000112534\n",
      "step 73580, training accuracy 0.96748\n",
      "step 73580, cost 5.06225\n",
      "step 73580, change in cost 0.000110626\n",
      "step 73590, training accuracy 0.96748\n",
      "step 73590, cost 5.06214\n",
      "step 73590, change in cost 0.000112534\n",
      "step 73600, training accuracy 0.96748\n",
      "step 73600, cost 5.06203\n",
      "step 73600, change in cost 0.00011301\n",
      "step 73610, training accuracy 0.96748\n",
      "step 73610, cost 5.06191\n",
      "step 73610, change in cost 0.000111103\n",
      "step 73620, training accuracy 0.96748\n",
      "step 73620, cost 5.0618\n",
      "step 73620, change in cost 0.00011301\n",
      "step 73630, training accuracy 0.96748\n",
      "step 73630, cost 5.06169\n",
      "step 73630, change in cost 0.000111103\n",
      "step 73640, training accuracy 0.96748\n",
      "step 73640, cost 5.06158\n",
      "step 73640, change in cost 0.000111103\n",
      "step 73650, training accuracy 0.96748\n",
      "step 73650, cost 5.06147\n",
      "step 73650, change in cost 0.000112534\n",
      "step 73660, training accuracy 0.96748\n",
      "step 73660, cost 5.06135\n",
      "step 73660, change in cost 0.000112057\n",
      "step 73670, training accuracy 0.96748\n",
      "step 73670, cost 5.06124\n",
      "step 73670, change in cost 0.000112057\n",
      "step 73680, training accuracy 0.96748\n",
      "step 73680, cost 5.06113\n",
      "step 73680, change in cost 0.000112057\n",
      "step 73690, training accuracy 0.96748\n",
      "step 73690, cost 5.06102\n",
      "step 73690, change in cost 0.00011158\n",
      "step 73700, training accuracy 0.96748\n",
      "step 73700, cost 5.06091\n",
      "step 73700, change in cost 0.000112534\n",
      "step 73710, training accuracy 0.96748\n",
      "step 73710, cost 5.0608\n",
      "step 73710, change in cost 0.000111103\n",
      "step 73720, training accuracy 0.96748\n",
      "step 73720, cost 5.06068\n",
      "step 73720, change in cost 0.00011158\n",
      "step 73730, training accuracy 0.96748\n",
      "step 73730, cost 5.06057\n",
      "step 73730, change in cost 0.000111103\n",
      "step 73740, training accuracy 0.96748\n",
      "step 73740, cost 5.06046\n",
      "step 73740, change in cost 0.00011158\n",
      "step 73750, training accuracy 0.96748\n",
      "step 73750, cost 5.06035\n",
      "step 73750, change in cost 0.000111103\n",
      "step 73760, training accuracy 0.96748\n",
      "step 73760, cost 5.06024\n",
      "step 73760, change in cost 0.00011158\n",
      "step 73770, training accuracy 0.96748\n",
      "step 73770, cost 5.06013\n",
      "step 73770, change in cost 0.000112057\n",
      "step 73780, training accuracy 0.96748\n",
      "step 73780, cost 5.06001\n",
      "step 73780, change in cost 0.00011158\n",
      "step 73790, training accuracy 0.96748\n",
      "step 73790, cost 5.0599\n",
      "step 73790, change in cost 0.000110626\n",
      "step 73800, training accuracy 0.96748\n",
      "step 73800, cost 5.05979\n",
      "step 73800, change in cost 0.000112534\n",
      "step 73810, training accuracy 0.96748\n",
      "step 73810, cost 5.05968\n",
      "step 73810, change in cost 0.000110149\n",
      "step 73820, training accuracy 0.96748\n",
      "step 73820, cost 5.05957\n",
      "step 73820, change in cost 0.000112057\n",
      "step 73830, training accuracy 0.96748\n",
      "step 73830, cost 5.05946\n",
      "step 73830, change in cost 0.000110626\n",
      "step 73840, training accuracy 0.96748\n",
      "step 73840, cost 5.05935\n",
      "step 73840, change in cost 0.00011158\n",
      "step 73850, training accuracy 0.96748\n",
      "step 73850, cost 5.05924\n",
      "step 73850, change in cost 0.000111103\n",
      "step 73860, training accuracy 0.96748\n",
      "step 73860, cost 5.05912\n",
      "step 73860, change in cost 0.000112057\n",
      "step 73870, training accuracy 0.96748\n",
      "step 73870, cost 5.05901\n",
      "step 73870, change in cost 0.000110626\n",
      "step 73880, training accuracy 0.96748\n",
      "step 73880, cost 5.0589\n",
      "step 73880, change in cost 0.00011158\n",
      "step 73890, training accuracy 0.96748\n",
      "step 73890, cost 5.05879\n",
      "step 73890, change in cost 0.00011158\n",
      "step 73900, training accuracy 0.96748\n",
      "step 73900, cost 5.05868\n",
      "step 73900, change in cost 0.000110626\n",
      "step 73910, training accuracy 0.96748\n",
      "step 73910, cost 5.05857\n",
      "step 73910, change in cost 0.000110626\n",
      "step 73920, training accuracy 0.96748\n",
      "step 73920, cost 5.05846\n",
      "step 73920, change in cost 0.00011158\n",
      "step 73930, training accuracy 0.96748\n",
      "step 73930, cost 5.05835\n",
      "step 73930, change in cost 0.00011158\n",
      "step 73940, training accuracy 0.96748\n",
      "step 73940, cost 5.05824\n",
      "step 73940, change in cost 0.000109673\n",
      "step 73950, training accuracy 0.96748\n",
      "step 73950, cost 5.05812\n",
      "step 73950, change in cost 0.00011158\n",
      "step 73960, training accuracy 0.96748\n",
      "step 73960, cost 5.05801\n",
      "step 73960, change in cost 0.000110626\n",
      "step 73970, training accuracy 0.96748\n",
      "step 73970, cost 5.0579\n",
      "step 73970, change in cost 0.000110626\n",
      "step 73980, training accuracy 0.96748\n",
      "step 73980, cost 5.05779\n",
      "step 73980, change in cost 0.000111103\n",
      "step 73990, training accuracy 0.96748\n",
      "step 73990, cost 5.05768\n",
      "step 73990, change in cost 0.00011158\n",
      "step 74000, training accuracy 0.96748\n",
      "step 74000, cost 5.05757\n",
      "step 74000, change in cost 0.000110149\n",
      "step 74010, training accuracy 0.96748\n",
      "step 74010, cost 5.05746\n",
      "step 74010, change in cost 0.000110626\n",
      "step 74020, training accuracy 0.96748\n",
      "step 74020, cost 5.05735\n",
      "step 74020, change in cost 0.00011158\n",
      "step 74030, training accuracy 0.96748\n",
      "step 74030, cost 5.05724\n",
      "step 74030, change in cost 0.000109673\n",
      "step 74040, training accuracy 0.96748\n",
      "step 74040, cost 5.05713\n",
      "step 74040, change in cost 0.00011158\n",
      "step 74050, training accuracy 0.96748\n",
      "step 74050, cost 5.05702\n",
      "step 74050, change in cost 0.000110626\n",
      "step 74060, training accuracy 0.96748\n",
      "step 74060, cost 5.0569\n",
      "step 74060, change in cost 0.00011158\n",
      "step 74070, training accuracy 0.96748\n",
      "step 74070, cost 5.0568\n",
      "step 74070, change in cost 0.000109673\n",
      "step 74080, training accuracy 0.96748\n",
      "step 74080, cost 5.05668\n",
      "step 74080, change in cost 0.000110149\n",
      "step 74090, training accuracy 0.96748\n",
      "step 74090, cost 5.05657\n",
      "step 74090, change in cost 0.000110149\n",
      "step 74100, training accuracy 0.96748\n",
      "step 74100, cost 5.05646\n",
      "step 74100, change in cost 0.000110149\n",
      "step 74110, training accuracy 0.96748\n",
      "step 74110, cost 5.05635\n",
      "step 74110, change in cost 0.000111103\n",
      "step 74120, training accuracy 0.96748\n",
      "step 74120, cost 5.05624\n",
      "step 74120, change in cost 0.000109673\n",
      "step 74130, training accuracy 0.96748\n",
      "step 74130, cost 5.05613\n",
      "step 74130, change in cost 0.000109673\n",
      "step 74140, training accuracy 0.96748\n",
      "step 74140, cost 5.05602\n",
      "step 74140, change in cost 0.00011158\n",
      "step 74150, training accuracy 0.96748\n",
      "step 74150, cost 5.05591\n",
      "step 74150, change in cost 0.000109673\n",
      "step 74160, training accuracy 0.96748\n",
      "step 74160, cost 5.0558\n",
      "step 74160, change in cost 0.000110626\n",
      "step 74170, training accuracy 0.96748\n",
      "step 74170, cost 5.05569\n",
      "step 74170, change in cost 0.00011158\n",
      "step 74180, training accuracy 0.96748\n",
      "step 74180, cost 5.05558\n",
      "step 74180, change in cost 0.000109673\n",
      "step 74190, training accuracy 0.96748\n",
      "step 74190, cost 5.05547\n",
      "step 74190, change in cost 0.000110626\n",
      "step 74200, training accuracy 0.96748\n",
      "step 74200, cost 5.05536\n",
      "step 74200, change in cost 0.000109673\n",
      "step 74210, training accuracy 0.96748\n",
      "step 74210, cost 5.05525\n",
      "step 74210, change in cost 0.000110626\n",
      "step 74220, training accuracy 0.96748\n",
      "step 74220, cost 5.05514\n",
      "step 74220, change in cost 0.000109673\n",
      "step 74230, training accuracy 0.96748\n",
      "step 74230, cost 5.05503\n",
      "step 74230, change in cost 0.000109673\n",
      "step 74240, training accuracy 0.96748\n",
      "step 74240, cost 5.05492\n",
      "step 74240, change in cost 0.000110626\n",
      "step 74250, training accuracy 0.96748\n",
      "step 74250, cost 5.05481\n",
      "step 74250, change in cost 0.000108719\n",
      "step 74260, training accuracy 0.96748\n",
      "step 74260, cost 5.0547\n",
      "step 74260, change in cost 0.00011158\n",
      "step 74270, training accuracy 0.96748\n",
      "step 74270, cost 5.05459\n",
      "step 74270, change in cost 0.000109196\n",
      "step 74280, training accuracy 0.96748\n",
      "step 74280, cost 5.05448\n",
      "step 74280, change in cost 0.000110149\n",
      "step 74290, training accuracy 0.96748\n",
      "step 74290, cost 5.05437\n",
      "step 74290, change in cost 0.000108719\n",
      "step 74300, training accuracy 0.96748\n",
      "step 74300, cost 5.05426\n",
      "step 74300, change in cost 0.000110149\n",
      "step 74310, training accuracy 0.96748\n",
      "step 74310, cost 5.05415\n",
      "step 74310, change in cost 0.000110149\n",
      "step 74320, training accuracy 0.96748\n",
      "step 74320, cost 5.05404\n",
      "step 74320, change in cost 0.000109196\n",
      "step 74330, training accuracy 0.96748\n",
      "step 74330, cost 5.05393\n",
      "step 74330, change in cost 0.000109673\n",
      "step 74340, training accuracy 0.96748\n",
      "step 74340, cost 5.05382\n",
      "step 74340, change in cost 0.000109673\n",
      "step 74350, training accuracy 0.96748\n",
      "step 74350, cost 5.05371\n",
      "step 74350, change in cost 0.000109196\n",
      "step 74360, training accuracy 0.96748\n",
      "step 74360, cost 5.0536\n",
      "step 74360, change in cost 0.000110626\n",
      "step 74370, training accuracy 0.96748\n",
      "step 74370, cost 5.05349\n",
      "step 74370, change in cost 0.000108719\n",
      "step 74380, training accuracy 0.96748\n",
      "step 74380, cost 5.05338\n",
      "step 74380, change in cost 0.000109673\n",
      "step 74390, training accuracy 0.96748\n",
      "step 74390, cost 5.05327\n",
      "step 74390, change in cost 0.000111103\n",
      "step 74400, training accuracy 0.96748\n",
      "step 74400, cost 5.05317\n",
      "step 74400, change in cost 0.000108242\n",
      "step 74410, training accuracy 0.96748\n",
      "step 74410, cost 5.05306\n",
      "step 74410, change in cost 0.000109673\n",
      "step 74420, training accuracy 0.96748\n",
      "step 74420, cost 5.05295\n",
      "step 74420, change in cost 0.000110149\n",
      "step 74430, training accuracy 0.96748\n",
      "step 74430, cost 5.05284\n",
      "step 74430, change in cost 0.000109673\n",
      "step 74440, training accuracy 0.96748\n",
      "step 74440, cost 5.05273\n",
      "step 74440, change in cost 0.000108719\n",
      "step 74450, training accuracy 0.96748\n",
      "step 74450, cost 5.05262\n",
      "step 74450, change in cost 0.000109196\n",
      "step 74460, training accuracy 0.96748\n",
      "step 74460, cost 5.05251\n",
      "step 74460, change in cost 0.000109673\n",
      "step 74470, training accuracy 0.96748\n",
      "step 74470, cost 5.0524\n",
      "step 74470, change in cost 0.000108719\n",
      "step 74480, training accuracy 0.96748\n",
      "step 74480, cost 5.05229\n",
      "step 74480, change in cost 0.000109673\n",
      "step 74490, training accuracy 0.96748\n",
      "step 74490, cost 5.05218\n",
      "step 74490, change in cost 0.000109673\n",
      "step 74500, training accuracy 0.96748\n",
      "step 74500, cost 5.05207\n",
      "step 74500, change in cost 0.000109673\n",
      "step 74510, training accuracy 0.96748\n",
      "step 74510, cost 5.05196\n",
      "step 74510, change in cost 0.000109673\n",
      "step 74520, training accuracy 0.96748\n",
      "step 74520, cost 5.05185\n",
      "step 74520, change in cost 0.000108242\n",
      "step 74530, training accuracy 0.96748\n",
      "step 74530, cost 5.05174\n",
      "step 74530, change in cost 0.000109196\n",
      "step 74540, training accuracy 0.96748\n",
      "step 74540, cost 5.05163\n",
      "step 74540, change in cost 0.000109196\n",
      "step 74550, training accuracy 0.96748\n",
      "step 74550, cost 5.05153\n",
      "step 74550, change in cost 0.000109196\n",
      "step 74560, training accuracy 0.96748\n",
      "step 74560, cost 5.05142\n",
      "step 74560, change in cost 0.000108719\n",
      "step 74570, training accuracy 0.96748\n",
      "step 74570, cost 5.05131\n",
      "step 74570, change in cost 0.000109673\n",
      "step 74580, training accuracy 0.96748\n",
      "step 74580, cost 5.0512\n",
      "step 74580, change in cost 0.000108719\n",
      "step 74590, training accuracy 0.96748\n",
      "step 74590, cost 5.05109\n",
      "step 74590, change in cost 0.000109196\n",
      "step 74600, training accuracy 0.96748\n",
      "step 74600, cost 5.05098\n",
      "step 74600, change in cost 0.000109196\n",
      "step 74610, training accuracy 0.96748\n",
      "step 74610, cost 5.05087\n",
      "step 74610, change in cost 0.000108719\n",
      "step 74620, training accuracy 0.96748\n",
      "step 74620, cost 5.05076\n",
      "step 74620, change in cost 0.000109196\n",
      "step 74630, training accuracy 0.96748\n",
      "step 74630, cost 5.05065\n",
      "step 74630, change in cost 0.000108719\n",
      "step 74640, training accuracy 0.96748\n",
      "step 74640, cost 5.05054\n",
      "step 74640, change in cost 0.000109673\n",
      "step 74650, training accuracy 0.96748\n",
      "step 74650, cost 5.05044\n",
      "step 74650, change in cost 0.000108242\n",
      "step 74660, training accuracy 0.96748\n",
      "step 74660, cost 5.05033\n",
      "step 74660, change in cost 0.000108719\n",
      "step 74670, training accuracy 0.96748\n",
      "step 74670, cost 5.05022\n",
      "step 74670, change in cost 0.000108719\n",
      "step 74680, training accuracy 0.96748\n",
      "step 74680, cost 5.05011\n",
      "step 74680, change in cost 0.000108719\n",
      "step 74690, training accuracy 0.96748\n",
      "step 74690, cost 5.05\n",
      "step 74690, change in cost 0.000108719\n",
      "step 74700, training accuracy 0.96748\n",
      "step 74700, cost 5.04989\n",
      "step 74700, change in cost 0.000108719\n",
      "step 74710, training accuracy 0.96748\n",
      "step 74710, cost 5.04978\n",
      "step 74710, change in cost 0.000107765\n",
      "step 74720, training accuracy 0.96748\n",
      "step 74720, cost 5.04967\n",
      "step 74720, change in cost 0.000109196\n",
      "step 74730, training accuracy 0.96748\n",
      "step 74730, cost 5.04957\n",
      "step 74730, change in cost 0.000109196\n",
      "step 74740, training accuracy 0.96748\n",
      "step 74740, cost 5.04946\n",
      "step 74740, change in cost 0.000108242\n",
      "step 74750, training accuracy 0.96748\n",
      "step 74750, cost 5.04935\n",
      "step 74750, change in cost 0.000109196\n",
      "step 74760, training accuracy 0.96748\n",
      "step 74760, cost 5.04924\n",
      "step 74760, change in cost 0.000108719\n",
      "step 74770, training accuracy 0.96748\n",
      "step 74770, cost 5.04913\n",
      "step 74770, change in cost 0.000108719\n",
      "step 74780, training accuracy 0.96748\n",
      "step 74780, cost 5.04902\n",
      "step 74780, change in cost 0.000107765\n",
      "step 74790, training accuracy 0.96748\n",
      "step 74790, cost 5.04891\n",
      "step 74790, change in cost 0.000108719\n",
      "step 74800, training accuracy 0.96748\n",
      "step 74800, cost 5.04881\n",
      "step 74800, change in cost 0.000107765\n",
      "step 74810, training accuracy 0.96748\n",
      "step 74810, cost 5.0487\n",
      "step 74810, change in cost 0.000109196\n",
      "step 74820, training accuracy 0.96748\n",
      "step 74820, cost 5.04859\n",
      "step 74820, change in cost 0.000108242\n",
      "step 74830, training accuracy 0.96748\n",
      "step 74830, cost 5.04848\n",
      "step 74830, change in cost 0.000107765\n",
      "step 74840, training accuracy 0.96748\n",
      "step 74840, cost 5.04837\n",
      "step 74840, change in cost 0.000109673\n",
      "step 74850, training accuracy 0.96748\n",
      "step 74850, cost 5.04826\n",
      "step 74850, change in cost 0.000107765\n",
      "step 74860, training accuracy 0.96748\n",
      "step 74860, cost 5.04816\n",
      "step 74860, change in cost 0.000107765\n",
      "step 74870, training accuracy 0.96748\n",
      "step 74870, cost 5.04805\n",
      "step 74870, change in cost 0.000107765\n",
      "step 74880, training accuracy 0.96748\n",
      "step 74880, cost 5.04794\n",
      "step 74880, change in cost 0.000108719\n",
      "step 74890, training accuracy 0.96748\n",
      "step 74890, cost 5.04783\n",
      "step 74890, change in cost 0.000108242\n",
      "step 74900, training accuracy 0.96748\n",
      "step 74900, cost 5.04772\n",
      "step 74900, change in cost 0.000108242\n",
      "step 74910, training accuracy 0.96748\n",
      "step 74910, cost 5.04762\n",
      "step 74910, change in cost 0.000107765\n",
      "step 74920, training accuracy 0.96748\n",
      "step 74920, cost 5.04751\n",
      "step 74920, change in cost 0.000108719\n",
      "step 74930, training accuracy 0.96748\n",
      "step 74930, cost 5.0474\n",
      "step 74930, change in cost 0.000109196\n",
      "step 74940, training accuracy 0.96748\n",
      "step 74940, cost 5.04729\n",
      "step 74940, change in cost 0.000106812\n",
      "step 74950, training accuracy 0.96748\n",
      "step 74950, cost 5.04718\n",
      "step 74950, change in cost 0.000107765\n",
      "step 74960, training accuracy 0.96748\n",
      "step 74960, cost 5.04707\n",
      "step 74960, change in cost 0.000107765\n",
      "step 74970, training accuracy 0.96748\n",
      "step 74970, cost 5.04697\n",
      "step 74970, change in cost 0.000108242\n",
      "step 74980, training accuracy 0.96748\n",
      "step 74980, cost 5.04686\n",
      "step 74980, change in cost 0.000108242\n",
      "step 74990, training accuracy 0.96748\n",
      "step 74990, cost 5.04675\n",
      "step 74990, change in cost 0.000108242\n",
      "step 75000, training accuracy 0.96748\n",
      "step 75000, cost 5.04664\n",
      "step 75000, change in cost 0.000107765\n",
      "step 75010, training accuracy 0.96748\n",
      "step 75010, cost 5.04654\n",
      "step 75010, change in cost 0.000106812\n",
      "step 75020, training accuracy 0.96748\n",
      "step 75020, cost 5.04643\n",
      "step 75020, change in cost 0.000108719\n",
      "step 75030, training accuracy 0.96748\n",
      "step 75030, cost 5.04632\n",
      "step 75030, change in cost 0.000108719\n",
      "step 75040, training accuracy 0.96748\n",
      "step 75040, cost 5.04621\n",
      "step 75040, change in cost 0.000106812\n",
      "step 75050, training accuracy 0.96748\n",
      "step 75050, cost 5.0461\n",
      "step 75050, change in cost 0.000107288\n",
      "step 75060, training accuracy 0.96748\n",
      "step 75060, cost 5.046\n",
      "step 75060, change in cost 0.000108242\n",
      "step 75070, training accuracy 0.96748\n",
      "step 75070, cost 5.04589\n",
      "step 75070, change in cost 0.000108719\n",
      "step 75080, training accuracy 0.96748\n",
      "step 75080, cost 5.04578\n",
      "step 75080, change in cost 0.000106812\n",
      "step 75090, training accuracy 0.96748\n",
      "step 75090, cost 5.04567\n",
      "step 75090, change in cost 0.000107765\n",
      "step 75100, training accuracy 0.96748\n",
      "step 75100, cost 5.04557\n",
      "step 75100, change in cost 0.000107288\n",
      "step 75110, training accuracy 0.96748\n",
      "step 75110, cost 5.04546\n",
      "step 75110, change in cost 0.000108242\n",
      "step 75120, training accuracy 0.96748\n",
      "step 75120, cost 5.04535\n",
      "step 75120, change in cost 0.000107765\n",
      "step 75130, training accuracy 0.96748\n",
      "step 75130, cost 5.04524\n",
      "step 75130, change in cost 0.000107765\n",
      "step 75140, training accuracy 0.96748\n",
      "step 75140, cost 5.04513\n",
      "step 75140, change in cost 0.000106812\n",
      "step 75150, training accuracy 0.96748\n",
      "step 75150, cost 5.04503\n",
      "step 75150, change in cost 0.000107288\n",
      "step 75160, training accuracy 0.96748\n",
      "step 75160, cost 5.04492\n",
      "step 75160, change in cost 0.000108719\n",
      "step 75170, training accuracy 0.96748\n",
      "step 75170, cost 5.04481\n",
      "step 75170, change in cost 0.000106812\n",
      "step 75180, training accuracy 0.96748\n",
      "step 75180, cost 5.0447\n",
      "step 75180, change in cost 0.000107288\n",
      "step 75190, training accuracy 0.96748\n",
      "step 75190, cost 5.0446\n",
      "step 75190, change in cost 0.000107765\n",
      "step 75200, training accuracy 0.96748\n",
      "step 75200, cost 5.04449\n",
      "step 75200, change in cost 0.000107765\n",
      "step 75210, training accuracy 0.96748\n",
      "step 75210, cost 5.04438\n",
      "step 75210, change in cost 0.000107765\n",
      "step 75220, training accuracy 0.96748\n",
      "step 75220, cost 5.04428\n",
      "step 75220, change in cost 0.000105858\n",
      "step 75230, training accuracy 0.96748\n",
      "step 75230, cost 5.04417\n",
      "step 75230, change in cost 0.000107765\n",
      "step 75240, training accuracy 0.96748\n",
      "step 75240, cost 5.04406\n",
      "step 75240, change in cost 0.000107765\n",
      "step 75250, training accuracy 0.96748\n",
      "step 75250, cost 5.04395\n",
      "step 75250, change in cost 0.000106812\n",
      "step 75260, training accuracy 0.96748\n",
      "step 75260, cost 5.04385\n",
      "step 75260, change in cost 0.000106335\n",
      "step 75270, training accuracy 0.96748\n",
      "step 75270, cost 5.04374\n",
      "step 75270, change in cost 0.000108242\n",
      "step 75280, training accuracy 0.96748\n",
      "step 75280, cost 5.04363\n",
      "step 75280, change in cost 0.000106335\n",
      "step 75290, training accuracy 0.96748\n",
      "step 75290, cost 5.04352\n",
      "step 75290, change in cost 0.000107288\n",
      "step 75300, training accuracy 0.96748\n",
      "step 75300, cost 5.04342\n",
      "step 75300, change in cost 0.000107288\n",
      "step 75310, training accuracy 0.96748\n",
      "step 75310, cost 5.04331\n",
      "step 75310, change in cost 0.000107288\n",
      "step 75320, training accuracy 0.96748\n",
      "step 75320, cost 5.0432\n",
      "step 75320, change in cost 0.000106812\n",
      "step 75330, training accuracy 0.96748\n",
      "step 75330, cost 5.0431\n",
      "step 75330, change in cost 0.000106812\n",
      "step 75340, training accuracy 0.96748\n",
      "step 75340, cost 5.04299\n",
      "step 75340, change in cost 0.000107765\n",
      "step 75350, training accuracy 0.96748\n",
      "step 75350, cost 5.04288\n",
      "step 75350, change in cost 0.000106812\n",
      "step 75360, training accuracy 0.96748\n",
      "step 75360, cost 5.04277\n",
      "step 75360, change in cost 0.000107765\n",
      "step 75370, training accuracy 0.96748\n",
      "step 75370, cost 5.04267\n",
      "step 75370, change in cost 0.000106812\n",
      "step 75380, training accuracy 0.96748\n",
      "step 75380, cost 5.04256\n",
      "step 75380, change in cost 0.000106812\n",
      "step 75390, training accuracy 0.96748\n",
      "step 75390, cost 5.04245\n",
      "step 75390, change in cost 0.000106812\n",
      "step 75400, training accuracy 0.96748\n",
      "step 75400, cost 5.04235\n",
      "step 75400, change in cost 0.000106812\n",
      "step 75410, training accuracy 0.96748\n",
      "step 75410, cost 5.04224\n",
      "step 75410, change in cost 0.000106812\n",
      "step 75420, training accuracy 0.96748\n",
      "step 75420, cost 5.04213\n",
      "step 75420, change in cost 0.000106812\n",
      "step 75430, training accuracy 0.96748\n",
      "step 75430, cost 5.04203\n",
      "step 75430, change in cost 0.000106812\n",
      "step 75440, training accuracy 0.96748\n",
      "step 75440, cost 5.04192\n",
      "step 75440, change in cost 0.000106812\n",
      "step 75450, training accuracy 0.96748\n",
      "step 75450, cost 5.04181\n",
      "step 75450, change in cost 0.000106335\n",
      "step 75460, training accuracy 0.96748\n",
      "step 75460, cost 5.04171\n",
      "step 75460, change in cost 0.000106812\n",
      "step 75470, training accuracy 0.96748\n",
      "step 75470, cost 5.0416\n",
      "step 75470, change in cost 0.000106335\n",
      "step 75480, training accuracy 0.96748\n",
      "step 75480, cost 5.04149\n",
      "step 75480, change in cost 0.000107765\n",
      "step 75490, training accuracy 0.96748\n",
      "step 75490, cost 5.04139\n",
      "step 75490, change in cost 0.000105858\n",
      "step 75500, training accuracy 0.96748\n",
      "step 75500, cost 5.04128\n",
      "step 75500, change in cost 0.000106812\n",
      "step 75510, training accuracy 0.96748\n",
      "step 75510, cost 5.04117\n",
      "step 75510, change in cost 0.000106335\n",
      "step 75520, training accuracy 0.96748\n",
      "step 75520, cost 5.04107\n",
      "step 75520, change in cost 0.000106335\n",
      "step 75530, training accuracy 0.96748\n",
      "step 75530, cost 5.04096\n",
      "step 75530, change in cost 0.000106812\n",
      "step 75540, training accuracy 0.96748\n",
      "step 75540, cost 5.04085\n",
      "step 75540, change in cost 0.000106335\n",
      "step 75550, training accuracy 0.96748\n",
      "step 75550, cost 5.04075\n",
      "step 75550, change in cost 0.000106335\n",
      "step 75560, training accuracy 0.96748\n",
      "step 75560, cost 5.04064\n",
      "step 75560, change in cost 0.000106335\n",
      "step 75570, training accuracy 0.96748\n",
      "step 75570, cost 5.04053\n",
      "step 75570, change in cost 0.000107288\n",
      "step 75580, training accuracy 0.96748\n",
      "step 75580, cost 5.04043\n",
      "step 75580, change in cost 0.000105858\n",
      "step 75590, training accuracy 0.96748\n",
      "step 75590, cost 5.04032\n",
      "step 75590, change in cost 0.000106335\n",
      "step 75600, training accuracy 0.96748\n",
      "step 75600, cost 5.04022\n",
      "step 75600, change in cost 0.000106335\n",
      "step 75610, training accuracy 0.96748\n",
      "step 75610, cost 5.04011\n",
      "step 75610, change in cost 0.000106812\n",
      "step 75620, training accuracy 0.96748\n",
      "step 75620, cost 5.04\n",
      "step 75620, change in cost 0.000106812\n",
      "step 75630, training accuracy 0.96748\n",
      "step 75630, cost 5.0399\n",
      "step 75630, change in cost 0.000104427\n",
      "step 75640, training accuracy 0.96748\n",
      "step 75640, cost 5.03979\n",
      "step 75640, change in cost 0.000106335\n",
      "step 75650, training accuracy 0.96748\n",
      "step 75650, cost 5.03969\n",
      "step 75650, change in cost 0.000105858\n",
      "step 75660, training accuracy 0.96748\n",
      "step 75660, cost 5.03958\n",
      "step 75660, change in cost 0.000107765\n",
      "step 75670, training accuracy 0.96748\n",
      "step 75670, cost 5.03947\n",
      "step 75670, change in cost 0.000105858\n",
      "step 75680, training accuracy 0.96748\n",
      "step 75680, cost 5.03937\n",
      "step 75680, change in cost 0.000105858\n",
      "step 75690, training accuracy 0.96748\n",
      "step 75690, cost 5.03926\n",
      "step 75690, change in cost 0.000104904\n",
      "step 75700, training accuracy 0.96748\n",
      "step 75700, cost 5.03915\n",
      "step 75700, change in cost 0.000106812\n",
      "step 75710, training accuracy 0.96748\n",
      "step 75710, cost 5.03905\n",
      "step 75710, change in cost 0.000106335\n",
      "step 75720, training accuracy 0.96748\n",
      "step 75720, cost 5.03894\n",
      "step 75720, change in cost 0.000105381\n",
      "step 75730, training accuracy 0.96748\n",
      "step 75730, cost 5.03884\n",
      "step 75730, change in cost 0.000106812\n",
      "step 75740, training accuracy 0.96748\n",
      "step 75740, cost 5.03873\n",
      "step 75740, change in cost 0.000105858\n",
      "step 75750, training accuracy 0.96748\n",
      "step 75750, cost 5.03862\n",
      "step 75750, change in cost 0.000106335\n",
      "step 75760, training accuracy 0.96748\n",
      "step 75760, cost 5.03852\n",
      "step 75760, change in cost 0.000105381\n",
      "step 75770, training accuracy 0.96748\n",
      "step 75770, cost 5.03841\n",
      "step 75770, change in cost 0.000107288\n",
      "step 75780, training accuracy 0.96748\n",
      "step 75780, cost 5.03831\n",
      "step 75780, change in cost 0.000103951\n",
      "step 75790, training accuracy 0.96748\n",
      "step 75790, cost 5.0382\n",
      "step 75790, change in cost 0.000106335\n",
      "step 75800, training accuracy 0.96748\n",
      "step 75800, cost 5.03809\n",
      "step 75800, change in cost 0.000105858\n",
      "step 75810, training accuracy 0.96748\n",
      "step 75810, cost 5.03799\n",
      "step 75810, change in cost 0.000105381\n",
      "step 75820, training accuracy 0.96748\n",
      "step 75820, cost 5.03788\n",
      "step 75820, change in cost 0.000105381\n",
      "step 75830, training accuracy 0.96748\n",
      "step 75830, cost 5.03778\n",
      "step 75830, change in cost 0.000105381\n",
      "step 75840, training accuracy 0.96748\n",
      "step 75840, cost 5.03767\n",
      "step 75840, change in cost 0.000107288\n",
      "step 75850, training accuracy 0.96748\n",
      "step 75850, cost 5.03757\n",
      "step 75850, change in cost 0.000104904\n",
      "step 75860, training accuracy 0.96748\n",
      "step 75860, cost 5.03746\n",
      "step 75860, change in cost 0.000105858\n",
      "step 75870, training accuracy 0.96748\n",
      "step 75870, cost 5.03735\n",
      "step 75870, change in cost 0.000105858\n",
      "step 75880, training accuracy 0.96748\n",
      "step 75880, cost 5.03725\n",
      "step 75880, change in cost 0.000105858\n",
      "step 75890, training accuracy 0.96748\n",
      "step 75890, cost 5.03714\n",
      "step 75890, change in cost 0.000105858\n",
      "step 75900, training accuracy 0.96748\n",
      "step 75900, cost 5.03704\n",
      "step 75900, change in cost 0.000104904\n",
      "step 75910, training accuracy 0.96748\n",
      "step 75910, cost 5.03693\n",
      "step 75910, change in cost 0.000104904\n",
      "step 75920, training accuracy 0.96748\n",
      "step 75920, cost 5.03683\n",
      "step 75920, change in cost 0.000105858\n",
      "step 75930, training accuracy 0.96748\n",
      "step 75930, cost 5.03672\n",
      "step 75930, change in cost 0.000105858\n",
      "step 75940, training accuracy 0.96748\n",
      "step 75940, cost 5.03662\n",
      "step 75940, change in cost 0.000105858\n",
      "step 75950, training accuracy 0.96748\n",
      "step 75950, cost 5.03651\n",
      "step 75950, change in cost 0.000105858\n",
      "step 75960, training accuracy 0.96748\n",
      "step 75960, cost 5.03641\n",
      "step 75960, change in cost 0.000104427\n",
      "step 75970, training accuracy 0.96748\n",
      "step 75970, cost 5.0363\n",
      "step 75970, change in cost 0.000105381\n",
      "step 75980, training accuracy 0.96748\n",
      "step 75980, cost 5.03619\n",
      "step 75980, change in cost 0.000105381\n",
      "step 75990, training accuracy 0.96748\n",
      "step 75990, cost 5.03609\n",
      "step 75990, change in cost 0.000104427\n",
      "step 76000, training accuracy 0.96748\n",
      "step 76000, cost 5.03598\n",
      "step 76000, change in cost 0.000105858\n",
      "step 76010, training accuracy 0.96748\n",
      "step 76010, cost 5.03588\n",
      "step 76010, change in cost 0.000105858\n",
      "step 76020, training accuracy 0.96748\n",
      "step 76020, cost 5.03577\n",
      "step 76020, change in cost 0.000105381\n",
      "step 76030, training accuracy 0.96748\n",
      "step 76030, cost 5.03567\n",
      "step 76030, change in cost 0.000104427\n",
      "step 76040, training accuracy 0.96748\n",
      "step 76040, cost 5.03556\n",
      "step 76040, change in cost 0.000104904\n",
      "step 76050, training accuracy 0.96748\n",
      "step 76050, cost 5.03546\n",
      "step 76050, change in cost 0.000105858\n",
      "step 76060, training accuracy 0.96748\n",
      "step 76060, cost 5.03535\n",
      "step 76060, change in cost 0.000104904\n",
      "step 76070, training accuracy 0.96748\n",
      "step 76070, cost 5.03525\n",
      "step 76070, change in cost 0.000105381\n",
      "step 76080, training accuracy 0.96748\n",
      "step 76080, cost 5.03514\n",
      "step 76080, change in cost 0.000103951\n",
      "step 76090, training accuracy 0.96748\n",
      "step 76090, cost 5.03504\n",
      "step 76090, change in cost 0.000105381\n",
      "step 76100, training accuracy 0.96748\n",
      "step 76100, cost 5.03493\n",
      "step 76100, change in cost 0.000105858\n",
      "step 76110, training accuracy 0.96748\n",
      "step 76110, cost 5.03483\n",
      "step 76110, change in cost 0.000103951\n",
      "step 76120, training accuracy 0.96748\n",
      "step 76120, cost 5.03472\n",
      "step 76120, change in cost 0.000105858\n",
      "step 76130, training accuracy 0.96748\n",
      "step 76130, cost 5.03462\n",
      "step 76130, change in cost 0.000105381\n",
      "step 76140, training accuracy 0.96748\n",
      "step 76140, cost 5.03451\n",
      "step 76140, change in cost 0.000103951\n",
      "step 76150, training accuracy 0.96748\n",
      "step 76150, cost 5.03441\n",
      "step 76150, change in cost 0.000105381\n",
      "step 76160, training accuracy 0.96748\n",
      "step 76160, cost 5.0343\n",
      "step 76160, change in cost 0.000104904\n",
      "step 76170, training accuracy 0.96748\n",
      "step 76170, cost 5.0342\n",
      "step 76170, change in cost 0.000104427\n",
      "step 76180, training accuracy 0.96748\n",
      "step 76180, cost 5.03409\n",
      "step 76180, change in cost 0.000104427\n",
      "step 76190, training accuracy 0.96748\n",
      "step 76190, cost 5.03399\n",
      "step 76190, change in cost 0.000104904\n",
      "step 76200, training accuracy 0.96748\n",
      "step 76200, cost 5.03388\n",
      "step 76200, change in cost 0.000104904\n",
      "step 76210, training accuracy 0.96748\n",
      "step 76210, cost 5.03378\n",
      "step 76210, change in cost 0.000104427\n",
      "step 76220, training accuracy 0.96748\n",
      "step 76220, cost 5.03368\n",
      "step 76220, change in cost 0.000104427\n",
      "step 76230, training accuracy 0.96748\n",
      "step 76230, cost 5.03357\n",
      "step 76230, change in cost 0.000104427\n",
      "step 76240, training accuracy 0.96748\n",
      "step 76240, cost 5.03347\n",
      "step 76240, change in cost 0.000105381\n",
      "step 76250, training accuracy 0.96748\n",
      "step 76250, cost 5.03336\n",
      "step 76250, change in cost 0.000104427\n",
      "step 76260, training accuracy 0.96748\n",
      "step 76260, cost 5.03326\n",
      "step 76260, change in cost 0.000104904\n",
      "step 76270, training accuracy 0.96748\n",
      "step 76270, cost 5.03315\n",
      "step 76270, change in cost 0.000104904\n",
      "step 76280, training accuracy 0.96748\n",
      "step 76280, cost 5.03305\n",
      "step 76280, change in cost 0.000105381\n",
      "step 76290, training accuracy 0.96748\n",
      "step 76290, cost 5.03294\n",
      "step 76290, change in cost 0.000103951\n",
      "step 76300, training accuracy 0.96748\n",
      "step 76300, cost 5.03284\n",
      "step 76300, change in cost 0.000104427\n",
      "step 76310, training accuracy 0.96748\n",
      "step 76310, cost 5.03273\n",
      "step 76310, change in cost 0.000104904\n",
      "step 76320, training accuracy 0.96748\n",
      "step 76320, cost 5.03263\n",
      "step 76320, change in cost 0.000104427\n",
      "step 76330, training accuracy 0.96748\n",
      "step 76330, cost 5.03252\n",
      "step 76330, change in cost 0.000104427\n",
      "step 76340, training accuracy 0.96748\n",
      "step 76340, cost 5.03242\n",
      "step 76340, change in cost 0.000103474\n",
      "step 76350, training accuracy 0.96748\n",
      "step 76350, cost 5.03232\n",
      "step 76350, change in cost 0.000104427\n",
      "step 76360, training accuracy 0.96748\n",
      "step 76360, cost 5.03221\n",
      "step 76360, change in cost 0.000104904\n",
      "step 76370, training accuracy 0.96748\n",
      "step 76370, cost 5.03211\n",
      "step 76370, change in cost 0.000104427\n",
      "step 76380, training accuracy 0.96748\n",
      "step 76380, cost 5.032\n",
      "step 76380, change in cost 0.000103951\n",
      "step 76390, training accuracy 0.96748\n",
      "step 76390, cost 5.0319\n",
      "step 76390, change in cost 0.000103474\n",
      "step 76400, training accuracy 0.96748\n",
      "step 76400, cost 5.0318\n",
      "step 76400, change in cost 0.000103474\n",
      "step 76410, training accuracy 0.96748\n",
      "step 76410, cost 5.03169\n",
      "step 76410, change in cost 0.000104904\n",
      "step 76420, training accuracy 0.96748\n",
      "step 76420, cost 5.03159\n",
      "step 76420, change in cost 0.000103951\n",
      "step 76430, training accuracy 0.96748\n",
      "step 76430, cost 5.03148\n",
      "step 76430, change in cost 0.000103951\n",
      "step 76440, training accuracy 0.96748\n",
      "step 76440, cost 5.03138\n",
      "step 76440, change in cost 0.000103951\n",
      "step 76450, training accuracy 0.96748\n",
      "step 76450, cost 5.03127\n",
      "step 76450, change in cost 0.000103951\n",
      "step 76460, training accuracy 0.96748\n",
      "step 76460, cost 5.03117\n",
      "step 76460, change in cost 0.000104427\n",
      "step 76470, training accuracy 0.96748\n",
      "step 76470, cost 5.03107\n",
      "step 76470, change in cost 0.000103951\n",
      "step 76480, training accuracy 0.96748\n",
      "step 76480, cost 5.03096\n",
      "step 76480, change in cost 0.000103474\n",
      "step 76490, training accuracy 0.96748\n",
      "step 76490, cost 5.03086\n",
      "step 76490, change in cost 0.000103951\n",
      "step 76500, training accuracy 0.96748\n",
      "step 76500, cost 5.03076\n",
      "step 76500, change in cost 0.000103951\n",
      "step 76510, training accuracy 0.96748\n",
      "step 76510, cost 5.03065\n",
      "step 76510, change in cost 0.000103951\n",
      "step 76520, training accuracy 0.96748\n",
      "step 76520, cost 5.03055\n",
      "step 76520, change in cost 0.000104427\n",
      "step 76530, training accuracy 0.96748\n",
      "step 76530, cost 5.03044\n",
      "step 76530, change in cost 0.000103951\n",
      "step 76540, training accuracy 0.96748\n",
      "step 76540, cost 5.03034\n",
      "step 76540, change in cost 0.000103474\n",
      "step 76550, training accuracy 0.96748\n",
      "step 76550, cost 5.03024\n",
      "step 76550, change in cost 0.000102997\n",
      "step 76560, training accuracy 0.96748\n",
      "step 76560, cost 5.03013\n",
      "step 76560, change in cost 0.000103474\n",
      "step 76570, training accuracy 0.96748\n",
      "step 76570, cost 5.03003\n",
      "step 76570, change in cost 0.000103474\n",
      "step 76580, training accuracy 0.96748\n",
      "step 76580, cost 5.02993\n",
      "step 76580, change in cost 0.000103474\n",
      "step 76590, training accuracy 0.96748\n",
      "step 76590, cost 5.02982\n",
      "step 76590, change in cost 0.000104427\n",
      "step 76600, training accuracy 0.96748\n",
      "step 76600, cost 5.02972\n",
      "step 76600, change in cost 0.000103951\n",
      "step 76610, training accuracy 0.96748\n",
      "step 76610, cost 5.02961\n",
      "step 76610, change in cost 0.000103951\n",
      "step 76620, training accuracy 0.96748\n",
      "step 76620, cost 5.02951\n",
      "step 76620, change in cost 0.000102997\n",
      "step 76630, training accuracy 0.96748\n",
      "step 76630, cost 5.02941\n",
      "step 76630, change in cost 0.000103951\n",
      "step 76640, training accuracy 0.96748\n",
      "step 76640, cost 5.0293\n",
      "step 76640, change in cost 0.000102997\n",
      "step 76650, training accuracy 0.96748\n",
      "step 76650, cost 5.0292\n",
      "step 76650, change in cost 0.000103951\n",
      "step 76660, training accuracy 0.96748\n",
      "step 76660, cost 5.0291\n",
      "step 76660, change in cost 0.000102997\n",
      "step 76670, training accuracy 0.96748\n",
      "step 76670, cost 5.02899\n",
      "step 76670, change in cost 0.000102997\n",
      "step 76680, training accuracy 0.96748\n",
      "step 76680, cost 5.02889\n",
      "step 76680, change in cost 0.000103951\n",
      "step 76690, training accuracy 0.96748\n",
      "step 76690, cost 5.02879\n",
      "step 76690, change in cost 0.000103951\n",
      "step 76700, training accuracy 0.96748\n",
      "step 76700, cost 5.02868\n",
      "step 76700, change in cost 0.000102997\n",
      "step 76710, training accuracy 0.96748\n",
      "step 76710, cost 5.02858\n",
      "step 76710, change in cost 0.000103951\n",
      "step 76720, training accuracy 0.96748\n",
      "step 76720, cost 5.02848\n",
      "step 76720, change in cost 0.00010252\n",
      "step 76730, training accuracy 0.96748\n",
      "step 76730, cost 5.02837\n",
      "step 76730, change in cost 0.000103474\n",
      "step 76740, training accuracy 0.96748\n",
      "step 76740, cost 5.02827\n",
      "step 76740, change in cost 0.000102997\n",
      "step 76750, training accuracy 0.96748\n",
      "step 76750, cost 5.02817\n",
      "step 76750, change in cost 0.000103951\n",
      "step 76760, training accuracy 0.96748\n",
      "step 76760, cost 5.02806\n",
      "step 76760, change in cost 0.00010252\n",
      "step 76770, training accuracy 0.96748\n",
      "step 76770, cost 5.02796\n",
      "step 76770, change in cost 0.000103474\n",
      "step 76780, training accuracy 0.96748\n",
      "step 76780, cost 5.02786\n",
      "step 76780, change in cost 0.000102997\n",
      "step 76790, training accuracy 0.96748\n",
      "step 76790, cost 5.02775\n",
      "step 76790, change in cost 0.000103951\n",
      "step 76800, training accuracy 0.96748\n",
      "step 76800, cost 5.02765\n",
      "step 76800, change in cost 0.000102997\n",
      "step 76810, training accuracy 0.96748\n",
      "step 76810, cost 5.02755\n",
      "step 76810, change in cost 0.00010252\n",
      "step 76820, training accuracy 0.96748\n",
      "step 76820, cost 5.02744\n",
      "step 76820, change in cost 0.000103951\n",
      "step 76830, training accuracy 0.96748\n",
      "step 76830, cost 5.02734\n",
      "step 76830, change in cost 0.00010252\n",
      "step 76840, training accuracy 0.96748\n",
      "step 76840, cost 5.02724\n",
      "step 76840, change in cost 0.000103951\n",
      "step 76850, training accuracy 0.96748\n",
      "step 76850, cost 5.02713\n",
      "step 76850, change in cost 0.000102043\n",
      "step 76860, training accuracy 0.96748\n",
      "step 76860, cost 5.02703\n",
      "step 76860, change in cost 0.000102997\n",
      "step 76870, training accuracy 0.96748\n",
      "step 76870, cost 5.02693\n",
      "step 76870, change in cost 0.000102997\n",
      "step 76880, training accuracy 0.96748\n",
      "step 76880, cost 5.02683\n",
      "step 76880, change in cost 0.000102043\n",
      "step 76890, training accuracy 0.96748\n",
      "step 76890, cost 5.02672\n",
      "step 76890, change in cost 0.000103951\n",
      "step 76900, training accuracy 0.96748\n",
      "step 76900, cost 5.02662\n",
      "step 76900, change in cost 0.000102997\n",
      "step 76910, training accuracy 0.96748\n",
      "step 76910, cost 5.02652\n",
      "step 76910, change in cost 0.000102997\n",
      "step 76920, training accuracy 0.96748\n",
      "step 76920, cost 5.02641\n",
      "step 76920, change in cost 0.000102997\n",
      "step 76930, training accuracy 0.96748\n",
      "step 76930, cost 5.02631\n",
      "step 76930, change in cost 0.000102997\n",
      "step 76940, training accuracy 0.96748\n",
      "step 76940, cost 5.02621\n",
      "step 76940, change in cost 0.000102997\n",
      "step 76950, training accuracy 0.96748\n",
      "step 76950, cost 5.0261\n",
      "step 76950, change in cost 0.000102997\n",
      "step 76960, training accuracy 0.96748\n",
      "step 76960, cost 5.026\n",
      "step 76960, change in cost 0.000102997\n",
      "step 76970, training accuracy 0.96748\n",
      "step 76970, cost 5.0259\n",
      "step 76970, change in cost 0.000102043\n",
      "step 76980, training accuracy 0.96748\n",
      "step 76980, cost 5.0258\n",
      "step 76980, change in cost 0.000102997\n",
      "step 76990, training accuracy 0.96748\n",
      "step 76990, cost 5.02569\n",
      "step 76990, change in cost 0.000102043\n",
      "step 77000, training accuracy 0.96748\n",
      "step 77000, cost 5.02559\n",
      "step 77000, change in cost 0.000103951\n",
      "step 77010, training accuracy 0.96748\n",
      "step 77010, cost 5.02549\n",
      "step 77010, change in cost 0.000102043\n",
      "step 77020, training accuracy 0.96748\n",
      "step 77020, cost 5.02539\n",
      "step 77020, change in cost 0.000102997\n",
      "step 77030, training accuracy 0.96748\n",
      "step 77030, cost 5.02528\n",
      "step 77030, change in cost 0.000102997\n",
      "step 77040, training accuracy 0.96748\n",
      "step 77040, cost 5.02518\n",
      "step 77040, change in cost 0.000102043\n",
      "step 77050, training accuracy 0.96748\n",
      "step 77050, cost 5.02508\n",
      "step 77050, change in cost 0.000102997\n",
      "step 77060, training accuracy 0.96748\n",
      "step 77060, cost 5.02498\n",
      "step 77060, change in cost 0.000102043\n",
      "step 77070, training accuracy 0.96748\n",
      "step 77070, cost 5.02487\n",
      "step 77070, change in cost 0.000102997\n",
      "step 77080, training accuracy 0.96748\n",
      "step 77080, cost 5.02477\n",
      "step 77080, change in cost 0.000102043\n",
      "step 77090, training accuracy 0.96748\n",
      "step 77090, cost 5.02467\n",
      "step 77090, change in cost 0.000102997\n",
      "step 77100, training accuracy 0.96748\n",
      "step 77100, cost 5.02457\n",
      "step 77100, change in cost 0.000102043\n",
      "step 77110, training accuracy 0.96748\n",
      "step 77110, cost 5.02446\n",
      "step 77110, change in cost 0.000103474\n",
      "step 77120, training accuracy 0.96748\n",
      "step 77120, cost 5.02436\n",
      "step 77120, change in cost 0.000101566\n",
      "step 77130, training accuracy 0.96748\n",
      "step 77130, cost 5.02426\n",
      "step 77130, change in cost 0.000102997\n",
      "step 77140, training accuracy 0.96748\n",
      "step 77140, cost 5.02416\n",
      "step 77140, change in cost 0.000101566\n",
      "step 77150, training accuracy 0.96748\n",
      "step 77150, cost 5.02405\n",
      "step 77150, change in cost 0.000103474\n",
      "step 77160, training accuracy 0.96748\n",
      "step 77160, cost 5.02395\n",
      "step 77160, change in cost 0.000102043\n",
      "step 77170, training accuracy 0.96748\n",
      "step 77170, cost 5.02385\n",
      "step 77170, change in cost 0.000101089\n",
      "step 77180, training accuracy 0.96748\n",
      "step 77180, cost 5.02375\n",
      "step 77180, change in cost 0.000102043\n",
      "step 77190, training accuracy 0.96748\n",
      "step 77190, cost 5.02365\n",
      "step 77190, change in cost 0.000102043\n",
      "step 77200, training accuracy 0.96748\n",
      "step 77200, cost 5.02354\n",
      "step 77200, change in cost 0.000102997\n",
      "step 77210, training accuracy 0.96748\n",
      "step 77210, cost 5.02344\n",
      "step 77210, change in cost 0.00010252\n",
      "step 77220, training accuracy 0.96748\n",
      "step 77220, cost 5.02334\n",
      "step 77220, change in cost 0.00010252\n",
      "step 77230, training accuracy 0.96748\n",
      "step 77230, cost 5.02324\n",
      "step 77230, change in cost 0.000101566\n",
      "step 77240, training accuracy 0.96748\n",
      "step 77240, cost 5.02313\n",
      "step 77240, change in cost 0.00010252\n",
      "step 77250, training accuracy 0.96748\n",
      "step 77250, cost 5.02303\n",
      "step 77250, change in cost 0.000102043\n",
      "step 77260, training accuracy 0.96748\n",
      "step 77260, cost 5.02293\n",
      "step 77260, change in cost 0.000102997\n",
      "step 77270, training accuracy 0.96748\n",
      "step 77270, cost 5.02283\n",
      "step 77270, change in cost 0.000102043\n",
      "step 77280, training accuracy 0.96748\n",
      "step 77280, cost 5.02272\n",
      "step 77280, change in cost 0.000102043\n",
      "step 77290, training accuracy 0.96748\n",
      "step 77290, cost 5.02262\n",
      "step 77290, change in cost 0.000102043\n",
      "step 77300, training accuracy 0.96748\n",
      "step 77300, cost 5.02252\n",
      "step 77300, change in cost 0.000101089\n",
      "step 77310, training accuracy 0.96748\n",
      "step 77310, cost 5.02242\n",
      "step 77310, change in cost 0.000101089\n",
      "step 77320, training accuracy 0.96748\n",
      "step 77320, cost 5.02232\n",
      "step 77320, change in cost 0.000102997\n",
      "step 77330, training accuracy 0.96748\n",
      "step 77330, cost 5.02222\n",
      "step 77330, change in cost 0.000101566\n",
      "step 77340, training accuracy 0.96748\n",
      "step 77340, cost 5.02211\n",
      "step 77340, change in cost 0.00010252\n",
      "step 77350, training accuracy 0.96748\n",
      "step 77350, cost 5.02201\n",
      "step 77350, change in cost 0.000102043\n",
      "step 77360, training accuracy 0.96748\n",
      "step 77360, cost 5.02191\n",
      "step 77360, change in cost 0.000102043\n",
      "step 77370, training accuracy 0.96748\n",
      "step 77370, cost 5.02181\n",
      "step 77370, change in cost 0.000102043\n",
      "step 77380, training accuracy 0.96748\n",
      "step 77380, cost 5.0217\n",
      "step 77380, change in cost 0.000102043\n",
      "step 77390, training accuracy 0.96748\n",
      "step 77390, cost 5.0216\n",
      "step 77390, change in cost 0.000102997\n",
      "step 77400, training accuracy 0.96748\n",
      "step 77400, cost 5.0215\n",
      "step 77400, change in cost 0.000100613\n",
      "step 77410, training accuracy 0.96748\n",
      "step 77410, cost 5.0214\n",
      "step 77410, change in cost 0.000101566\n",
      "step 77420, training accuracy 0.96748\n",
      "step 77420, cost 5.0213\n",
      "step 77420, change in cost 0.000102043\n",
      "step 77430, training accuracy 0.96748\n",
      "step 77430, cost 5.0212\n",
      "step 77430, change in cost 0.000102043\n",
      "step 77440, training accuracy 0.96748\n",
      "step 77440, cost 5.02109\n",
      "step 77440, change in cost 0.000101089\n",
      "step 77450, training accuracy 0.96748\n",
      "step 77450, cost 5.02099\n",
      "step 77450, change in cost 0.000102043\n",
      "step 77460, training accuracy 0.96748\n",
      "step 77460, cost 5.02089\n",
      "step 77460, change in cost 0.000101089\n",
      "step 77470, training accuracy 0.96748\n",
      "step 77470, cost 5.02079\n",
      "step 77470, change in cost 0.000101566\n",
      "step 77480, training accuracy 0.96748\n",
      "step 77480, cost 5.02069\n",
      "step 77480, change in cost 0.000101089\n",
      "step 77490, training accuracy 0.96748\n",
      "step 77490, cost 5.02059\n",
      "step 77490, change in cost 0.000102997\n",
      "step 77500, training accuracy 0.96748\n",
      "step 77500, cost 5.02048\n",
      "step 77500, change in cost 0.000102043\n",
      "step 77510, training accuracy 0.96748\n",
      "step 77510, cost 5.02038\n",
      "step 77510, change in cost 0.000100136\n",
      "step 77520, training accuracy 0.96748\n",
      "step 77520, cost 5.02028\n",
      "step 77520, change in cost 0.000102043\n",
      "step 77530, training accuracy 0.96748\n",
      "step 77530, cost 5.02018\n",
      "step 77530, change in cost 0.000101566\n",
      "step 77540, training accuracy 0.96748\n",
      "step 77540, cost 5.02008\n",
      "step 77540, change in cost 0.000102043\n",
      "step 77550, training accuracy 0.96748\n",
      "step 77550, cost 5.01998\n",
      "step 77550, change in cost 0.000102043\n",
      "step 77560, training accuracy 0.96748\n",
      "step 77560, cost 5.01988\n",
      "step 77560, change in cost 0.000100136\n",
      "step 77570, training accuracy 0.96748\n",
      "step 77570, cost 5.01977\n",
      "step 77570, change in cost 0.000101566\n",
      "step 77580, training accuracy 0.96748\n",
      "step 77580, cost 5.01967\n",
      "step 77580, change in cost 0.000101089\n",
      "step 77590, training accuracy 0.96748\n",
      "step 77590, cost 5.01957\n",
      "step 77590, change in cost 0.000101089\n",
      "step 77600, training accuracy 0.96748\n",
      "step 77600, cost 5.01947\n",
      "step 77600, change in cost 0.00010252\n",
      "step 77610, training accuracy 0.96748\n",
      "step 77610, cost 5.01937\n",
      "step 77610, change in cost 0.000100136\n",
      "step 77620, training accuracy 0.96748\n",
      "step 77620, cost 5.01927\n",
      "step 77620, change in cost 0.000102043\n",
      "step 77630, training accuracy 0.96748\n",
      "step 77630, cost 5.01917\n",
      "step 77630, change in cost 0.000102043\n",
      "step 77640, training accuracy 0.96748\n",
      "step 77640, cost 5.01906\n",
      "step 77640, change in cost 0.000100136\n",
      "step 77650, training accuracy 0.96748\n",
      "step 77650, cost 5.01896\n",
      "step 77650, change in cost 0.000101566\n",
      "step 77660, training accuracy 0.96748\n",
      "step 77660, cost 5.01886\n",
      "step 77660, change in cost 0.000101566\n",
      "step 77670, training accuracy 0.96748\n",
      "step 77670, cost 5.01876\n",
      "step 77670, change in cost 9.9659e-05\n",
      "change in cost 9.9659e-05; convergence.\n"
     ]
    }
   ],
   "source": [
    "# tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(Y,1))\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "\n",
    "\n",
    "cost = 0\n",
    "diff = 1\n",
    "epoch_values=[]\n",
    "accuracy_values=[]\n",
    "cost_values=[]\n",
    "\n",
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "        break\n",
    "    else:\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={X: X_train, Y: y_train})\n",
    "        # Report occasional stats\n",
    "        if i % 10 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            train_accuracy, newCost = sess.run(\n",
    "                [accuracy_OP, cost_OP], \n",
    "                feed_dict={X: X_train, Y: y_train}\n",
    "            )\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            \n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            print(\"step %d, cost %g\"%(i, newCost))\n",
    "            print(\"step %d, change in cost %g\"%(i, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy on test set: 0.870968\n"
     ]
    }
   ],
   "source": [
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={X: X_test, \n",
    "                                                                Y: y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
